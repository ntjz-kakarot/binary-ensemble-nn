{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bda5d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "0.16.0\n",
      "0.9.1\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "print(torchvision.__version__)\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import brevitas\n",
    "from brevitas.nn import QuantLinear\n",
    "from brevitas.core.quant.binary import ClampedBinaryQuant\n",
    "from brevitas.core.scaling import ConstScaling\n",
    "from brevitas.core.quant import QuantType\n",
    "print(brevitas.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af5ff2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR-10\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb38195",
   "metadata": {},
   "source": [
    "# Network Architectures\n",
    "\n",
    "## Simple BNN vs. Real-Valued DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eb46fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-valued DNN with a single layer\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(32 * 32 * 3, 10)  # For CIFAR-10\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 32 * 32 * 3)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "class BNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BNN, self).__init__()\n",
    "        \n",
    "        # Use predefined BINARY weight quant type\n",
    "        self.fc1 = QuantLinear(\n",
    "            32 * 32 * 3, \n",
    "            10, \n",
    "            bias=True, \n",
    "            weight_quant_type=QuantType.BINARY)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 32 * 32 * 3)\n",
    "        x = self.fc1(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "344f2f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model = DNN()\n",
    "bnn_model = BNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "197dc458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Linear: 1-1                            30,730\n",
      "=================================================================\n",
      "Total params: 30,730\n",
      "Trainable params: 30,730\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "30730\n",
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "├─QuantLinear: 1-1                                      --\n",
      "|    └─ActQuantProxyFromInjector: 2-1                   --\n",
      "|    |    └─StatelessBuffer: 3-1                        --\n",
      "|    └─ActQuantProxyFromInjector: 2-2                   --\n",
      "|    |    └─StatelessBuffer: 3-2                        --\n",
      "|    └─WeightQuantProxyFromInjector: 2-3                --\n",
      "|    |    └─StatelessBuffer: 3-3                        --\n",
      "|    |    └─BinaryQuant: 3-4                            30,720\n",
      "|    └─BiasQuantProxyFromInjector: 2-4                  --\n",
      "|    |    └─StatelessBuffer: 3-5                        --\n",
      "================================================================================\n",
      "Total params: 30,720\n",
      "Trainable params: 30,720\n",
      "Non-trainable params: 0\n",
      "================================================================================\n",
      "30720\n"
     ]
    }
   ],
   "source": [
    "print(summary(dnn_model).trainable_params)\n",
    "print(summary(bnn_model).trainable_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07702b6",
   "metadata": {},
   "source": [
    "## XNOR NIN vs. Real-Valued NIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01b3105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BinActive(torch.autograd.Function):\n",
    "    '''\n",
    "    Binarize the input activations and calculate the mean across channel dimension.\n",
    "    '''\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        size = input.size()\n",
    "        mean = torch.mean(input.abs(), 1, keepdim=True)\n",
    "        input = input.sign()\n",
    "        return input, mean\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output, grad_output_mean):\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input[input.ge(1)] = 0\n",
    "        grad_input[input.le(-1)] = 0\n",
    "        return grad_input\n",
    "\n",
    "\n",
    "class BinConv2d(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels,\n",
    "            kernel_size=-1, stride=-1, padding=-1, dropout=0):\n",
    "        super(BinConv2d, self).__init__()\n",
    "        self.layer_type = 'BinConv2d'\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dropout_ratio = dropout\n",
    "\n",
    "        self.bn = nn.BatchNorm2d(input_channels, eps=1e-4, momentum=0.1, affine=True)\n",
    "        self.bn.weight.data = self.bn.weight.data.zero_().add(1.0)\n",
    "        if dropout!=0:\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "        self.conv = nn.Conv2d(input_channels, output_channels,\n",
    "                kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.bn(x)\n",
    "        x, mean = BinActive.apply(x)\n",
    "        if self.dropout_ratio!=0:\n",
    "            x = self.dropout(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "# XNOR NIN\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.xnor = nn.Sequential(\n",
    "                nn.Conv2d(3, 192, kernel_size=5, stride=1, padding=2),\n",
    "                nn.BatchNorm2d(192, eps=1e-4, momentum=0.1, affine=False),\n",
    "                nn.ReLU(inplace=True),\n",
    "                BinConv2d(192, 160, kernel_size=1, stride=1, padding=0),\n",
    "                BinConv2d(160,  96, kernel_size=1, stride=1, padding=0),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "\n",
    "                BinConv2d( 96, 192, kernel_size=5, stride=1, padding=2, dropout=0.5),\n",
    "                BinConv2d(192, 192, kernel_size=1, stride=1, padding=0),\n",
    "                BinConv2d(192, 192, kernel_size=1, stride=1, padding=0),\n",
    "                nn.AvgPool2d(kernel_size=3, stride=2, padding=1),\n",
    "\n",
    "                BinConv2d(192, 192, kernel_size=3, stride=1, padding=1, dropout=0.5),\n",
    "                BinConv2d(192, 192, kernel_size=1, stride=1, padding=0),\n",
    "                nn.BatchNorm2d(192, eps=1e-4, momentum=0.1, affine=False),\n",
    "                nn.Conv2d(192,  10, kernel_size=1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.AvgPool2d(kernel_size=8, stride=1, padding=0),\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):\n",
    "                if hasattr(m.weight, 'data'):\n",
    "                    m.weight.data.clamp_(min=0.01)\n",
    "        x = self.xnor(x)\n",
    "        x = x.view(x.size(0), 10)\n",
    "        return x\n",
    "    \n",
    "# Real NIN\n",
    "class RealNIN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RealNIN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "                nn.Conv2d(3, 192, kernel_size=5, stride=1, padding=2),\n",
    "                nn.BatchNorm2d(192, eps=1e-4, momentum=0.1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(192, 160, kernel_size=1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(160,  96, kernel_size=1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "\n",
    "                nn.Conv2d(96, 192, kernel_size=5, stride=1, padding=2),\n",
    "                nn.BatchNorm2d(192, eps=1e-4, momentum=0.1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(192, 192, kernel_size=1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(192, 192, kernel_size=1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.AvgPool2d(kernel_size=3, stride=2, padding=1),\n",
    "\n",
    "                nn.Conv2d(192, 192, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(192, eps=1e-4, momentum=0.1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(192, 192, kernel_size=1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(192,  10, kernel_size=1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.AdaptiveAvgPool2d(1)\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        x = x.view(x.size(0), 10)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3959784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nin = Net()\n",
    "model_real_nin = RealNIN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "718373be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Sequential: 1-1                        --\n",
      "|    └─Conv2d: 2-1                       14,592\n",
      "|    └─BatchNorm2d: 2-2                  --\n",
      "|    └─ReLU: 2-3                         --\n",
      "|    └─BinConv2d: 2-4                    --\n",
      "|    |    └─BatchNorm2d: 3-1             384\n",
      "|    |    └─Conv2d: 3-2                  30,880\n",
      "|    |    └─ReLU: 3-3                    --\n",
      "|    └─BinConv2d: 2-5                    --\n",
      "|    |    └─BatchNorm2d: 3-4             320\n",
      "|    |    └─Conv2d: 3-5                  15,456\n",
      "|    |    └─ReLU: 3-6                    --\n",
      "|    └─MaxPool2d: 2-6                    --\n",
      "|    └─BinConv2d: 2-7                    --\n",
      "|    |    └─BatchNorm2d: 3-7             192\n",
      "|    |    └─Dropout: 3-8                 --\n",
      "|    |    └─Conv2d: 3-9                  460,992\n",
      "|    |    └─ReLU: 3-10                   --\n",
      "|    └─BinConv2d: 2-8                    --\n",
      "|    |    └─BatchNorm2d: 3-11            384\n",
      "|    |    └─Conv2d: 3-12                 37,056\n",
      "|    |    └─ReLU: 3-13                   --\n",
      "|    └─BinConv2d: 2-9                    --\n",
      "|    |    └─BatchNorm2d: 3-14            384\n",
      "|    |    └─Conv2d: 3-15                 37,056\n",
      "|    |    └─ReLU: 3-16                   --\n",
      "|    └─AvgPool2d: 2-10                   --\n",
      "|    └─BinConv2d: 2-11                   --\n",
      "|    |    └─BatchNorm2d: 3-17            384\n",
      "|    |    └─Dropout: 3-18                --\n",
      "|    |    └─Conv2d: 3-19                 331,968\n",
      "|    |    └─ReLU: 3-20                   --\n",
      "|    └─BinConv2d: 2-12                   --\n",
      "|    |    └─BatchNorm2d: 3-21            384\n",
      "|    |    └─Conv2d: 3-22                 37,056\n",
      "|    |    └─ReLU: 3-23                   --\n",
      "|    └─BatchNorm2d: 2-13                 --\n",
      "|    └─Conv2d: 2-14                      1,930\n",
      "|    └─ReLU: 2-15                        --\n",
      "|    └─AvgPool2d: 2-16                   --\n",
      "=================================================================\n",
      "Total params: 969,418\n",
      "Trainable params: 969,418\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "969418\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Sequential: 1-1                        --\n",
      "|    └─Conv2d: 2-1                       14,592\n",
      "|    └─BatchNorm2d: 2-2                  384\n",
      "|    └─ReLU: 2-3                         --\n",
      "|    └─Conv2d: 2-4                       30,880\n",
      "|    └─ReLU: 2-5                         --\n",
      "|    └─Conv2d: 2-6                       15,456\n",
      "|    └─ReLU: 2-7                         --\n",
      "|    └─MaxPool2d: 2-8                    --\n",
      "|    └─Conv2d: 2-9                       460,992\n",
      "|    └─BatchNorm2d: 2-10                 384\n",
      "|    └─ReLU: 2-11                        --\n",
      "|    └─Conv2d: 2-12                      37,056\n",
      "|    └─ReLU: 2-13                        --\n",
      "|    └─Conv2d: 2-14                      37,056\n",
      "|    └─ReLU: 2-15                        --\n",
      "|    └─AvgPool2d: 2-16                   --\n",
      "|    └─Conv2d: 2-17                      331,968\n",
      "|    └─BatchNorm2d: 2-18                 384\n",
      "|    └─ReLU: 2-19                        --\n",
      "|    └─Conv2d: 2-20                      37,056\n",
      "|    └─ReLU: 2-21                        --\n",
      "|    └─Conv2d: 2-22                      1,930\n",
      "|    └─ReLU: 2-23                        --\n",
      "|    └─AdaptiveAvgPool2d: 2-24           --\n",
      "=================================================================\n",
      "Total params: 968,138\n",
      "Trainable params: 968,138\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "968138\n"
     ]
    }
   ],
   "source": [
    "print(summary(model_nin).trainable_params)\n",
    "print(summary(model_real_nin).trainable_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff4be05",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "## BNN vs. RDNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9130f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.154309051605463\n",
      "Epoch 2, Loss: 2.1049341724646093\n",
      "Epoch 3, Loss: 2.0855155343353746\n",
      "Epoch 4, Loss: 2.075864036922455\n",
      "Epoch 5, Loss: 2.066716543700695\n",
      "Epoch 6, Loss: 2.061993913832903\n",
      "Epoch 7, Loss: 2.0530951206195356\n",
      "Epoch 8, Loss: 2.046263520656824\n",
      "Epoch 9, Loss: 2.0302124366790055\n",
      "Epoch 10, Loss: 2.0334975581109522\n",
      "Finished Training\n",
      "Epoch 1, Loss: 2.1836362445765736\n",
      "Epoch 2, Loss: 2.165489381093979\n",
      "Epoch 3, Loss: 2.2206116836598517\n",
      "Epoch 4, Loss: 2.193145127355009\n",
      "Epoch 5, Loss: 2.267161365763396\n",
      "Epoch 6, Loss: 2.2126669481050967\n",
      "Epoch 7, Loss: 2.2651475597362967\n",
      "Epoch 8, Loss: 2.228112700407803\n",
      "Epoch 9, Loss: 2.2825963844022157\n",
      "Epoch 10, Loss: 2.2447486337159575\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "def train(model, dataloader, criterion, optimizer, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss / len(dataloader)}\")\n",
    "    print('Finished Training')\n",
    "\n",
    "# Train the real-valued DNN\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(dnn_model.parameters(), lr=0.001, momentum=0.9)\n",
    "train(dnn_model, trainloader, criterion, optimizer)\n",
    "\n",
    "# Train the BNN\n",
    "optimizer_bnn = optim.SGD(bnn_model.parameters(), lr=0.001, momentum=0.9)\n",
    "train(bnn_model, trainloader, criterion, optimizer_bnn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eba1d52",
   "metadata": {},
   "source": [
    "## NIN vs. Real NIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4847e4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.3026707262802124\n",
      "Epoch 2, Loss: 2.3025851249694824\n",
      "Epoch 3, Loss: 2.3025851249694824\n",
      "Epoch 4, Loss: 2.3025851249694824\n",
      "Epoch 5, Loss: 2.3025851249694824\n",
      "Epoch 6, Loss: 2.3025851249694824\n",
      "Epoch 7, Loss: 2.3025851249694824\n",
      "Epoch 8, Loss: 2.3025851249694824\n",
      "Epoch 9, Loss: 2.3025851249694824\n",
      "Epoch 10, Loss: 2.3025851249694824\n",
      "Finished Training\n",
      "Epoch 1, Loss: 2.3027420357322694\n",
      "Epoch 2, Loss: 2.302663890571594\n",
      "Epoch 3, Loss: 2.3026093805122376\n",
      "Epoch 4, Loss: 2.3025438442611694\n",
      "Epoch 5, Loss: 2.302365941066742\n",
      "Epoch 6, Loss: 2.2497773061943054\n",
      "Epoch 7, Loss: 2.0179050044202804\n",
      "Epoch 8, Loss: 1.9382286017131805\n",
      "Epoch 9, Loss: 1.8031506101131438\n",
      "Epoch 10, Loss: 1.681749998474121\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "def train(model, dataloader, criterion, optimizer, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss / len(dataloader)}\")\n",
    "    print('Finished Training')\n",
    "\n",
    "# Train the real-valued NIN\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_real_nin.parameters(), lr=0.001, momentum=0.9)\n",
    "train(model_real_nin, trainloader, criterion, optimizer)\n",
    "\n",
    "# Train the B-NIN\n",
    "optimizer_bnn = optim.SGD(model_nin.parameters(), lr=0.001, momentum=0.9)\n",
    "train(model_nin, trainloader, criterion, optimizer_bnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dae0d48",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "282e6324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN Accuracy on test set: 33.82%\n",
      "BNN Accuracy on test set: 33.08%\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "dnn_accuracy = evaluate(dnn_model, testloader)\n",
    "bnn_accuracy = evaluate(bnn_model, testloader)\n",
    "\n",
    "print(f'DNN Accuracy on test set: {dnn_accuracy}%')\n",
    "print(f'BNN Accuracy on test set: {bnn_accuracy}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bae0f4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-NIN Accuracy on test set: 10.0%\n",
      "B-NIN Accuracy on test set: 41.03%\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "r_nin_accuracy = evaluate(model_real_nin, testloader)\n",
    "b_nin_accuracy = evaluate(model_nin, testloader)\n",
    "\n",
    "print(f'R-NIN Accuracy on test set: {r_nin_accuracy}%')\n",
    "print(f'B-NIN Accuracy on test set: {b_nin_accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa5f2d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
