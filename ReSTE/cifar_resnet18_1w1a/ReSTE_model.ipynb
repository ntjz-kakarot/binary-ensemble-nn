{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hd0yrX6CJa8W",
        "outputId": "d0ee4813-9301-4461-c6f4-bcf25c70448f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ReSTE'...\n",
            "remote: Enumerating objects: 106, done.\u001b[K\n",
            "remote: Counting objects: 100% (106/106), done.\u001b[K\n",
            "remote: Compressing objects: 100% (81/81), done.\u001b[K\n",
            "remote: Total 106 (delta 36), reused 93 (delta 23), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (106/106), 208.84 KiB | 1.47 MiB/s, done.\n",
            "Resolving deltas: 100% (36/36), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/DravenALG/ReSTE.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ReSTE/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lhxFjxBJu-0",
        "outputId": "4d77ad63-087d-4ccd-f4aa-ddf52e35aaf3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset  figures  main.py  model  README.md  utils\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python ReSTE/main.py --gpus 0 --model resnet18_1w1a --results_dir ./cifar_resnet18_1w1a --data_path [DATA_PATH] --dataset cifar10 --epochs 1000 --lr 0.1 -b 256 -bt 128 --estimator ReSTE --o_end 3 --warm_up"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKQ7BJ6SJ_6M",
        "outputId": "7034a61a-2539-4670-8256-a205c1961fbb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Training loss 0.0768 \tTraining Prec@1 97.280 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.6044 \tValidation Prec@1 86.410 \tValidation Prec@5 99.350 \n",
            "\n",
            "lr: 0.04370993517029616\n",
            "o is 1.6915740966796875,  o_a is 1.6915740966796875\n",
            "TRAINING - Epoch: [546][0/196]\tTime 2.846 (2.846)\tData 1.436 (1.436)\tloss 0.0821 (0.0821)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [546][100/196]\tTime 0.374 (0.414)\tData 0.000 (0.015)\tloss 0.1035 (0.0824)\tPrec@1 96.875 (97.061)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [546][0/79]\tTime 0.879 (0.879)\tData 0.682 (0.682)\tloss 0.2671 (0.2671)\tPrec@1 89.062 (89.062)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:23\tTime of Finish: 2023-11-27 09:52:03\n",
            "\n",
            " Epoch: 547\n",
            "Training loss 0.0806 \tTraining Prec@1 97.148 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5518 \tValidation Prec@1 87.440 \tValidation Prec@5 99.340 \n",
            "\n",
            "lr: 0.04355350400676058\n",
            "o is 1.6939516067504883,  o_a is 1.6939516067504883\n",
            "TRAINING - Epoch: [547][0/196]\tTime 1.734 (1.734)\tData 0.896 (0.896)\tloss 0.0575 (0.0575)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [547][100/196]\tTime 0.445 (0.405)\tData 0.000 (0.010)\tloss 0.0803 (0.0790)\tPrec@1 96.875 (97.150)\tPrec@5 100.000 (99.988)\n",
            "EVALUATING - Epoch: [547][0/79]\tTime 0.429 (0.429)\tData 0.315 (0.315)\tloss 0.3924 (0.3924)\tPrec@1 88.281 (88.281)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:38:48\n",
            "\n",
            " Epoch: 548\n",
            "Training loss 0.0800 \tTraining Prec@1 97.120 \tTraining Prec@5 99.990 \n",
            "Validation loss 0.5298 \tValidation Prec@1 87.430 \tValidation Prec@5 99.490 \n",
            "\n",
            "lr: 0.04339713699816217\n",
            "o is 1.696332573890686,  o_a is 1.696332573890686\n",
            "TRAINING - Epoch: [548][0/196]\tTime 1.808 (1.808)\tData 0.940 (0.940)\tloss 0.0521 (0.0521)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [548][100/196]\tTime 0.369 (0.411)\tData 0.000 (0.010)\tloss 0.0495 (0.0781)\tPrec@1 97.656 (97.215)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [548][0/79]\tTime 0.414 (0.414)\tData 0.297 (0.297)\tloss 0.2335 (0.2335)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:46:24\n",
            "\n",
            " Epoch: 549\n",
            "Training loss 0.0786 \tTraining Prec@1 97.136 \tTraining Prec@5 99.996 \n",
            "Validation loss 0.5156 \tValidation Prec@1 87.720 \tValidation Prec@5 99.560 \n",
            "\n",
            "lr: 0.04324083570020084\n",
            "o is 1.6987167596817017,  o_a is 1.6987167596817017\n",
            "TRAINING - Epoch: [549][0/196]\tTime 2.862 (2.862)\tData 1.529 (1.529)\tloss 0.0419 (0.0419)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [549][100/196]\tTime 0.369 (0.412)\tData 0.000 (0.016)\tloss 0.0599 (0.0747)\tPrec@1 98.047 (97.324)\tPrec@5 100.000 (99.988)\n",
            "EVALUATING - Epoch: [549][0/79]\tTime 0.906 (0.906)\tData 0.715 (0.715)\tloss 0.2999 (0.2999)\tPrec@1 89.062 (89.062)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:23\tTime of Finish: 2023-11-27 09:50:39\n",
            "\n",
            " Epoch: 550\n",
            "Training loss 0.0742 \tTraining Prec@1 97.390 \tTraining Prec@5 99.994 \n",
            "Validation loss 0.4958 \tValidation Prec@1 87.910 \tValidation Prec@5 99.530 \n",
            "\n",
            "lr: 0.043084601667922814\n",
            "o is 1.7011040449142456,  o_a is 1.7011040449142456\n",
            "TRAINING - Epoch: [550][0/196]\tTime 1.722 (1.722)\tData 0.828 (0.828)\tloss 0.0716 (0.0716)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [550][100/196]\tTime 0.446 (0.405)\tData 0.003 (0.009)\tloss 0.0784 (0.0796)\tPrec@1 96.484 (97.099)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [550][0/79]\tTime 0.494 (0.494)\tData 0.357 (0.357)\tloss 0.2298 (0.2298)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:37:47\n",
            "\n",
            " Epoch: 551\n",
            "Training loss 0.0799 \tTraining Prec@1 97.144 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5425 \tValidation Prec@1 87.740 \tValidation Prec@5 99.480 \n",
            "\n",
            "lr: 0.04292843645570503\n",
            "o is 1.7034944295883179,  o_a is 1.7034944295883179\n",
            "TRAINING - Epoch: [551][0/196]\tTime 1.608 (1.608)\tData 0.695 (0.695)\tloss 0.0797 (0.0797)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [551][100/196]\tTime 0.371 (0.409)\tData 0.000 (0.008)\tloss 0.0572 (0.0826)\tPrec@1 98.047 (96.999)\tPrec@5 100.000 (99.988)\n",
            "EVALUATING - Epoch: [551][0/79]\tTime 0.375 (0.375)\tData 0.248 (0.248)\tloss 0.3713 (0.3713)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:45:09\n",
            "\n",
            " Epoch: 552\n",
            "Training loss 0.0867 \tTraining Prec@1 96.928 \tTraining Prec@5 99.982 \n",
            "Validation loss 0.5071 \tValidation Prec@1 87.840 \tValidation Prec@5 99.610 \n",
            "\n",
            "lr: 0.042772341617239744\n",
            "o is 1.705888032913208,  o_a is 1.705888032913208\n",
            "TRAINING - Epoch: [552][0/196]\tTime 3.077 (3.077)\tData 1.561 (1.561)\tloss 0.0553 (0.0553)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [552][100/196]\tTime 0.371 (0.420)\tData 0.000 (0.016)\tloss 0.1258 (0.0845)\tPrec@1 94.922 (97.057)\tPrec@5 100.000 (99.992)\n",
            "EVALUATING - Epoch: [552][0/79]\tTime 0.848 (0.848)\tData 0.652 (0.652)\tloss 0.3389 (0.3389)\tPrec@1 89.062 (89.062)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:24\tTime of Finish: 2023-11-27 10:00:30\n",
            "\n",
            " Epoch: 553\n",
            "Training loss 0.0812 \tTraining Prec@1 97.148 \tTraining Prec@5 99.994 \n",
            "Validation loss 0.5362 \tValidation Prec@1 87.260 \tValidation Prec@5 99.480 \n",
            "\n",
            "lr: 0.042616318705519095\n",
            "o is 1.7082849740982056,  o_a is 1.7082849740982056\n",
            "TRAINING - Epoch: [553][0/196]\tTime 1.765 (1.765)\tData 0.926 (0.926)\tloss 0.0352 (0.0352)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [553][100/196]\tTime 0.432 (0.401)\tData 0.000 (0.010)\tloss 0.0738 (0.0739)\tPrec@1 97.266 (97.440)\tPrec@5 100.000 (99.992)\n",
            "EVALUATING - Epoch: [553][0/79]\tTime 0.468 (0.468)\tData 0.392 (0.392)\tloss 0.3084 (0.3084)\tPrec@1 89.844 (89.844)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:33:25\n",
            "\n",
            " Epoch: 554\n",
            "Training loss 0.0758 \tTraining Prec@1 97.338 \tTraining Prec@5 99.996 \n",
            "Validation loss 0.5263 \tValidation Prec@1 87.860 \tValidation Prec@5 99.480 \n",
            "\n",
            "lr: 0.04246036927281959\n",
            "o is 1.7106850147247314,  o_a is 1.7106850147247314\n",
            "TRAINING - Epoch: [554][0/196]\tTime 1.658 (1.658)\tData 0.520 (0.520)\tloss 0.0840 (0.0840)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [554][100/196]\tTime 0.432 (0.410)\tData 0.000 (0.006)\tloss 0.0925 (0.0793)\tPrec@1 96.484 (97.184)\tPrec@5 100.000 (99.988)\n",
            "EVALUATING - Epoch: [554][0/79]\tTime 0.360 (0.360)\tData 0.269 (0.269)\tloss 0.2623 (0.2623)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:41:32\n",
            "\n",
            " Epoch: 555\n",
            "Training loss 0.0770 \tTraining Prec@1 97.274 \tTraining Prec@5 99.994 \n",
            "Validation loss 0.5146 \tValidation Prec@1 88.350 \tValidation Prec@5 99.590 \n",
            "\n",
            "lr: 0.0423044948706867\n",
            "o is 1.7130883932113647,  o_a is 1.7130883932113647\n",
            "TRAINING - Epoch: [555][0/196]\tTime 2.700 (2.700)\tData 1.305 (1.305)\tloss 0.0464 (0.0464)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [555][100/196]\tTime 0.368 (0.417)\tData 0.000 (0.014)\tloss 0.0560 (0.0729)\tPrec@1 98.047 (97.405)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [555][0/79]\tTime 0.618 (0.618)\tData 0.438 (0.438)\tloss 0.5165 (0.5165)\tPrec@1 86.719 (86.719)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:24\tTime of Finish: 2023-11-27 10:00:46\n",
            "\n",
            " Epoch: 556\n",
            "Training loss 0.0760 \tTraining Prec@1 97.300 \tTraining Prec@5 99.996 \n",
            "Validation loss 0.5949 \tValidation Prec@1 86.340 \tValidation Prec@5 99.440 \n",
            "\n",
            "lr: 0.042148697049919415\n",
            "o is 1.7154947519302368,  o_a is 1.7154947519302368\n",
            "TRAINING - Epoch: [556][0/196]\tTime 1.960 (1.960)\tData 1.018 (1.018)\tloss 0.0839 (0.0839)\tPrec@1 95.703 (95.703)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [556][100/196]\tTime 0.372 (0.405)\tData 0.000 (0.011)\tloss 0.0543 (0.0759)\tPrec@1 97.656 (97.277)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [556][0/79]\tTime 0.768 (0.768)\tData 0.575 (0.575)\tloss 0.3794 (0.3794)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:42:22\n",
            "\n",
            " Epoch: 557\n",
            "Training loss 0.0756 \tTraining Prec@1 97.296 \tTraining Prec@5 99.990 \n",
            "Validation loss 0.5800 \tValidation Prec@1 86.830 \tValidation Prec@5 99.460 \n",
            "\n",
            "lr: 0.041992977360554816\n",
            "o is 1.7179042100906372,  o_a is 1.7179042100906372\n",
            "TRAINING - Epoch: [557][0/196]\tTime 1.784 (1.784)\tData 0.916 (0.916)\tloss 0.0660 (0.0660)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [557][100/196]\tTime 0.391 (0.406)\tData 0.000 (0.010)\tloss 0.0631 (0.0767)\tPrec@1 97.656 (97.273)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [557][0/79]\tTime 0.238 (0.238)\tData 0.185 (0.185)\tloss 0.5529 (0.5529)\tPrec@1 85.938 (85.938)\tPrec@5 98.438 (98.438)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:38:38\n",
            "\n",
            " Epoch: 558\n",
            "Training loss 0.0773 \tTraining Prec@1 97.248 \tTraining Prec@5 99.994 \n",
            "Validation loss 0.5635 \tValidation Prec@1 86.960 \tValidation Prec@5 99.430 \n",
            "\n",
            "lr: 0.04183733735185263\n",
            "o is 1.7203171253204346,  o_a is 1.7203171253204346\n",
            "TRAINING - Epoch: [558][0/196]\tTime 1.662 (1.662)\tData 0.607 (0.607)\tloss 0.0842 (0.0842)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [558][100/196]\tTime 0.368 (0.409)\tData 0.000 (0.007)\tloss 0.0794 (0.0776)\tPrec@1 97.266 (97.304)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [558][0/79]\tTime 0.587 (0.587)\tData 0.467 (0.467)\tloss 0.4455 (0.4455)\tPrec@1 89.844 (89.844)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:41:19\n",
            "\n",
            " Epoch: 559\n",
            "Training loss 0.0789 \tTraining Prec@1 97.278 \tTraining Prec@5 99.990 \n",
            "Validation loss 0.5301 \tValidation Prec@1 87.200 \tValidation Prec@5 99.510 \n",
            "\n",
            "lr: 0.0416817785722799\n",
            "o is 1.7227330207824707,  o_a is 1.7227330207824707\n",
            "TRAINING - Epoch: [559][0/196]\tTime 2.854 (2.854)\tData 1.467 (1.467)\tloss 0.0417 (0.0417)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [559][100/196]\tTime 0.370 (0.414)\tData 0.000 (0.015)\tloss 0.0536 (0.0865)\tPrec@1 98.438 (96.948)\tPrec@5 100.000 (99.992)\n",
            "EVALUATING - Epoch: [559][0/79]\tTime 0.833 (0.833)\tData 0.594 (0.594)\tloss 0.2403 (0.2403)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:23\tTime of Finish: 2023-11-27 09:52:19\n",
            "\n",
            " Epoch: 560\n",
            "Training loss 0.0785 \tTraining Prec@1 97.218 \tTraining Prec@5 99.992 \n",
            "Validation loss 0.4718 \tValidation Prec@1 88.740 \tValidation Prec@5 99.610 \n",
            "\n",
            "lr: 0.041526302569495424\n",
            "o is 1.7251520156860352,  o_a is 1.7251520156860352\n",
            "TRAINING - Epoch: [560][0/196]\tTime 1.761 (1.761)\tData 0.939 (0.939)\tloss 0.0533 (0.0533)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [560][100/196]\tTime 0.443 (0.404)\tData 0.006 (0.010)\tloss 0.0937 (0.0754)\tPrec@1 95.312 (97.386)\tPrec@5 100.000 (99.988)\n",
            "EVALUATING - Epoch: [560][0/79]\tTime 0.470 (0.470)\tData 0.340 (0.340)\tloss 0.3871 (0.3871)\tPrec@1 90.625 (90.625)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:36:36\n",
            "\n",
            " Epoch: 561\n",
            "Training loss 0.0789 \tTraining Prec@1 97.242 \tTraining Prec@5 99.994 \n",
            "Validation loss 0.5405 \tValidation Prec@1 87.300 \tValidation Prec@5 99.550 \n",
            "\n",
            "lr: 0.04137091089033456\n",
            "o is 1.7275742292404175,  o_a is 1.7275742292404175\n",
            "TRAINING - Epoch: [561][0/196]\tTime 1.804 (1.804)\tData 0.942 (0.942)\tloss 0.0931 (0.0931)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [561][100/196]\tTime 0.367 (0.410)\tData 0.000 (0.010)\tloss 0.0520 (0.0813)\tPrec@1 98.047 (97.080)\tPrec@5 100.000 (99.988)\n",
            "EVALUATING - Epoch: [561][0/79]\tTime 0.508 (0.508)\tData 0.393 (0.393)\tloss 0.4572 (0.4572)\tPrec@1 89.062 (89.062)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:42:13\n",
            "\n",
            " Epoch: 562\n",
            "Training loss 0.0809 \tTraining Prec@1 97.114 \tTraining Prec@5 99.990 \n",
            "Validation loss 0.5063 \tValidation Prec@1 87.710 \tValidation Prec@5 99.590 \n",
            "\n",
            "lr: 0.04121560508079362\n",
            "o is 1.7299995422363281,  o_a is 1.7299995422363281\n",
            "TRAINING - Epoch: [562][0/196]\tTime 2.802 (2.802)\tData 1.354 (1.354)\tloss 0.0853 (0.0853)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [562][100/196]\tTime 0.368 (0.412)\tData 0.001 (0.014)\tloss 0.0975 (0.0766)\tPrec@1 95.312 (97.246)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [562][0/79]\tTime 0.810 (0.810)\tData 0.606 (0.606)\tloss 0.3399 (0.3399)\tPrec@1 89.062 (89.062)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:23\tTime of Finish: 2023-11-27 09:50:05\n",
            "\n",
            " Epoch: 563\n",
            "Training loss 0.0782 \tTraining Prec@1 97.218 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5315 \tValidation Prec@1 87.290 \tValidation Prec@5 99.490 \n",
            "\n",
            "lr: 0.04106038668601466\n",
            "o is 1.7324281930923462,  o_a is 1.7324281930923462\n",
            "TRAINING - Epoch: [563][0/196]\tTime 1.727 (1.727)\tData 0.877 (0.877)\tloss 0.0651 (0.0651)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [563][100/196]\tTime 0.445 (0.402)\tData 0.005 (0.009)\tloss 0.0817 (0.0758)\tPrec@1 97.266 (97.328)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [563][0/79]\tTime 0.519 (0.519)\tData 0.402 (0.402)\tloss 0.4444 (0.4444)\tPrec@1 88.281 (88.281)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:34:18\n",
            "\n",
            " Epoch: 564\n",
            "Training loss 0.0784 \tTraining Prec@1 97.240 \tTraining Prec@5 99.996 \n",
            "Validation loss 0.5769 \tValidation Prec@1 87.010 \tValidation Prec@5 99.450 \n",
            "\n",
            "lr: 0.040905257250270076\n",
            "o is 1.7348597049713135,  o_a is 1.7348597049713135\n",
            "TRAINING - Epoch: [564][0/196]\tTime 1.770 (1.770)\tData 0.998 (0.998)\tloss 0.1206 (0.1206)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [564][100/196]\tTime 0.367 (0.408)\tData 0.000 (0.011)\tloss 0.0788 (0.0752)\tPrec@1 97.656 (97.273)\tPrec@5 100.000 (99.988)\n",
            "EVALUATING - Epoch: [564][0/79]\tTime 0.505 (0.505)\tData 0.376 (0.376)\tloss 0.5123 (0.5123)\tPrec@1 89.844 (89.844)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:40:26\n",
            "\n",
            " Epoch: 565\n",
            "Training loss 0.0766 \tTraining Prec@1 97.264 \tTraining Prec@5 99.994 \n",
            "Validation loss 0.5364 \tValidation Prec@1 87.790 \tValidation Prec@5 99.460 \n",
            "\n",
            "lr: 0.040750218316947105\n",
            "o is 1.7372944355010986,  o_a is 1.7372944355010986\n",
            "TRAINING - Epoch: [565][0/196]\tTime 2.852 (2.852)\tData 1.397 (1.397)\tloss 0.0908 (0.0908)\tPrec@1 96.484 (96.484)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [565][100/196]\tTime 0.365 (0.414)\tData 0.000 (0.015)\tloss 0.0698 (0.0835)\tPrec@1 96.875 (97.049)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [565][0/79]\tTime 0.945 (0.945)\tData 0.725 (0.725)\tloss 0.3082 (0.3082)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:23\tTime of Finish: 2023-11-27 09:51:27\n",
            "\n",
            " Epoch: 566\n",
            "Training loss 0.0805 \tTraining Prec@1 97.104 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5775 \tValidation Prec@1 87.410 \tValidation Prec@5 99.450 \n",
            "\n",
            "lr: 0.04059527142853269\n",
            "o is 1.739732265472412,  o_a is 1.739732265472412\n",
            "TRAINING - Epoch: [566][0/196]\tTime 1.743 (1.743)\tData 0.807 (0.807)\tloss 0.0637 (0.0637)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [566][100/196]\tTime 0.418 (0.403)\tData 0.000 (0.009)\tloss 0.0740 (0.0758)\tPrec@1 97.656 (97.262)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [566][0/79]\tTime 0.364 (0.364)\tData 0.256 (0.256)\tloss 0.4355 (0.4355)\tPrec@1 89.062 (89.062)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:35:08\n",
            "\n",
            " Epoch: 567\n",
            "Training loss 0.0740 \tTraining Prec@1 97.334 \tTraining Prec@5 99.996 \n",
            "Validation loss 0.5455 \tValidation Prec@1 87.490 \tValidation Prec@5 99.540 \n",
            "\n",
            "lr: 0.04044041812659791\n",
            "o is 1.742173194885254,  o_a is 1.742173194885254\n",
            "TRAINING - Epoch: [567][0/196]\tTime 1.740 (1.740)\tData 0.865 (0.865)\tloss 0.0609 (0.0609)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [567][100/196]\tTime 0.368 (0.408)\tData 0.000 (0.009)\tloss 0.0924 (0.0728)\tPrec@1 96.484 (97.471)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [567][0/79]\tTime 0.594 (0.594)\tData 0.520 (0.520)\tloss 0.4600 (0.4600)\tPrec@1 88.281 (88.281)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:42:22\n",
            "\n",
            " Epoch: 568\n",
            "Training loss 0.0741 \tTraining Prec@1 97.426 \tTraining Prec@5 99.994 \n",
            "Validation loss 0.5664 \tValidation Prec@1 86.970 \tValidation Prec@5 99.550 \n",
            "\n",
            "lr: 0.04028565995178282\n",
            "o is 1.7446173429489136,  o_a is 1.7446173429489136\n",
            "TRAINING - Epoch: [568][0/196]\tTime 2.810 (2.810)\tData 1.371 (1.371)\tloss 0.0517 (0.0517)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [568][100/196]\tTime 0.369 (0.412)\tData 0.001 (0.014)\tloss 0.0881 (0.0743)\tPrec@1 97.266 (97.347)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [568][0/79]\tTime 0.962 (0.962)\tData 0.765 (0.765)\tloss 0.2458 (0.2458)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:23\tTime of Finish: 2023-11-27 09:50:23\n",
            "\n",
            " Epoch: 569\n",
            "Training loss 0.0733 \tTraining Prec@1 97.326 \tTraining Prec@5 99.996 \n",
            "Validation loss 0.5111 \tValidation Prec@1 87.400 \tValidation Prec@5 99.610 \n",
            "\n",
            "lr: 0.040130998443781034\n",
            "o is 1.747064471244812,  o_a is 1.747064471244812\n",
            "TRAINING - Epoch: [569][0/196]\tTime 1.787 (1.787)\tData 0.972 (0.972)\tloss 0.0635 (0.0635)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [569][100/196]\tTime 0.437 (0.404)\tData 0.000 (0.010)\tloss 0.0657 (0.0731)\tPrec@1 98.047 (97.335)\tPrec@5 100.000 (99.992)\n",
            "EVALUATING - Epoch: [569][0/79]\tTime 0.449 (0.449)\tData 0.384 (0.384)\tloss 0.3660 (0.3660)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:35:19\n",
            "\n",
            " Epoch: 570\n",
            "Training loss 0.0758 \tTraining Prec@1 97.316 \tTraining Prec@5 99.994 \n",
            "Validation loss 0.5214 \tValidation Prec@1 88.140 \tValidation Prec@5 99.610 \n",
            "\n",
            "lr: 0.039976435141324415\n",
            "o is 1.7495146989822388,  o_a is 1.7495146989822388\n",
            "TRAINING - Epoch: [570][0/196]\tTime 1.750 (1.750)\tData 0.712 (0.712)\tloss 0.0535 (0.0535)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [570][100/196]\tTime 0.412 (0.410)\tData 0.000 (0.008)\tloss 0.0837 (0.0699)\tPrec@1 97.656 (97.474)\tPrec@5 100.000 (99.992)\n",
            "EVALUATING - Epoch: [570][0/79]\tTime 0.529 (0.529)\tData 0.391 (0.391)\tloss 0.4081 (0.4081)\tPrec@1 89.844 (89.844)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:41:06\n",
            "\n",
            " Epoch: 571\n",
            "Training loss 0.0721 \tTraining Prec@1 97.394 \tTraining Prec@5 99.996 \n",
            "Validation loss 0.5871 \tValidation Prec@1 87.120 \tValidation Prec@5 99.520 \n",
            "\n",
            "lr: 0.03982197158216778\n",
            "o is 1.7519680261611938,  o_a is 1.7519680261611938\n",
            "TRAINING - Epoch: [571][0/196]\tTime 2.693 (2.693)\tData 1.270 (1.270)\tloss 0.0556 (0.0556)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [571][100/196]\tTime 0.368 (0.415)\tData 0.004 (0.013)\tloss 0.0474 (0.0729)\tPrec@1 98.828 (97.355)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [571][0/79]\tTime 0.556 (0.556)\tData 0.393 (0.393)\tloss 0.4174 (0.4174)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:24\tTime of Finish: 2023-11-27 09:57:42\n",
            "\n",
            " Epoch: 572\n",
            "Training loss 0.0740 \tTraining Prec@1 97.374 \tTraining Prec@5 99.996 \n",
            "Validation loss 0.5928 \tValidation Prec@1 87.660 \tValidation Prec@5 99.420 \n",
            "\n",
            "lr: 0.039667609303073614\n",
            "o is 1.7544245719909668,  o_a is 1.7544245719909668\n",
            "TRAINING - Epoch: [572][0/196]\tTime 1.780 (1.780)\tData 0.895 (0.895)\tloss 0.0664 (0.0664)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [572][100/196]\tTime 0.366 (0.400)\tData 0.000 (0.009)\tloss 0.0421 (0.0739)\tPrec@1 98.438 (97.463)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [572][0/79]\tTime 0.669 (0.669)\tData 0.526 (0.526)\tloss 0.4039 (0.4039)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:34:30\n",
            "\n",
            " Epoch: 573\n",
            "Training loss 0.0748 \tTraining Prec@1 97.386 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5093 \tValidation Prec@1 87.910 \tValidation Prec@5 99.430 \n",
            "\n",
            "lr: 0.03951334983979672\n",
            "o is 1.756883978843689,  o_a is 1.756883978843689\n",
            "TRAINING - Epoch: [573][0/196]\tTime 1.932 (1.932)\tData 0.887 (0.887)\tloss 0.0569 (0.0569)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [573][100/196]\tTime 0.440 (0.406)\tData 0.000 (0.010)\tloss 0.0849 (0.0697)\tPrec@1 97.656 (97.505)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [573][0/79]\tTime 0.487 (0.487)\tData 0.346 (0.346)\tloss 0.5402 (0.5402)\tPrec@1 87.500 (87.500)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:37:03\n",
            "\n",
            " Epoch: 574\n",
            "Training loss 0.0714 \tTraining Prec@1 97.434 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5262 \tValidation Prec@1 88.100 \tValidation Prec@5 99.580 \n",
            "\n",
            "lr: 0.03935919472706905\n",
            "o is 1.759346604347229,  o_a is 1.759346604347229\n",
            "TRAINING - Epoch: [574][0/196]\tTime 1.725 (1.725)\tData 0.820 (0.820)\tloss 0.0433 (0.0433)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [574][100/196]\tTime 0.370 (0.410)\tData 0.000 (0.009)\tloss 0.0938 (0.0741)\tPrec@1 96.875 (97.440)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [574][0/79]\tTime 0.553 (0.553)\tData 0.452 (0.452)\tloss 0.4623 (0.4623)\tPrec@1 89.062 (89.062)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:23\tTime of Finish: 2023-11-27 09:48:00\n",
            "\n",
            " Epoch: 575\n",
            "Training loss 0.0730 \tTraining Prec@1 97.498 \tTraining Prec@5 99.994 \n",
            "Validation loss 0.5399 \tValidation Prec@1 87.900 \tValidation Prec@5 99.510 \n",
            "\n",
            "lr: 0.03920514549858431\n",
            "o is 1.7618120908737183,  o_a is 1.7618120908737183\n",
            "TRAINING - Epoch: [575][0/196]\tTime 2.621 (2.621)\tData 1.473 (1.473)\tloss 0.0584 (0.0584)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [575][100/196]\tTime 0.367 (0.409)\tData 0.000 (0.015)\tloss 0.0731 (0.0779)\tPrec@1 97.656 (97.285)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [575][0/79]\tTime 0.881 (0.881)\tData 0.665 (0.665)\tloss 0.5042 (0.5042)\tPrec@1 87.500 (87.500)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:23\tTime of Finish: 2023-11-27 09:48:27\n",
            "\n",
            " Epoch: 576\n",
            "Training loss 0.0765 \tTraining Prec@1 97.304 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5239 \tValidation Prec@1 88.380 \tValidation Prec@5 99.520 \n",
            "\n",
            "lr: 0.03905120368698278\n",
            "o is 1.7642806768417358,  o_a is 1.7642806768417358\n",
            "TRAINING - Epoch: [576][0/196]\tTime 1.718 (1.718)\tData 0.775 (0.775)\tloss 0.0458 (0.0458)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [576][100/196]\tTime 0.431 (0.403)\tData 0.000 (0.009)\tloss 0.0595 (0.0767)\tPrec@1 97.656 (97.374)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [576][0/79]\tTime 0.497 (0.497)\tData 0.377 (0.377)\tloss 0.4620 (0.4620)\tPrec@1 87.500 (87.500)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:35:46\n",
            "\n",
            " Epoch: 577\n",
            "Training loss 0.0769 \tTraining Prec@1 97.280 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5469 \tValidation Prec@1 87.450 \tValidation Prec@5 99.600 \n",
            "\n",
            "lr: 0.03889737082383608\n",
            "o is 1.7667526006698608,  o_a is 1.7667526006698608\n",
            "TRAINING - Epoch: [577][0/196]\tTime 1.788 (1.788)\tData 0.906 (0.906)\tloss 0.1363 (0.1363)\tPrec@1 94.141 (94.141)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [577][100/196]\tTime 0.366 (0.409)\tData 0.000 (0.010)\tloss 0.0436 (0.0742)\tPrec@1 98.828 (97.382)\tPrec@5 100.000 (99.988)\n",
            "EVALUATING - Epoch: [577][0/79]\tTime 0.570 (0.570)\tData 0.453 (0.453)\tloss 0.3313 (0.3313)\tPrec@1 89.062 (89.062)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:39:05\n",
            "\n",
            " Epoch: 578\n",
            "Training loss 0.0747 \tTraining Prec@1 97.312 \tTraining Prec@5 99.992 \n",
            "Validation loss 0.5520 \tValidation Prec@1 87.490 \tValidation Prec@5 99.560 \n",
            "\n",
            "lr: 0.038743648439631816\n",
            "o is 1.7692272663116455,  o_a is 1.7692272663116455\n",
            "TRAINING - Epoch: [578][0/196]\tTime 2.596 (2.596)\tData 1.237 (1.237)\tloss 0.0877 (0.0877)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [578][100/196]\tTime 0.369 (0.415)\tData 0.000 (0.013)\tloss 0.0430 (0.0669)\tPrec@1 98.828 (97.602)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [578][0/79]\tTime 0.538 (0.538)\tData 0.375 (0.375)\tloss 0.4284 (0.4284)\tPrec@1 88.281 (88.281)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:24\tTime of Finish: 2023-11-27 09:56:21\n",
            "\n",
            " Epoch: 579\n",
            "Training loss 0.0685 \tTraining Prec@1 97.564 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5465 \tValidation Prec@1 87.650 \tValidation Prec@5 99.470 \n",
            "\n",
            "lr: 0.03859003806375854\n",
            "o is 1.771705150604248,  o_a is 1.771705150604248\n",
            "TRAINING - Epoch: [579][0/196]\tTime 1.635 (1.635)\tData 0.612 (0.612)\tloss 0.0493 (0.0493)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [579][100/196]\tTime 0.370 (0.399)\tData 0.000 (0.007)\tloss 0.0881 (0.0717)\tPrec@1 96.875 (97.447)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [579][0/79]\tTime 0.616 (0.616)\tData 0.484 (0.484)\tloss 0.5888 (0.5888)\tPrec@1 85.156 (85.156)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:35:02\n",
            "\n",
            " Epoch: 580\n",
            "Training loss 0.0728 \tTraining Prec@1 97.406 \tTraining Prec@5 99.994 \n",
            "Validation loss 0.6154 \tValidation Prec@1 86.700 \tValidation Prec@5 99.320 \n",
            "\n",
            "lr: 0.03843654122449034\n",
            "o is 1.7741858959197998,  o_a is 1.7741858959197998\n",
            "TRAINING - Epoch: [580][0/196]\tTime 1.800 (1.800)\tData 0.960 (0.960)\tloss 0.0674 (0.0674)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [580][100/196]\tTime 0.432 (0.408)\tData 0.000 (0.010)\tloss 0.0584 (0.0678)\tPrec@1 98.828 (97.614)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [580][0/79]\tTime 0.363 (0.363)\tData 0.261 (0.261)\tloss 0.4078 (0.4078)\tPrec@1 89.062 (89.062)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:38:58\n",
            "\n",
            " Epoch: 581\n",
            "Training loss 0.0688 \tTraining Prec@1 97.548 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5600 \tValidation Prec@1 87.100 \tValidation Prec@5 99.410 \n",
            "\n",
            "lr: 0.03828315944897178\n",
            "o is 1.7766697406768799,  o_a is 1.7766697406768799\n",
            "TRAINING - Epoch: [581][0/196]\tTime 1.816 (1.816)\tData 0.811 (0.811)\tloss 0.0667 (0.0667)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [581][100/196]\tTime 0.370 (0.409)\tData 0.000 (0.009)\tloss 0.0620 (0.0726)\tPrec@1 98.438 (97.455)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [581][0/79]\tTime 0.352 (0.352)\tData 0.273 (0.273)\tloss 0.5538 (0.5538)\tPrec@1 88.281 (88.281)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:23\tTime of Finish: 2023-11-27 09:47:29\n",
            "\n",
            " Epoch: 582\n",
            "Training loss 0.0738 \tTraining Prec@1 97.322 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.6363 \tValidation Prec@1 86.240 \tValidation Prec@5 99.350 \n",
            "\n",
            "lr: 0.03812989426320263\n",
            "o is 1.7791566848754883,  o_a is 1.7791566848754883\n",
            "TRAINING - Epoch: [582][0/196]\tTime 2.651 (2.651)\tData 1.562 (1.562)\tloss 0.1012 (0.1012)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [582][100/196]\tTime 0.368 (0.409)\tData 0.000 (0.016)\tloss 0.0928 (0.0674)\tPrec@1 97.266 (97.571)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [582][0/79]\tTime 0.842 (0.842)\tData 0.653 (0.653)\tloss 0.3103 (0.3103)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:23\tTime of Finish: 2023-11-27 09:47:07\n",
            "\n",
            " Epoch: 583\n",
            "Training loss 0.0685 \tTraining Prec@1 97.546 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5244 \tValidation Prec@1 87.750 \tValidation Prec@5 99.570 \n",
            "\n",
            "lr: 0.037976747192022715\n",
            "o is 1.7816466093063354,  o_a is 1.7816466093063354\n",
            "TRAINING - Epoch: [583][0/196]\tTime 1.601 (1.601)\tData 0.609 (0.609)\tloss 0.0912 (0.0912)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [583][100/196]\tTime 0.426 (0.405)\tData 0.000 (0.007)\tloss 0.0908 (0.0714)\tPrec@1 96.484 (97.532)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [583][0/79]\tTime 0.529 (0.529)\tData 0.410 (0.410)\tloss 0.5157 (0.5157)\tPrec@1 87.500 (87.500)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:37:02\n",
            "\n",
            " Epoch: 584\n",
            "Training loss 0.0726 \tTraining Prec@1 97.462 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5453 \tValidation Prec@1 87.840 \tValidation Prec@5 99.550 \n",
            "\n",
            "lr: 0.03782371975909671\n",
            "o is 1.7841393947601318,  o_a is 1.7841393947601318\n",
            "TRAINING - Epoch: [584][0/196]\tTime 1.818 (1.818)\tData 0.933 (0.933)\tloss 0.0545 (0.0545)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [584][100/196]\tTime 0.366 (0.410)\tData 0.000 (0.010)\tloss 0.0721 (0.0678)\tPrec@1 97.266 (97.629)\tPrec@5 100.000 (99.992)\n",
            "EVALUATING - Epoch: [584][0/79]\tTime 0.450 (0.450)\tData 0.312 (0.312)\tloss 0.3907 (0.3907)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:40:08\n",
            "\n",
            " Epoch: 585\n",
            "Training loss 0.0691 \tTraining Prec@1 97.598 \tTraining Prec@5 99.994 \n",
            "Validation loss 0.5254 \tValidation Prec@1 87.700 \tValidation Prec@5 99.500 \n",
            "\n",
            "lr: 0.03767081348689905\n",
            "o is 1.7866352796554565,  o_a is 1.7866352796554565\n",
            "TRAINING - Epoch: [585][0/196]\tTime 2.870 (2.870)\tData 1.408 (1.408)\tloss 0.0536 (0.0536)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [585][100/196]\tTime 0.366 (0.413)\tData 0.000 (0.015)\tloss 0.0697 (0.0658)\tPrec@1 97.266 (97.618)\tPrec@5 100.000 (99.988)\n",
            "EVALUATING - Epoch: [585][0/79]\tTime 0.805 (0.805)\tData 0.584 (0.584)\tloss 0.3826 (0.3826)\tPrec@1 88.281 (88.281)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:23\tTime of Finish: 2023-11-27 09:49:22\n",
            "\n",
            " Epoch: 586\n",
            "Training loss 0.0649 \tTraining Prec@1 97.692 \tTraining Prec@5 99.990 \n",
            "Validation loss 0.5406 \tValidation Prec@1 87.370 \tValidation Prec@5 99.580 \n",
            "\n",
            "lr: 0.03751802989669869\n",
            "o is 1.7891342639923096,  o_a is 1.7891342639923096\n",
            "TRAINING - Epoch: [586][0/196]\tTime 1.743 (1.743)\tData 0.821 (0.821)\tloss 0.0584 (0.0584)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [586][100/196]\tTime 0.464 (0.402)\tData 0.000 (0.009)\tloss 0.0696 (0.0688)\tPrec@1 98.047 (97.463)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [586][0/79]\tTime 0.361 (0.361)\tData 0.273 (0.273)\tloss 0.3004 (0.3004)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:34:12\n",
            "\n",
            " Epoch: 587\n",
            "Training loss 0.0699 \tTraining Prec@1 97.496 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5675 \tValidation Prec@1 87.370 \tValidation Prec@5 99.590 \n",
            "\n",
            "lr: 0.03736537050854406\n",
            "o is 1.7916361093521118,  o_a is 1.7916361093521118\n",
            "TRAINING - Epoch: [587][0/196]\tTime 1.821 (1.821)\tData 0.954 (0.954)\tloss 0.0770 (0.0770)\tPrec@1 96.484 (96.484)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [587][100/196]\tTime 0.438 (0.408)\tData 0.000 (0.010)\tloss 0.0484 (0.0677)\tPrec@1 98.047 (97.563)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [587][0/79]\tTime 0.529 (0.529)\tData 0.395 (0.395)\tloss 0.4047 (0.4047)\tPrec@1 89.062 (89.062)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:38:08\n",
            "\n",
            " Epoch: 588\n",
            "Training loss 0.0665 \tTraining Prec@1 97.612 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5087 \tValidation Prec@1 87.630 \tValidation Prec@5 99.410 \n",
            "\n",
            "lr: 0.03721283684124786\n",
            "o is 1.7941409349441528,  o_a is 1.7941409349441528\n",
            "TRAINING - Epoch: [588][0/196]\tTime 2.626 (2.626)\tData 1.130 (1.130)\tloss 0.0688 (0.0688)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [588][100/196]\tTime 0.367 (0.413)\tData 0.000 (0.012)\tloss 0.0716 (0.0655)\tPrec@1 97.266 (97.652)\tPrec@5 100.000 (99.992)\n",
            "EVALUATING - Epoch: [588][0/79]\tTime 0.457 (0.457)\tData 0.312 (0.312)\tloss 0.3399 (0.3399)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:23\tTime of Finish: 2023-11-27 09:51:34\n",
            "\n",
            " Epoch: 589\n",
            "Training loss 0.0659 \tTraining Prec@1 97.646 \tTraining Prec@5 99.996 \n",
            "Validation loss 0.5037 \tValidation Prec@1 88.410 \tValidation Prec@5 99.630 \n",
            "\n",
            "lr: 0.03706043041237202\n",
            "o is 1.7966487407684326,  o_a is 1.7966487407684326\n",
            "TRAINING - Epoch: [589][0/196]\tTime 2.178 (2.178)\tData 1.380 (1.380)\tloss 0.0378 (0.0378)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [589][100/196]\tTime 0.366 (0.403)\tData 0.000 (0.015)\tloss 0.0996 (0.0654)\tPrec@1 96.875 (97.683)\tPrec@5 100.000 (99.992)\n",
            "EVALUATING - Epoch: [589][0/79]\tTime 0.713 (0.713)\tData 0.491 (0.491)\tloss 0.5676 (0.5676)\tPrec@1 88.281 (88.281)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:37:34\n",
            "\n",
            " Epoch: 590\n",
            "Training loss 0.0673 \tTraining Prec@1 97.614 \tTraining Prec@5 99.996 \n",
            "Validation loss 0.5625 \tValidation Prec@1 87.460 \tValidation Prec@5 99.570 \n",
            "\n",
            "lr: 0.03690815273821258\n",
            "o is 1.7991595268249512,  o_a is 1.7991595268249512\n",
            "TRAINING - Epoch: [590][0/196]\tTime 1.757 (1.757)\tData 1.024 (1.024)\tloss 0.0558 (0.0558)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [590][100/196]\tTime 0.438 (0.401)\tData 0.000 (0.011)\tloss 0.1016 (0.0686)\tPrec@1 97.266 (97.621)\tPrec@5 100.000 (99.992)\n",
            "EVALUATING - Epoch: [590][0/79]\tTime 0.352 (0.352)\tData 0.237 (0.237)\tloss 0.3761 (0.3761)\tPrec@1 88.281 (88.281)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:32:56\n",
            "\n",
            " Epoch: 591\n",
            "Training loss 0.0693 \tTraining Prec@1 97.576 \tTraining Prec@5 99.996 \n",
            "Validation loss 0.5414 \tValidation Prec@1 86.970 \tValidation Prec@5 99.640 \n",
            "\n",
            "lr: 0.036756005333784536\n",
            "o is 1.801673412322998,  o_a is 1.801673412322998\n",
            "TRAINING - Epoch: [591][0/196]\tTime 1.696 (1.696)\tData 0.899 (0.899)\tloss 0.0949 (0.0949)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [591][100/196]\tTime 0.365 (0.406)\tData 0.004 (0.010)\tloss 0.0757 (0.0755)\tPrec@1 97.656 (97.208)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [591][0/79]\tTime 0.458 (0.458)\tData 0.316 (0.316)\tloss 0.4040 (0.4040)\tPrec@1 92.188 (92.188)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:37:13\n",
            "\n",
            " Epoch: 592\n",
            "Training loss 0.0741 \tTraining Prec@1 97.276 \tTraining Prec@5 99.996 \n",
            "Validation loss 0.5234 \tValidation Prec@1 88.210 \tValidation Prec@5 99.580 \n",
            "\n",
            "lr: 0.036603989712806914\n",
            "o is 1.8041900396347046,  o_a is 1.8041900396347046\n",
            "TRAINING - Epoch: [592][0/196]\tTime 2.934 (2.934)\tData 1.587 (1.587)\tloss 0.0630 (0.0630)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [592][100/196]\tTime 0.367 (0.410)\tData 0.000 (0.017)\tloss 0.0420 (0.0704)\tPrec@1 98.047 (97.521)\tPrec@5 100.000 (99.988)\n",
            "EVALUATING - Epoch: [592][0/79]\tTime 0.954 (0.954)\tData 0.753 (0.753)\tloss 0.2788 (0.2788)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:23\tTime of Finish: 2023-11-27 09:47:33\n",
            "\n",
            " Epoch: 593\n",
            "Training loss 0.0720 \tTraining Prec@1 97.444 \tTraining Prec@5 99.992 \n",
            "Validation loss 0.5144 \tValidation Prec@1 87.810 \tValidation Prec@5 99.660 \n",
            "\n",
            "lr: 0.036452107387687525\n",
            "o is 1.8067097663879395,  o_a is 1.8067097663879395\n",
            "TRAINING - Epoch: [593][0/196]\tTime 1.712 (1.712)\tData 0.863 (0.863)\tloss 0.0633 (0.0633)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [593][100/196]\tTime 0.470 (0.399)\tData 0.000 (0.009)\tloss 0.0400 (0.0632)\tPrec@1 98.047 (97.753)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [593][0/79]\tTime 0.521 (0.521)\tData 0.421 (0.421)\tloss 0.3989 (0.3989)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:31:40\n",
            "\n",
            " Epoch: 594\n",
            "Training loss 0.0650 \tTraining Prec@1 97.650 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5214 \tValidation Prec@1 88.140 \tValidation Prec@5 99.560 \n",
            "\n",
            "lr: 0.036300359869508116\n",
            "o is 1.8092323541641235,  o_a is 1.8092323541641235\n",
            "TRAINING - Epoch: [594][0/196]\tTime 1.733 (1.733)\tData 0.916 (0.916)\tloss 0.0532 (0.0532)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [594][100/196]\tTime 0.456 (0.405)\tData 0.008 (0.010)\tloss 0.1061 (0.0720)\tPrec@1 95.703 (97.517)\tPrec@5 100.000 (99.992)\n",
            "EVALUATING - Epoch: [594][0/79]\tTime 0.439 (0.439)\tData 0.318 (0.318)\tloss 0.4996 (0.4996)\tPrec@1 86.719 (86.719)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:35:36\n",
            "\n",
            " Epoch: 595\n",
            "Training loss 0.0722 \tTraining Prec@1 97.496 \tTraining Prec@5 99.992 \n",
            "Validation loss 0.5927 \tValidation Prec@1 86.050 \tValidation Prec@5 99.610 \n",
            "\n",
            "lr: 0.03614874866800916\n",
            "o is 1.811758041381836,  o_a is 1.811758041381836\n",
            "TRAINING - Epoch: [595][0/196]\tTime 1.910 (1.910)\tData 0.893 (0.893)\tloss 0.0578 (0.0578)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [595][100/196]\tTime 0.367 (0.408)\tData 0.000 (0.010)\tloss 0.0496 (0.0662)\tPrec@1 99.219 (97.679)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [595][0/79]\tTime 0.472 (0.472)\tData 0.357 (0.357)\tloss 0.4371 (0.4371)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:23\tTime of Finish: 2023-11-27 09:47:16\n",
            "\n",
            " Epoch: 596\n",
            "Training loss 0.0659 \tTraining Prec@1 97.668 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5371 \tValidation Prec@1 88.170 \tValidation Prec@5 99.560 \n",
            "\n",
            "lr: 0.03599727529157494\n",
            "o is 1.814286470413208,  o_a is 1.814286470413208\n",
            "TRAINING - Epoch: [596][0/196]\tTime 2.683 (2.683)\tData 1.614 (1.614)\tloss 0.0335 (0.0335)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [596][100/196]\tTime 0.369 (0.406)\tData 0.000 (0.017)\tloss 0.0790 (0.0679)\tPrec@1 97.656 (97.645)\tPrec@5 100.000 (99.992)\n",
            "EVALUATING - Epoch: [596][0/79]\tTime 0.846 (0.846)\tData 0.661 (0.661)\tloss 0.3461 (0.3461)\tPrec@1 89.844 (89.844)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:43:04\n",
            "\n",
            " Epoch: 597\n",
            "Training loss 0.0680 \tTraining Prec@1 97.624 \tTraining Prec@5 99.994 \n",
            "Validation loss 0.5308 \tValidation Prec@1 87.470 \tValidation Prec@5 99.540 \n",
            "\n",
            "lr: 0.035845941247218516\n",
            "o is 1.8168177604675293,  o_a is 1.8168177604675293\n",
            "TRAINING - Epoch: [597][0/196]\tTime 1.659 (1.659)\tData 0.681 (0.681)\tloss 0.0798 (0.0798)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [597][100/196]\tTime 0.455 (0.400)\tData 0.000 (0.007)\tloss 0.0559 (0.0636)\tPrec@1 98.047 (97.819)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [597][0/79]\tTime 0.492 (0.492)\tData 0.354 (0.354)\tloss 0.4664 (0.4664)\tPrec@1 89.062 (89.062)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:33:26\n",
            "\n",
            " Epoch: 598\n",
            "Training loss 0.0649 \tTraining Prec@1 97.714 \tTraining Prec@5 99.996 \n",
            "Validation loss 0.5464 \tValidation Prec@1 87.580 \tValidation Prec@5 99.520 \n",
            "\n",
            "lr: 0.03569474804056673\n",
            "o is 1.819352149963379,  o_a is 1.819352149963379\n",
            "TRAINING - Epoch: [598][0/196]\tTime 1.742 (1.742)\tData 0.758 (0.758)\tloss 0.0531 (0.0531)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [598][100/196]\tTime 0.365 (0.406)\tData 0.000 (0.008)\tloss 0.0580 (0.0623)\tPrec@1 98.438 (97.803)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [598][0/79]\tTime 0.465 (0.465)\tData 0.404 (0.404)\tloss 0.3251 (0.3251)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:38:33\n",
            "\n",
            " Epoch: 599\n",
            "Training loss 0.0643 \tTraining Prec@1 97.736 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5593 \tValidation Prec@1 87.810 \tValidation Prec@5 99.610 \n",
            "\n",
            "lr: 0.03554369717584521\n",
            "o is 1.8218894004821777,  o_a is 1.8218894004821777\n",
            "TRAINING - Epoch: [599][0/196]\tTime 2.929 (2.929)\tData 1.577 (1.577)\tloss 0.0321 (0.0321)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [599][100/196]\tTime 0.364 (0.410)\tData 0.000 (0.016)\tloss 0.0970 (0.0664)\tPrec@1 96.484 (97.621)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [599][0/79]\tTime 0.895 (0.895)\tData 0.695 (0.695)\tloss 0.3995 (0.3995)\tPrec@1 89.844 (89.844)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:23\tTime of Finish: 2023-11-27 09:47:02\n",
            "\n",
            " Epoch: 600\n",
            "Training loss 0.0659 \tTraining Prec@1 97.582 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5952 \tValidation Prec@1 87.280 \tValidation Prec@5 99.650 \n",
            "\n",
            "lr: 0.03539279015586344\n",
            "o is 1.8244296312332153,  o_a is 1.8244296312332153\n",
            "TRAINING - Epoch: [600][0/196]\tTime 1.745 (1.745)\tData 0.771 (0.771)\tloss 0.0553 (0.0553)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [600][100/196]\tTime 0.463 (0.401)\tData 0.000 (0.008)\tloss 0.0902 (0.0677)\tPrec@1 96.875 (97.726)\tPrec@5 100.000 (99.981)\n",
            "EVALUATING - Epoch: [600][0/79]\tTime 0.385 (0.385)\tData 0.293 (0.293)\tloss 0.3466 (0.3466)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:33:08\n",
            "\n",
            " Epoch: 601\n",
            "Training loss 0.0682 \tTraining Prec@1 97.630 \tTraining Prec@5 99.990 \n",
            "Validation loss 0.5248 \tValidation Prec@1 88.000 \tValidation Prec@5 99.600 \n",
            "\n",
            "lr: 0.03524202848199977\n",
            "o is 1.8269726037979126,  o_a is 1.8269726037979126\n",
            "TRAINING - Epoch: [601][0/196]\tTime 1.719 (1.719)\tData 0.884 (0.884)\tloss 0.0543 (0.0543)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [601][100/196]\tTime 0.373 (0.406)\tData 0.000 (0.010)\tloss 0.0428 (0.0605)\tPrec@1 98.438 (97.815)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [601][0/79]\tTime 0.511 (0.511)\tData 0.406 (0.406)\tloss 0.4365 (0.4365)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:37:10\n",
            "\n",
            " Epoch: 602\n",
            "Training loss 0.0629 \tTraining Prec@1 97.700 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5960 \tValidation Prec@1 87.030 \tValidation Prec@5 99.500 \n",
            "\n",
            "lr: 0.0350914136541865\n",
            "o is 1.8295185565948486,  o_a is 1.8295185565948486\n",
            "TRAINING - Epoch: [602][0/196]\tTime 2.581 (2.581)\tData 1.191 (1.191)\tloss 0.0712 (0.0712)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [602][100/196]\tTime 0.365 (0.414)\tData 0.000 (0.013)\tloss 0.0684 (0.0651)\tPrec@1 97.266 (97.645)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [602][0/79]\tTime 0.470 (0.470)\tData 0.379 (0.379)\tloss 0.3273 (0.3273)\tPrec@1 89.062 (89.062)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:23\tTime of Finish: 2023-11-27 09:52:02\n",
            "\n",
            " Epoch: 603\n",
            "Training loss 0.0673 \tTraining Prec@1 97.592 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5357 \tValidation Prec@1 87.860 \tValidation Prec@5 99.650 \n",
            "\n",
            "lr: 0.034940947170894986\n",
            "o is 1.8320672512054443,  o_a is 1.8320672512054443\n",
            "TRAINING - Epoch: [603][0/196]\tTime 2.589 (2.589)\tData 1.521 (1.521)\tloss 0.0261 (0.0261)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [603][100/196]\tTime 0.367 (0.407)\tData 0.001 (0.016)\tloss 0.0444 (0.0675)\tPrec@1 98.047 (97.513)\tPrec@5 100.000 (99.992)\n",
            "EVALUATING - Epoch: [603][0/79]\tTime 0.832 (0.832)\tData 0.608 (0.608)\tloss 0.3786 (0.3786)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:43:29\n",
            "\n",
            " Epoch: 604\n",
            "Training loss 0.0688 \tTraining Prec@1 97.522 \tTraining Prec@5 99.990 \n",
            "Validation loss 0.5527 \tValidation Prec@1 88.080 \tValidation Prec@5 99.620 \n",
            "\n",
            "lr: 0.03479063052912063\n",
            "o is 1.8346190452575684,  o_a is 1.8346190452575684\n",
            "TRAINING - Epoch: [604][0/196]\tTime 1.729 (1.729)\tData 0.826 (0.826)\tloss 0.0633 (0.0633)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [604][100/196]\tTime 0.476 (0.399)\tData 0.000 (0.009)\tloss 0.0602 (0.0714)\tPrec@1 98.047 (97.532)\tPrec@5 100.000 (99.992)\n",
            "EVALUATING - Epoch: [604][0/79]\tTime 0.377 (0.377)\tData 0.281 (0.281)\tloss 0.5525 (0.5525)\tPrec@1 86.719 (86.719)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:31:21\n",
            "\n",
            " Epoch: 605\n",
            "Training loss 0.0689 \tTraining Prec@1 97.584 \tTraining Prec@5 99.994 \n",
            "Validation loss 0.5559 \tValidation Prec@1 87.460 \tValidation Prec@5 99.550 \n",
            "\n",
            "lr: 0.03464046522436815\n",
            "o is 1.8371737003326416,  o_a is 1.8371737003326416\n",
            "TRAINING - Epoch: [605][0/196]\tTime 1.759 (1.759)\tData 0.899 (0.899)\tloss 0.0575 (0.0575)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [605][100/196]\tTime 0.424 (0.407)\tData 0.000 (0.010)\tloss 0.0756 (0.0720)\tPrec@1 97.266 (97.413)\tPrec@5 100.000 (99.992)\n",
            "EVALUATING - Epoch: [605][0/79]\tTime 0.584 (0.584)\tData 0.437 (0.437)\tloss 0.5307 (0.5307)\tPrec@1 89.844 (89.844)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:37:20\n",
            "\n",
            " Epoch: 606\n",
            "Training loss 0.0702 \tTraining Prec@1 97.492 \tTraining Prec@5 99.990 \n",
            "Validation loss 0.6143 \tValidation Prec@1 86.600 \tValidation Prec@5 99.500 \n",
            "\n",
            "lr: 0.03449045275063652\n",
            "o is 1.839731216430664,  o_a is 1.839731216430664\n",
            "TRAINING - Epoch: [606][0/196]\tTime 2.430 (2.430)\tData 0.920 (0.920)\tloss 0.0867 (0.0867)\tPrec@1 96.484 (96.484)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [606][100/196]\tTime 0.365 (0.411)\tData 0.000 (0.010)\tloss 0.0470 (0.0663)\tPrec@1 98.438 (97.563)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [606][0/79]\tTime 0.443 (0.443)\tData 0.305 (0.305)\tloss 0.3827 (0.3827)\tPrec@1 90.625 (90.625)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:23\tTime of Finish: 2023-11-27 09:49:31\n",
            "\n",
            " Epoch: 607\n",
            "Training loss 0.0667 \tTraining Prec@1 97.552 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5325 \tValidation Prec@1 87.300 \tValidation Prec@5 99.550 \n",
            "\n",
            "lr: 0.03434059460040425\n",
            "o is 1.8422914743423462,  o_a is 1.8422914743423462\n",
            "TRAINING - Epoch: [607][0/196]\tTime 2.324 (2.324)\tData 1.448 (1.448)\tloss 0.0551 (0.0551)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [607][100/196]\tTime 0.364 (0.402)\tData 0.000 (0.015)\tloss 0.0555 (0.0661)\tPrec@1 98.047 (97.683)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [607][0/79]\tTime 0.935 (0.935)\tData 0.741 (0.741)\tloss 0.3821 (0.3821)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:39:52\n",
            "\n",
            " Epoch: 608\n",
            "Training loss 0.0665 \tTraining Prec@1 97.622 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5330 \tValidation Prec@1 87.630 \tValidation Prec@5 99.650 \n",
            "\n",
            "lr: 0.03419089226461448\n",
            "o is 1.8448545932769775,  o_a is 1.8448545932769775\n",
            "TRAINING - Epoch: [608][0/196]\tTime 1.727 (1.727)\tData 0.782 (0.782)\tloss 0.0387 (0.0387)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [608][100/196]\tTime 0.425 (0.403)\tData 0.000 (0.009)\tloss 0.0388 (0.0651)\tPrec@1 98.047 (97.679)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [608][0/79]\tTime 0.415 (0.415)\tData 0.271 (0.271)\tloss 0.3579 (0.3579)\tPrec@1 89.844 (89.844)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:33:14\n",
            "\n",
            " Epoch: 609\n",
            "Training loss 0.0673 \tTraining Prec@1 97.556 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5244 \tValidation Prec@1 87.910 \tValidation Prec@5 99.650 \n",
            "\n",
            "lr: 0.03404134723266008\n",
            "o is 1.8474206924438477,  o_a is 1.8474206924438477\n",
            "TRAINING - Epoch: [609][0/196]\tTime 1.578 (1.578)\tData 0.610 (0.610)\tloss 0.0821 (0.0821)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [609][100/196]\tTime 0.415 (0.405)\tData 0.000 (0.007)\tloss 0.0491 (0.0704)\tPrec@1 97.656 (97.467)\tPrec@5 100.000 (99.992)\n",
            "EVALUATING - Epoch: [609][0/79]\tTime 0.523 (0.523)\tData 0.395 (0.395)\tloss 0.4348 (0.4348)\tPrec@1 87.500 (87.500)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:35:19\n",
            "\n",
            " Epoch: 610\n",
            "Training loss 0.0672 \tTraining Prec@1 97.564 \tTraining Prec@5 99.994 \n",
            "Validation loss 0.5823 \tValidation Prec@1 87.270 \tValidation Prec@5 99.520 \n",
            "\n",
            "lr: 0.033891960992369005\n",
            "o is 1.8499895334243774,  o_a is 1.8499895334243774\n",
            "TRAINING - Epoch: [610][0/196]\tTime 2.413 (2.413)\tData 0.980 (0.980)\tloss 0.0491 (0.0491)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [610][100/196]\tTime 0.368 (0.413)\tData 0.000 (0.011)\tloss 0.0607 (0.0662)\tPrec@1 98.047 (97.687)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [610][0/79]\tTime 0.537 (0.537)\tData 0.460 (0.460)\tloss 0.4098 (0.4098)\tPrec@1 90.625 (90.625)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:23\tTime of Finish: 2023-11-27 09:51:24\n",
            "\n",
            " Epoch: 611\n",
            "Training loss 0.0673 \tTraining Prec@1 97.626 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5448 \tValidation Prec@1 87.780 \tValidation Prec@5 99.650 \n",
            "\n",
            "lr: 0.033742735029989285\n",
            "o is 1.852561354637146,  o_a is 1.852561354637146\n",
            "TRAINING - Epoch: [611][0/196]\tTime 2.270 (2.270)\tData 1.317 (1.317)\tloss 0.0631 (0.0631)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [611][100/196]\tTime 0.366 (0.402)\tData 0.000 (0.014)\tloss 0.0640 (0.0665)\tPrec@1 98.047 (97.687)\tPrec@5 100.000 (99.992)\n",
            "EVALUATING - Epoch: [611][0/79]\tTime 0.862 (0.862)\tData 0.673 (0.673)\tloss 0.2902 (0.2902)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:39:34\n",
            "\n",
            " Epoch: 612\n",
            "Training loss 0.0660 \tTraining Prec@1 97.680 \tTraining Prec@5 99.994 \n",
            "Validation loss 0.4997 \tValidation Prec@1 88.590 \tValidation Prec@5 99.620 \n",
            "\n",
            "lr: 0.033593670830174414\n",
            "o is 1.8551357984542847,  o_a is 1.8551357984542847\n",
            "TRAINING - Epoch: [612][0/196]\tTime 1.796 (1.796)\tData 0.821 (0.821)\tloss 0.0805 (0.0805)\tPrec@1 96.484 (96.484)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [612][100/196]\tTime 0.442 (0.402)\tData 0.000 (0.009)\tloss 0.0422 (0.0620)\tPrec@1 98.438 (97.834)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [612][0/79]\tTime 0.445 (0.445)\tData 0.317 (0.317)\tloss 0.3939 (0.3939)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:33:17\n",
            "\n",
            " Epoch: 613\n",
            "Training loss 0.0624 \tTraining Prec@1 97.810 \tTraining Prec@5 99.996 \n",
            "Validation loss 0.4859 \tValidation Prec@1 88.470 \tValidation Prec@5 99.600 \n",
            "\n",
            "lr: 0.03344476987596848\n",
            "o is 1.8577131032943726,  o_a is 1.8577131032943726\n",
            "TRAINING - Epoch: [613][0/196]\tTime 1.726 (1.726)\tData 0.859 (0.859)\tloss 0.0729 (0.0729)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [613][100/196]\tTime 0.364 (0.406)\tData 0.000 (0.009)\tloss 0.0432 (0.0683)\tPrec@1 98.828 (97.575)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [613][0/79]\tTime 0.523 (0.523)\tData 0.422 (0.422)\tloss 0.3112 (0.3112)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:36:58\n",
            "\n",
            " Epoch: 614\n",
            "Training loss 0.0647 \tTraining Prec@1 97.690 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5116 \tValidation Prec@1 88.470 \tValidation Prec@5 99.490 \n",
            "\n",
            "lr: 0.033296033648791426\n",
            "o is 1.8602933883666992,  o_a is 1.8602933883666992\n",
            "TRAINING - Epoch: [614][0/196]\tTime 2.957 (2.957)\tData 1.493 (1.493)\tloss 0.0612 (0.0612)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [614][100/196]\tTime 0.368 (0.412)\tData 0.001 (0.016)\tloss 0.0397 (0.0634)\tPrec@1 98.438 (97.726)\tPrec@5 100.000 (99.992)\n",
            "EVALUATING - Epoch: [614][0/79]\tTime 0.820 (0.820)\tData 0.626 (0.626)\tloss 0.3776 (0.3776)\tPrec@1 89.062 (89.062)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:23\tTime of Finish: 2023-11-27 09:47:00\n",
            "\n",
            " Epoch: 615\n",
            "Training loss 0.0644 \tTraining Prec@1 97.704 \tTraining Prec@5 99.996 \n",
            "Validation loss 0.5356 \tValidation Prec@1 87.650 \tValidation Prec@5 99.510 \n",
            "\n",
            "lr: 0.033147463628424315\n",
            "o is 1.862876296043396,  o_a is 1.862876296043396\n",
            "TRAINING - Epoch: [615][0/196]\tTime 1.724 (1.724)\tData 0.671 (0.671)\tloss 0.0943 (0.0943)\tPrec@1 96.484 (96.484)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [615][100/196]\tTime 0.458 (0.397)\tData 0.000 (0.007)\tloss 0.0735 (0.0677)\tPrec@1 96.484 (97.579)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [615][0/79]\tTime 0.449 (0.449)\tData 0.343 (0.343)\tloss 0.2977 (0.2977)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:29:41\n",
            "\n",
            " Epoch: 616\n",
            "Training loss 0.0662 \tTraining Prec@1 97.682 \tTraining Prec@5 99.994 \n",
            "Validation loss 0.5152 \tValidation Prec@1 88.460 \tValidation Prec@5 99.550 \n",
            "\n",
            "lr: 0.03299906129299467\n",
            "o is 1.865462064743042,  o_a is 1.865462064743042\n",
            "TRAINING - Epoch: [616][0/196]\tTime 1.723 (1.723)\tData 0.874 (0.874)\tloss 0.0488 (0.0488)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [616][100/196]\tTime 0.424 (0.403)\tData 0.000 (0.009)\tloss 0.0598 (0.0637)\tPrec@1 97.656 (97.734)\tPrec@5 100.000 (99.988)\n",
            "EVALUATING - Epoch: [616][0/79]\tTime 0.431 (0.431)\tData 0.301 (0.301)\tloss 0.4615 (0.4615)\tPrec@1 89.062 (89.062)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:33:45\n",
            "\n",
            " Epoch: 617\n",
            "Training loss 0.0614 \tTraining Prec@1 97.806 \tTraining Prec@5 99.992 \n",
            "Validation loss 0.5872 \tValidation Prec@1 87.610 \tValidation Prec@5 99.450 \n",
            "\n",
            "lr: 0.032850828118961624\n",
            "o is 1.8680506944656372,  o_a is 1.8680506944656372\n",
            "TRAINING - Epoch: [617][0/196]\tTime 1.899 (1.899)\tData 0.743 (0.743)\tloss 0.0791 (0.0791)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [617][100/196]\tTime 0.368 (0.406)\tData 0.003 (0.008)\tloss 0.0722 (0.0648)\tPrec@1 96.875 (97.730)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [617][0/79]\tTime 0.541 (0.541)\tData 0.429 (0.429)\tloss 0.4731 (0.4731)\tPrec@1 89.844 (89.844)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:43:09\n",
            "\n",
            " Epoch: 618\n",
            "Training loss 0.0636 \tTraining Prec@1 97.806 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5663 \tValidation Prec@1 87.390 \tValidation Prec@5 99.450 \n",
            "\n",
            "lr: 0.0327027655811014\n",
            "o is 1.870642066001892,  o_a is 1.870642066001892\n",
            "TRAINING - Epoch: [618][0/196]\tTime 2.595 (2.595)\tData 1.505 (1.505)\tloss 0.0827 (0.0827)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [618][100/196]\tTime 0.366 (0.405)\tData 0.000 (0.016)\tloss 0.0626 (0.0612)\tPrec@1 98.438 (97.792)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [618][0/79]\tTime 0.825 (0.825)\tData 0.634 (0.634)\tloss 0.2523 (0.2523)\tPrec@1 93.750 (93.750)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:42:17\n",
            "\n",
            " Epoch: 619\n",
            "Training loss 0.0600 \tTraining Prec@1 97.858 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5201 \tValidation Prec@1 88.300 \tValidation Prec@5 99.580 \n",
            "\n",
            "lr: 0.032554875152492495\n",
            "o is 1.8732364177703857,  o_a is 1.8732364177703857\n",
            "TRAINING - Epoch: [619][0/196]\tTime 1.735 (1.735)\tData 0.898 (0.898)\tloss 0.0429 (0.0429)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [619][100/196]\tTime 0.421 (0.400)\tData 0.000 (0.010)\tloss 0.1047 (0.0615)\tPrec@1 95.312 (97.826)\tPrec@5 100.000 (99.988)\n",
            "EVALUATING - Epoch: [619][0/79]\tTime 0.451 (0.451)\tData 0.312 (0.312)\tloss 0.3065 (0.3065)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:30:31\n",
            "\n",
            " Epoch: 620\n",
            "Training loss 0.0603 \tTraining Prec@1 97.862 \tTraining Prec@5 99.992 \n",
            "Validation loss 0.5227 \tValidation Prec@1 88.680 \tValidation Prec@5 99.560 \n",
            "\n",
            "lr: 0.03240715830450111\n",
            "o is 1.87583327293396,  o_a is 1.87583327293396\n",
            "TRAINING - Epoch: [620][0/196]\tTime 1.763 (1.763)\tData 0.957 (0.957)\tloss 0.0863 (0.0863)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [620][100/196]\tTime 0.439 (0.403)\tData 0.000 (0.010)\tloss 0.1195 (0.0611)\tPrec@1 95.312 (97.776)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [620][0/79]\tTime 0.438 (0.438)\tData 0.358 (0.358)\tloss 0.4520 (0.4520)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:33:52\n",
            "\n",
            " Epoch: 621\n",
            "Training loss 0.0622 \tTraining Prec@1 97.760 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5539 \tValidation Prec@1 87.560 \tValidation Prec@5 99.510 \n",
            "\n",
            "lr: 0.03225961650676652\n",
            "o is 1.8784329891204834,  o_a is 1.8784329891204834\n",
            "TRAINING - Epoch: [621][0/196]\tTime 1.797 (1.797)\tData 0.846 (0.846)\tloss 0.0435 (0.0435)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [621][100/196]\tTime 0.366 (0.405)\tData 0.000 (0.009)\tloss 0.0905 (0.0653)\tPrec@1 98.047 (97.745)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [621][0/79]\tTime 0.288 (0.288)\tData 0.218 (0.218)\tloss 0.3643 (0.3643)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:40:16\n",
            "\n",
            " Epoch: 622\n",
            "Training loss 0.0631 \tTraining Prec@1 97.768 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5458 \tValidation Prec@1 87.560 \tValidation Prec@5 99.450 \n",
            "\n",
            "lr: 0.03211225122718636\n",
            "o is 1.8810354471206665,  o_a is 1.8810354471206665\n",
            "TRAINING - Epoch: [622][0/196]\tTime 2.875 (2.875)\tData 1.487 (1.487)\tloss 0.0713 (0.0713)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [622][100/196]\tTime 0.362 (0.409)\tData 0.000 (0.016)\tloss 0.0755 (0.0597)\tPrec@1 97.266 (97.881)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [622][0/79]\tTime 0.888 (0.888)\tData 0.657 (0.657)\tloss 0.4633 (0.4633)\tPrec@1 89.062 (89.062)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:43:08\n",
            "\n",
            " Epoch: 623\n",
            "Training loss 0.0589 \tTraining Prec@1 97.928 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5279 \tValidation Prec@1 88.310 \tValidation Prec@5 99.580 \n",
            "\n",
            "lr: 0.031965063931902134\n",
            "o is 1.8836408853530884,  o_a is 1.8836408853530884\n",
            "TRAINING - Epoch: [623][0/196]\tTime 1.758 (1.758)\tData 0.907 (0.907)\tloss 0.0426 (0.0426)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [623][100/196]\tTime 0.431 (0.399)\tData 0.001 (0.010)\tloss 0.0495 (0.0588)\tPrec@1 98.438 (97.954)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [623][0/79]\tTime 0.348 (0.348)\tData 0.235 (0.235)\tloss 0.4256 (0.4256)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:30:54\n",
            "\n",
            " Epoch: 624\n",
            "Training loss 0.0629 \tTraining Prec@1 97.804 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5689 \tValidation Prec@1 87.590 \tValidation Prec@5 99.520 \n",
            "\n",
            "lr: 0.03181805608528451\n",
            "o is 1.8862488269805908,  o_a is 1.8862488269805908\n",
            "TRAINING - Epoch: [624][0/196]\tTime 1.721 (1.721)\tData 0.819 (0.819)\tloss 0.0493 (0.0493)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [624][100/196]\tTime 0.412 (0.403)\tData 0.000 (0.009)\tloss 0.0504 (0.0586)\tPrec@1 98.047 (97.973)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [624][0/79]\tTime 0.648 (0.648)\tData 0.478 (0.478)\tloss 0.2062 (0.2062)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:34:21\n",
            "\n",
            " Epoch: 625\n",
            "Training loss 0.0604 \tTraining Prec@1 97.898 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5087 \tValidation Prec@1 87.920 \tValidation Prec@5 99.630 \n",
            "\n",
            "lr: 0.0316712291499189\n",
            "o is 1.8888596296310425,  o_a is 1.8888596296310425\n",
            "TRAINING - Epoch: [625][0/196]\tTime 2.046 (2.046)\tData 0.778 (0.778)\tloss 0.0213 (0.0213)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [625][100/196]\tTime 0.365 (0.409)\tData 0.000 (0.008)\tloss 0.0745 (0.0591)\tPrec@1 96.484 (97.900)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [625][0/79]\tTime 0.558 (0.558)\tData 0.435 (0.435)\tloss 0.4260 (0.4260)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:43:46\n",
            "\n",
            " Epoch: 626\n",
            "Training loss 0.0584 \tTraining Prec@1 97.954 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5377 \tValidation Prec@1 88.490 \tValidation Prec@5 99.530 \n",
            "\n",
            "lr: 0.03152458458659076\n",
            "o is 1.8914730548858643,  o_a is 1.8914730548858643\n",
            "TRAINING - Epoch: [626][0/196]\tTime 2.603 (2.603)\tData 1.461 (1.461)\tloss 0.0677 (0.0677)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [626][100/196]\tTime 0.364 (0.405)\tData 0.000 (0.015)\tloss 0.0529 (0.0644)\tPrec@1 98.438 (97.618)\tPrec@5 100.000 (99.992)\n",
            "EVALUATING - Epoch: [626][0/79]\tTime 0.871 (0.871)\tData 0.654 (0.654)\tloss 0.3473 (0.3473)\tPrec@1 88.281 (88.281)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:39:53\n",
            "\n",
            " Epoch: 627\n",
            "Training loss 0.0622 \tTraining Prec@1 97.738 \tTraining Prec@5 99.994 \n",
            "Validation loss 0.5691 \tValidation Prec@1 87.850 \tValidation Prec@5 99.520 \n",
            "\n",
            "lr: 0.031378123854271134\n",
            "o is 1.8940892219543457,  o_a is 1.8940892219543457\n",
            "TRAINING - Epoch: [627][0/196]\tTime 1.797 (1.797)\tData 1.005 (1.005)\tloss 0.0679 (0.0679)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [627][100/196]\tTime 0.455 (0.400)\tData 0.000 (0.011)\tloss 0.0506 (0.0597)\tPrec@1 97.656 (97.846)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [627][0/79]\tTime 0.423 (0.423)\tData 0.320 (0.320)\tloss 0.4745 (0.4745)\tPrec@1 89.844 (89.844)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:31:59\n",
            "\n",
            " Epoch: 628\n",
            "Training loss 0.0610 \tTraining Prec@1 97.796 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5245 \tValidation Prec@1 88.400 \tValidation Prec@5 99.560 \n",
            "\n",
            "lr: 0.03123184841010216\n",
            "o is 1.896708369255066,  o_a is 1.896708369255066\n",
            "TRAINING - Epoch: [628][0/196]\tTime 1.738 (1.738)\tData 0.862 (0.862)\tloss 0.0696 (0.0696)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [628][100/196]\tTime 0.417 (0.402)\tData 0.000 (0.010)\tloss 0.0437 (0.0587)\tPrec@1 98.438 (97.977)\tPrec@5 100.000 (99.992)\n",
            "EVALUATING - Epoch: [628][0/79]\tTime 0.455 (0.455)\tData 0.323 (0.323)\tloss 0.2957 (0.2957)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:33:05\n",
            "\n",
            " Epoch: 629\n",
            "Training loss 0.0582 \tTraining Prec@1 97.980 \tTraining Prec@5 99.996 \n",
            "Validation loss 0.5220 \tValidation Prec@1 88.700 \tValidation Prec@5 99.500 \n",
            "\n",
            "lr: 0.031085759709382498\n",
            "o is 1.8993300199508667,  o_a is 1.8993300199508667\n",
            "TRAINING - Epoch: [629][0/196]\tTime 2.257 (2.257)\tData 0.828 (0.828)\tloss 0.0378 (0.0378)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [629][100/196]\tTime 0.362 (0.408)\tData 0.001 (0.009)\tloss 0.0414 (0.0576)\tPrec@1 98.438 (97.962)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [629][0/79]\tTime 0.392 (0.392)\tData 0.316 (0.316)\tloss 0.3817 (0.3817)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:42:12\n",
            "\n",
            " Epoch: 630\n",
            "Training loss 0.0587 \tTraining Prec@1 97.944 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.4941 \tValidation Prec@1 88.240 \tValidation Prec@5 99.620 \n",
            "\n",
            "lr: 0.030939859205552915\n",
            "o is 1.9019544124603271,  o_a is 1.9019544124603271\n",
            "TRAINING - Epoch: [630][0/196]\tTime 2.641 (2.641)\tData 1.500 (1.500)\tloss 0.0395 (0.0395)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [630][100/196]\tTime 0.365 (0.404)\tData 0.000 (0.016)\tloss 0.1248 (0.0599)\tPrec@1 96.484 (97.915)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [630][0/79]\tTime 0.826 (0.826)\tData 0.590 (0.590)\tloss 0.3547 (0.3547)\tPrec@1 89.844 (89.844)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:39:47\n",
            "\n",
            " Epoch: 631\n",
            "Training loss 0.0584 \tTraining Prec@1 97.980 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5168 \tValidation Prec@1 88.600 \tValidation Prec@5 99.550 \n",
            "\n",
            "lr: 0.030794148350181783\n",
            "o is 1.9045815467834473,  o_a is 1.9045815467834473\n",
            "TRAINING - Epoch: [631][0/196]\tTime 1.765 (1.765)\tData 0.931 (0.931)\tloss 0.0727 (0.0727)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [631][100/196]\tTime 0.435 (0.397)\tData 0.008 (0.010)\tloss 0.0627 (0.0615)\tPrec@1 98.438 (97.834)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [631][0/79]\tTime 0.596 (0.596)\tData 0.471 (0.471)\tloss 0.3575 (0.3575)\tPrec@1 88.281 (88.281)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:29:29\n",
            "\n",
            " Epoch: 632\n",
            "Training loss 0.0605 \tTraining Prec@1 97.896 \tTraining Prec@5 99.996 \n",
            "Validation loss 0.5525 \tValidation Prec@1 87.880 \tValidation Prec@5 99.590 \n",
            "\n",
            "lr: 0.030648628592950672\n",
            "o is 1.907211422920227,  o_a is 1.907211422920227\n",
            "TRAINING - Epoch: [632][0/196]\tTime 1.739 (1.739)\tData 0.915 (0.915)\tloss 0.0465 (0.0465)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [632][100/196]\tTime 0.424 (0.404)\tData 0.000 (0.010)\tloss 0.1171 (0.0629)\tPrec@1 96.094 (97.776)\tPrec@5 100.000 (99.988)\n",
            "EVALUATING - Epoch: [632][0/79]\tTime 0.511 (0.511)\tData 0.368 (0.368)\tloss 0.3540 (0.3540)\tPrec@1 89.844 (89.844)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:33:33\n",
            "\n",
            " Epoch: 633\n",
            "Training loss 0.0605 \tTraining Prec@1 97.856 \tTraining Prec@5 99.994 \n",
            "Validation loss 0.5733 \tValidation Prec@1 87.550 \tValidation Prec@5 99.470 \n",
            "\n",
            "lr: 0.030503301381639893\n",
            "o is 1.909843921661377,  o_a is 1.909843921661377\n",
            "TRAINING - Epoch: [633][0/196]\tTime 2.223 (2.223)\tData 0.998 (0.998)\tloss 0.0737 (0.0737)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [633][100/196]\tTime 0.364 (0.411)\tData 0.000 (0.011)\tloss 0.0719 (0.0623)\tPrec@1 98.047 (97.830)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [633][0/79]\tTime 0.529 (0.529)\tData 0.434 (0.434)\tloss 0.2986 (0.2986)\tPrec@1 89.844 (89.844)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:23\tTime of Finish: 2023-11-27 09:46:38\n",
            "\n",
            " Epoch: 634\n",
            "Training loss 0.0611 \tTraining Prec@1 97.852 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5598 \tValidation Prec@1 87.540 \tValidation Prec@5 99.580 \n",
            "\n",
            "lr: 0.030358168162114164\n",
            "o is 1.912479043006897,  o_a is 1.912479043006897\n",
            "TRAINING - Epoch: [634][0/196]\tTime 2.442 (2.442)\tData 1.430 (1.430)\tloss 0.0748 (0.0748)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [634][100/196]\tTime 0.365 (0.402)\tData 0.000 (0.015)\tloss 0.0577 (0.0566)\tPrec@1 98.047 (98.000)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [634][0/79]\tTime 0.977 (0.977)\tData 0.780 (0.780)\tloss 0.3859 (0.3859)\tPrec@1 89.844 (89.844)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:38:57\n",
            "\n",
            " Epoch: 635\n",
            "Training loss 0.0592 \tTraining Prec@1 97.924 \tTraining Prec@5 99.996 \n",
            "Validation loss 0.5509 \tValidation Prec@1 87.940 \tValidation Prec@5 99.590 \n",
            "\n",
            "lr: 0.03021323037830808\n",
            "o is 1.9151169061660767,  o_a is 1.9151169061660767\n",
            "TRAINING - Epoch: [635][0/196]\tTime 1.888 (1.888)\tData 0.824 (0.824)\tloss 0.0509 (0.0509)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [635][100/196]\tTime 0.439 (0.399)\tData 0.003 (0.009)\tloss 0.0937 (0.0583)\tPrec@1 95.703 (97.904)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [635][0/79]\tTime 0.520 (0.520)\tData 0.367 (0.367)\tloss 0.3045 (0.3045)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:31:04\n",
            "\n",
            " Epoch: 636\n",
            "Training loss 0.0582 \tTraining Prec@1 97.938 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5421 \tValidation Prec@1 87.960 \tValidation Prec@5 99.420 \n",
            "\n",
            "lr: 0.03006848947221194\n",
            "o is 1.917757511138916,  o_a is 1.917757511138916\n",
            "TRAINING - Epoch: [636][0/196]\tTime 1.790 (1.790)\tData 0.987 (0.987)\tloss 0.0764 (0.0764)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [636][100/196]\tTime 0.405 (0.403)\tData 0.000 (0.011)\tloss 0.0231 (0.0608)\tPrec@1 99.609 (97.927)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [636][0/79]\tTime 0.353 (0.353)\tData 0.282 (0.282)\tloss 0.2425 (0.2425)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:33:25\n",
            "\n",
            " Epoch: 637\n",
            "Training loss 0.0610 \tTraining Prec@1 97.868 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5026 \tValidation Prec@1 87.920 \tValidation Prec@5 99.670 \n",
            "\n",
            "lr: 0.02992394688385722\n",
            "o is 1.920400857925415,  o_a is 1.920400857925415\n",
            "TRAINING - Epoch: [637][0/196]\tTime 2.338 (2.338)\tData 1.047 (1.047)\tloss 0.0986 (0.0986)\tPrec@1 96.484 (96.484)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [637][100/196]\tTime 0.366 (0.409)\tData 0.000 (0.011)\tloss 0.0275 (0.0583)\tPrec@1 98.828 (97.927)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [637][0/79]\tTime 0.405 (0.405)\tData 0.302 (0.302)\tloss 0.3038 (0.3038)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:42:16\n",
            "\n",
            " Epoch: 638\n",
            "Training loss 0.0583 \tTraining Prec@1 97.940 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5546 \tValidation Prec@1 87.900 \tValidation Prec@5 99.480 \n",
            "\n",
            "lr: 0.029779604051302366\n",
            "o is 1.923046588897705,  o_a is 1.923046588897705\n",
            "TRAINING - Epoch: [638][0/196]\tTime 2.699 (2.699)\tData 1.556 (1.556)\tloss 0.0324 (0.0324)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [638][100/196]\tTime 0.365 (0.405)\tData 0.000 (0.016)\tloss 0.0797 (0.0577)\tPrec@1 97.266 (97.981)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [638][0/79]\tTime 0.976 (0.976)\tData 0.771 (0.771)\tloss 0.2875 (0.2875)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:40:21\n",
            "\n",
            " Epoch: 639\n",
            "Training loss 0.0592 \tTraining Prec@1 97.916 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.4980 \tValidation Prec@1 88.500 \tValidation Prec@5 99.670 \n",
            "\n",
            "lr: 0.02963546241061849\n",
            "o is 1.9256951808929443,  o_a is 1.9256951808929443\n",
            "TRAINING - Epoch: [639][0/196]\tTime 1.788 (1.788)\tData 0.888 (0.888)\tloss 0.0428 (0.0428)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [639][100/196]\tTime 0.405 (0.399)\tData 0.000 (0.010)\tloss 0.0708 (0.0555)\tPrec@1 96.875 (98.055)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [639][0/79]\tTime 0.476 (0.476)\tData 0.332 (0.332)\tloss 0.3161 (0.3161)\tPrec@1 89.062 (89.062)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:31:20\n",
            "\n",
            " Epoch: 640\n",
            "Training loss 0.0543 \tTraining Prec@1 98.048 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5409 \tValidation Prec@1 88.040 \tValidation Prec@5 99.590 \n",
            "\n",
            "lr: 0.029491523395874936\n",
            "o is 1.9283465147018433,  o_a is 1.9283465147018433\n",
            "TRAINING - Epoch: [640][0/196]\tTime 1.766 (1.766)\tData 0.878 (0.878)\tloss 0.0806 (0.0806)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [640][100/196]\tTime 0.433 (0.405)\tData 0.000 (0.009)\tloss 0.0620 (0.0569)\tPrec@1 98.438 (97.966)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [640][0/79]\tTime 0.548 (0.548)\tData 0.389 (0.389)\tloss 0.3746 (0.3746)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:33:08\n",
            "\n",
            " Epoch: 641\n",
            "Training loss 0.0573 \tTraining Prec@1 97.938 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5380 \tValidation Prec@1 88.270 \tValidation Prec@5 99.560 \n",
            "\n",
            "lr: 0.0293477884391252\n",
            "o is 1.9310002326965332,  o_a is 1.9310002326965332\n",
            "TRAINING - Epoch: [641][0/196]\tTime 1.837 (1.837)\tData 1.012 (1.012)\tloss 0.0433 (0.0433)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [641][100/196]\tTime 0.363 (0.404)\tData 0.001 (0.011)\tloss 0.0970 (0.0556)\tPrec@1 96.875 (98.113)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [641][0/79]\tTime 0.407 (0.407)\tData 0.297 (0.297)\tloss 0.2931 (0.2931)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:34:48\n",
            "\n",
            " Epoch: 642\n",
            "Training loss 0.0576 \tTraining Prec@1 97.992 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5460 \tValidation Prec@1 87.720 \tValidation Prec@5 99.530 \n",
            "\n",
            "lr: 0.029204258970392576\n",
            "o is 1.933656930923462,  o_a is 1.933656930923462\n",
            "TRAINING - Epoch: [642][0/196]\tTime 2.807 (2.807)\tData 1.406 (1.406)\tloss 0.0387 (0.0387)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [642][100/196]\tTime 0.362 (0.407)\tData 0.001 (0.015)\tloss 0.0520 (0.0575)\tPrec@1 97.266 (98.031)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [642][0/79]\tTime 0.829 (0.829)\tData 0.617 (0.617)\tloss 0.2805 (0.2805)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:42:55\n",
            "\n",
            " Epoch: 643\n",
            "Training loss 0.0574 \tTraining Prec@1 98.042 \tTraining Prec@5 99.996 \n",
            "Validation loss 0.5264 \tValidation Prec@1 88.200 \tValidation Prec@5 99.530 \n",
            "\n",
            "lr: 0.029060936417655947\n",
            "o is 1.936315894126892,  o_a is 1.936315894126892\n",
            "TRAINING - Epoch: [643][0/196]\tTime 1.749 (1.749)\tData 0.905 (0.905)\tloss 0.0431 (0.0431)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [643][100/196]\tTime 0.418 (0.396)\tData 0.000 (0.010)\tloss 0.0804 (0.0573)\tPrec@1 96.484 (98.043)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [643][0/79]\tTime 0.531 (0.531)\tData 0.441 (0.441)\tloss 0.3477 (0.3477)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:29:17\n",
            "\n",
            " Epoch: 644\n",
            "Training loss 0.0559 \tTraining Prec@1 98.068 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5211 \tValidation Prec@1 88.610 \tValidation Prec@5 99.410 \n",
            "\n",
            "lr: 0.028917822206835583\n",
            "o is 1.9389777183532715,  o_a is 1.9389777183532715\n",
            "TRAINING - Epoch: [644][0/196]\tTime 1.766 (1.766)\tData 0.688 (0.688)\tloss 0.0472 (0.0472)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [644][100/196]\tTime 0.430 (0.400)\tData 0.000 (0.007)\tloss 0.0472 (0.0581)\tPrec@1 98.438 (97.973)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [644][0/79]\tTime 0.505 (0.505)\tData 0.362 (0.362)\tloss 0.3305 (0.3305)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:31:52\n",
            "\n",
            " Epoch: 645\n",
            "Training loss 0.0560 \tTraining Prec@1 98.024 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5184 \tValidation Prec@1 88.540 \tValidation Prec@5 99.720 \n",
            "\n",
            "lr: 0.028774917761778963\n",
            "o is 1.9416420459747314,  o_a is 1.9416420459747314\n",
            "TRAINING - Epoch: [645][0/196]\tTime 1.804 (1.804)\tData 1.034 (1.034)\tloss 0.0362 (0.0362)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [645][100/196]\tTime 0.364 (0.405)\tData 0.000 (0.011)\tloss 0.0583 (0.0524)\tPrec@1 98.828 (98.140)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [645][0/79]\tTime 0.487 (0.487)\tData 0.433 (0.433)\tloss 0.2916 (0.2916)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:34:12\n",
            "\n",
            " Epoch: 646\n",
            "Training loss 0.0526 \tTraining Prec@1 98.202 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.6320 \tValidation Prec@1 86.700 \tValidation Prec@5 99.510 \n",
            "\n",
            "lr: 0.028632224504246573\n",
            "o is 1.944309115409851,  o_a is 1.944309115409851\n",
            "TRAINING - Epoch: [646][0/196]\tTime 2.862 (2.862)\tData 1.418 (1.418)\tloss 0.0321 (0.0321)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [646][100/196]\tTime 0.363 (0.412)\tData 0.000 (0.015)\tloss 0.0472 (0.0545)\tPrec@1 97.656 (98.175)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [646][0/79]\tTime 0.533 (0.533)\tData 0.425 (0.425)\tloss 0.4280 (0.4280)\tPrec@1 88.281 (88.281)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:23\tTime of Finish: 2023-11-27 09:47:25\n",
            "\n",
            " Epoch: 647\n",
            "Training loss 0.0558 \tTraining Prec@1 98.082 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5251 \tValidation Prec@1 87.450 \tValidation Prec@5 99.540 \n",
            "\n",
            "lr: 0.028489743853897832\n",
            "o is 1.9469786882400513,  o_a is 1.9469786882400513\n",
            "TRAINING - Epoch: [647][0/196]\tTime 2.584 (2.584)\tData 1.538 (1.538)\tloss 0.0480 (0.0480)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [647][100/196]\tTime 0.363 (0.404)\tData 0.000 (0.016)\tloss 0.0290 (0.0527)\tPrec@1 99.219 (98.097)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [647][0/79]\tTime 1.020 (1.020)\tData 0.818 (0.818)\tloss 0.3138 (0.3138)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:40:10\n",
            "\n",
            " Epoch: 648\n",
            "Training loss 0.0530 \tTraining Prec@1 98.096 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5528 \tValidation Prec@1 87.580 \tValidation Prec@5 99.570 \n",
            "\n",
            "lr: 0.028347477228276886\n",
            "o is 1.949650764465332,  o_a is 1.949650764465332\n",
            "TRAINING - Epoch: [648][0/196]\tTime 1.743 (1.743)\tData 0.779 (0.779)\tloss 0.0409 (0.0409)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [648][100/196]\tTime 0.441 (0.398)\tData 0.000 (0.008)\tloss 0.0455 (0.0518)\tPrec@1 99.219 (98.225)\tPrec@5 100.000 (99.992)\n",
            "EVALUATING - Epoch: [648][0/79]\tTime 0.531 (0.531)\tData 0.438 (0.438)\tloss 0.4034 (0.4034)\tPrec@1 89.844 (89.844)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:29:41\n",
            "\n",
            " Epoch: 649\n",
            "Training loss 0.0519 \tTraining Prec@1 98.184 \tTraining Prec@5 99.996 \n",
            "Validation loss 0.5659 \tValidation Prec@1 87.960 \tValidation Prec@5 99.580 \n",
            "\n",
            "lr: 0.028205426042798545\n",
            "o is 1.9523255825042725,  o_a is 1.9523255825042725\n",
            "TRAINING - Epoch: [649][0/196]\tTime 1.772 (1.772)\tData 0.960 (0.960)\tloss 0.0651 (0.0651)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [649][100/196]\tTime 0.395 (0.402)\tData 0.000 (0.010)\tloss 0.0368 (0.0543)\tPrec@1 98.828 (98.163)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [649][0/79]\tTime 0.423 (0.423)\tData 0.346 (0.346)\tloss 0.3815 (0.3815)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:32:59\n",
            "\n",
            " Epoch: 650\n",
            "Training loss 0.0539 \tTraining Prec@1 98.156 \tTraining Prec@5 99.996 \n",
            "Validation loss 0.5221 \tValidation Prec@1 88.420 \tValidation Prec@5 99.430 \n",
            "\n",
            "lr: 0.028063591710734245\n",
            "o is 1.955002784729004,  o_a is 1.955002784729004\n",
            "TRAINING - Epoch: [650][0/196]\tTime 1.735 (1.735)\tData 0.868 (0.868)\tloss 0.0374 (0.0374)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [650][100/196]\tTime 0.360 (0.404)\tData 0.000 (0.010)\tloss 0.0593 (0.0484)\tPrec@1 98.438 (98.368)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [650][0/79]\tTime 0.357 (0.357)\tData 0.267 (0.267)\tloss 0.4080 (0.4080)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:35:39\n",
            "\n",
            " Epoch: 651\n",
            "Training loss 0.0489 \tTraining Prec@1 98.344 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5242 \tValidation Prec@1 88.670 \tValidation Prec@5 99.570 \n",
            "\n",
            "lr: 0.02792197564319789\n",
            "o is 1.9576829671859741,  o_a is 1.9576829671859741\n",
            "TRAINING - Epoch: [651][0/196]\tTime 2.972 (2.972)\tData 1.509 (1.509)\tloss 0.0749 (0.0749)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [651][100/196]\tTime 0.364 (0.409)\tData 0.000 (0.016)\tloss 0.0625 (0.0523)\tPrec@1 96.875 (98.128)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [651][0/79]\tTime 0.955 (0.955)\tData 0.771 (0.771)\tloss 0.2664 (0.2664)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:43:57\n",
            "\n",
            " Epoch: 652\n",
            "Training loss 0.0534 \tTraining Prec@1 98.072 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5403 \tValidation Prec@1 87.360 \tValidation Prec@5 99.590 \n",
            "\n",
            "lr: 0.02778057924913187\n",
            "o is 1.9603652954101562,  o_a is 1.9603652954101562\n",
            "TRAINING - Epoch: [652][0/196]\tTime 1.765 (1.765)\tData 0.830 (0.830)\tloss 0.0582 (0.0582)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [652][100/196]\tTime 0.472 (0.397)\tData 0.006 (0.009)\tloss 0.0564 (0.0584)\tPrec@1 97.656 (97.985)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [652][0/79]\tTime 0.504 (0.504)\tData 0.427 (0.427)\tloss 0.2522 (0.2522)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:30:37\n",
            "\n",
            " Epoch: 653\n",
            "Training loss 0.0573 \tTraining Prec@1 98.014 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5532 \tValidation Prec@1 87.750 \tValidation Prec@5 99.600 \n",
            "\n",
            "lr: 0.027639403935293072\n",
            "o is 1.963050365447998,  o_a is 1.963050365447998\n",
            "TRAINING - Epoch: [653][0/196]\tTime 1.747 (1.747)\tData 0.832 (0.832)\tloss 0.0979 (0.0979)\tPrec@1 95.703 (95.703)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [653][100/196]\tTime 0.422 (0.402)\tData 0.006 (0.009)\tloss 0.0297 (0.0541)\tPrec@1 99.219 (98.136)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [653][0/79]\tTime 0.451 (0.451)\tData 0.328 (0.328)\tloss 0.3829 (0.3829)\tPrec@1 89.062 (89.062)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:31:29\n",
            "\n",
            " Epoch: 654\n",
            "Training loss 0.0545 \tTraining Prec@1 98.102 \tTraining Prec@5 99.996 \n",
            "Validation loss 0.5435 \tValidation Prec@1 87.720 \tValidation Prec@5 99.620 \n",
            "\n",
            "lr: 0.027498451106238806\n",
            "o is 1.96573805809021,  o_a is 1.96573805809021\n",
            "TRAINING - Epoch: [654][0/196]\tTime 1.621 (1.621)\tData 0.690 (0.690)\tloss 0.0324 (0.0324)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [654][100/196]\tTime 0.370 (0.404)\tData 0.000 (0.008)\tloss 0.0382 (0.0513)\tPrec@1 99.219 (98.190)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [654][0/79]\tTime 0.408 (0.408)\tData 0.303 (0.303)\tloss 0.3002 (0.3002)\tPrec@1 90.625 (90.625)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:33:41\n",
            "\n",
            " Epoch: 655\n",
            "Training loss 0.0539 \tTraining Prec@1 98.072 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5184 \tValidation Prec@1 88.340 \tValidation Prec@5 99.530 \n",
            "\n",
            "lr: 0.027357722164312898\n",
            "o is 1.968428134918213,  o_a is 1.968428134918213\n",
            "TRAINING - Epoch: [655][0/196]\tTime 2.759 (2.759)\tData 1.310 (1.310)\tloss 0.0471 (0.0471)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [655][100/196]\tTime 0.371 (0.410)\tData 0.000 (0.014)\tloss 0.0409 (0.0575)\tPrec@1 99.219 (97.850)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [655][0/79]\tTime 0.368 (0.368)\tData 0.245 (0.245)\tloss 0.4908 (0.4908)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:44:00\n",
            "\n",
            " Epoch: 656\n",
            "Training loss 0.0566 \tTraining Prec@1 97.956 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5488 \tValidation Prec@1 88.030 \tValidation Prec@5 99.580 \n",
            "\n",
            "lr: 0.027217218509631713\n",
            "o is 1.971121072769165,  o_a is 1.971121072769165\n",
            "TRAINING - Epoch: [656][0/196]\tTime 2.667 (2.667)\tData 1.488 (1.488)\tloss 0.0675 (0.0675)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [656][100/196]\tTime 0.362 (0.402)\tData 0.000 (0.016)\tloss 0.0690 (0.0502)\tPrec@1 97.656 (98.221)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [656][0/79]\tTime 0.855 (0.855)\tData 0.651 (0.651)\tloss 0.3186 (0.3186)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:39:01\n",
            "\n",
            " Epoch: 657\n",
            "Training loss 0.0516 \tTraining Prec@1 98.176 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5590 \tValidation Prec@1 88.490 \tValidation Prec@5 99.470 \n",
            "\n",
            "lr: 0.027076941540070218\n",
            "o is 1.973816156387329,  o_a is 1.973816156387329\n",
            "TRAINING - Epoch: [657][0/196]\tTime 1.815 (1.815)\tData 1.027 (1.027)\tloss 0.0566 (0.0566)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [657][100/196]\tTime 0.396 (0.395)\tData 0.000 (0.011)\tloss 0.0736 (0.0500)\tPrec@1 97.656 (98.178)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [657][0/79]\tTime 0.450 (0.450)\tData 0.313 (0.313)\tloss 0.3773 (0.3773)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:28:18\n",
            "\n",
            " Epoch: 658\n",
            "Training loss 0.0502 \tTraining Prec@1 98.214 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5115 \tValidation Prec@1 88.120 \tValidation Prec@5 99.600 \n",
            "\n",
            "lr: 0.026936892651248094\n",
            "o is 1.9765139818191528,  o_a is 1.9765139818191528\n",
            "TRAINING - Epoch: [658][0/196]\tTime 1.732 (1.732)\tData 0.765 (0.765)\tloss 0.0844 (0.0844)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [658][100/196]\tTime 0.426 (0.401)\tData 0.000 (0.008)\tloss 0.1051 (0.0547)\tPrec@1 96.484 (98.132)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [658][0/79]\tTime 0.538 (0.538)\tData 0.430 (0.430)\tloss 0.5199 (0.5199)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:31:05\n",
            "\n",
            " Epoch: 659\n",
            "Training loss 0.0529 \tTraining Prec@1 98.180 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5693 \tValidation Prec@1 87.350 \tValidation Prec@5 99.480 \n",
            "\n",
            "lr: 0.026797073236515832\n",
            "o is 1.9792144298553467,  o_a is 1.9792144298553467\n",
            "TRAINING - Epoch: [659][0/196]\tTime 1.783 (1.783)\tData 0.899 (0.899)\tloss 0.0491 (0.0491)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [659][100/196]\tTime 0.360 (0.405)\tData 0.000 (0.010)\tloss 0.0665 (0.0422)\tPrec@1 96.875 (98.600)\tPrec@5 100.000 (99.992)\n",
            "EVALUATING - Epoch: [659][0/79]\tTime 0.410 (0.410)\tData 0.350 (0.350)\tloss 0.4745 (0.4745)\tPrec@1 87.500 (87.500)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:35:11\n",
            "\n",
            " Epoch: 660\n",
            "Training loss 0.0433 \tTraining Prec@1 98.540 \tTraining Prec@5 99.994 \n",
            "Validation loss 0.5495 \tValidation Prec@1 88.220 \tValidation Prec@5 99.600 \n",
            "\n",
            "lr: 0.02665748468694088\n",
            "o is 1.9819172620773315,  o_a is 1.9819172620773315\n",
            "TRAINING - Epoch: [660][0/196]\tTime 2.889 (2.889)\tData 1.481 (1.481)\tloss 0.0585 (0.0585)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [660][100/196]\tTime 0.362 (0.408)\tData 0.000 (0.015)\tloss 0.0441 (0.0431)\tPrec@1 99.609 (98.457)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [660][0/79]\tTime 0.617 (0.617)\tData 0.465 (0.465)\tloss 0.4604 (0.4604)\tPrec@1 90.625 (90.625)\tPrec@5 98.438 (98.438)\n",
            "Time cost: 01:23\tTime of Finish: 2023-11-27 09:46:54\n",
            "\n",
            " Epoch: 661\n",
            "Training loss 0.0443 \tTraining Prec@1 98.410 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5242 \tValidation Prec@1 88.700 \tValidation Prec@5 99.570 \n",
            "\n",
            "lr: 0.026518128391293794\n",
            "o is 1.9846227169036865,  o_a is 1.9846227169036865\n",
            "TRAINING - Epoch: [661][0/196]\tTime 1.804 (1.804)\tData 0.768 (0.768)\tloss 0.0467 (0.0467)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [661][100/196]\tTime 0.362 (0.395)\tData 0.000 (0.008)\tloss 0.0584 (0.0477)\tPrec@1 98.438 (98.349)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [661][0/79]\tTime 0.880 (0.880)\tData 0.663 (0.663)\tloss 0.3425 (0.3425)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:32:47\n",
            "\n",
            " Epoch: 662\n",
            "Training loss 0.0471 \tTraining Prec@1 98.374 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5698 \tValidation Prec@1 88.020 \tValidation Prec@5 99.560 \n",
            "\n",
            "lr: 0.02637900573603447\n",
            "o is 1.9873303174972534,  o_a is 1.9873303174972534\n",
            "TRAINING - Epoch: [662][0/196]\tTime 1.809 (1.809)\tData 0.933 (0.933)\tloss 0.0313 (0.0313)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [662][100/196]\tTime 0.442 (0.398)\tData 0.000 (0.010)\tloss 0.0575 (0.0475)\tPrec@1 98.047 (98.302)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [662][0/79]\tTime 0.516 (0.516)\tData 0.365 (0.365)\tloss 0.5031 (0.5031)\tPrec@1 86.719 (86.719)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:29:16\n",
            "\n",
            " Epoch: 663\n",
            "Training loss 0.0486 \tTraining Prec@1 98.266 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5128 \tValidation Prec@1 88.250 \tValidation Prec@5 99.590 \n",
            "\n",
            "lr: 0.026240118105298256\n",
            "o is 1.9900407791137695,  o_a is 1.9900407791137695\n",
            "TRAINING - Epoch: [663][0/196]\tTime 1.784 (1.784)\tData 0.932 (0.932)\tloss 0.0584 (0.0584)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [663][100/196]\tTime 0.432 (0.402)\tData 0.000 (0.010)\tloss 0.0430 (0.0445)\tPrec@1 98.438 (98.472)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [663][0/79]\tTime 0.554 (0.554)\tData 0.410 (0.410)\tloss 0.4304 (0.4304)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:31:33\n",
            "\n",
            " Epoch: 664\n",
            "Training loss 0.0464 \tTraining Prec@1 98.384 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5208 \tValidation Prec@1 88.030 \tValidation Prec@5 99.550 \n",
            "\n",
            "lr: 0.026101466880882274\n",
            "o is 1.9927536249160767,  o_a is 1.9927536249160767\n",
            "TRAINING - Epoch: [664][0/196]\tTime 1.984 (1.984)\tData 1.006 (1.006)\tloss 0.0453 (0.0453)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [664][100/196]\tTime 0.359 (0.407)\tData 0.000 (0.011)\tloss 0.0609 (0.0453)\tPrec@1 97.656 (98.461)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [664][0/79]\tTime 0.460 (0.460)\tData 0.324 (0.324)\tloss 0.3618 (0.3618)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:36:39\n",
            "\n",
            " Epoch: 665\n",
            "Training loss 0.0458 \tTraining Prec@1 98.436 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5598 \tValidation Prec@1 87.930 \tValidation Prec@5 99.610 \n",
            "\n",
            "lr: 0.025963053442231553\n",
            "o is 1.995469093322754,  o_a is 1.995469093322754\n",
            "TRAINING - Epoch: [665][0/196]\tTime 2.877 (2.877)\tData 1.454 (1.454)\tloss 0.0446 (0.0446)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [665][100/196]\tTime 0.360 (0.407)\tData 0.000 (0.015)\tloss 0.0525 (0.0515)\tPrec@1 98.438 (98.302)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [665][0/79]\tTime 0.869 (0.869)\tData 0.654 (0.654)\tloss 0.4452 (0.4452)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:41:52\n",
            "\n",
            " Epoch: 666\n",
            "Training loss 0.0487 \tTraining Prec@1 98.364 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5182 \tValidation Prec@1 88.800 \tValidation Prec@5 99.560 \n",
            "\n",
            "lr: 0.025824879166425514\n",
            "o is 1.9981869459152222,  o_a is 1.9981869459152222\n",
            "TRAINING - Epoch: [666][0/196]\tTime 1.675 (1.675)\tData 0.798 (0.798)\tloss 0.0391 (0.0391)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [666][100/196]\tTime 0.447 (0.397)\tData 0.000 (0.009)\tloss 0.0756 (0.0435)\tPrec@1 97.266 (98.511)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [666][0/79]\tTime 0.419 (0.419)\tData 0.307 (0.307)\tloss 0.4565 (0.4565)\tPrec@1 89.844 (89.844)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:29:33\n",
            "\n",
            " Epoch: 667\n",
            "Training loss 0.0484 \tTraining Prec@1 98.322 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5647 \tValidation Prec@1 87.570 \tValidation Prec@5 99.510 \n",
            "\n",
            "lr: 0.02568694542816404\n",
            "o is 2.0009069442749023,  o_a is 2.0009069442749023\n",
            "TRAINING - Epoch: [667][0/196]\tTime 1.775 (1.775)\tData 0.938 (0.938)\tloss 0.0520 (0.0520)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [667][100/196]\tTime 0.417 (0.402)\tData 0.000 (0.010)\tloss 0.0687 (0.0520)\tPrec@1 98.047 (98.205)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [667][0/79]\tTime 0.473 (0.473)\tData 0.325 (0.325)\tloss 0.3687 (0.3687)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:31:00\n",
            "\n",
            " Epoch: 668\n",
            "Training loss 0.0476 \tTraining Prec@1 98.336 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5859 \tValidation Prec@1 88.060 \tValidation Prec@5 99.550 \n",
            "\n",
            "lr: 0.02554925359975394\n",
            "o is 2.003629684448242,  o_a is 2.003629684448242\n",
            "TRAINING - Epoch: [668][0/196]\tTime 1.778 (1.778)\tData 0.857 (0.857)\tloss 0.0328 (0.0328)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [668][100/196]\tTime 0.362 (0.404)\tData 0.001 (0.009)\tloss 0.0578 (0.0453)\tPrec@1 97.656 (98.523)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [668][0/79]\tTime 0.464 (0.464)\tData 0.331 (0.331)\tloss 0.2719 (0.2719)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:33:06\n",
            "\n",
            " Epoch: 669\n",
            "Training loss 0.0467 \tTraining Prec@1 98.386 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5403 \tValidation Prec@1 88.310 \tValidation Prec@5 99.500 \n",
            "\n",
            "lr: 0.02541180505109524\n",
            "o is 2.006355047225952,  o_a is 2.006355047225952\n",
            "TRAINING - Epoch: [669][0/196]\tTime 2.840 (2.840)\tData 1.491 (1.491)\tloss 0.0360 (0.0360)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [669][100/196]\tTime 0.360 (0.407)\tData 0.000 (0.016)\tloss 0.0414 (0.0470)\tPrec@1 98.047 (98.321)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [669][0/79]\tTime 0.792 (0.792)\tData 0.537 (0.537)\tloss 0.3214 (0.3214)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:23\tTime of Finish: 2023-11-27 09:45:17\n",
            "\n",
            " Epoch: 670\n",
            "Training loss 0.0475 \tTraining Prec@1 98.336 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5530 \tValidation Prec@1 88.090 \tValidation Prec@5 99.580 \n",
            "\n",
            "lr: 0.02527460114966757\n",
            "o is 2.009082794189453,  o_a is 2.009082794189453\n",
            "TRAINING - Epoch: [670][0/196]\tTime 1.807 (1.807)\tData 0.867 (0.867)\tloss 0.0873 (0.0873)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [670][100/196]\tTime 0.361 (0.393)\tData 0.000 (0.009)\tloss 0.0608 (0.0453)\tPrec@1 96.875 (98.430)\tPrec@5 100.000 (99.992)\n",
            "EVALUATING - Epoch: [670][0/79]\tTime 0.898 (0.898)\tData 0.644 (0.644)\tloss 0.3109 (0.3109)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:31:47\n",
            "\n",
            " Epoch: 671\n",
            "Training loss 0.0450 \tTraining Prec@1 98.414 \tTraining Prec@5 99.996 \n",
            "Validation loss 0.5271 \tValidation Prec@1 88.220 \tValidation Prec@5 99.660 \n",
            "\n",
            "lr: 0.02513764326051657\n",
            "o is 2.011812686920166,  o_a is 2.011812686920166\n",
            "TRAINING - Epoch: [671][0/196]\tTime 1.705 (1.705)\tData 0.979 (0.979)\tloss 0.0673 (0.0673)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [671][100/196]\tTime 0.451 (0.393)\tData 0.000 (0.011)\tloss 0.0321 (0.0466)\tPrec@1 98.828 (98.376)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [671][0/79]\tTime 0.524 (0.524)\tData 0.417 (0.417)\tloss 0.3222 (0.3222)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:25:22\n",
            "\n",
            " Epoch: 672\n",
            "Training loss 0.0457 \tTraining Prec@1 98.366 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5284 \tValidation Prec@1 88.210 \tValidation Prec@5 99.450 \n",
            "\n",
            "lr: 0.025000932746240257\n",
            "o is 2.014545440673828,  o_a is 2.014545440673828\n",
            "TRAINING - Epoch: [672][0/196]\tTime 1.735 (1.735)\tData 0.909 (0.909)\tloss 0.1007 (0.1007)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [672][100/196]\tTime 0.449 (0.398)\tData 0.003 (0.010)\tloss 0.0387 (0.0467)\tPrec@1 99.609 (98.376)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [672][0/79]\tTime 0.475 (0.475)\tData 0.334 (0.334)\tloss 0.3885 (0.3885)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:28:47\n",
            "\n",
            " Epoch: 673\n",
            "Training loss 0.0461 \tTraining Prec@1 98.396 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5342 \tValidation Prec@1 88.440 \tValidation Prec@5 99.450 \n",
            "\n",
            "lr: 0.024864470966975586\n",
            "o is 2.017280340194702,  o_a is 2.017280340194702\n",
            "TRAINING - Epoch: [673][0/196]\tTime 1.792 (1.792)\tData 0.865 (0.865)\tloss 0.0330 (0.0330)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [673][100/196]\tTime 0.359 (0.401)\tData 0.000 (0.010)\tloss 0.0643 (0.0497)\tPrec@1 97.266 (98.325)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [673][0/79]\tTime 0.300 (0.300)\tData 0.218 (0.218)\tloss 0.2191 (0.2191)\tPrec@1 91.406 (91.406)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:31:03\n",
            "\n",
            " Epoch: 674\n",
            "Training loss 0.0480 \tTraining Prec@1 98.320 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5072 \tValidation Prec@1 88.900 \tValidation Prec@5 99.670 \n",
            "\n",
            "lr: 0.02472825928038479\n",
            "o is 2.0200178623199463,  o_a is 2.0200178623199463\n",
            "TRAINING - Epoch: [674][0/196]\tTime 2.866 (2.866)\tData 1.553 (1.553)\tloss 0.0361 (0.0361)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [674][100/196]\tTime 0.366 (0.407)\tData 0.000 (0.016)\tloss 0.0443 (0.0437)\tPrec@1 98.828 (98.507)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [674][0/79]\tTime 0.543 (0.543)\tData 0.429 (0.429)\tloss 0.2477 (0.2477)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:40:19\n",
            "\n",
            " Epoch: 675\n",
            "Training loss 0.0438 \tTraining Prec@1 98.480 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5771 \tValidation Prec@1 88.120 \tValidation Prec@5 99.450 \n",
            "\n",
            "lr: 0.024592299041641886\n",
            "o is 2.0227575302124023,  o_a is 2.0227575302124023\n",
            "TRAINING - Epoch: [675][0/196]\tTime 2.403 (2.403)\tData 1.431 (1.431)\tloss 0.0304 (0.0304)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [675][100/196]\tTime 0.361 (0.398)\tData 0.000 (0.015)\tloss 0.0291 (0.0393)\tPrec@1 99.219 (98.612)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [675][0/79]\tTime 0.706 (0.706)\tData 0.509 (0.509)\tloss 0.3259 (0.3259)\tPrec@1 92.969 (92.969)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:35:08\n",
            "\n",
            " Epoch: 676\n",
            "Training loss 0.0404 \tTraining Prec@1 98.562 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5255 \tValidation Prec@1 88.760 \tValidation Prec@5 99.660 \n",
            "\n",
            "lr: 0.024456591603419273\n",
            "o is 2.0254998207092285,  o_a is 2.0254998207092285\n",
            "TRAINING - Epoch: [676][0/196]\tTime 1.759 (1.759)\tData 0.825 (0.825)\tloss 0.0377 (0.0377)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [676][100/196]\tTime 0.447 (0.393)\tData 0.000 (0.009)\tloss 0.0410 (0.0419)\tPrec@1 98.828 (98.526)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [676][0/79]\tTime 0.404 (0.404)\tData 0.281 (0.281)\tloss 0.2799 (0.2799)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:27:13\n",
            "\n",
            " Epoch: 677\n",
            "Training loss 0.0437 \tTraining Prec@1 98.414 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5362 \tValidation Prec@1 88.350 \tValidation Prec@5 99.480 \n",
            "\n",
            "lr: 0.02432113831587426\n",
            "o is 2.0282444953918457,  o_a is 2.0282444953918457\n",
            "TRAINING - Epoch: [677][0/196]\tTime 1.771 (1.771)\tData 0.977 (0.977)\tloss 0.0220 (0.0220)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [677][100/196]\tTime 0.411 (0.399)\tData 0.000 (0.010)\tloss 0.0382 (0.0431)\tPrec@1 99.219 (98.488)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [677][0/79]\tTime 0.401 (0.401)\tData 0.279 (0.279)\tloss 0.3017 (0.3017)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:29:52\n",
            "\n",
            " Epoch: 678\n",
            "Training loss 0.0435 \tTraining Prec@1 98.464 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5390 \tValidation Prec@1 88.460 \tValidation Prec@5 99.620 \n",
            "\n",
            "lr: 0.024185940526635544\n",
            "o is 2.030991554260254,  o_a is 2.030991554260254\n",
            "TRAINING - Epoch: [678][0/196]\tTime 1.767 (1.767)\tData 0.875 (0.875)\tloss 0.0244 (0.0244)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [678][100/196]\tTime 0.361 (0.403)\tData 0.000 (0.009)\tloss 0.0314 (0.0433)\tPrec@1 98.828 (98.584)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [678][0/79]\tTime 0.371 (0.371)\tData 0.329 (0.329)\tloss 0.5434 (0.5434)\tPrec@1 87.500 (87.500)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:31:11\n",
            "\n",
            " Epoch: 679\n",
            "Training loss 0.0457 \tTraining Prec@1 98.430 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.6310 \tValidation Prec@1 86.930 \tValidation Prec@5 99.330 \n",
            "\n",
            "lr: 0.024050999580789916\n",
            "o is 2.033740997314453,  o_a is 2.033740997314453\n",
            "TRAINING - Epoch: [679][0/196]\tTime 2.251 (2.251)\tData 0.980 (0.980)\tloss 0.0382 (0.0382)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [679][100/196]\tTime 0.362 (0.406)\tData 0.000 (0.011)\tloss 0.0638 (0.0419)\tPrec@1 97.656 (98.530)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [679][0/79]\tTime 0.471 (0.471)\tData 0.317 (0.317)\tloss 0.4132 (0.4132)\tPrec@1 89.844 (89.844)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:40:08\n",
            "\n",
            " Epoch: 680\n",
            "Training loss 0.0452 \tTraining Prec@1 98.390 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5686 \tValidation Prec@1 88.060 \tValidation Prec@5 99.590 \n",
            "\n",
            "lr: 0.023916316820868738\n",
            "o is 2.0364928245544434,  o_a is 2.0364928245544434\n",
            "TRAINING - Epoch: [680][0/196]\tTime 2.671 (2.671)\tData 1.472 (1.472)\tloss 0.0630 (0.0630)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [680][100/196]\tTime 0.359 (0.403)\tData 0.000 (0.015)\tloss 0.0351 (0.0423)\tPrec@1 98.828 (98.538)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [680][0/79]\tTime 0.831 (0.831)\tData 0.601 (0.601)\tloss 0.5010 (0.5010)\tPrec@1 85.156 (85.156)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:39:44\n",
            "\n",
            " Epoch: 681\n",
            "Training loss 0.0452 \tTraining Prec@1 98.442 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5852 \tValidation Prec@1 86.890 \tValidation Prec@5 99.350 \n",
            "\n",
            "lr: 0.023781893586834784\n",
            "o is 2.0392467975616455,  o_a is 2.0392467975616455\n",
            "TRAINING - Epoch: [681][0/196]\tTime 1.765 (1.765)\tData 0.854 (0.854)\tloss 0.0209 (0.0209)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [681][100/196]\tTime 0.428 (0.395)\tData 0.000 (0.009)\tloss 0.0923 (0.0455)\tPrec@1 95.703 (98.507)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [681][0/79]\tTime 0.555 (0.555)\tData 0.414 (0.414)\tloss 0.2570 (0.2570)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:29:03\n",
            "\n",
            " Epoch: 682\n",
            "Training loss 0.0448 \tTraining Prec@1 98.480 \tTraining Prec@5 99.996 \n",
            "Validation loss 0.5199 \tValidation Prec@1 88.640 \tValidation Prec@5 99.510 \n",
            "\n",
            "lr: 0.023647731216068727\n",
            "o is 2.0420033931732178,  o_a is 2.0420033931732178\n",
            "TRAINING - Epoch: [682][0/196]\tTime 1.790 (1.790)\tData 0.863 (0.863)\tloss 0.0635 (0.0635)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [682][100/196]\tTime 0.418 (0.400)\tData 0.000 (0.009)\tloss 0.0199 (0.0414)\tPrec@1 99.609 (98.573)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [682][0/79]\tTime 0.419 (0.419)\tData 0.344 (0.344)\tloss 0.4676 (0.4676)\tPrec@1 89.844 (89.844)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:31:06\n",
            "\n",
            " Epoch: 683\n",
            "Training loss 0.0417 \tTraining Prec@1 98.536 \tTraining Prec@5 99.996 \n",
            "Validation loss 0.5338 \tValidation Prec@1 88.590 \tValidation Prec@5 99.610 \n",
            "\n",
            "lr: 0.0235138310433559\n",
            "o is 2.044762372970581,  o_a is 2.044762372970581\n",
            "TRAINING - Epoch: [683][0/196]\tTime 1.740 (1.740)\tData 0.766 (0.766)\tloss 0.0633 (0.0633)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [683][100/196]\tTime 0.360 (0.403)\tData 0.000 (0.009)\tloss 0.0354 (0.0422)\tPrec@1 99.219 (98.554)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [683][0/79]\tTime 0.528 (0.528)\tData 0.402 (0.402)\tloss 0.3165 (0.3165)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:32:00\n",
            "\n",
            " Epoch: 684\n",
            "Training loss 0.0419 \tTraining Prec@1 98.574 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5238 \tValidation Prec@1 88.480 \tValidation Prec@5 99.520 \n",
            "\n",
            "lr: 0.023380194400873095\n",
            "o is 2.0475237369537354,  o_a is 2.0475237369537354\n",
            "TRAINING - Epoch: [684][0/196]\tTime 2.166 (2.166)\tData 0.917 (0.917)\tloss 0.0316 (0.0316)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [684][100/196]\tTime 0.362 (0.407)\tData 0.000 (0.010)\tloss 0.0428 (0.0414)\tPrec@1 98.438 (98.542)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [684][0/79]\tTime 0.553 (0.553)\tData 0.431 (0.431)\tloss 0.3695 (0.3695)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:37:20\n",
            "\n",
            " Epoch: 685\n",
            "Training loss 0.0411 \tTraining Prec@1 98.580 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5417 \tValidation Prec@1 88.200 \tValidation Prec@5 99.540 \n",
            "\n",
            "lr: 0.023246822618175126\n",
            "o is 2.0502872467041016,  o_a is 2.0502872467041016\n",
            "TRAINING - Epoch: [685][0/196]\tTime 2.935 (2.935)\tData 1.681 (1.681)\tloss 0.0310 (0.0310)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [685][100/196]\tTime 0.360 (0.406)\tData 0.001 (0.017)\tloss 0.0265 (0.0398)\tPrec@1 99.219 (98.716)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [685][0/79]\tTime 0.881 (0.881)\tData 0.675 (0.675)\tloss 0.4843 (0.4843)\tPrec@1 88.281 (88.281)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:43:22\n",
            "\n",
            " Epoch: 686\n",
            "Training loss 0.0398 \tTraining Prec@1 98.616 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5246 \tValidation Prec@1 88.650 \tValidation Prec@5 99.600 \n",
            "\n",
            "lr: 0.023113717022181783\n",
            "o is 2.053053140640259,  o_a is 2.053053140640259\n",
            "TRAINING - Epoch: [686][0/196]\tTime 1.660 (1.660)\tData 0.738 (0.738)\tloss 0.0327 (0.0327)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [686][100/196]\tTime 0.360 (0.394)\tData 0.000 (0.008)\tloss 0.0327 (0.0413)\tPrec@1 98.828 (98.542)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [686][0/79]\tTime 0.850 (0.850)\tData 0.643 (0.643)\tloss 0.3707 (0.3707)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:30:14\n",
            "\n",
            " Epoch: 687\n",
            "Training loss 0.0431 \tTraining Prec@1 98.442 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5318 \tValidation Prec@1 88.590 \tValidation Prec@5 99.600 \n",
            "\n",
            "lr: 0.022980878937164516\n",
            "o is 2.055821418762207,  o_a is 2.055821418762207\n",
            "TRAINING - Epoch: [687][0/196]\tTime 1.424 (1.424)\tData 0.431 (0.431)\tloss 0.0547 (0.0547)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [687][100/196]\tTime 0.422 (0.397)\tData 0.000 (0.005)\tloss 0.0509 (0.0470)\tPrec@1 98.438 (98.387)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [687][0/79]\tTime 0.465 (0.465)\tData 0.351 (0.351)\tloss 0.3874 (0.3874)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:28:54\n",
            "\n",
            " Epoch: 688\n",
            "Training loss 0.0442 \tTraining Prec@1 98.520 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5549 \tValidation Prec@1 87.870 \tValidation Prec@5 99.600 \n",
            "\n",
            "lr: 0.022848309684733354\n",
            "o is 2.0585923194885254,  o_a is 2.0585923194885254\n",
            "TRAINING - Epoch: [688][0/196]\tTime 1.752 (1.752)\tData 0.849 (0.849)\tloss 0.0452 (0.0452)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [688][100/196]\tTime 0.418 (0.401)\tData 0.012 (0.009)\tloss 0.0576 (0.0392)\tPrec@1 98.438 (98.646)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [688][0/79]\tTime 0.543 (0.543)\tData 0.468 (0.468)\tloss 0.3647 (0.3647)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:32:09\n",
            "\n",
            " Epoch: 689\n",
            "Training loss 0.0401 \tTraining Prec@1 98.616 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5872 \tValidation Prec@1 88.130 \tValidation Prec@5 99.530 \n",
            "\n",
            "lr: 0.02271601058382367\n",
            "o is 2.0613651275634766,  o_a is 2.0613651275634766\n",
            "TRAINING - Epoch: [689][0/196]\tTime 2.074 (2.074)\tData 0.868 (0.868)\tloss 0.0232 (0.0232)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [689][100/196]\tTime 0.356 (0.405)\tData 0.000 (0.010)\tloss 0.0350 (0.0420)\tPrec@1 98.828 (98.577)\tPrec@5 100.000 (99.988)\n",
            "EVALUATING - Epoch: [689][0/79]\tTime 0.476 (0.476)\tData 0.344 (0.344)\tloss 0.2810 (0.2810)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:35:22\n",
            "\n",
            " Epoch: 690\n",
            "Training loss 0.0408 \tTraining Prec@1 98.580 \tTraining Prec@5 99.994 \n",
            "Validation loss 0.5425 \tValidation Prec@1 88.580 \tValidation Prec@5 99.570 \n",
            "\n",
            "lr: 0.02258398295068306\n",
            "o is 2.064140558242798,  o_a is 2.064140558242798\n",
            "TRAINING - Epoch: [690][0/196]\tTime 2.760 (2.760)\tData 1.439 (1.439)\tloss 0.0292 (0.0292)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [690][100/196]\tTime 0.358 (0.404)\tData 0.000 (0.015)\tloss 0.0613 (0.0436)\tPrec@1 98.047 (98.557)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [690][0/79]\tTime 0.882 (0.882)\tData 0.643 (0.643)\tloss 0.3954 (0.3954)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:39:51\n",
            "\n",
            " Epoch: 691\n",
            "Training loss 0.0449 \tTraining Prec@1 98.524 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.6000 \tValidation Prec@1 87.830 \tValidation Prec@5 99.500 \n",
            "\n",
            "lr: 0.0224522280988583\n",
            "o is 2.066917896270752,  o_a is 2.066917896270752\n",
            "TRAINING - Epoch: [691][0/196]\tTime 1.732 (1.732)\tData 0.866 (0.866)\tloss 0.0383 (0.0383)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [691][100/196]\tTime 0.401 (0.393)\tData 0.000 (0.009)\tloss 0.0533 (0.0420)\tPrec@1 96.875 (98.561)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [691][0/79]\tTime 0.284 (0.284)\tData 0.215 (0.215)\tloss 0.2433 (0.2433)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:27:57\n",
            "\n",
            " Epoch: 692\n",
            "Training loss 0.0432 \tTraining Prec@1 98.554 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5309 \tValidation Prec@1 88.660 \tValidation Prec@5 99.540 \n",
            "\n",
            "lr: 0.02232074733918232\n",
            "o is 2.069697856903076,  o_a is 2.069697856903076\n",
            "TRAINING - Epoch: [692][0/196]\tTime 1.749 (1.749)\tData 0.842 (0.842)\tloss 0.0353 (0.0353)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [692][100/196]\tTime 0.441 (0.397)\tData 0.000 (0.009)\tloss 0.0341 (0.0387)\tPrec@1 98.047 (98.650)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [692][0/79]\tTime 0.435 (0.435)\tData 0.333 (0.333)\tloss 0.4079 (0.4079)\tPrec@1 89.062 (89.062)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:28:36\n",
            "\n",
            " Epoch: 693\n",
            "Training loss 0.0405 \tTraining Prec@1 98.594 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5704 \tValidation Prec@1 88.210 \tValidation Prec@5 99.460 \n",
            "\n",
            "lr: 0.022189541979761015\n",
            "o is 2.0724802017211914,  o_a is 2.0724802017211914\n",
            "TRAINING - Epoch: [693][0/196]\tTime 1.834 (1.834)\tData 0.931 (0.931)\tloss 0.0840 (0.0840)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [693][100/196]\tTime 0.436 (0.400)\tData 0.000 (0.010)\tloss 0.0280 (0.0428)\tPrec@1 99.609 (98.472)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [693][0/79]\tTime 0.335 (0.335)\tData 0.240 (0.240)\tloss 0.3472 (0.3472)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:29:27\n",
            "\n",
            " Epoch: 694\n",
            "Training loss 0.0423 \tTraining Prec@1 98.510 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5795 \tValidation Prec@1 87.880 \tValidation Prec@5 99.560 \n",
            "\n",
            "lr: 0.022058613325960336\n",
            "o is 2.0752646923065186,  o_a is 2.0752646923065186\n",
            "TRAINING - Epoch: [694][0/196]\tTime 2.021 (2.021)\tData 0.945 (0.945)\tloss 0.0308 (0.0308)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [694][100/196]\tTime 0.360 (0.403)\tData 0.000 (0.010)\tloss 0.0352 (0.0400)\tPrec@1 98.828 (98.608)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [694][0/79]\tTime 0.401 (0.401)\tData 0.319 (0.319)\tloss 0.3220 (0.3220)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:32:23\n",
            "\n",
            " Epoch: 695\n",
            "Training loss 0.0387 \tTraining Prec@1 98.698 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.4980 \tValidation Prec@1 88.650 \tValidation Prec@5 99.560 \n",
            "\n",
            "lr: 0.021927962680393338\n",
            "o is 2.0780510902404785,  o_a is 2.0780510902404785\n",
            "TRAINING - Epoch: [695][0/196]\tTime 2.907 (2.907)\tData 1.474 (1.474)\tloss 0.0247 (0.0247)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [695][100/196]\tTime 0.359 (0.406)\tData 0.000 (0.016)\tloss 0.0470 (0.0375)\tPrec@1 99.609 (98.615)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [695][0/79]\tTime 0.474 (0.474)\tData 0.354 (0.354)\tloss 0.3127 (0.3127)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:43:36\n",
            "\n",
            " Epoch: 696\n",
            "Training loss 0.0413 \tTraining Prec@1 98.502 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5493 \tValidation Prec@1 88.390 \tValidation Prec@5 99.570 \n",
            "\n",
            "lr: 0.021797591342907065\n",
            "o is 2.0808401107788086,  o_a is 2.0808401107788086\n",
            "TRAINING - Epoch: [696][0/196]\tTime 1.928 (1.928)\tData 1.040 (1.040)\tloss 0.0690 (0.0690)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [696][100/196]\tTime 0.355 (0.393)\tData 0.000 (0.011)\tloss 0.0266 (0.0420)\tPrec@1 98.828 (98.542)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [696][0/79]\tTime 0.931 (0.931)\tData 0.683 (0.683)\tloss 0.3573 (0.3573)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:32:10\n",
            "\n",
            " Epoch: 697\n",
            "Training loss 0.0416 \tTraining Prec@1 98.550 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5580 \tValidation Prec@1 88.430 \tValidation Prec@5 99.530 \n",
            "\n",
            "lr: 0.021667500610569785\n",
            "o is 2.0836315155029297,  o_a is 2.0836315155029297\n",
            "TRAINING - Epoch: [697][0/196]\tTime 1.753 (1.753)\tData 0.730 (0.730)\tloss 0.0455 (0.0455)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [697][100/196]\tTime 0.434 (0.393)\tData 0.000 (0.008)\tloss 0.0166 (0.0402)\tPrec@1 99.609 (98.588)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [697][0/79]\tTime 0.578 (0.578)\tData 0.450 (0.450)\tloss 0.3663 (0.3663)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:27:51\n",
            "\n",
            " Epoch: 698\n",
            "Training loss 0.0407 \tTraining Prec@1 98.546 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5088 \tValidation Prec@1 89.110 \tValidation Prec@5 99.630 \n",
            "\n",
            "lr: 0.02153769177765799\n",
            "o is 2.086425304412842,  o_a is 2.086425304412842\n",
            "TRAINING - Epoch: [698][0/196]\tTime 1.732 (1.732)\tData 0.911 (0.911)\tloss 0.0529 (0.0529)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [698][100/196]\tTime 0.442 (0.398)\tData 0.000 (0.010)\tloss 0.0280 (0.0350)\tPrec@1 98.828 (98.789)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [698][0/79]\tTime 0.536 (0.536)\tData 0.397 (0.397)\tloss 0.4252 (0.4252)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:28:42\n",
            "\n",
            " Epoch: 699\n",
            "Training loss 0.0366 \tTraining Prec@1 98.742 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5891 \tValidation Prec@1 87.570 \tValidation Prec@5 99.580 \n",
            "\n",
            "lr: 0.021408166135643596\n",
            "o is 2.0892210006713867,  o_a is 2.0892210006713867\n",
            "TRAINING - Epoch: [699][0/196]\tTime 1.774 (1.774)\tData 1.015 (1.015)\tloss 0.0205 (0.0205)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [699][100/196]\tTime 0.407 (0.401)\tData 0.000 (0.011)\tloss 0.0152 (0.0416)\tPrec@1 99.609 (98.581)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [699][0/79]\tTime 0.490 (0.490)\tData 0.412 (0.412)\tloss 0.3876 (0.3876)\tPrec@1 89.062 (89.062)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:29:35\n",
            "\n",
            " Epoch: 700\n",
            "Training loss 0.0407 \tTraining Prec@1 98.588 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5795 \tValidation Prec@1 88.410 \tValidation Prec@5 99.500 \n",
            "\n",
            "lr: 0.021278924973181\n",
            "o is 2.0920190811157227,  o_a is 2.0920190811157227\n",
            "TRAINING - Epoch: [700][0/196]\tTime 1.929 (1.929)\tData 0.921 (0.921)\tloss 0.0325 (0.0325)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [700][100/196]\tTime 0.359 (0.403)\tData 0.001 (0.010)\tloss 0.0448 (0.0377)\tPrec@1 97.656 (98.681)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [700][0/79]\tTime 0.254 (0.254)\tData 0.197 (0.197)\tloss 0.4474 (0.4474)\tPrec@1 89.062 (89.062)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:31:43\n",
            "\n",
            " Epoch: 701\n",
            "Training loss 0.0393 \tTraining Prec@1 98.614 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5417 \tValidation Prec@1 88.130 \tValidation Prec@5 99.560 \n",
            "\n",
            "lr: 0.02114996957609427\n",
            "o is 2.0948193073272705,  o_a is 2.0948193073272705\n",
            "TRAINING - Epoch: [701][0/196]\tTime 2.827 (2.827)\tData 1.373 (1.373)\tloss 0.0245 (0.0245)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [701][100/196]\tTime 0.359 (0.406)\tData 0.004 (0.014)\tloss 0.0179 (0.0393)\tPrec@1 99.609 (98.673)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [701][0/79]\tTime 0.482 (0.482)\tData 0.347 (0.347)\tloss 0.4568 (0.4568)\tPrec@1 88.281 (88.281)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:41:00\n",
            "\n",
            " Epoch: 702\n",
            "Training loss 0.0389 \tTraining Prec@1 98.674 \tTraining Prec@5 99.996 \n",
            "Validation loss 0.5888 \tValidation Prec@1 87.850 \tValidation Prec@5 99.480 \n",
            "\n",
            "lr: 0.021021301227364442\n",
            "o is 2.0976219177246094,  o_a is 2.0976219177246094\n",
            "TRAINING - Epoch: [702][0/196]\tTime 2.242 (2.242)\tData 1.333 (1.333)\tloss 0.0330 (0.0330)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [702][100/196]\tTime 0.357 (0.396)\tData 0.000 (0.014)\tloss 0.0353 (0.0414)\tPrec@1 98.438 (98.561)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [702][0/79]\tTime 0.877 (0.877)\tData 0.646 (0.646)\tloss 0.4233 (0.4233)\tPrec@1 88.281 (88.281)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:35:26\n",
            "\n",
            " Epoch: 703\n",
            "Training loss 0.0406 \tTraining Prec@1 98.588 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5499 \tValidation Prec@1 87.720 \tValidation Prec@5 99.550 \n",
            "\n",
            "lr: 0.020892921207116704\n",
            "o is 2.10042667388916,  o_a is 2.10042667388916\n",
            "TRAINING - Epoch: [703][0/196]\tTime 1.810 (1.810)\tData 0.956 (0.956)\tloss 0.0309 (0.0309)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [703][100/196]\tTime 0.362 (0.392)\tData 0.000 (0.010)\tloss 0.0389 (0.0392)\tPrec@1 98.828 (98.700)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [703][0/79]\tTime 0.520 (0.520)\tData 0.437 (0.437)\tloss 0.3009 (0.3009)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:26:19\n",
            "\n",
            " Epoch: 704\n",
            "Training loss 0.0371 \tTraining Prec@1 98.742 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5813 \tValidation Prec@1 87.800 \tValidation Prec@5 99.610 \n",
            "\n",
            "lr: 0.02076483079260762\n",
            "o is 2.103233814239502,  o_a is 2.103233814239502\n",
            "TRAINING - Epoch: [704][0/196]\tTime 1.735 (1.735)\tData 0.803 (0.803)\tloss 0.0198 (0.0198)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [704][100/196]\tTime 0.434 (0.397)\tData 0.000 (0.009)\tloss 0.0400 (0.0368)\tPrec@1 98.828 (98.778)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [704][0/79]\tTime 0.440 (0.440)\tData 0.306 (0.306)\tloss 0.3750 (0.3750)\tPrec@1 87.500 (87.500)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:27:56\n",
            "\n",
            " Epoch: 705\n",
            "Training loss 0.0383 \tTraining Prec@1 98.698 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5235 \tValidation Prec@1 88.800 \tValidation Prec@5 99.550 \n",
            "\n",
            "lr: 0.02063703125821248\n",
            "o is 2.1060426235198975,  o_a is 2.1060426235198975\n",
            "TRAINING - Epoch: [705][0/196]\tTime 1.804 (1.804)\tData 1.023 (1.023)\tloss 0.0393 (0.0393)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [705][100/196]\tTime 0.402 (0.400)\tData 0.000 (0.011)\tloss 0.0303 (0.0388)\tPrec@1 98.828 (98.650)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [705][0/79]\tTime 0.516 (0.516)\tData 0.346 (0.346)\tloss 0.4431 (0.4431)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:29:46\n",
            "\n",
            " Epoch: 706\n",
            "Training loss 0.0371 \tTraining Prec@1 98.704 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5494 \tValidation Prec@1 88.760 \tValidation Prec@5 99.490 \n",
            "\n",
            "lr: 0.02050952387541258\n",
            "o is 2.108854293823242,  o_a is 2.108854293823242\n",
            "TRAINING - Epoch: [706][0/196]\tTime 1.635 (1.635)\tData 0.703 (0.703)\tloss 0.0131 (0.0131)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [706][100/196]\tTime 0.358 (0.402)\tData 0.000 (0.008)\tloss 0.0554 (0.0386)\tPrec@1 98.047 (98.642)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [706][0/79]\tTime 0.542 (0.542)\tData 0.436 (0.436)\tloss 0.3333 (0.3333)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:32:43\n",
            "\n",
            " Epoch: 707\n",
            "Training loss 0.0395 \tTraining Prec@1 98.592 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5389 \tValidation Prec@1 88.350 \tValidation Prec@5 99.630 \n",
            "\n",
            "lr: 0.020382309912782618\n",
            "o is 2.1116678714752197,  o_a is 2.1116678714752197\n",
            "TRAINING - Epoch: [707][0/196]\tTime 3.007 (3.007)\tData 1.490 (1.490)\tloss 0.0188 (0.0188)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [707][100/196]\tTime 0.359 (0.407)\tData 0.000 (0.015)\tloss 0.0281 (0.0349)\tPrec@1 98.828 (98.797)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [707][0/79]\tTime 0.601 (0.601)\tData 0.401 (0.401)\tloss 0.3118 (0.3118)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:23\tTime of Finish: 2023-11-27 09:44:03\n",
            "\n",
            " Epoch: 708\n",
            "Training loss 0.0357 \tTraining Prec@1 98.764 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5232 \tValidation Prec@1 88.690 \tValidation Prec@5 99.510 \n",
            "\n",
            "lr: 0.020255390635978025\n",
            "o is 2.114483594894409,  o_a is 2.114483594894409\n",
            "TRAINING - Epoch: [708][0/196]\tTime 1.774 (1.774)\tData 0.906 (0.906)\tloss 0.0465 (0.0465)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [708][100/196]\tTime 0.358 (0.392)\tData 0.000 (0.010)\tloss 0.0310 (0.0357)\tPrec@1 99.219 (98.762)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [708][0/79]\tTime 0.834 (0.834)\tData 0.627 (0.627)\tloss 0.3254 (0.3254)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:32:54\n",
            "\n",
            " Epoch: 709\n",
            "Training loss 0.0353 \tTraining Prec@1 98.776 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5429 \tValidation Prec@1 88.980 \tValidation Prec@5 99.450 \n",
            "\n",
            "lr: 0.020128767307722378\n",
            "o is 2.1173017024993896,  o_a is 2.1173017024993896\n",
            "TRAINING - Epoch: [709][0/196]\tTime 1.853 (1.853)\tData 0.886 (0.886)\tloss 0.0652 (0.0652)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [709][100/196]\tTime 0.396 (0.395)\tData 0.000 (0.010)\tloss 0.0643 (0.0363)\tPrec@1 96.875 (98.724)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [709][0/79]\tTime 0.440 (0.440)\tData 0.305 (0.305)\tloss 0.3308 (0.3308)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:28:14\n",
            "\n",
            " Epoch: 710\n",
            "Training loss 0.0378 \tTraining Prec@1 98.744 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5312 \tValidation Prec@1 89.090 \tValidation Prec@5 99.500 \n",
            "\n",
            "lr: 0.02000244118779493\n",
            "o is 2.120121479034424,  o_a is 2.120121479034424\n",
            "TRAINING - Epoch: [710][0/196]\tTime 1.826 (1.826)\tData 0.906 (0.906)\tloss 0.0498 (0.0498)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [710][100/196]\tTime 0.433 (0.396)\tData 0.000 (0.010)\tloss 0.0330 (0.0373)\tPrec@1 98.828 (98.689)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [710][0/79]\tTime 0.516 (0.516)\tData 0.405 (0.405)\tloss 0.3801 (0.3801)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:28:01\n",
            "\n",
            " Epoch: 711\n",
            "Training loss 0.0351 \tTraining Prec@1 98.796 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5537 \tValidation Prec@1 88.810 \tValidation Prec@5 99.590 \n",
            "\n",
            "lr: 0.0198764135330179\n",
            "o is 2.1229441165924072,  o_a is 2.1229441165924072\n",
            "TRAINING - Epoch: [711][0/196]\tTime 1.814 (1.814)\tData 0.995 (0.995)\tloss 0.0219 (0.0219)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [711][100/196]\tTime 0.414 (0.399)\tData 0.000 (0.011)\tloss 0.0298 (0.0319)\tPrec@1 98.438 (98.917)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [711][0/79]\tTime 0.478 (0.478)\tData 0.344 (0.344)\tloss 0.4008 (0.4008)\tPrec@1 92.188 (92.188)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:30:15\n",
            "\n",
            " Epoch: 712\n",
            "Training loss 0.0319 \tTraining Prec@1 98.924 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5494 \tValidation Prec@1 88.870 \tValidation Prec@5 99.640 \n",
            "\n",
            "lr: 0.019750685597244123\n",
            "o is 2.1257684230804443,  o_a is 2.1257684230804443\n",
            "TRAINING - Epoch: [712][0/196]\tTime 1.832 (1.832)\tData 0.819 (0.819)\tloss 0.0293 (0.0293)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [712][100/196]\tTime 0.358 (0.402)\tData 0.000 (0.009)\tloss 0.0159 (0.0329)\tPrec@1 99.609 (98.944)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [712][0/79]\tTime 0.531 (0.531)\tData 0.371 (0.371)\tloss 0.3112 (0.3112)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:31:08\n",
            "\n",
            " Epoch: 713\n",
            "Training loss 0.0337 \tTraining Prec@1 98.912 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5129 \tValidation Prec@1 89.020 \tValidation Prec@5 99.600 \n",
            "\n",
            "lr: 0.0196252586313445\n",
            "o is 2.1285951137542725,  o_a is 2.1285951137542725\n",
            "TRAINING - Epoch: [713][0/196]\tTime 2.203 (2.203)\tData 0.872 (0.872)\tloss 0.0571 (0.0571)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [713][100/196]\tTime 0.360 (0.403)\tData 0.000 (0.010)\tloss 0.0396 (0.0352)\tPrec@1 98.828 (98.809)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [713][0/79]\tTime 0.515 (0.515)\tData 0.390 (0.390)\tloss 0.2936 (0.2936)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:33:09\n",
            "\n",
            " Epoch: 714\n",
            "Training loss 0.0353 \tTraining Prec@1 98.816 \tTraining Prec@5 99.996 \n",
            "Validation loss 0.5428 \tValidation Prec@1 88.160 \tValidation Prec@5 99.530 \n",
            "\n",
            "lr: 0.01950013388319562\n",
            "o is 2.1314239501953125,  o_a is 2.1314239501953125\n",
            "TRAINING - Epoch: [714][0/196]\tTime 2.934 (2.934)\tData 1.480 (1.480)\tloss 0.0364 (0.0364)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [714][100/196]\tTime 0.367 (0.407)\tData 0.003 (0.015)\tloss 0.0298 (0.0336)\tPrec@1 99.219 (98.886)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [714][0/79]\tTime 0.576 (0.576)\tData 0.446 (0.446)\tloss 0.3547 (0.3547)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:42:57\n",
            "\n",
            " Epoch: 715\n",
            "Training loss 0.0337 \tTraining Prec@1 98.864 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5373 \tValidation Prec@1 88.950 \tValidation Prec@5 99.480 \n",
            "\n",
            "lr: 0.019375312597667265\n",
            "o is 2.1342549324035645,  o_a is 2.1342549324035645\n",
            "TRAINING - Epoch: [715][0/196]\tTime 2.233 (2.233)\tData 1.325 (1.325)\tloss 0.0363 (0.0363)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [715][100/196]\tTime 0.358 (0.397)\tData 0.000 (0.014)\tloss 0.0499 (0.0334)\tPrec@1 98.828 (98.859)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [715][0/79]\tTime 0.889 (0.889)\tData 0.696 (0.696)\tloss 0.2533 (0.2533)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:35:41\n",
            "\n",
            " Epoch: 716\n",
            "Training loss 0.0325 \tTraining Prec@1 98.914 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5756 \tValidation Prec@1 88.020 \tValidation Prec@5 99.480 \n",
            "\n",
            "lr: 0.01925079601661\n",
            "o is 2.137087821960449,  o_a is 2.137087821960449\n",
            "TRAINING - Epoch: [716][0/196]\tTime 1.581 (1.581)\tData 0.547 (0.547)\tloss 0.0159 (0.0159)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [716][100/196]\tTime 0.360 (0.391)\tData 0.000 (0.006)\tloss 0.0113 (0.0303)\tPrec@1 99.609 (99.002)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [716][0/79]\tTime 0.613 (0.613)\tData 0.521 (0.521)\tloss 0.4404 (0.4404)\tPrec@1 88.281 (88.281)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:27:47\n",
            "\n",
            " Epoch: 717\n",
            "Training loss 0.0331 \tTraining Prec@1 98.888 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5301 \tValidation Prec@1 88.560 \tValidation Prec@5 99.550 \n",
            "\n",
            "lr: 0.019126585378842986\n",
            "o is 2.139923095703125,  o_a is 2.139923095703125\n",
            "TRAINING - Epoch: [717][0/196]\tTime 1.705 (1.705)\tData 0.786 (0.786)\tloss 0.0345 (0.0345)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [717][100/196]\tTime 0.411 (0.397)\tData 0.000 (0.008)\tloss 0.0392 (0.0321)\tPrec@1 98.828 (98.902)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [717][0/79]\tTime 0.475 (0.475)\tData 0.315 (0.315)\tloss 0.3725 (0.3725)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:28:30\n",
            "\n",
            " Epoch: 718\n",
            "Training loss 0.0346 \tTraining Prec@1 98.812 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5550 \tValidation Prec@1 88.940 \tValidation Prec@5 99.460 \n",
            "\n",
            "lr: 0.019002681920141488\n",
            "o is 2.1427605152130127,  o_a is 2.1427605152130127\n",
            "TRAINING - Epoch: [718][0/196]\tTime 1.747 (1.747)\tData 0.743 (0.743)\tloss 0.0265 (0.0265)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [718][100/196]\tTime 0.411 (0.400)\tData 0.000 (0.008)\tloss 0.0199 (0.0367)\tPrec@1 99.219 (98.720)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [718][0/79]\tTime 0.464 (0.464)\tData 0.326 (0.326)\tloss 0.3043 (0.3043)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:29:49\n",
            "\n",
            " Epoch: 719\n",
            "Training loss 0.0351 \tTraining Prec@1 98.776 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5414 \tValidation Prec@1 88.770 \tValidation Prec@5 99.630 \n",
            "\n",
            "lr: 0.01887908687322463\n",
            "o is 2.145599842071533,  o_a is 2.145599842071533\n",
            "TRAINING - Epoch: [719][0/196]\tTime 2.199 (2.199)\tData 1.009 (1.009)\tloss 0.0369 (0.0369)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [719][100/196]\tTime 0.364 (0.404)\tData 0.000 (0.011)\tloss 0.0176 (0.0334)\tPrec@1 99.609 (98.813)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [719][0/79]\tTime 0.456 (0.456)\tData 0.365 (0.365)\tloss 0.4836 (0.4836)\tPrec@1 88.281 (88.281)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:33:29\n",
            "\n",
            " Epoch: 720\n",
            "Training loss 0.0318 \tTraining Prec@1 98.932 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5592 \tValidation Prec@1 88.830 \tValidation Prec@5 99.520 \n",
            "\n",
            "lr: 0.01875580146774315\n",
            "o is 2.1484415531158447,  o_a is 2.1484415531158447\n",
            "TRAINING - Epoch: [720][0/196]\tTime 2.804 (2.804)\tData 1.461 (1.461)\tloss 0.0256 (0.0256)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [720][100/196]\tTime 0.364 (0.402)\tData 0.000 (0.015)\tloss 0.0240 (0.0326)\tPrec@1 99.219 (98.898)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [720][0/79]\tTime 0.551 (0.551)\tData 0.390 (0.390)\tloss 0.3494 (0.3494)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:41:08\n",
            "\n",
            " Epoch: 721\n",
            "Training loss 0.0334 \tTraining Prec@1 98.872 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5451 \tValidation Prec@1 88.800 \tValidation Prec@5 99.550 \n",
            "\n",
            "lr: 0.018632826930267188\n",
            "o is 2.151285171508789,  o_a is 2.151285171508789\n",
            "TRAINING - Epoch: [721][0/196]\tTime 1.835 (1.835)\tData 0.844 (0.844)\tloss 0.0162 (0.0162)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [721][100/196]\tTime 0.357 (0.390)\tData 0.000 (0.009)\tloss 0.0392 (0.0304)\tPrec@1 98.828 (98.991)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [721][0/79]\tTime 0.783 (0.783)\tData 0.563 (0.563)\tloss 0.3894 (0.3894)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:30:34\n",
            "\n",
            " Epoch: 722\n",
            "Training loss 0.0323 \tTraining Prec@1 98.892 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5480 \tValidation Prec@1 88.950 \tValidation Prec@5 99.530 \n",
            "\n",
            "lr: 0.018510164484273974\n",
            "o is 2.1541309356689453,  o_a is 2.1541309356689453\n",
            "TRAINING - Epoch: [722][0/196]\tTime 1.786 (1.786)\tData 0.881 (0.881)\tloss 0.0319 (0.0319)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [722][100/196]\tTime 0.399 (0.391)\tData 0.000 (0.009)\tloss 0.0547 (0.0345)\tPrec@1 98.828 (98.778)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [722][0/79]\tTime 0.461 (0.461)\tData 0.335 (0.335)\tloss 0.2724 (0.2724)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:26:41\n",
            "\n",
            " Epoch: 723\n",
            "Training loss 0.0345 \tTraining Prec@1 98.806 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5157 \tValidation Prec@1 88.840 \tValidation Prec@5 99.650 \n",
            "\n",
            "lr: 0.018387815350135776\n",
            "o is 2.1569786071777344,  o_a is 2.1569786071777344\n",
            "TRAINING - Epoch: [723][0/196]\tTime 1.770 (1.770)\tData 0.862 (0.862)\tloss 0.0846 (0.0846)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [723][100/196]\tTime 0.428 (0.396)\tData 0.003 (0.009)\tloss 0.0396 (0.0336)\tPrec@1 98.438 (98.859)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [723][0/79]\tTime 0.545 (0.545)\tData 0.468 (0.468)\tloss 0.2589 (0.2589)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:27:32\n",
            "\n",
            " Epoch: 724\n",
            "Training loss 0.0341 \tTraining Prec@1 98.820 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5156 \tValidation Prec@1 88.910 \tValidation Prec@5 99.600 \n",
            "\n",
            "lr: 0.01826578074510774\n",
            "o is 2.1598284244537354,  o_a is 2.1598284244537354\n",
            "TRAINING - Epoch: [724][0/196]\tTime 1.772 (1.772)\tData 0.884 (0.884)\tloss 0.0489 (0.0489)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [724][100/196]\tTime 0.412 (0.398)\tData 0.000 (0.010)\tloss 0.0255 (0.0319)\tPrec@1 99.219 (98.917)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [724][0/79]\tTime 0.535 (0.535)\tData 0.369 (0.369)\tloss 0.5231 (0.5231)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:28:08\n",
            "\n",
            " Epoch: 725\n",
            "Training loss 0.0328 \tTraining Prec@1 98.904 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5231 \tValidation Prec@1 88.970 \tValidation Prec@5 99.630 \n",
            "\n",
            "lr: 0.018144061883315705\n",
            "o is 2.1626806259155273,  o_a is 2.1626806259155273\n",
            "TRAINING - Epoch: [725][0/196]\tTime 1.738 (1.738)\tData 0.815 (0.815)\tloss 0.0528 (0.0528)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [725][100/196]\tTime 0.395 (0.398)\tData 0.007 (0.009)\tloss 0.0166 (0.0341)\tPrec@1 100.000 (98.820)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [725][0/79]\tTime 0.559 (0.559)\tData 0.443 (0.443)\tloss 0.2329 (0.2329)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:28:13\n",
            "\n",
            " Epoch: 726\n",
            "Training loss 0.0332 \tTraining Prec@1 98.856 \tTraining Prec@5 99.996 \n",
            "Validation loss 0.5201 \tValidation Prec@1 89.300 \tValidation Prec@5 99.580 \n",
            "\n",
            "lr: 0.01802265997574421\n",
            "o is 2.165534496307373,  o_a is 2.165534496307373\n",
            "TRAINING - Epoch: [726][0/196]\tTime 1.871 (1.871)\tData 1.020 (1.020)\tloss 0.0224 (0.0224)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [726][100/196]\tTime 0.359 (0.402)\tData 0.000 (0.011)\tloss 0.0240 (0.0307)\tPrec@1 99.219 (98.960)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [726][0/79]\tTime 0.430 (0.430)\tData 0.310 (0.310)\tloss 0.3675 (0.3675)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:31:10\n",
            "\n",
            " Epoch: 727\n",
            "Training loss 0.0313 \tTraining Prec@1 98.980 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5247 \tValidation Prec@1 89.070 \tValidation Prec@5 99.510 \n",
            "\n",
            "lr: 0.017901576230224342\n",
            "o is 2.1683907508850098,  o_a is 2.1683907508850098\n",
            "TRAINING - Epoch: [727][0/196]\tTime 3.052 (3.052)\tData 1.637 (1.637)\tloss 0.0401 (0.0401)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [727][100/196]\tTime 0.354 (0.406)\tData 0.000 (0.017)\tloss 0.0208 (0.0277)\tPrec@1 99.609 (99.056)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [727][0/79]\tTime 0.656 (0.656)\tData 0.459 (0.459)\tloss 0.4065 (0.4065)\tPrec@1 89.062 (89.062)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:41:43\n",
            "\n",
            " Epoch: 728\n",
            "Training loss 0.0281 \tTraining Prec@1 99.038 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5758 \tValidation Prec@1 88.030 \tValidation Prec@5 99.650 \n",
            "\n",
            "lr: 0.017780811851421864\n",
            "o is 2.1712489128112793,  o_a is 2.1712489128112793\n",
            "TRAINING - Epoch: [728][0/196]\tTime 1.781 (1.781)\tData 0.852 (0.852)\tloss 0.0298 (0.0298)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [728][100/196]\tTime 0.355 (0.391)\tData 0.000 (0.009)\tloss 0.0187 (0.0287)\tPrec@1 99.609 (99.064)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [728][0/79]\tTime 0.923 (0.923)\tData 0.776 (0.776)\tloss 0.4867 (0.4867)\tPrec@1 88.281 (88.281)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:31:50\n",
            "\n",
            " Epoch: 729\n",
            "Training loss 0.0291 \tTraining Prec@1 99.044 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5214 \tValidation Prec@1 88.840 \tValidation Prec@5 99.670 \n",
            "\n",
            "lr: 0.017660368040825113\n",
            "o is 2.1741089820861816,  o_a is 2.1741089820861816\n",
            "TRAINING - Epoch: [729][0/196]\tTime 1.778 (1.778)\tData 0.835 (0.835)\tloss 0.0380 (0.0380)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [729][100/196]\tTime 0.364 (0.392)\tData 0.001 (0.009)\tloss 0.0514 (0.0317)\tPrec@1 98.828 (98.890)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [729][0/79]\tTime 0.765 (0.765)\tData 0.580 (0.580)\tloss 0.3820 (0.3820)\tPrec@1 89.844 (89.844)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:28:06\n",
            "\n",
            " Epoch: 730\n",
            "Training loss 0.0314 \tTraining Prec@1 98.886 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5068 \tValidation Prec@1 89.020 \tValidation Prec@5 99.680 \n",
            "\n",
            "lr: 0.017540245996733077\n",
            "o is 2.176971435546875,  o_a is 2.176971435546875\n",
            "TRAINING - Epoch: [730][0/196]\tTime 1.817 (1.817)\tData 0.956 (0.956)\tloss 0.0455 (0.0455)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [730][100/196]\tTime 0.409 (0.394)\tData 0.000 (0.010)\tloss 0.0130 (0.0314)\tPrec@1 99.609 (98.933)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [730][0/79]\tTime 0.442 (0.442)\tData 0.296 (0.296)\tloss 0.2447 (0.2447)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:26:45\n",
            "\n",
            " Epoch: 731\n",
            "Training loss 0.0328 \tTraining Prec@1 98.892 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5207 \tValidation Prec@1 89.060 \tValidation Prec@5 99.580 \n",
            "\n",
            "lr: 0.017420446914243493\n",
            "o is 2.179835557937622,  o_a is 2.179835557937622\n",
            "TRAINING - Epoch: [731][0/196]\tTime 1.748 (1.748)\tData 0.954 (0.954)\tloss 0.0199 (0.0199)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [731][100/196]\tTime 0.399 (0.395)\tData 0.000 (0.010)\tloss 0.0065 (0.0296)\tPrec@1 100.000 (99.064)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [731][0/79]\tTime 0.577 (0.577)\tData 0.454 (0.454)\tloss 0.2588 (0.2588)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:26:14\n",
            "\n",
            " Epoch: 732\n",
            "Training loss 0.0306 \tTraining Prec@1 99.008 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5097 \tValidation Prec@1 88.990 \tValidation Prec@5 99.630 \n",
            "\n",
            "lr: 0.01730097198524094\n",
            "o is 2.18270206451416,  o_a is 2.18270206451416\n",
            "TRAINING - Epoch: [732][0/196]\tTime 1.972 (1.972)\tData 1.120 (1.120)\tloss 0.0220 (0.0220)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [732][100/196]\tTime 0.445 (0.401)\tData 0.000 (0.012)\tloss 0.0287 (0.0283)\tPrec@1 98.828 (99.064)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [732][0/79]\tTime 0.369 (0.369)\tData 0.276 (0.276)\tloss 0.2098 (0.2098)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:29:08\n",
            "\n",
            " Epoch: 733\n",
            "Training loss 0.0305 \tTraining Prec@1 98.968 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5143 \tValidation Prec@1 88.890 \tValidation Prec@5 99.600 \n",
            "\n",
            "lr: 0.017181822398384977\n",
            "o is 2.185570001602173,  o_a is 2.185570001602173\n",
            "TRAINING - Epoch: [733][0/196]\tTime 1.822 (1.822)\tData 1.017 (1.017)\tloss 0.0186 (0.0186)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [733][100/196]\tTime 0.358 (0.399)\tData 0.000 (0.011)\tloss 0.0264 (0.0299)\tPrec@1 99.609 (98.967)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [733][0/79]\tTime 0.465 (0.465)\tData 0.307 (0.307)\tloss 0.3726 (0.3726)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:29:26\n",
            "\n",
            " Epoch: 734\n",
            "Training loss 0.0311 \tTraining Prec@1 98.914 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5273 \tValidation Prec@1 88.580 \tValidation Prec@5 99.540 \n",
            "\n",
            "lr: 0.017062999339098314\n",
            "o is 2.1884405612945557,  o_a is 2.1884405612945557\n",
            "TRAINING - Epoch: [734][0/196]\tTime 2.567 (2.567)\tData 1.063 (1.063)\tloss 0.0308 (0.0308)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [734][100/196]\tTime 0.355 (0.407)\tData 0.000 (0.012)\tloss 0.0128 (0.0299)\tPrec@1 100.000 (98.994)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [734][0/79]\tTime 0.508 (0.508)\tData 0.418 (0.418)\tloss 0.2345 (0.2345)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:37:13\n",
            "\n",
            " Epoch: 735\n",
            "Training loss 0.0294 \tTraining Prec@1 99.024 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5113 \tValidation Prec@1 89.420 \tValidation Prec@5 99.560 \n",
            "\n",
            "lr: 0.016944503989555094\n",
            "o is 2.1913130283355713,  o_a is 2.1913130283355713\n",
            "TRAINING - Epoch: [735][0/196]\tTime 2.804 (2.804)\tData 1.549 (1.549)\tloss 0.0356 (0.0356)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [735][100/196]\tTime 0.358 (0.400)\tData 0.000 (0.016)\tloss 0.0562 (0.0264)\tPrec@1 97.656 (99.165)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [735][0/79]\tTime 0.875 (0.875)\tData 0.643 (0.643)\tloss 0.4017 (0.4017)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:37:19\n",
            "\n",
            " Epoch: 736\n",
            "Training loss 0.0286 \tTraining Prec@1 99.044 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5745 \tValidation Prec@1 87.700 \tValidation Prec@5 99.600 \n",
            "\n",
            "lr: 0.016826337528668994\n",
            "o is 2.1941871643066406,  o_a is 2.1941871643066406\n",
            "TRAINING - Epoch: [736][0/196]\tTime 1.649 (1.649)\tData 0.672 (0.672)\tloss 0.0439 (0.0439)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [736][100/196]\tTime 0.358 (0.390)\tData 0.000 (0.007)\tloss 0.0354 (0.0289)\tPrec@1 98.828 (99.076)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [736][0/79]\tTime 0.918 (0.918)\tData 0.700 (0.700)\tloss 0.3450 (0.3450)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:29:32\n",
            "\n",
            " Epoch: 737\n",
            "Training loss 0.0281 \tTraining Prec@1 99.086 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5244 \tValidation Prec@1 88.570 \tValidation Prec@5 99.570 \n",
            "\n",
            "lr: 0.01670850113208158\n",
            "o is 2.197063446044922,  o_a is 2.197063446044922\n",
            "TRAINING - Epoch: [737][0/196]\tTime 1.738 (1.738)\tData 0.926 (0.926)\tloss 0.0145 (0.0145)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [737][100/196]\tTime 0.391 (0.388)\tData 0.000 (0.010)\tloss 0.0807 (0.0293)\tPrec@1 98.047 (98.987)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [737][0/79]\tTime 0.586 (0.586)\tData 0.502 (0.502)\tloss 0.2670 (0.2670)\tPrec@1 89.062 (89.062)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:25:36\n",
            "\n",
            " Epoch: 738\n",
            "Training loss 0.0293 \tTraining Prec@1 99.030 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.4907 \tValidation Prec@1 89.220 \tValidation Prec@5 99.730 \n",
            "\n",
            "lr: 0.016590995972150597\n",
            "o is 2.199941635131836,  o_a is 2.199941635131836\n",
            "TRAINING - Epoch: [738][0/196]\tTime 1.610 (1.610)\tData 0.659 (0.659)\tloss 0.0253 (0.0253)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [738][100/196]\tTime 0.409 (0.395)\tData 0.000 (0.007)\tloss 0.0190 (0.0294)\tPrec@1 99.219 (98.987)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [738][0/79]\tTime 0.512 (0.512)\tData 0.412 (0.412)\tloss 0.2748 (0.2748)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:26:13\n",
            "\n",
            " Epoch: 739\n",
            "Training loss 0.0296 \tTraining Prec@1 98.996 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5023 \tValidation Prec@1 88.960 \tValidation Prec@5 99.640 \n",
            "\n",
            "lr: 0.016473823217938357\n",
            "o is 2.202822208404541,  o_a is 2.202822208404541\n",
            "TRAINING - Epoch: [739][0/196]\tTime 1.754 (1.754)\tData 0.949 (0.949)\tloss 0.0160 (0.0160)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [739][100/196]\tTime 0.430 (0.395)\tData 0.000 (0.010)\tloss 0.0277 (0.0271)\tPrec@1 99.219 (99.099)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [739][0/79]\tTime 0.586 (0.586)\tData 0.444 (0.444)\tloss 0.2224 (0.2224)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:27:42\n",
            "\n",
            " Epoch: 740\n",
            "Training loss 0.0280 \tTraining Prec@1 99.070 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.4972 \tValidation Prec@1 89.090 \tValidation Prec@5 99.660 \n",
            "\n",
            "lr: 0.01635698403520001\n",
            "o is 2.2057042121887207,  o_a is 2.2057042121887207\n",
            "TRAINING - Epoch: [740][0/196]\tTime 1.775 (1.775)\tData 1.056 (1.056)\tloss 0.0227 (0.0227)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [740][100/196]\tTime 0.368 (0.399)\tData 0.000 (0.011)\tloss 0.0347 (0.0286)\tPrec@1 98.828 (99.083)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [740][0/79]\tTime 0.418 (0.418)\tData 0.284 (0.284)\tloss 0.3443 (0.3443)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:28:42\n",
            "\n",
            " Epoch: 741\n",
            "Training loss 0.0291 \tTraining Prec@1 99.022 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5062 \tValidation Prec@1 88.850 \tValidation Prec@5 99.660 \n",
            "\n",
            "lr: 0.016240479586372016\n",
            "o is 2.2085883617401123,  o_a is 2.2085883617401123\n",
            "TRAINING - Epoch: [741][0/196]\tTime 2.112 (2.112)\tData 1.114 (1.114)\tloss 0.0132 (0.0132)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [741][100/196]\tTime 0.354 (0.402)\tData 0.001 (0.012)\tloss 0.0343 (0.0299)\tPrec@1 98.828 (99.022)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [741][0/79]\tTime 0.343 (0.343)\tData 0.242 (0.242)\tloss 0.4466 (0.4466)\tPrec@1 89.062 (89.062)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:29:50\n",
            "\n",
            " Epoch: 742\n",
            "Training loss 0.0296 \tTraining Prec@1 99.052 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5503 \tValidation Prec@1 88.550 \tValidation Prec@5 99.610 \n",
            "\n",
            "lr: 0.016124311030560494\n",
            "o is 2.211474657058716,  o_a is 2.211474657058716\n",
            "TRAINING - Epoch: [742][0/196]\tTime 2.514 (2.514)\tData 1.125 (1.125)\tloss 0.0232 (0.0232)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [742][100/196]\tTime 0.357 (0.405)\tData 0.000 (0.012)\tloss 0.0245 (0.0267)\tPrec@1 99.609 (99.080)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [742][0/79]\tTime 0.471 (0.471)\tData 0.331 (0.331)\tloss 0.2760 (0.2760)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:33:09\n",
            "\n",
            " Epoch: 743\n",
            "Training loss 0.0277 \tTraining Prec@1 99.044 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5321 \tValidation Prec@1 89.000 \tValidation Prec@5 99.650 \n",
            "\n",
            "lr: 0.01600847952352986\n",
            "o is 2.214362621307373,  o_a is 2.214362621307373\n",
            "TRAINING - Epoch: [743][0/196]\tTime 3.015 (3.015)\tData 1.601 (1.601)\tloss 0.0389 (0.0389)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [743][100/196]\tTime 0.355 (0.404)\tData 0.003 (0.017)\tloss 0.0260 (0.0287)\tPrec@1 99.609 (98.952)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [743][0/79]\tTime 0.312 (0.312)\tData 0.226 (0.226)\tloss 0.4726 (0.4726)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:37:58\n",
            "\n",
            " Epoch: 744\n",
            "Training loss 0.0276 \tTraining Prec@1 99.022 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5268 \tValidation Prec@1 88.970 \tValidation Prec@5 99.620 \n",
            "\n",
            "lr: 0.015892986217691155\n",
            "o is 2.217252731323242,  o_a is 2.217252731323242\n",
            "TRAINING - Epoch: [744][0/196]\tTime 2.408 (2.408)\tData 1.420 (1.420)\tloss 0.0123 (0.0123)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [744][100/196]\tTime 0.358 (0.395)\tData 0.000 (0.015)\tloss 0.0176 (0.0263)\tPrec@1 99.219 (99.134)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [744][0/79]\tTime 0.873 (0.873)\tData 0.670 (0.670)\tloss 0.2733 (0.2733)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:34:01\n",
            "\n",
            " Epoch: 745\n",
            "Training loss 0.0257 \tTraining Prec@1 99.160 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5093 \tValidation Prec@1 89.620 \tValidation Prec@5 99.610 \n",
            "\n",
            "lr: 0.01577783226209063\n",
            "o is 2.220144748687744,  o_a is 2.220144748687744\n",
            "TRAINING - Epoch: [745][0/196]\tTime 1.716 (1.716)\tData 0.795 (0.795)\tloss 0.0247 (0.0247)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [745][100/196]\tTime 0.353 (0.389)\tData 0.000 (0.008)\tloss 0.0237 (0.0292)\tPrec@1 98.828 (99.002)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [745][0/79]\tTime 0.849 (0.849)\tData 0.582 (0.582)\tloss 0.3805 (0.3805)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:28:00\n",
            "\n",
            " Epoch: 746\n",
            "Training loss 0.0273 \tTraining Prec@1 99.050 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5210 \tValidation Prec@1 89.330 \tValidation Prec@5 99.590 \n",
            "\n",
            "lr: 0.015663018802398423\n",
            "o is 2.223038673400879,  o_a is 2.223038673400879\n",
            "TRAINING - Epoch: [746][0/196]\tTime 1.728 (1.728)\tData 0.796 (0.796)\tloss 0.0199 (0.0199)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [746][100/196]\tTime 0.465 (0.392)\tData 0.000 (0.009)\tloss 0.0178 (0.0294)\tPrec@1 99.609 (99.022)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [746][0/79]\tTime 0.408 (0.408)\tData 0.302 (0.302)\tloss 0.3641 (0.3641)\tPrec@1 89.844 (89.844)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:25:46\n",
            "\n",
            " Epoch: 747\n",
            "Training loss 0.0295 \tTraining Prec@1 99.004 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5257 \tValidation Prec@1 89.230 \tValidation Prec@5 99.630 \n",
            "\n",
            "lr: 0.015548546980896943\n",
            "o is 2.2259345054626465,  o_a is 2.2259345054626465\n",
            "TRAINING - Epoch: [747][0/196]\tTime 1.772 (1.772)\tData 0.786 (0.786)\tloss 0.0100 (0.0100)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [747][100/196]\tTime 0.409 (0.394)\tData 0.000 (0.009)\tloss 0.0351 (0.0248)\tPrec@1 98.828 (99.172)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [747][0/79]\tTime 0.505 (0.505)\tData 0.383 (0.383)\tloss 0.2726 (0.2726)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:25:54\n",
            "\n",
            " Epoch: 748\n",
            "Training loss 0.0271 \tTraining Prec@1 99.078 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5200 \tValidation Prec@1 88.950 \tValidation Prec@5 99.620 \n",
            "\n",
            "lr: 0.015434417936469718\n",
            "o is 2.228832244873047,  o_a is 2.228832244873047\n",
            "TRAINING - Epoch: [748][0/196]\tTime 1.780 (1.780)\tData 0.754 (0.754)\tloss 0.0346 (0.0346)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [748][100/196]\tTime 0.469 (0.397)\tData 0.000 (0.008)\tloss 0.0456 (0.0268)\tPrec@1 98.828 (99.076)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [748][0/79]\tTime 0.611 (0.611)\tData 0.457 (0.457)\tloss 0.2594 (0.2594)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:27:17\n",
            "\n",
            " Epoch: 749\n",
            "Training loss 0.0271 \tTraining Prec@1 99.070 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5003 \tValidation Prec@1 88.880 \tValidation Prec@5 99.660 \n",
            "\n",
            "lr: 0.015320632804589928\n",
            "o is 2.23173189163208,  o_a is 2.23173189163208\n",
            "TRAINING - Epoch: [749][0/196]\tTime 1.783 (1.783)\tData 1.033 (1.033)\tloss 0.0300 (0.0300)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [749][100/196]\tTime 0.418 (0.400)\tData 0.000 (0.011)\tloss 0.0617 (0.0256)\tPrec@1 98.047 (99.168)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [749][0/79]\tTime 0.395 (0.395)\tData 0.254 (0.254)\tloss 0.3114 (0.3114)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:28:20\n",
            "\n",
            " Epoch: 750\n",
            "Training loss 0.0256 \tTraining Prec@1 99.132 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5295 \tValidation Prec@1 89.030 \tValidation Prec@5 99.640 \n",
            "\n",
            "lr: 0.01520719271730922\n",
            "o is 2.234633207321167,  o_a is 2.234633207321167\n",
            "TRAINING - Epoch: [750][0/196]\tTime 1.785 (1.785)\tData 0.933 (0.933)\tloss 0.0172 (0.0172)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [750][100/196]\tTime 0.354 (0.399)\tData 0.000 (0.010)\tloss 0.0434 (0.0286)\tPrec@1 98.438 (98.948)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [750][0/79]\tTime 0.579 (0.579)\tData 0.428 (0.428)\tloss 0.3397 (0.3397)\tPrec@1 90.625 (90.625)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:28:44\n",
            "\n",
            " Epoch: 751\n",
            "Training loss 0.0278 \tTraining Prec@1 99.038 \tTraining Prec@5 99.994 \n",
            "Validation loss 0.5156 \tValidation Prec@1 88.910 \tValidation Prec@5 99.630 \n",
            "\n",
            "lr: 0.015094098803246324\n",
            "o is 2.2375364303588867,  o_a is 2.2375364303588867\n",
            "TRAINING - Epoch: [751][0/196]\tTime 1.993 (1.993)\tData 0.826 (0.826)\tloss 0.0155 (0.0155)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [751][100/196]\tTime 0.357 (0.401)\tData 0.000 (0.009)\tloss 0.0117 (0.0243)\tPrec@1 100.000 (99.172)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [751][0/79]\tTime 0.536 (0.536)\tData 0.396 (0.396)\tloss 0.2687 (0.2687)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:29:49\n",
            "\n",
            " Epoch: 752\n",
            "Training loss 0.0243 \tTraining Prec@1 99.178 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.4860 \tValidation Prec@1 89.250 \tValidation Prec@5 99.660 \n",
            "\n",
            "lr: 0.014981352187575916\n",
            "o is 2.2404417991638184,  o_a is 2.2404417991638184\n",
            "TRAINING - Epoch: [752][0/196]\tTime 2.678 (2.678)\tData 1.341 (1.341)\tloss 0.0086 (0.0086)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [752][100/196]\tTime 0.357 (0.404)\tData 0.000 (0.014)\tloss 0.0291 (0.0262)\tPrec@1 98.438 (99.060)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [752][0/79]\tTime 0.486 (0.486)\tData 0.352 (0.352)\tloss 0.2503 (0.2503)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:33:02\n",
            "\n",
            " Epoch: 753\n",
            "Training loss 0.0261 \tTraining Prec@1 99.072 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5144 \tValidation Prec@1 88.950 \tValidation Prec@5 99.640 \n",
            "\n",
            "lr: 0.01486895399201733\n",
            "o is 2.243349075317383,  o_a is 2.243349075317383\n",
            "TRAINING - Epoch: [753][0/196]\tTime 2.887 (2.887)\tData 1.524 (1.524)\tloss 0.0181 (0.0181)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [753][100/196]\tTime 0.355 (0.400)\tData 0.000 (0.016)\tloss 0.0422 (0.0258)\tPrec@1 97.656 (99.196)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [753][0/79]\tTime 0.502 (0.502)\tData 0.323 (0.323)\tloss 0.3763 (0.3763)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:22\tTime of Finish: 2023-11-27 09:37:50\n",
            "\n",
            " Epoch: 754\n",
            "Training loss 0.0259 \tTraining Prec@1 99.154 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5100 \tValidation Prec@1 89.270 \tValidation Prec@5 99.560 \n",
            "\n",
            "lr: 0.014756905334823548\n",
            "o is 2.24625825881958,  o_a is 2.24625825881958\n",
            "TRAINING - Epoch: [754][0/196]\tTime 1.930 (1.930)\tData 1.183 (1.183)\tloss 0.0198 (0.0198)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [754][100/196]\tTime 0.356 (0.391)\tData 0.000 (0.012)\tloss 0.0209 (0.0233)\tPrec@1 99.219 (99.257)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [754][0/79]\tTime 0.797 (0.797)\tData 0.614 (0.614)\tloss 0.5048 (0.5048)\tPrec@1 89.844 (89.844)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:31:57\n",
            "\n",
            " Epoch: 755\n",
            "Training loss 0.0243 \tTraining Prec@1 99.212 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5648 \tValidation Prec@1 88.690 \tValidation Prec@5 99.510 \n",
            "\n",
            "lr: 0.014645207330769922\n",
            "o is 2.249168872833252,  o_a is 2.249168872833252\n",
            "TRAINING - Epoch: [755][0/196]\tTime 1.801 (1.801)\tData 0.965 (0.965)\tloss 0.0338 (0.0338)\tPrec@1 98.047 (98.047)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [755][100/196]\tTime 0.356 (0.389)\tData 0.003 (0.010)\tloss 0.0598 (0.0279)\tPrec@1 98.438 (99.002)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [755][0/79]\tTime 0.831 (0.831)\tData 0.662 (0.662)\tloss 0.4267 (0.4267)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:28:29\n",
            "\n",
            " Epoch: 756\n",
            "Training loss 0.0262 \tTraining Prec@1 99.110 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5349 \tValidation Prec@1 88.670 \tValidation Prec@5 99.630 \n",
            "\n",
            "lr: 0.014533861091143152\n",
            "o is 2.2520816326141357,  o_a is 2.2520816326141357\n",
            "TRAINING - Epoch: [756][0/196]\tTime 1.776 (1.776)\tData 0.820 (0.820)\tloss 0.0172 (0.0172)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [756][100/196]\tTime 0.373 (0.389)\tData 0.000 (0.009)\tloss 0.0116 (0.0249)\tPrec@1 100.000 (99.157)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [756][0/79]\tTime 0.762 (0.762)\tData 0.586 (0.586)\tloss 0.3326 (0.3326)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:26:26\n",
            "\n",
            " Epoch: 757\n",
            "Training loss 0.0262 \tTraining Prec@1 99.150 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5279 \tValidation Prec@1 89.080 \tValidation Prec@5 99.630 \n",
            "\n",
            "lr: 0.014422867723730281\n",
            "o is 2.2549962997436523,  o_a is 2.2549962997436523\n",
            "TRAINING - Epoch: [757][0/196]\tTime 1.915 (1.915)\tData 1.032 (1.032)\tloss 0.0112 (0.0112)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [757][100/196]\tTime 0.450 (0.394)\tData 0.000 (0.011)\tloss 0.0331 (0.0256)\tPrec@1 98.828 (99.126)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [757][0/79]\tTime 0.387 (0.387)\tData 0.283 (0.283)\tloss 0.2820 (0.2820)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:25:44\n",
            "\n",
            " Epoch: 758\n",
            "Training loss 0.0245 \tTraining Prec@1 99.196 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5280 \tValidation Prec@1 89.140 \tValidation Prec@5 99.620 \n",
            "\n",
            "lr: 0.014312228332807521\n",
            "o is 2.2579126358032227,  o_a is 2.2579126358032227\n",
            "TRAINING - Epoch: [758][0/196]\tTime 1.761 (1.761)\tData 0.942 (0.942)\tloss 0.0138 (0.0138)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [758][100/196]\tTime 0.429 (0.394)\tData 0.000 (0.010)\tloss 0.0322 (0.0247)\tPrec@1 99.219 (99.226)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [758][0/79]\tTime 0.376 (0.376)\tData 0.281 (0.281)\tloss 0.3431 (0.3431)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:25:57\n",
            "\n",
            " Epoch: 759\n",
            "Training loss 0.0240 \tTraining Prec@1 99.248 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5266 \tValidation Prec@1 89.000 \tValidation Prec@5 99.580 \n",
            "\n",
            "lr: 0.014201944019129425\n",
            "o is 2.260830879211426,  o_a is 2.260830879211426\n",
            "TRAINING - Epoch: [759][0/196]\tTime 1.811 (1.811)\tData 0.834 (0.834)\tloss 0.0123 (0.0123)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [759][100/196]\tTime 0.455 (0.396)\tData 0.005 (0.009)\tloss 0.0102 (0.0215)\tPrec@1 100.000 (99.292)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [759][0/79]\tTime 0.459 (0.459)\tData 0.331 (0.331)\tloss 0.3629 (0.3629)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:26:47\n",
            "\n",
            " Epoch: 760\n",
            "Training loss 0.0227 \tTraining Prec@1 99.230 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5157 \tValidation Prec@1 89.070 \tValidation Prec@5 99.650 \n",
            "\n",
            "lr: 0.014092015879917843\n",
            "o is 2.2637510299682617,  o_a is 2.2637510299682617\n",
            "TRAINING - Epoch: [760][0/196]\tTime 1.731 (1.731)\tData 0.829 (0.829)\tloss 0.0119 (0.0119)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [760][100/196]\tTime 0.442 (0.396)\tData 0.007 (0.009)\tloss 0.0162 (0.0231)\tPrec@1 99.609 (99.242)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [760][0/79]\tTime 0.578 (0.578)\tData 0.466 (0.466)\tloss 0.3740 (0.3740)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:26:30\n",
            "\n",
            " Epoch: 761\n",
            "Training loss 0.0230 \tTraining Prec@1 99.234 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5084 \tValidation Prec@1 89.390 \tValidation Prec@5 99.580 \n",
            "\n",
            "lr: 0.013982445008851083\n",
            "o is 2.2666728496551514,  o_a is 2.2666728496551514\n",
            "TRAINING - Epoch: [761][0/196]\tTime 1.729 (1.729)\tData 0.923 (0.923)\tloss 0.0090 (0.0090)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [761][100/196]\tTime 0.423 (0.397)\tData 0.000 (0.010)\tloss 0.0133 (0.0219)\tPrec@1 99.609 (99.257)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [761][0/79]\tTime 0.408 (0.408)\tData 0.305 (0.305)\tloss 0.3344 (0.3344)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:26:35\n",
            "\n",
            " Epoch: 762\n",
            "Training loss 0.0218 \tTraining Prec@1 99.266 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5338 \tValidation Prec@1 89.000 \tValidation Prec@5 99.600 \n",
            "\n",
            "lr: 0.01387323249605295\n",
            "o is 2.269596576690674,  o_a is 2.269596576690674\n",
            "TRAINING - Epoch: [762][0/196]\tTime 1.992 (1.992)\tData 1.149 (1.149)\tloss 0.0360 (0.0360)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [762][100/196]\tTime 0.364 (0.399)\tData 0.000 (0.012)\tloss 0.0167 (0.0222)\tPrec@1 99.609 (99.230)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [762][0/79]\tTime 0.524 (0.524)\tData 0.429 (0.429)\tloss 0.3717 (0.3717)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:27:51\n",
            "\n",
            " Epoch: 763\n",
            "Training loss 0.0225 \tTraining Prec@1 99.246 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.4987 \tValidation Prec@1 89.650 \tValidation Prec@5 99.730 \n",
            "\n",
            "lr: 0.013764379428081895\n",
            "o is 2.272522211074829,  o_a is 2.272522211074829\n",
            "TRAINING - Epoch: [763][0/196]\tTime 2.198 (2.198)\tData 0.996 (0.996)\tloss 0.0075 (0.0075)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [763][100/196]\tTime 0.356 (0.400)\tData 0.000 (0.011)\tloss 0.0215 (0.0220)\tPrec@1 99.219 (99.288)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [763][0/79]\tTime 0.571 (0.571)\tData 0.430 (0.430)\tloss 0.2430 (0.2430)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:29:10\n",
            "\n",
            " Epoch: 764\n",
            "Training loss 0.0218 \tTraining Prec@1 99.290 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.4962 \tValidation Prec@1 89.490 \tValidation Prec@5 99.680 \n",
            "\n",
            "lr: 0.013655886887920275\n",
            "o is 2.275449275970459,  o_a is 2.275449275970459\n",
            "TRAINING - Epoch: [764][0/196]\tTime 2.707 (2.707)\tData 1.364 (1.364)\tloss 0.0260 (0.0260)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [764][100/196]\tTime 0.355 (0.403)\tData 0.000 (0.014)\tloss 0.0456 (0.0227)\tPrec@1 97.656 (99.223)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [764][0/79]\tTime 0.476 (0.476)\tData 0.342 (0.342)\tloss 0.3839 (0.3839)\tPrec@1 89.062 (89.062)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:31:31\n",
            "\n",
            " Epoch: 765\n",
            "Training loss 0.0232 \tTraining Prec@1 99.226 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5669 \tValidation Prec@1 88.720 \tValidation Prec@5 99.520 \n",
            "\n",
            "lr: 0.013547755954963584\n",
            "o is 2.278378486633301,  o_a is 2.278378486633301\n",
            "TRAINING - Epoch: [765][0/196]\tTime 3.011 (3.011)\tData 1.559 (1.559)\tloss 0.0523 (0.0523)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [765][100/196]\tTime 0.352 (0.402)\tData 0.000 (0.016)\tloss 0.0344 (0.0271)\tPrec@1 98.438 (99.068)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [765][0/79]\tTime 0.513 (0.513)\tData 0.425 (0.425)\tloss 0.2538 (0.2538)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:36:42\n",
            "\n",
            " Epoch: 766\n",
            "Training loss 0.0263 \tTraining Prec@1 99.072 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5305 \tValidation Prec@1 89.120 \tValidation Prec@5 99.650 \n",
            "\n",
            "lr: 0.013439987705009624\n",
            "o is 2.281309127807617,  o_a is 2.281309127807617\n",
            "TRAINING - Epoch: [766][0/196]\tTime 2.056 (2.056)\tData 1.217 (1.217)\tloss 0.0395 (0.0395)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [766][100/196]\tTime 0.353 (0.390)\tData 0.000 (0.013)\tloss 0.0274 (0.0244)\tPrec@1 99.609 (99.141)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [766][0/79]\tTime 0.901 (0.901)\tData 0.681 (0.681)\tloss 0.4782 (0.4782)\tPrec@1 89.844 (89.844)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:31:42\n",
            "\n",
            " Epoch: 767\n",
            "Training loss 0.0236 \tTraining Prec@1 99.194 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5334 \tValidation Prec@1 89.170 \tValidation Prec@5 99.650 \n",
            "\n",
            "lr: 0.013332583210247865\n",
            "o is 2.2842419147491455,  o_a is 2.2842419147491455\n",
            "TRAINING - Epoch: [767][0/196]\tTime 1.596 (1.596)\tData 0.706 (0.706)\tloss 0.0194 (0.0194)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [767][100/196]\tTime 0.355 (0.387)\tData 0.000 (0.008)\tloss 0.0157 (0.0203)\tPrec@1 99.219 (99.315)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [767][0/79]\tTime 0.830 (0.830)\tData 0.610 (0.610)\tloss 0.4062 (0.4062)\tPrec@1 89.844 (89.844)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:27:38\n",
            "\n",
            " Epoch: 768\n",
            "Training loss 0.0214 \tTraining Prec@1 99.268 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5060 \tValidation Prec@1 89.150 \tValidation Prec@5 99.610 \n",
            "\n",
            "lr: 0.013225543539248766\n",
            "o is 2.2871763706207275,  o_a is 2.2871763706207275\n",
            "TRAINING - Epoch: [768][0/196]\tTime 1.761 (1.761)\tData 0.892 (0.892)\tloss 0.0148 (0.0148)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [768][100/196]\tTime 0.394 (0.388)\tData 0.000 (0.009)\tloss 0.0188 (0.0221)\tPrec@1 99.609 (99.304)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [768][0/79]\tTime 0.845 (0.845)\tData 0.625 (0.625)\tloss 0.2828 (0.2828)\tPrec@1 92.969 (92.969)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:26:23\n",
            "\n",
            " Epoch: 769\n",
            "Training loss 0.0215 \tTraining Prec@1 99.308 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5328 \tValidation Prec@1 89.260 \tValidation Prec@5 99.660 \n",
            "\n",
            "lr: 0.01311886975695315\n",
            "o is 2.2901124954223633,  o_a is 2.2901124954223633\n",
            "TRAINING - Epoch: [769][0/196]\tTime 1.744 (1.744)\tData 0.874 (0.874)\tloss 0.0283 (0.0283)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [769][100/196]\tTime 0.433 (0.388)\tData 0.000 (0.009)\tloss 0.0157 (0.0229)\tPrec@1 99.219 (99.188)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [769][0/79]\tTime 0.817 (0.817)\tData 0.673 (0.673)\tloss 0.4349 (0.4349)\tPrec@1 92.969 (92.969)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:26:06\n",
            "\n",
            " Epoch: 770\n",
            "Training loss 0.0237 \tTraining Prec@1 99.200 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5260 \tValidation Prec@1 89.050 \tValidation Prec@5 99.560 \n",
            "\n",
            "lr: 0.013012562924661599\n",
            "o is 2.2930502891540527,  o_a is 2.2930502891540527\n",
            "TRAINING - Epoch: [770][0/196]\tTime 1.685 (1.685)\tData 0.707 (0.707)\tloss 0.0094 (0.0094)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [770][100/196]\tTime 0.424 (0.390)\tData 0.000 (0.008)\tloss 0.0145 (0.0191)\tPrec@1 99.609 (99.385)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [770][0/79]\tTime 0.554 (0.554)\tData 0.485 (0.485)\tloss 0.3345 (0.3345)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:33\n",
            "\n",
            " Epoch: 771\n",
            "Training loss 0.0209 \tTraining Prec@1 99.326 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5371 \tValidation Prec@1 89.400 \tValidation Prec@5 99.630 \n",
            "\n",
            "lr: 0.01290662410002388\n",
            "o is 2.295989990234375,  o_a is 2.295989990234375\n",
            "TRAINING - Epoch: [771][0/196]\tTime 1.828 (1.828)\tData 1.018 (1.018)\tloss 0.0081 (0.0081)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [771][100/196]\tTime 0.446 (0.392)\tData 0.000 (0.011)\tloss 0.0160 (0.0212)\tPrec@1 99.609 (99.284)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [771][0/79]\tTime 0.528 (0.528)\tData 0.397 (0.397)\tloss 0.2360 (0.2360)\tPrec@1 96.094 (96.094)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:37\n",
            "\n",
            " Epoch: 772\n",
            "Training loss 0.0211 \tTraining Prec@1 99.316 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.4968 \tValidation Prec@1 89.510 \tValidation Prec@5 99.720 \n",
            "\n",
            "lr: 0.012801054337028515\n",
            "o is 2.29893159866333,  o_a is 2.29893159866333\n",
            "TRAINING - Epoch: [772][0/196]\tTime 1.815 (1.815)\tData 1.029 (1.029)\tloss 0.0136 (0.0136)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [772][100/196]\tTime 0.436 (0.393)\tData 0.000 (0.011)\tloss 0.0186 (0.0251)\tPrec@1 99.219 (99.161)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [772][0/79]\tTime 0.525 (0.525)\tData 0.380 (0.380)\tloss 0.3478 (0.3478)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:25:06\n",
            "\n",
            " Epoch: 773\n",
            "Training loss 0.0248 \tTraining Prec@1 99.170 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5257 \tValidation Prec@1 89.700 \tValidation Prec@5 99.610 \n",
            "\n",
            "lr: 0.01269585468599211\n",
            "o is 2.3018746376037598,  o_a is 2.3018746376037598\n",
            "TRAINING - Epoch: [773][0/196]\tTime 1.806 (1.806)\tData 0.878 (0.878)\tloss 0.0379 (0.0379)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [773][100/196]\tTime 0.440 (0.392)\tData 0.000 (0.010)\tloss 0.0401 (0.0201)\tPrec@1 98.828 (99.424)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [773][0/79]\tTime 0.407 (0.407)\tData 0.301 (0.301)\tloss 0.4080 (0.4080)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:25:16\n",
            "\n",
            " Epoch: 774\n",
            "Training loss 0.0213 \tTraining Prec@1 99.358 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5457 \tValidation Prec@1 88.800 \tValidation Prec@5 99.590 \n",
            "\n",
            "lr: 0.01259102619354909\n",
            "o is 2.304819345474243,  o_a is 2.304819345474243\n",
            "TRAINING - Epoch: [774][0/196]\tTime 1.770 (1.770)\tData 0.953 (0.953)\tloss 0.0155 (0.0155)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [774][100/196]\tTime 0.410 (0.392)\tData 0.000 (0.010)\tloss 0.0306 (0.0211)\tPrec@1 98.047 (99.327)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [774][0/79]\tTime 0.563 (0.563)\tData 0.479 (0.479)\tloss 0.2806 (0.2806)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:49\n",
            "\n",
            " Epoch: 775\n",
            "Training loss 0.0214 \tTraining Prec@1 99.294 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5344 \tValidation Prec@1 89.040 \tValidation Prec@5 99.580 \n",
            "\n",
            "lr: 0.012486569902641187\n",
            "o is 2.3077659606933594,  o_a is 2.3077659606933594\n",
            "TRAINING - Epoch: [775][0/196]\tTime 1.802 (1.802)\tData 0.897 (0.897)\tloss 0.0220 (0.0220)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [775][100/196]\tTime 0.437 (0.394)\tData 0.000 (0.010)\tloss 0.0287 (0.0196)\tPrec@1 99.219 (99.366)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [775][0/79]\tTime 0.560 (0.560)\tData 0.481 (0.481)\tloss 0.3491 (0.3491)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:26:15\n",
            "\n",
            " Epoch: 776\n",
            "Training loss 0.0211 \tTraining Prec@1 99.310 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5221 \tValidation Prec@1 89.450 \tValidation Prec@5 99.660 \n",
            "\n",
            "lr: 0.012382486852507119\n",
            "o is 2.3107142448425293,  o_a is 2.3107142448425293\n",
            "TRAINING - Epoch: [776][0/196]\tTime 1.820 (1.820)\tData 0.927 (0.927)\tloss 0.0091 (0.0091)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [776][100/196]\tTime 0.380 (0.396)\tData 0.000 (0.010)\tloss 0.0349 (0.0233)\tPrec@1 99.609 (99.226)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [776][0/79]\tTime 0.592 (0.592)\tData 0.466 (0.466)\tloss 0.2853 (0.2853)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:26:05\n",
            "\n",
            " Epoch: 777\n",
            "Training loss 0.0228 \tTraining Prec@1 99.218 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5127 \tValidation Prec@1 89.280 \tValidation Prec@5 99.620 \n",
            "\n",
            "lr: 0.012278778078672196\n",
            "o is 2.313664197921753,  o_a is 2.313664197921753\n",
            "TRAINING - Epoch: [777][0/196]\tTime 1.755 (1.755)\tData 0.901 (0.901)\tloss 0.0282 (0.0282)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [777][100/196]\tTime 0.428 (0.396)\tData 0.000 (0.010)\tloss 0.0249 (0.0184)\tPrec@1 98.828 (99.408)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [777][0/79]\tTime 0.345 (0.345)\tData 0.245 (0.245)\tloss 0.3466 (0.3466)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:26:14\n",
            "\n",
            " Epoch: 778\n",
            "Training loss 0.0210 \tTraining Prec@1 99.296 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5645 \tValidation Prec@1 89.230 \tValidation Prec@5 99.600 \n",
            "\n",
            "lr: 0.012175444612938005\n",
            "o is 2.316615581512451,  o_a is 2.316615581512451\n",
            "TRAINING - Epoch: [778][0/196]\tTime 1.768 (1.768)\tData 0.836 (0.836)\tloss 0.0267 (0.0267)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [778][100/196]\tTime 0.362 (0.398)\tData 0.000 (0.009)\tloss 0.0124 (0.0226)\tPrec@1 99.219 (99.211)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [778][0/79]\tTime 0.561 (0.561)\tData 0.435 (0.435)\tloss 0.2725 (0.2725)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:27:09\n",
            "\n",
            " Epoch: 779\n",
            "Training loss 0.0222 \tTraining Prec@1 99.244 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5140 \tValidation Prec@1 89.230 \tValidation Prec@5 99.600 \n",
            "\n",
            "lr: 0.012072487483372267\n",
            "o is 2.3195691108703613,  o_a is 2.3195691108703613\n",
            "TRAINING - Epoch: [779][0/196]\tTime 1.806 (1.806)\tData 0.807 (0.807)\tloss 0.0305 (0.0305)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [779][100/196]\tTime 0.355 (0.399)\tData 0.000 (0.009)\tloss 0.0144 (0.0177)\tPrec@1 99.609 (99.416)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [779][0/79]\tTime 0.434 (0.434)\tData 0.302 (0.302)\tloss 0.2995 (0.2995)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:27:35\n",
            "\n",
            " Epoch: 780\n",
            "Training loss 0.0184 \tTraining Prec@1 99.398 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5245 \tValidation Prec@1 89.540 \tValidation Prec@5 99.570 \n",
            "\n",
            "lr: 0.011969907714298456\n",
            "o is 2.322524070739746,  o_a is 2.322524070739746\n",
            "TRAINING - Epoch: [780][0/196]\tTime 2.028 (2.028)\tData 0.948 (0.948)\tloss 0.0127 (0.0127)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [780][100/196]\tTime 0.350 (0.398)\tData 0.000 (0.010)\tloss 0.0373 (0.0189)\tPrec@1 98.828 (99.408)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [780][0/79]\tTime 0.479 (0.479)\tData 0.399 (0.399)\tloss 0.3693 (0.3693)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:27:52\n",
            "\n",
            " Epoch: 781\n",
            "Training loss 0.0199 \tTraining Prec@1 99.364 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5092 \tValidation Prec@1 89.630 \tValidation Prec@5 99.680 \n",
            "\n",
            "lr: 0.011867706326285695\n",
            "o is 2.3254809379577637,  o_a is 2.3254809379577637\n",
            "TRAINING - Epoch: [781][0/196]\tTime 2.484 (2.484)\tData 1.196 (1.196)\tloss 0.0119 (0.0119)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [781][100/196]\tTime 0.351 (0.402)\tData 0.000 (0.013)\tloss 0.0109 (0.0211)\tPrec@1 100.000 (99.362)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [781][0/79]\tTime 0.470 (0.470)\tData 0.335 (0.335)\tloss 0.3232 (0.3232)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:31:15\n",
            "\n",
            " Epoch: 782\n",
            "Training loss 0.0208 \tTraining Prec@1 99.360 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5129 \tValidation Prec@1 89.600 \tValidation Prec@5 99.710 \n",
            "\n",
            "lr: 0.01176588433613858\n",
            "o is 2.328439235687256,  o_a is 2.328439235687256\n",
            "TRAINING - Epoch: [782][0/196]\tTime 2.930 (2.930)\tData 1.497 (1.497)\tloss 0.0232 (0.0232)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [782][100/196]\tTime 0.355 (0.400)\tData 0.000 (0.016)\tloss 0.0325 (0.0200)\tPrec@1 98.438 (99.339)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [782][0/79]\tTime 0.529 (0.529)\tData 0.445 (0.445)\tloss 0.2810 (0.2810)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:21\tTime of Finish: 2023-11-27 09:35:15\n",
            "\n",
            " Epoch: 783\n",
            "Training loss 0.0205 \tTraining Prec@1 99.334 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.4842 \tValidation Prec@1 89.800 \tValidation Prec@5 99.630 \n",
            "\n",
            "lr: 0.011664442756887113\n",
            "o is 2.3313992023468018,  o_a is 2.3313992023468018\n",
            "TRAINING - Epoch: [783][0/196]\tTime 2.028 (2.028)\tData 1.165 (1.165)\tloss 0.0056 (0.0056)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [783][100/196]\tTime 0.352 (0.389)\tData 0.000 (0.012)\tloss 0.0145 (0.0180)\tPrec@1 99.219 (99.404)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [783][0/79]\tTime 0.890 (0.890)\tData 0.652 (0.652)\tloss 0.4529 (0.4529)\tPrec@1 88.281 (88.281)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:29:59\n",
            "\n",
            " Epoch: 784\n",
            "Training loss 0.0201 \tTraining Prec@1 99.340 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5228 \tValidation Prec@1 89.150 \tValidation Prec@5 99.540 \n",
            "\n",
            "lr: 0.01156338259777648\n",
            "o is 2.3343608379364014,  o_a is 2.3343608379364014\n",
            "TRAINING - Epoch: [784][0/196]\tTime 1.731 (1.731)\tData 0.913 (0.913)\tloss 0.0143 (0.0143)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [784][100/196]\tTime 0.354 (0.386)\tData 0.001 (0.010)\tloss 0.0252 (0.0200)\tPrec@1 99.219 (99.343)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [784][0/79]\tTime 0.984 (0.984)\tData 0.774 (0.774)\tloss 0.2185 (0.2185)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:27:21\n",
            "\n",
            " Epoch: 785\n",
            "Training loss 0.0202 \tTraining Prec@1 99.336 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5164 \tValidation Prec@1 89.290 \tValidation Prec@5 99.520 \n",
            "\n",
            "lr: 0.011462704864257192\n",
            "o is 2.3373241424560547,  o_a is 2.3373241424560547\n",
            "TRAINING - Epoch: [785][0/196]\tTime 1.737 (1.737)\tData 0.768 (0.768)\tloss 0.0243 (0.0243)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [785][100/196]\tTime 0.352 (0.386)\tData 0.000 (0.008)\tloss 0.0066 (0.0216)\tPrec@1 100.000 (99.300)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [785][0/79]\tTime 0.811 (0.811)\tData 0.617 (0.617)\tloss 0.3175 (0.3175)\tPrec@1 91.406 (91.406)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:25:48\n",
            "\n",
            " Epoch: 786\n",
            "Training loss 0.0204 \tTraining Prec@1 99.352 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5203 \tValidation Prec@1 89.310 \tValidation Prec@5 99.580 \n",
            "\n",
            "lr: 0.011362410557974942\n",
            "o is 2.3402891159057617,  o_a is 2.3402891159057617\n",
            "TRAINING - Epoch: [786][0/196]\tTime 1.786 (1.786)\tData 0.841 (0.841)\tloss 0.0280 (0.0280)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [786][100/196]\tTime 0.430 (0.387)\tData 0.000 (0.009)\tloss 0.0215 (0.0210)\tPrec@1 99.219 (99.331)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [786][0/79]\tTime 0.764 (0.764)\tData 0.561 (0.561)\tloss 0.3792 (0.3792)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:25:18\n",
            "\n",
            " Epoch: 787\n",
            "Training loss 0.0200 \tTraining Prec@1 99.348 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5049 \tValidation Prec@1 89.190 \tValidation Prec@5 99.570 \n",
            "\n",
            "lr: 0.01126250067676075\n",
            "o is 2.3432559967041016,  o_a is 2.3432559967041016\n",
            "TRAINING - Epoch: [787][0/196]\tTime 1.809 (1.809)\tData 1.003 (1.003)\tloss 0.0196 (0.0196)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [787][100/196]\tTime 0.442 (0.388)\tData 0.006 (0.011)\tloss 0.0320 (0.0196)\tPrec@1 97.656 (99.308)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [787][0/79]\tTime 0.486 (0.486)\tData 0.387 (0.387)\tloss 0.2194 (0.2194)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:43\n",
            "\n",
            " Epoch: 788\n",
            "Training loss 0.0190 \tTraining Prec@1 99.368 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.4982 \tValidation Prec@1 89.800 \tValidation Prec@5 99.670 \n",
            "\n",
            "lr: 0.011162976214620944\n",
            "o is 2.346223831176758,  o_a is 2.346223831176758\n",
            "TRAINING - Epoch: [788][0/196]\tTime 1.759 (1.759)\tData 1.056 (1.056)\tloss 0.0111 (0.0111)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [788][100/196]\tTime 0.435 (0.388)\tData 0.000 (0.011)\tloss 0.0186 (0.0176)\tPrec@1 99.219 (99.493)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [788][0/79]\tTime 0.476 (0.476)\tData 0.347 (0.347)\tloss 0.3021 (0.3021)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:49\n",
            "\n",
            " Epoch: 789\n",
            "Training loss 0.0187 \tTraining Prec@1 99.446 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5238 \tValidation Prec@1 89.070 \tValidation Prec@5 99.600 \n",
            "\n",
            "lr: 0.011063838161727277\n",
            "o is 2.349193811416626,  o_a is 2.349193811416626\n",
            "TRAINING - Epoch: [789][0/196]\tTime 1.779 (1.779)\tData 0.830 (0.830)\tloss 0.0113 (0.0113)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [789][100/196]\tTime 0.433 (0.391)\tData 0.000 (0.009)\tloss 0.0081 (0.0203)\tPrec@1 100.000 (99.323)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [789][0/79]\tTime 0.457 (0.457)\tData 0.327 (0.327)\tloss 0.2814 (0.2814)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:21\n",
            "\n",
            " Epoch: 790\n",
            "Training loss 0.0198 \tTraining Prec@1 99.346 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5059 \tValidation Prec@1 89.300 \tValidation Prec@5 99.690 \n",
            "\n",
            "lr: 0.010965087504407178\n",
            "o is 2.3521652221679688,  o_a is 2.3521652221679688\n",
            "TRAINING - Epoch: [790][0/196]\tTime 1.874 (1.874)\tData 1.035 (1.035)\tloss 0.0192 (0.0192)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [790][100/196]\tTime 0.407 (0.392)\tData 0.000 (0.011)\tloss 0.0121 (0.0190)\tPrec@1 99.609 (99.381)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [790][0/79]\tTime 0.565 (0.565)\tData 0.424 (0.424)\tloss 0.3460 (0.3460)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:44\n",
            "\n",
            " Epoch: 791\n",
            "Training loss 0.0187 \tTraining Prec@1 99.362 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5582 \tValidation Prec@1 89.240 \tValidation Prec@5 99.690 \n",
            "\n",
            "lr: 0.010866725225133805\n",
            "o is 2.3551383018493652,  o_a is 2.3551383018493652\n",
            "TRAINING - Epoch: [791][0/196]\tTime 1.823 (1.823)\tData 0.938 (0.938)\tloss 0.0436 (0.0436)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [791][100/196]\tTime 0.423 (0.392)\tData 0.000 (0.010)\tloss 0.0117 (0.0203)\tPrec@1 99.609 (99.370)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [791][0/79]\tTime 0.435 (0.435)\tData 0.322 (0.322)\tloss 0.3488 (0.3488)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:10\n",
            "\n",
            " Epoch: 792\n",
            "Training loss 0.0200 \tTraining Prec@1 99.354 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5094 \tValidation Prec@1 89.470 \tValidation Prec@5 99.620 \n",
            "\n",
            "lr: 0.010768752302516366\n",
            "o is 2.3581128120422363,  o_a is 2.3581128120422363\n",
            "TRAINING - Epoch: [792][0/196]\tTime 1.766 (1.766)\tData 0.775 (0.775)\tloss 0.0214 (0.0214)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [792][100/196]\tTime 0.434 (0.392)\tData 0.000 (0.008)\tloss 0.0284 (0.0181)\tPrec@1 98.438 (99.470)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [792][0/79]\tTime 0.479 (0.479)\tData 0.348 (0.348)\tloss 0.4782 (0.4782)\tPrec@1 89.844 (89.844)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:26\n",
            "\n",
            " Epoch: 793\n",
            "Training loss 0.0184 \tTraining Prec@1 99.432 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5379 \tValidation Prec@1 89.340 \tValidation Prec@5 99.640 \n",
            "\n",
            "lr: 0.010671169711290323\n",
            "o is 2.361088991165161,  o_a is 2.361088991165161\n",
            "TRAINING - Epoch: [793][0/196]\tTime 2.004 (2.004)\tData 1.055 (1.055)\tloss 0.0271 (0.0271)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [793][100/196]\tTime 0.408 (0.394)\tData 0.000 (0.011)\tloss 0.0047 (0.0169)\tPrec@1 100.000 (99.420)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [793][0/79]\tTime 0.528 (0.528)\tData 0.472 (0.472)\tloss 0.4111 (0.4111)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:25:08\n",
            "\n",
            " Epoch: 794\n",
            "Training loss 0.0173 \tTraining Prec@1 99.426 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5583 \tValidation Prec@1 88.710 \tValidation Prec@5 99.620 \n",
            "\n",
            "lr: 0.010573978422307739\n",
            "o is 2.3640670776367188,  o_a is 2.3640670776367188\n",
            "TRAINING - Epoch: [794][0/196]\tTime 1.788 (1.788)\tData 0.899 (0.899)\tloss 0.0216 (0.0216)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [794][100/196]\tTime 0.439 (0.393)\tData 0.000 (0.010)\tloss 0.0633 (0.0184)\tPrec@1 98.438 (99.397)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [794][0/79]\tTime 0.378 (0.378)\tData 0.239 (0.239)\tloss 0.3206 (0.3206)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:55\n",
            "\n",
            " Epoch: 795\n",
            "Training loss 0.0179 \tTraining Prec@1 99.418 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5387 \tValidation Prec@1 89.180 \tValidation Prec@5 99.620 \n",
            "\n",
            "lr: 0.010477179402527596\n",
            "o is 2.3670461177825928,  o_a is 2.3670461177825928\n",
            "TRAINING - Epoch: [795][0/196]\tTime 1.798 (1.798)\tData 0.892 (0.892)\tloss 0.0268 (0.0268)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [795][100/196]\tTime 0.419 (0.394)\tData 0.000 (0.010)\tloss 0.0119 (0.0183)\tPrec@1 99.609 (99.370)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [795][0/79]\tTime 0.550 (0.550)\tData 0.428 (0.428)\tloss 0.4001 (0.4001)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:36\n",
            "\n",
            " Epoch: 796\n",
            "Training loss 0.0194 \tTraining Prec@1 99.332 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5338 \tValidation Prec@1 88.950 \tValidation Prec@5 99.620 \n",
            "\n",
            "lr: 0.010380773615006167\n",
            "o is 2.3700270652770996,  o_a is 2.3700270652770996\n",
            "TRAINING - Epoch: [796][0/196]\tTime 1.820 (1.820)\tData 0.872 (0.872)\tloss 0.0137 (0.0137)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [796][100/196]\tTime 0.443 (0.394)\tData 0.000 (0.009)\tloss 0.0206 (0.0180)\tPrec@1 99.219 (99.435)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [796][0/79]\tTime 0.362 (0.362)\tData 0.256 (0.256)\tloss 0.3756 (0.3756)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:32\n",
            "\n",
            " Epoch: 797\n",
            "Training loss 0.0179 \tTraining Prec@1 99.412 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5009 \tValidation Prec@1 89.390 \tValidation Prec@5 99.610 \n",
            "\n",
            "lr: 0.01028476201888745\n",
            "o is 2.373009204864502,  o_a is 2.373009204864502\n",
            "TRAINING - Epoch: [797][0/196]\tTime 1.580 (1.580)\tData 0.593 (0.593)\tloss 0.0148 (0.0148)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [797][100/196]\tTime 0.416 (0.395)\tData 0.007 (0.007)\tloss 0.0279 (0.0189)\tPrec@1 98.828 (99.389)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [797][0/79]\tTime 0.584 (0.584)\tData 0.483 (0.483)\tloss 0.3054 (0.3054)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:25:00\n",
            "\n",
            " Epoch: 798\n",
            "Training loss 0.0185 \tTraining Prec@1 99.376 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.4915 \tValidation Prec@1 89.530 \tValidation Prec@5 99.690 \n",
            "\n",
            "lr: 0.010189145569393652\n",
            "o is 2.375993251800537,  o_a is 2.375993251800537\n",
            "TRAINING - Epoch: [798][0/196]\tTime 1.795 (1.795)\tData 0.989 (0.989)\tloss 0.0160 (0.0160)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [798][100/196]\tTime 0.350 (0.396)\tData 0.000 (0.010)\tloss 0.0026 (0.0174)\tPrec@1 100.000 (99.501)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [798][0/79]\tTime 0.544 (0.544)\tData 0.455 (0.455)\tloss 0.4432 (0.4432)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:25:20\n",
            "\n",
            " Epoch: 799\n",
            "Training loss 0.0177 \tTraining Prec@1 99.460 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5427 \tValidation Prec@1 89.370 \tValidation Prec@5 99.590 \n",
            "\n",
            "lr: 0.010093925217815599\n",
            "o is 2.378979206085205,  o_a is 2.378979206085205\n",
            "TRAINING - Epoch: [799][0/196]\tTime 1.928 (1.928)\tData 1.066 (1.066)\tloss 0.0192 (0.0192)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [799][100/196]\tTime 0.348 (0.396)\tData 0.000 (0.011)\tloss 0.0106 (0.0168)\tPrec@1 100.000 (99.505)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [799][0/79]\tTime 0.536 (0.536)\tData 0.377 (0.377)\tloss 0.3347 (0.3347)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:26:54\n",
            "\n",
            " Epoch: 800\n",
            "Training loss 0.0176 \tTraining Prec@1 99.468 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5067 \tValidation Prec@1 89.400 \tValidation Prec@5 99.620 \n",
            "\n",
            "lr: 0.009999101911503352\n",
            "o is 2.3819661140441895,  o_a is 2.3819661140441895\n",
            "TRAINING - Epoch: [800][0/196]\tTime 2.532 (2.532)\tData 1.207 (1.207)\tloss 0.0318 (0.0318)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [800][100/196]\tTime 0.353 (0.400)\tData 0.001 (0.013)\tloss 0.0194 (0.0180)\tPrec@1 99.219 (99.393)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [800][0/79]\tTime 0.479 (0.479)\tData 0.362 (0.362)\tloss 0.4209 (0.4209)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:28:59\n",
            "\n",
            " Epoch: 801\n",
            "Training loss 0.0170 \tTraining Prec@1 99.434 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.4906 \tValidation Prec@1 89.620 \tValidation Prec@5 99.690 \n",
            "\n",
            "lr: 0.009904676593856783\n",
            "o is 2.3849546909332275,  o_a is 2.3849546909332275\n",
            "TRAINING - Epoch: [801][0/196]\tTime 2.955 (2.955)\tData 1.448 (1.448)\tloss 0.0056 (0.0056)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [801][100/196]\tTime 0.351 (0.401)\tData 0.000 (0.015)\tloss 0.0052 (0.0163)\tPrec@1 100.000 (99.493)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [801][0/79]\tTime 0.455 (0.455)\tData 0.337 (0.337)\tloss 0.4462 (0.4462)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:30:44\n",
            "\n",
            " Epoch: 802\n",
            "Training loss 0.0162 \tTraining Prec@1 99.510 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5270 \tValidation Prec@1 89.520 \tValidation Prec@5 99.590 \n",
            "\n",
            "lr: 0.009810650204316132\n",
            "o is 2.3879446983337402,  o_a is 2.3879446983337402\n",
            "TRAINING - Epoch: [802][0/196]\tTime 2.569 (2.569)\tData 1.461 (1.461)\tloss 0.0167 (0.0167)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [802][100/196]\tTime 0.353 (0.393)\tData 0.000 (0.015)\tloss 0.0147 (0.0167)\tPrec@1 99.609 (99.447)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [802][0/79]\tTime 0.626 (0.626)\tData 0.423 (0.423)\tloss 0.4037 (0.4037)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:31:37\n",
            "\n",
            " Epoch: 803\n",
            "Training loss 0.0184 \tTraining Prec@1 99.386 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5608 \tValidation Prec@1 88.900 \tValidation Prec@5 99.580 \n",
            "\n",
            "lr: 0.00971702367835272\n",
            "o is 2.3909363746643066,  o_a is 2.3909363746643066\n",
            "TRAINING - Epoch: [803][0/196]\tTime 2.020 (2.020)\tData 1.125 (1.125)\tloss 0.0141 (0.0141)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [803][100/196]\tTime 0.352 (0.386)\tData 0.000 (0.012)\tloss 0.0159 (0.0164)\tPrec@1 99.609 (99.482)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [803][0/79]\tTime 0.816 (0.816)\tData 0.605 (0.605)\tloss 0.3429 (0.3429)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:20\tTime of Finish: 2023-11-27 09:28:59\n",
            "\n",
            " Epoch: 804\n",
            "Training loss 0.0166 \tTraining Prec@1 99.486 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5354 \tValidation Prec@1 89.460 \tValidation Prec@5 99.650 \n",
            "\n",
            "lr: 0.009623797947459541\n",
            "o is 2.3939294815063477,  o_a is 2.3939294815063477\n",
            "TRAINING - Epoch: [804][0/196]\tTime 1.794 (1.794)\tData 0.799 (0.799)\tloss 0.0108 (0.0108)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [804][100/196]\tTime 0.349 (0.386)\tData 0.003 (0.009)\tloss 0.0131 (0.0165)\tPrec@1 99.609 (99.544)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [804][0/79]\tTime 0.951 (0.951)\tData 0.712 (0.712)\tloss 0.3067 (0.3067)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:26:16\n",
            "\n",
            " Epoch: 805\n",
            "Training loss 0.0168 \tTraining Prec@1 99.498 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5214 \tValidation Prec@1 89.670 \tValidation Prec@5 99.620 \n",
            "\n",
            "lr: 0.009530973939142167\n",
            "o is 2.3969240188598633,  o_a is 2.3969240188598633\n",
            "TRAINING - Epoch: [805][0/196]\tTime 1.802 (1.802)\tData 0.846 (0.846)\tloss 0.0080 (0.0080)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [805][100/196]\tTime 0.350 (0.385)\tData 0.000 (0.009)\tloss 0.0263 (0.0176)\tPrec@1 99.219 (99.466)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [805][0/79]\tTime 0.839 (0.839)\tData 0.632 (0.632)\tloss 0.3914 (0.3914)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:25:54\n",
            "\n",
            " Epoch: 806\n",
            "Training loss 0.0172 \tTraining Prec@1 99.462 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5141 \tValidation Prec@1 89.360 \tValidation Prec@5 99.610 \n",
            "\n",
            "lr: 0.00943855257690936\n",
            "o is 2.3999202251434326,  o_a is 2.3999202251434326\n",
            "TRAINING - Epoch: [806][0/196]\tTime 1.771 (1.771)\tData 0.848 (0.848)\tloss 0.0074 (0.0074)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [806][100/196]\tTime 0.367 (0.386)\tData 0.000 (0.009)\tloss 0.0059 (0.0147)\tPrec@1 100.000 (99.536)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [806][0/79]\tTime 0.830 (0.830)\tData 0.633 (0.633)\tloss 0.3091 (0.3091)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:52\n",
            "\n",
            " Epoch: 807\n",
            "Training loss 0.0152 \tTraining Prec@1 99.532 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5493 \tValidation Prec@1 89.330 \tValidation Prec@5 99.610 \n",
            "\n",
            "lr: 0.00934653478026396\n",
            "o is 2.4029176235198975,  o_a is 2.4029176235198975\n",
            "TRAINING - Epoch: [807][0/196]\tTime 1.807 (1.807)\tData 0.982 (0.982)\tloss 0.0121 (0.0121)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [807][100/196]\tTime 0.436 (0.389)\tData 0.006 (0.011)\tloss 0.0119 (0.0154)\tPrec@1 99.609 (99.524)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [807][0/79]\tTime 0.527 (0.527)\tData 0.452 (0.452)\tloss 0.3737 (0.3737)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:05\n",
            "\n",
            " Epoch: 808\n",
            "Training loss 0.0160 \tTraining Prec@1 99.488 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5078 \tValidation Prec@1 89.620 \tValidation Prec@5 99.700 \n",
            "\n",
            "lr: 0.009254921464693701\n",
            "o is 2.405917167663574,  o_a is 2.405917167663574\n",
            "TRAINING - Epoch: [808][0/196]\tTime 1.729 (1.729)\tData 0.787 (0.787)\tloss 0.0122 (0.0122)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [808][100/196]\tTime 0.445 (0.387)\tData 0.000 (0.009)\tloss 0.0196 (0.0152)\tPrec@1 99.219 (99.544)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [808][0/79]\tTime 0.586 (0.586)\tData 0.475 (0.475)\tloss 0.2453 (0.2453)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:22:25\n",
            "\n",
            " Epoch: 809\n",
            "Training loss 0.0153 \tTraining Prec@1 99.550 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5678 \tValidation Prec@1 89.300 \tValidation Prec@5 99.550 \n",
            "\n",
            "lr: 0.009163713541662184\n",
            "o is 2.4089174270629883,  o_a is 2.4089174270629883\n",
            "TRAINING - Epoch: [809][0/196]\tTime 1.798 (1.798)\tData 1.030 (1.030)\tloss 0.0089 (0.0089)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [809][100/196]\tTime 0.422 (0.390)\tData 0.007 (0.011)\tloss 0.0095 (0.0157)\tPrec@1 100.000 (99.547)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [809][0/79]\tTime 0.422 (0.422)\tData 0.295 (0.295)\tloss 0.3068 (0.3068)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:22:56\n",
            "\n",
            " Epoch: 810\n",
            "Training loss 0.0158 \tTraining Prec@1 99.546 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5145 \tValidation Prec@1 89.520 \tValidation Prec@5 99.620 \n",
            "\n",
            "lr: 0.009072911918599665\n",
            "o is 2.411919355392456,  o_a is 2.411919355392456\n",
            "TRAINING - Epoch: [810][0/196]\tTime 1.787 (1.787)\tData 0.827 (0.827)\tloss 0.0113 (0.0113)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [810][100/196]\tTime 0.402 (0.389)\tData 0.001 (0.009)\tloss 0.0182 (0.0143)\tPrec@1 99.609 (99.571)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [810][0/79]\tTime 0.504 (0.504)\tData 0.394 (0.394)\tloss 0.2997 (0.2997)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:02\n",
            "\n",
            " Epoch: 811\n",
            "Training loss 0.0147 \tTraining Prec@1 99.540 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5320 \tValidation Prec@1 89.320 \tValidation Prec@5 99.580 \n",
            "\n",
            "lr: 0.008982517498894147\n",
            "o is 2.4149229526519775,  o_a is 2.4149229526519775\n",
            "TRAINING - Epoch: [811][0/196]\tTime 1.755 (1.755)\tData 0.783 (0.783)\tloss 0.0142 (0.0142)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [811][100/196]\tTime 0.426 (0.391)\tData 0.000 (0.008)\tloss 0.0073 (0.0172)\tPrec@1 99.609 (99.428)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [811][0/79]\tTime 0.428 (0.428)\tData 0.330 (0.330)\tloss 0.3814 (0.3814)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:09\n",
            "\n",
            " Epoch: 812\n",
            "Training loss 0.0170 \tTraining Prec@1 99.462 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5345 \tValidation Prec@1 89.610 \tValidation Prec@5 99.610 \n",
            "\n",
            "lr: 0.008892531181882386\n",
            "o is 2.4179277420043945,  o_a is 2.4179277420043945\n",
            "TRAINING - Epoch: [812][0/196]\tTime 1.555 (1.555)\tData 0.595 (0.595)\tloss 0.0106 (0.0106)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [812][100/196]\tTime 0.410 (0.390)\tData 0.000 (0.007)\tloss 0.0042 (0.0166)\tPrec@1 100.000 (99.470)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [812][0/79]\tTime 0.567 (0.567)\tData 0.481 (0.481)\tloss 0.3869 (0.3869)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:24\n",
            "\n",
            " Epoch: 813\n",
            "Training loss 0.0176 \tTraining Prec@1 99.428 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5369 \tValidation Prec@1 89.770 \tValidation Prec@5 99.680 \n",
            "\n",
            "lr: 0.008802953862840867\n",
            "o is 2.4209342002868652,  o_a is 2.4209342002868652\n",
            "TRAINING - Epoch: [813][0/196]\tTime 1.776 (1.776)\tData 1.002 (1.002)\tloss 0.0108 (0.0108)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [813][100/196]\tTime 0.411 (0.390)\tData 0.000 (0.011)\tloss 0.0121 (0.0159)\tPrec@1 99.219 (99.540)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [813][0/79]\tTime 0.435 (0.435)\tData 0.374 (0.374)\tloss 0.3513 (0.3513)\tPrec@1 89.844 (89.844)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:23\n",
            "\n",
            " Epoch: 814\n",
            "Training loss 0.0154 \tTraining Prec@1 99.526 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5232 \tValidation Prec@1 89.280 \tValidation Prec@5 99.590 \n",
            "\n",
            "lr: 0.008713786432976975\n",
            "o is 2.4239418506622314,  o_a is 2.4239418506622314\n",
            "TRAINING - Epoch: [814][0/196]\tTime 1.748 (1.748)\tData 0.842 (0.842)\tloss 0.0108 (0.0108)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [814][100/196]\tTime 0.433 (0.390)\tData 0.000 (0.009)\tloss 0.0092 (0.0151)\tPrec@1 100.000 (99.575)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [814][0/79]\tTime 0.577 (0.577)\tData 0.499 (0.499)\tloss 0.3895 (0.3895)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:56\n",
            "\n",
            " Epoch: 815\n",
            "Training loss 0.0153 \tTraining Prec@1 99.556 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5403 \tValidation Prec@1 89.380 \tValidation Prec@5 99.590 \n",
            "\n",
            "lr: 0.008625029779420042\n",
            "o is 2.4269509315490723,  o_a is 2.4269509315490723\n",
            "TRAINING - Epoch: [815][0/196]\tTime 1.797 (1.797)\tData 0.897 (0.897)\tloss 0.0192 (0.0192)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [815][100/196]\tTime 0.419 (0.392)\tData 0.000 (0.010)\tloss 0.0108 (0.0158)\tPrec@1 100.000 (99.466)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [815][0/79]\tTime 0.505 (0.505)\tData 0.376 (0.376)\tloss 0.3715 (0.3715)\tPrec@1 89.844 (89.844)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:33\n",
            "\n",
            " Epoch: 816\n",
            "Training loss 0.0149 \tTraining Prec@1 99.532 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5225 \tValidation Prec@1 89.490 \tValidation Prec@5 99.610 \n",
            "\n",
            "lr: 0.00853668478521265\n",
            "o is 2.429961681365967,  o_a is 2.429961681365967\n",
            "TRAINING - Epoch: [816][0/196]\tTime 1.628 (1.628)\tData 0.738 (0.738)\tloss 0.0170 (0.0170)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [816][100/196]\tTime 0.410 (0.391)\tData 0.008 (0.008)\tloss 0.0106 (0.0154)\tPrec@1 100.000 (99.547)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [816][0/79]\tTime 0.400 (0.400)\tData 0.302 (0.302)\tloss 0.3770 (0.3770)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:10\n",
            "\n",
            " Epoch: 817\n",
            "Training loss 0.0154 \tTraining Prec@1 99.562 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5126 \tValidation Prec@1 89.490 \tValidation Prec@5 99.590 \n",
            "\n",
            "lr: 0.008448752329301716\n",
            "o is 2.4329733848571777,  o_a is 2.4329733848571777\n",
            "TRAINING - Epoch: [817][0/196]\tTime 1.810 (1.810)\tData 0.949 (0.949)\tloss 0.0070 (0.0070)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [817][100/196]\tTime 0.428 (0.394)\tData 0.000 (0.011)\tloss 0.0091 (0.0148)\tPrec@1 99.609 (99.528)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [817][0/79]\tTime 0.505 (0.505)\tData 0.406 (0.406)\tloss 0.3257 (0.3257)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:42\n",
            "\n",
            " Epoch: 818\n",
            "Training loss 0.0151 \tTraining Prec@1 99.510 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5152 \tValidation Prec@1 89.740 \tValidation Prec@5 99.600 \n",
            "\n",
            "lr: 0.008361233286529822\n",
            "o is 2.4359869956970215,  o_a is 2.4359869956970215\n",
            "TRAINING - Epoch: [818][0/196]\tTime 1.799 (1.799)\tData 1.037 (1.037)\tloss 0.0090 (0.0090)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [818][100/196]\tTime 0.405 (0.393)\tData 0.001 (0.011)\tloss 0.0168 (0.0139)\tPrec@1 99.219 (99.575)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [818][0/79]\tTime 0.461 (0.461)\tData 0.316 (0.316)\tloss 0.4277 (0.4277)\tPrec@1 89.062 (89.062)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:17\n",
            "\n",
            " Epoch: 819\n",
            "Training loss 0.0151 \tTraining Prec@1 99.502 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5032 \tValidation Prec@1 89.670 \tValidation Prec@5 99.730 \n",
            "\n",
            "lr: 0.008274128527626481\n",
            "o is 2.4390015602111816,  o_a is 2.4390015602111816\n",
            "TRAINING - Epoch: [819][0/196]\tTime 1.836 (1.836)\tData 1.047 (1.047)\tloss 0.0055 (0.0055)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [819][100/196]\tTime 0.425 (0.394)\tData 0.007 (0.011)\tloss 0.0174 (0.0166)\tPrec@1 99.609 (99.455)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [819][0/79]\tTime 0.526 (0.526)\tData 0.476 (0.476)\tloss 0.2865 (0.2865)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:49\n",
            "\n",
            " Epoch: 820\n",
            "Training loss 0.0158 \tTraining Prec@1 99.490 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5118 \tValidation Prec@1 89.800 \tValidation Prec@5 99.590 \n",
            "\n",
            "lr: 0.00818743891919949\n",
            "o is 2.4420177936553955,  o_a is 2.4420177936553955\n",
            "TRAINING - Epoch: [820][0/196]\tTime 1.888 (1.888)\tData 0.924 (0.924)\tloss 0.0262 (0.0262)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [820][100/196]\tTime 0.416 (0.397)\tData 0.000 (0.010)\tloss 0.0114 (0.0147)\tPrec@1 99.609 (99.555)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [820][0/79]\tTime 0.354 (0.354)\tData 0.246 (0.246)\tloss 0.2480 (0.2480)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:57\n",
            "\n",
            " Epoch: 821\n",
            "Training loss 0.0148 \tTraining Prec@1 99.554 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5313 \tValidation Prec@1 89.340 \tValidation Prec@5 99.700 \n",
            "\n",
            "lr: 0.008101165323726303\n",
            "o is 2.445035219192505,  o_a is 2.445035219192505\n",
            "TRAINING - Epoch: [821][0/196]\tTime 1.730 (1.730)\tData 0.803 (0.803)\tloss 0.0171 (0.0171)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [821][100/196]\tTime 0.385 (0.394)\tData 0.000 (0.009)\tloss 0.0228 (0.0145)\tPrec@1 99.219 (99.555)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [821][0/79]\tTime 0.496 (0.496)\tData 0.383 (0.383)\tloss 0.2789 (0.2789)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:50\n",
            "\n",
            " Epoch: 822\n",
            "Training loss 0.0142 \tTraining Prec@1 99.564 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5258 \tValidation Prec@1 89.290 \tValidation Prec@5 99.560 \n",
            "\n",
            "lr: 0.008015308599545438\n",
            "o is 2.448054313659668,  o_a is 2.448054313659668\n",
            "TRAINING - Epoch: [822][0/196]\tTime 1.799 (1.799)\tData 0.899 (0.899)\tloss 0.0099 (0.0099)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [822][100/196]\tTime 0.350 (0.394)\tData 0.000 (0.010)\tloss 0.0046 (0.0142)\tPrec@1 100.000 (99.582)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [822][0/79]\tTime 0.582 (0.582)\tData 0.422 (0.422)\tloss 0.2601 (0.2601)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:50\n",
            "\n",
            " Epoch: 823\n",
            "Training loss 0.0153 \tTraining Prec@1 99.538 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5183 \tValidation Prec@1 89.870 \tValidation Prec@5 99.650 \n",
            "\n",
            "lr: 0.007929869600847971\n",
            "o is 2.4510746002197266,  o_a is 2.4510746002197266\n",
            "TRAINING - Epoch: [823][0/196]\tTime 1.904 (1.904)\tData 1.020 (1.020)\tloss 0.0075 (0.0075)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [823][100/196]\tTime 0.352 (0.396)\tData 0.000 (0.011)\tloss 0.0120 (0.0139)\tPrec@1 99.609 (99.578)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [823][0/79]\tTime 0.347 (0.347)\tData 0.257 (0.257)\tloss 0.2467 (0.2467)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:25:05\n",
            "\n",
            " Epoch: 824\n",
            "Training loss 0.0146 \tTraining Prec@1 99.564 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5152 \tValidation Prec@1 89.720 \tValidation Prec@5 99.670 \n",
            "\n",
            "lr: 0.007844849177669004\n",
            "o is 2.4540963172912598,  o_a is 2.4540963172912598\n",
            "TRAINING - Epoch: [824][0/196]\tTime 1.702 (1.702)\tData 0.833 (0.833)\tloss 0.0245 (0.0245)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [824][100/196]\tTime 0.353 (0.395)\tData 0.000 (0.009)\tloss 0.0232 (0.0161)\tPrec@1 98.828 (99.493)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [824][0/79]\tTime 0.538 (0.538)\tData 0.390 (0.390)\tloss 0.4083 (0.4083)\tPrec@1 93.750 (93.750)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:25:00\n",
            "\n",
            " Epoch: 825\n",
            "Training loss 0.0155 \tTraining Prec@1 99.520 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5715 \tValidation Prec@1 89.040 \tValidation Prec@5 99.640 \n",
            "\n",
            "lr: 0.007760248175879194\n",
            "o is 2.4571192264556885,  o_a is 2.4571192264556885\n",
            "TRAINING - Epoch: [825][0/196]\tTime 1.713 (1.713)\tData 0.803 (0.803)\tloss 0.0124 (0.0124)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [825][100/196]\tTime 0.413 (0.395)\tData 0.000 (0.009)\tloss 0.0150 (0.0156)\tPrec@1 99.609 (99.528)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [825][0/79]\tTime 0.412 (0.412)\tData 0.290 (0.290)\tloss 0.3387 (0.3387)\tPrec@1 94.531 (94.531)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:24\n",
            "\n",
            " Epoch: 826\n",
            "Training loss 0.0145 \tTraining Prec@1 99.550 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5199 \tValidation Prec@1 89.450 \tValidation Prec@5 99.720 \n",
            "\n",
            "lr: 0.007676067437176386\n",
            "o is 2.4601433277130127,  o_a is 2.4601433277130127\n",
            "TRAINING - Epoch: [826][0/196]\tTime 1.806 (1.806)\tData 0.922 (0.922)\tloss 0.0073 (0.0073)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [826][100/196]\tTime 0.407 (0.394)\tData 0.000 (0.010)\tloss 0.0124 (0.0140)\tPrec@1 100.000 (99.563)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [826][0/79]\tTime 0.547 (0.547)\tData 0.444 (0.444)\tloss 0.2922 (0.2922)\tPrec@1 94.531 (94.531)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:49\n",
            "\n",
            " Epoch: 827\n",
            "Training loss 0.0150 \tTraining Prec@1 99.514 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5308 \tValidation Prec@1 89.500 \tValidation Prec@5 99.770 \n",
            "\n",
            "lr: 0.007592307799077235\n",
            "o is 2.4631690979003906,  o_a is 2.4631690979003906\n",
            "TRAINING - Epoch: [827][0/196]\tTime 1.678 (1.678)\tData 0.745 (0.745)\tloss 0.0224 (0.0224)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [827][100/196]\tTime 0.360 (0.392)\tData 0.000 (0.008)\tloss 0.0093 (0.0132)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [827][0/79]\tTime 0.541 (0.541)\tData 0.418 (0.418)\tloss 0.3885 (0.3885)\tPrec@1 92.188 (92.188)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:03\n",
            "\n",
            " Epoch: 828\n",
            "Training loss 0.0136 \tTraining Prec@1 99.608 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.4893 \tValidation Prec@1 89.760 \tValidation Prec@5 99.620 \n",
            "\n",
            "lr: 0.007508970094908814\n",
            "o is 2.466196060180664,  o_a is 2.466196060180664\n",
            "TRAINING - Epoch: [828][0/196]\tTime 1.563 (1.563)\tData 0.685 (0.685)\tloss 0.0301 (0.0301)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [828][100/196]\tTime 0.360 (0.393)\tData 0.000 (0.008)\tloss 0.0087 (0.0152)\tPrec@1 99.609 (99.528)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [828][0/79]\tTime 0.422 (0.422)\tData 0.349 (0.349)\tloss 0.3006 (0.3006)\tPrec@1 89.844 (89.844)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:28\n",
            "\n",
            " Epoch: 829\n",
            "Training loss 0.0148 \tTraining Prec@1 99.564 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5124 \tValidation Prec@1 89.290 \tValidation Prec@5 99.620 \n",
            "\n",
            "lr: 0.0074260551538004\n",
            "o is 2.469224452972412,  o_a is 2.469224452972412\n",
            "TRAINING - Epoch: [829][0/196]\tTime 1.760 (1.760)\tData 0.945 (0.945)\tloss 0.0126 (0.0126)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [829][100/196]\tTime 0.352 (0.393)\tData 0.000 (0.010)\tloss 0.0074 (0.0137)\tPrec@1 100.000 (99.594)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [829][0/79]\tTime 0.433 (0.433)\tData 0.295 (0.295)\tloss 0.3536 (0.3536)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:14\n",
            "\n",
            " Epoch: 830\n",
            "Training loss 0.0137 \tTraining Prec@1 99.564 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5172 \tValidation Prec@1 89.350 \tValidation Prec@5 99.620 \n",
            "\n",
            "lr: 0.007343563800675132\n",
            "o is 2.4722540378570557,  o_a is 2.4722540378570557\n",
            "TRAINING - Epoch: [830][0/196]\tTime 1.857 (1.857)\tData 0.961 (0.961)\tloss 0.0053 (0.0053)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [830][100/196]\tTime 0.352 (0.395)\tData 0.000 (0.011)\tloss 0.0047 (0.0130)\tPrec@1 100.000 (99.629)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [830][0/79]\tTime 0.492 (0.492)\tData 0.342 (0.342)\tloss 0.4153 (0.4153)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:56\n",
            "\n",
            " Epoch: 831\n",
            "Training loss 0.0131 \tTraining Prec@1 99.624 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5137 \tValidation Prec@1 89.730 \tValidation Prec@5 99.670 \n",
            "\n",
            "lr: 0.007261496856241932\n",
            "o is 2.4752845764160156,  o_a is 2.4752845764160156\n",
            "TRAINING - Epoch: [831][0/196]\tTime 1.734 (1.734)\tData 0.833 (0.833)\tloss 0.0059 (0.0059)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [831][100/196]\tTime 0.347 (0.395)\tData 0.000 (0.010)\tloss 0.0085 (0.0134)\tPrec@1 100.000 (99.555)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [831][0/79]\tTime 0.501 (0.501)\tData 0.437 (0.437)\tloss 0.3836 (0.3836)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:23\n",
            "\n",
            " Epoch: 832\n",
            "Training loss 0.0143 \tTraining Prec@1 99.560 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5220 \tValidation Prec@1 89.420 \tValidation Prec@5 99.610 \n",
            "\n",
            "lr: 0.007179855136987219\n",
            "o is 2.4783172607421875,  o_a is 2.4783172607421875\n",
            "TRAINING - Epoch: [832][0/196]\tTime 1.728 (1.728)\tData 0.788 (0.788)\tloss 0.0177 (0.0177)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [832][100/196]\tTime 0.347 (0.393)\tData 0.000 (0.009)\tloss 0.0123 (0.0143)\tPrec@1 100.000 (99.563)\tPrec@5 100.000 (99.996)\n",
            "EVALUATING - Epoch: [832][0/79]\tTime 0.407 (0.407)\tData 0.326 (0.326)\tloss 0.2834 (0.2834)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:09\n",
            "\n",
            " Epoch: 833\n",
            "Training loss 0.0145 \tTraining Prec@1 99.558 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5194 \tValidation Prec@1 89.610 \tValidation Prec@5 99.680 \n",
            "\n",
            "lr: 0.007098639455166835\n",
            "o is 2.4813504219055176,  o_a is 2.4813504219055176\n",
            "TRAINING - Epoch: [833][0/196]\tTime 1.779 (1.779)\tData 0.817 (0.817)\tloss 0.0163 (0.0163)\tPrec@1 98.828 (98.828)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [833][100/196]\tTime 0.349 (0.394)\tData 0.000 (0.009)\tloss 0.0078 (0.0145)\tPrec@1 100.000 (99.540)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [833][0/79]\tTime 0.410 (0.410)\tData 0.284 (0.284)\tloss 0.3301 (0.3301)\tPrec@1 92.969 (92.969)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:41\n",
            "\n",
            " Epoch: 834\n",
            "Training loss 0.0136 \tTraining Prec@1 99.580 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5140 \tValidation Prec@1 89.570 \tValidation Prec@5 99.630 \n",
            "\n",
            "lr: 0.007017850618798014\n",
            "o is 2.4843852519989014,  o_a is 2.4843852519989014\n",
            "TRAINING - Epoch: [834][0/196]\tTime 1.914 (1.914)\tData 0.997 (0.997)\tloss 0.0061 (0.0061)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [834][100/196]\tTime 0.350 (0.396)\tData 0.000 (0.011)\tloss 0.0222 (0.0129)\tPrec@1 99.219 (99.621)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [834][0/79]\tTime 0.450 (0.450)\tData 0.357 (0.357)\tloss 0.3404 (0.3404)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:43\n",
            "\n",
            " Epoch: 835\n",
            "Training loss 0.0128 \tTraining Prec@1 99.624 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5246 \tValidation Prec@1 89.560 \tValidation Prec@5 99.620 \n",
            "\n",
            "lr: 0.006937489431651212\n",
            "o is 2.4874212741851807,  o_a is 2.4874212741851807\n",
            "TRAINING - Epoch: [835][0/196]\tTime 1.851 (1.851)\tData 0.989 (0.989)\tloss 0.0034 (0.0034)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [835][100/196]\tTime 0.351 (0.394)\tData 0.001 (0.011)\tloss 0.0098 (0.0124)\tPrec@1 100.000 (99.648)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [835][0/79]\tTime 0.583 (0.583)\tData 0.490 (0.490)\tloss 0.4157 (0.4157)\tPrec@1 92.969 (92.969)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:53\n",
            "\n",
            " Epoch: 836\n",
            "Training loss 0.0128 \tTraining Prec@1 99.626 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5223 \tValidation Prec@1 89.490 \tValidation Prec@5 99.570 \n",
            "\n",
            "lr: 0.006857556693242252\n",
            "o is 2.4904587268829346,  o_a is 2.4904587268829346\n",
            "TRAINING - Epoch: [836][0/196]\tTime 1.780 (1.780)\tData 0.878 (0.878)\tloss 0.0057 (0.0057)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [836][100/196]\tTime 0.406 (0.392)\tData 0.000 (0.010)\tloss 0.0107 (0.0127)\tPrec@1 99.609 (99.629)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [836][0/79]\tTime 0.413 (0.413)\tData 0.320 (0.320)\tloss 0.3679 (0.3679)\tPrec@1 87.500 (87.500)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:10\n",
            "\n",
            " Epoch: 837\n",
            "Training loss 0.0126 \tTraining Prec@1 99.618 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5103 \tValidation Prec@1 89.680 \tValidation Prec@5 99.580 \n",
            "\n",
            "lr: 0.006778053198824273\n",
            "o is 2.493497371673584,  o_a is 2.493497371673584\n",
            "TRAINING - Epoch: [837][0/196]\tTime 1.765 (1.765)\tData 0.975 (0.975)\tloss 0.0161 (0.0161)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [837][100/196]\tTime 0.448 (0.390)\tData 0.000 (0.010)\tloss 0.0183 (0.0123)\tPrec@1 99.219 (99.609)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [837][0/79]\tTime 0.495 (0.495)\tData 0.317 (0.317)\tloss 0.3758 (0.3758)\tPrec@1 92.969 (92.969)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:16\n",
            "\n",
            " Epoch: 838\n",
            "Training loss 0.0128 \tTraining Prec@1 99.584 \tTraining Prec@5 99.998 \n",
            "Validation loss 0.5208 \tValidation Prec@1 89.680 \tValidation Prec@5 99.570 \n",
            "\n",
            "lr: 0.0066989797393798844\n",
            "o is 2.49653697013855,  o_a is 2.49653697013855\n",
            "TRAINING - Epoch: [838][0/196]\tTime 1.815 (1.815)\tData 1.015 (1.015)\tloss 0.0085 (0.0085)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [838][100/196]\tTime 0.434 (0.393)\tData 0.000 (0.011)\tloss 0.0045 (0.0143)\tPrec@1 100.000 (99.536)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [838][0/79]\tTime 0.481 (0.481)\tData 0.394 (0.394)\tloss 0.2940 (0.2940)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:02\n",
            "\n",
            " Epoch: 839\n",
            "Training loss 0.0142 \tTraining Prec@1 99.550 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5137 \tValidation Prec@1 89.790 \tValidation Prec@5 99.600 \n",
            "\n",
            "lr: 0.00662033710161325\n",
            "o is 2.4995779991149902,  o_a is 2.4995779991149902\n",
            "TRAINING - Epoch: [839][0/196]\tTime 1.755 (1.755)\tData 0.983 (0.983)\tloss 0.0129 (0.0129)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [839][100/196]\tTime 0.429 (0.393)\tData 0.000 (0.010)\tloss 0.0117 (0.0126)\tPrec@1 99.609 (99.656)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [839][0/79]\tTime 0.508 (0.508)\tData 0.414 (0.414)\tloss 0.3012 (0.3012)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:02\n",
            "\n",
            " Epoch: 840\n",
            "Training loss 0.0125 \tTraining Prec@1 99.628 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.4943 \tValidation Prec@1 89.550 \tValidation Prec@5 99.680 \n",
            "\n",
            "lr: 0.006542126067942265\n",
            "o is 2.502620220184326,  o_a is 2.502620220184326\n",
            "TRAINING - Epoch: [840][0/196]\tTime 1.765 (1.765)\tData 0.749 (0.749)\tloss 0.0053 (0.0053)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [840][100/196]\tTime 0.401 (0.392)\tData 0.000 (0.008)\tloss 0.0126 (0.0107)\tPrec@1 99.609 (99.725)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [840][0/79]\tTime 0.534 (0.534)\tData 0.402 (0.402)\tloss 0.2839 (0.2839)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:40\n",
            "\n",
            " Epoch: 841\n",
            "Training loss 0.0121 \tTraining Prec@1 99.646 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5356 \tValidation Prec@1 89.350 \tValidation Prec@5 99.650 \n",
            "\n",
            "lr: 0.006464347416490793\n",
            "o is 2.5056638717651367,  o_a is 2.5056638717651367\n",
            "TRAINING - Epoch: [841][0/196]\tTime 1.763 (1.763)\tData 0.916 (0.916)\tloss 0.0082 (0.0082)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [841][100/196]\tTime 0.446 (0.391)\tData 0.000 (0.010)\tloss 0.0094 (0.0140)\tPrec@1 100.000 (99.544)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [841][0/79]\tTime 0.603 (0.603)\tData 0.482 (0.482)\tloss 0.2475 (0.2475)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:41\n",
            "\n",
            " Epoch: 842\n",
            "Training loss 0.0144 \tTraining Prec@1 99.540 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5034 \tValidation Prec@1 89.680 \tValidation Prec@5 99.570 \n",
            "\n",
            "lr: 0.006387001921080916\n",
            "o is 2.5087084770202637,  o_a is 2.5087084770202637\n",
            "TRAINING - Epoch: [842][0/196]\tTime 1.593 (1.593)\tData 0.658 (0.658)\tloss 0.0247 (0.0247)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [842][100/196]\tTime 0.454 (0.390)\tData 0.000 (0.007)\tloss 0.0161 (0.0106)\tPrec@1 99.219 (99.706)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [842][0/79]\tTime 0.545 (0.545)\tData 0.435 (0.435)\tloss 0.2991 (0.2991)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:22:46\n",
            "\n",
            " Epoch: 843\n",
            "Training loss 0.0112 \tTraining Prec@1 99.682 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.4928 \tValidation Prec@1 89.800 \tValidation Prec@5 99.600 \n",
            "\n",
            "lr: 0.006310090351225232\n",
            "o is 2.5117545127868652,  o_a is 2.5117545127868652\n",
            "TRAINING - Epoch: [843][0/196]\tTime 1.747 (1.747)\tData 0.856 (0.856)\tloss 0.0062 (0.0062)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [843][100/196]\tTime 0.442 (0.390)\tData 0.005 (0.009)\tloss 0.0060 (0.0126)\tPrec@1 100.000 (99.625)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [843][0/79]\tTime 0.378 (0.378)\tData 0.337 (0.337)\tloss 0.2413 (0.2413)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:22:50\n",
            "\n",
            " Epoch: 844\n",
            "Training loss 0.0126 \tTraining Prec@1 99.636 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5024 \tValidation Prec@1 89.750 \tValidation Prec@5 99.690 \n",
            "\n",
            "lr: 0.006233613472119191\n",
            "o is 2.514801502227783,  o_a is 2.514801502227783\n",
            "TRAINING - Epoch: [844][0/196]\tTime 1.895 (1.895)\tData 0.905 (0.905)\tloss 0.0036 (0.0036)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [844][100/196]\tTime 0.414 (0.391)\tData 0.000 (0.010)\tloss 0.0032 (0.0126)\tPrec@1 100.000 (99.636)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [844][0/79]\tTime 0.541 (0.541)\tData 0.442 (0.442)\tloss 0.2522 (0.2522)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:12\n",
            "\n",
            " Epoch: 845\n",
            "Training loss 0.0118 \tTraining Prec@1 99.668 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5110 \tValidation Prec@1 89.480 \tValidation Prec@5 99.540 \n",
            "\n",
            "lr: 0.0061575720446335296\n",
            "o is 2.517849922180176,  o_a is 2.517849922180176\n",
            "TRAINING - Epoch: [845][0/196]\tTime 1.818 (1.818)\tData 0.938 (0.938)\tloss 0.0083 (0.0083)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [845][100/196]\tTime 0.433 (0.389)\tData 0.000 (0.010)\tloss 0.0120 (0.0134)\tPrec@1 99.609 (99.602)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [845][0/79]\tTime 0.366 (0.366)\tData 0.275 (0.275)\tloss 0.3334 (0.3334)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:58\n",
            "\n",
            " Epoch: 846\n",
            "Training loss 0.0133 \tTraining Prec@1 99.598 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5120 \tValidation Prec@1 89.560 \tValidation Prec@5 99.600 \n",
            "\n",
            "lr: 0.0060819668253066\n",
            "o is 2.520899534225464,  o_a is 2.520899534225464\n",
            "TRAINING - Epoch: [846][0/196]\tTime 1.847 (1.847)\tData 0.923 (0.923)\tloss 0.0106 (0.0106)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [846][100/196]\tTime 0.409 (0.391)\tData 0.005 (0.010)\tloss 0.0236 (0.0122)\tPrec@1 99.219 (99.640)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [846][0/79]\tTime 0.565 (0.565)\tData 0.455 (0.455)\tloss 0.3476 (0.3476)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:27\n",
            "\n",
            " Epoch: 847\n",
            "Training loss 0.0121 \tTraining Prec@1 99.650 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5150 \tValidation Prec@1 89.840 \tValidation Prec@5 99.600 \n",
            "\n",
            "lr: 0.006006798566336966\n",
            "o is 2.5239500999450684,  o_a is 2.5239500999450684\n",
            "TRAINING - Epoch: [847][0/196]\tTime 1.765 (1.765)\tData 0.915 (0.915)\tloss 0.0042 (0.0042)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [847][100/196]\tTime 0.418 (0.391)\tData 0.000 (0.010)\tloss 0.0077 (0.0103)\tPrec@1 100.000 (99.722)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [847][0/79]\tTime 0.598 (0.598)\tData 0.489 (0.489)\tloss 0.2702 (0.2702)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:00\n",
            "\n",
            " Epoch: 848\n",
            "Training loss 0.0109 \tTraining Prec@1 99.684 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5184 \tValidation Prec@1 89.670 \tValidation Prec@5 99.650 \n",
            "\n",
            "lr: 0.005932068015575818\n",
            "o is 2.5270020961761475,  o_a is 2.5270020961761475\n",
            "TRAINING - Epoch: [848][0/196]\tTime 1.775 (1.775)\tData 0.990 (0.990)\tloss 0.0173 (0.0173)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [848][100/196]\tTime 0.433 (0.391)\tData 0.000 (0.011)\tloss 0.0098 (0.0112)\tPrec@1 99.609 (99.664)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [848][0/79]\tTime 0.419 (0.419)\tData 0.300 (0.300)\tloss 0.2941 (0.2941)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:22:59\n",
            "\n",
            " Epoch: 849\n",
            "Training loss 0.0108 \tTraining Prec@1 99.682 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.4996 \tValidation Prec@1 89.930 \tValidation Prec@5 99.640 \n",
            "\n",
            "lr: 0.00585777591651961\n",
            "o is 2.530055046081543,  o_a is 2.530055046081543\n",
            "TRAINING - Epoch: [849][0/196]\tTime 1.771 (1.771)\tData 0.996 (0.996)\tloss 0.0046 (0.0046)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [849][100/196]\tTime 0.445 (0.390)\tData 0.000 (0.011)\tloss 0.0345 (0.0113)\tPrec@1 98.438 (99.687)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [849][0/79]\tTime 0.460 (0.460)\tData 0.341 (0.341)\tloss 0.3082 (0.3082)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:22:48\n",
            "\n",
            " Epoch: 850\n",
            "Training loss 0.0111 \tTraining Prec@1 99.684 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5153 \tValidation Prec@1 89.870 \tValidation Prec@5 99.730 \n",
            "\n",
            "lr: 0.005783923008302611\n",
            "o is 2.533109426498413,  o_a is 2.533109426498413\n",
            "TRAINING - Epoch: [850][0/196]\tTime 1.683 (1.683)\tData 0.842 (0.842)\tloss 0.0110 (0.0110)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [850][100/196]\tTime 0.425 (0.390)\tData 0.000 (0.009)\tloss 0.0287 (0.0108)\tPrec@1 99.219 (99.694)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [850][0/79]\tTime 0.482 (0.482)\tData 0.355 (0.355)\tloss 0.3965 (0.3965)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:22:44\n",
            "\n",
            " Epoch: 851\n",
            "Training loss 0.0112 \tTraining Prec@1 99.686 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5229 \tValidation Prec@1 89.390 \tValidation Prec@5 99.640 \n",
            "\n",
            "lr: 0.005710510025689544\n",
            "o is 2.5361647605895996,  o_a is 2.5361647605895996\n",
            "TRAINING - Epoch: [851][0/196]\tTime 1.786 (1.786)\tData 0.870 (0.870)\tloss 0.0238 (0.0238)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [851][100/196]\tTime 0.416 (0.389)\tData 0.007 (0.010)\tloss 0.0110 (0.0122)\tPrec@1 99.609 (99.594)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [851][0/79]\tTime 0.508 (0.508)\tData 0.376 (0.376)\tloss 0.3535 (0.3535)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:22:00\n",
            "\n",
            " Epoch: 852\n",
            "Training loss 0.0116 \tTraining Prec@1 99.654 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5107 \tValidation Prec@1 89.680 \tValidation Prec@5 99.620 \n",
            "\n",
            "lr: 0.0056375376990683455\n",
            "o is 2.5392212867736816,  o_a is 2.5392212867736816\n",
            "TRAINING - Epoch: [852][0/196]\tTime 1.511 (1.511)\tData 0.698 (0.698)\tloss 0.0101 (0.0101)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [852][100/196]\tTime 0.396 (0.386)\tData 0.000 (0.008)\tloss 0.0041 (0.0111)\tPrec@1 100.000 (99.687)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [852][0/79]\tTime 0.399 (0.399)\tData 0.276 (0.276)\tloss 0.2784 (0.2784)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:22:30\n",
            "\n",
            " Epoch: 853\n",
            "Training loss 0.0108 \tTraining Prec@1 99.684 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5432 \tValidation Prec@1 89.420 \tValidation Prec@5 99.630 \n",
            "\n",
            "lr: 0.0055650067544428155\n",
            "o is 2.54227876663208,  o_a is 2.54227876663208\n",
            "TRAINING - Epoch: [853][0/196]\tTime 1.739 (1.739)\tData 0.874 (0.874)\tloss 0.0061 (0.0061)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [853][100/196]\tTime 0.430 (0.388)\tData 0.000 (0.009)\tloss 0.0068 (0.0106)\tPrec@1 100.000 (99.691)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [853][0/79]\tTime 0.419 (0.419)\tData 0.289 (0.289)\tloss 0.3447 (0.3447)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:22:16\n",
            "\n",
            " Epoch: 854\n",
            "Training loss 0.0106 \tTraining Prec@1 99.706 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5257 \tValidation Prec@1 89.760 \tValidation Prec@5 99.700 \n",
            "\n",
            "lr: 0.00549291791342545\n",
            "o is 2.545337677001953,  o_a is 2.545337677001953\n",
            "TRAINING - Epoch: [854][0/196]\tTime 1.796 (1.796)\tData 0.938 (0.938)\tloss 0.0024 (0.0024)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [854][100/196]\tTime 0.408 (0.387)\tData 0.000 (0.010)\tloss 0.0040 (0.0110)\tPrec@1 100.000 (99.656)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [854][0/79]\tTime 0.523 (0.523)\tData 0.437 (0.437)\tloss 0.3363 (0.3363)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:22:01\n",
            "\n",
            " Epoch: 855\n",
            "Training loss 0.0105 \tTraining Prec@1 99.676 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5047 \tValidation Prec@1 89.860 \tValidation Prec@5 99.640 \n",
            "\n",
            "lr: 0.005421271893230239\n",
            "o is 2.5483975410461426,  o_a is 2.5483975410461426\n",
            "TRAINING - Epoch: [855][0/196]\tTime 1.769 (1.769)\tData 0.914 (0.914)\tloss 0.0053 (0.0053)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [855][100/196]\tTime 0.426 (0.387)\tData 0.000 (0.010)\tloss 0.0076 (0.0116)\tPrec@1 99.609 (99.664)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [855][0/79]\tTime 0.538 (0.538)\tData 0.391 (0.391)\tloss 0.3676 (0.3676)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:21:56\n",
            "\n",
            " Epoch: 856\n",
            "Training loss 0.0114 \tTraining Prec@1 99.664 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5254 \tValidation Prec@1 89.610 \tValidation Prec@5 99.600 \n",
            "\n",
            "lr: 0.005350069406665533\n",
            "o is 2.5514585971832275,  o_a is 2.5514585971832275\n",
            "TRAINING - Epoch: [856][0/196]\tTime 1.835 (1.835)\tData 0.927 (0.927)\tloss 0.0090 (0.0090)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [856][100/196]\tTime 0.370 (0.388)\tData 0.000 (0.010)\tloss 0.0102 (0.0108)\tPrec@1 100.000 (99.636)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [856][0/79]\tTime 0.364 (0.364)\tData 0.262 (0.262)\tloss 0.5056 (0.5056)\tPrec@1 92.188 (92.188)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:22:30\n",
            "\n",
            " Epoch: 857\n",
            "Training loss 0.0108 \tTraining Prec@1 99.650 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5148 \tValidation Prec@1 90.040 \tValidation Prec@5 99.690 \n",
            "\n",
            "lr: 0.005279311162126951\n",
            "o is 2.554520606994629,  o_a is 2.554520606994629\n",
            "TRAINING - Epoch: [857][0/196]\tTime 1.756 (1.756)\tData 0.773 (0.773)\tloss 0.0124 (0.0124)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [857][100/196]\tTime 0.410 (0.387)\tData 0.001 (0.008)\tloss 0.0107 (0.0102)\tPrec@1 99.609 (99.714)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [857][0/79]\tTime 0.523 (0.523)\tData 0.425 (0.425)\tloss 0.4665 (0.4665)\tPrec@1 92.188 (92.188)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:22:35\n",
            "\n",
            " Epoch: 858\n",
            "Training loss 0.0113 \tTraining Prec@1 99.698 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5234 \tValidation Prec@1 90.090 \tValidation Prec@5 99.620 \n",
            "\n",
            "lr: 0.00520899786359034\n",
            "o is 2.557583808898926,  o_a is 2.557583808898926\n",
            "TRAINING - Epoch: [858][0/196]\tTime 1.825 (1.825)\tData 1.016 (1.016)\tloss 0.0138 (0.0138)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [858][100/196]\tTime 0.448 (0.386)\tData 0.000 (0.011)\tloss 0.0159 (0.0112)\tPrec@1 99.609 (99.679)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [858][0/79]\tTime 0.588 (0.588)\tData 0.494 (0.494)\tloss 0.3621 (0.3621)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:21:48\n",
            "\n",
            " Epoch: 859\n",
            "Training loss 0.0110 \tTraining Prec@1 99.706 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5055 \tValidation Prec@1 89.740 \tValidation Prec@5 99.680 \n",
            "\n",
            "lr: 0.005139130210604761\n",
            "o is 2.560648202896118,  o_a is 2.560648202896118\n",
            "TRAINING - Epoch: [859][0/196]\tTime 1.763 (1.763)\tData 0.733 (0.733)\tloss 0.0142 (0.0142)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [859][100/196]\tTime 0.384 (0.386)\tData 0.001 (0.008)\tloss 0.0144 (0.0113)\tPrec@1 99.219 (99.648)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [859][0/79]\tTime 0.718 (0.718)\tData 0.602 (0.602)\tloss 0.2841 (0.2841)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:22:44\n",
            "\n",
            " Epoch: 860\n",
            "Training loss 0.0107 \tTraining Prec@1 99.696 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5332 \tValidation Prec@1 89.570 \tValidation Prec@5 99.620 \n",
            "\n",
            "lr: 0.005069708898285566\n",
            "o is 2.563713550567627,  o_a is 2.563713550567627\n",
            "TRAINING - Epoch: [860][0/196]\tTime 1.783 (1.783)\tData 0.897 (0.897)\tloss 0.0258 (0.0258)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [860][100/196]\tTime 0.406 (0.384)\tData 0.000 (0.010)\tloss 0.0102 (0.0113)\tPrec@1 99.609 (99.683)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [860][0/79]\tTime 0.878 (0.878)\tData 0.681 (0.681)\tloss 0.3721 (0.3721)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:19\n",
            "\n",
            " Epoch: 861\n",
            "Training loss 0.0111 \tTraining Prec@1 99.688 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5446 \tValidation Prec@1 89.730 \tValidation Prec@5 99.620 \n",
            "\n",
            "lr: 0.00500073461730739\n",
            "o is 2.5667800903320312,  o_a is 2.5667800903320312\n",
            "TRAINING - Epoch: [861][0/196]\tTime 1.804 (1.804)\tData 0.866 (0.866)\tloss 0.0068 (0.0068)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [861][100/196]\tTime 0.417 (0.384)\tData 0.000 (0.009)\tloss 0.0168 (0.0120)\tPrec@1 99.609 (99.667)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [861][0/79]\tTime 0.872 (0.872)\tData 0.696 (0.696)\tloss 0.3904 (0.3904)\tPrec@1 93.750 (93.750)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:41\n",
            "\n",
            " Epoch: 862\n",
            "Training loss 0.0114 \tTraining Prec@1 99.678 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5287 \tValidation Prec@1 89.810 \tValidation Prec@5 99.680 \n",
            "\n",
            "lr: 0.004932208053897369\n",
            "o is 2.569847583770752,  o_a is 2.569847583770752\n",
            "TRAINING - Epoch: [862][0/196]\tTime 1.791 (1.791)\tData 0.901 (0.901)\tloss 0.0077 (0.0077)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [862][100/196]\tTime 0.367 (0.382)\tData 0.003 (0.010)\tloss 0.0082 (0.0099)\tPrec@1 100.000 (99.722)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [862][0/79]\tTime 0.942 (0.942)\tData 0.673 (0.673)\tloss 0.3202 (0.3202)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:42\n",
            "\n",
            " Epoch: 863\n",
            "Training loss 0.0098 \tTraining Prec@1 99.728 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5291 \tValidation Prec@1 89.730 \tValidation Prec@5 99.610 \n",
            "\n",
            "lr: 0.0048641298898283196\n",
            "o is 2.572916030883789,  o_a is 2.572916030883789\n",
            "TRAINING - Epoch: [863][0/196]\tTime 1.677 (1.677)\tData 0.853 (0.853)\tloss 0.0032 (0.0032)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [863][100/196]\tTime 0.347 (0.382)\tData 0.000 (0.009)\tloss 0.0058 (0.0099)\tPrec@1 100.000 (99.725)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [863][0/79]\tTime 0.893 (0.893)\tData 0.680 (0.680)\tloss 0.2875 (0.2875)\tPrec@1 95.312 (95.312)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:59\n",
            "\n",
            " Epoch: 864\n",
            "Training loss 0.0104 \tTraining Prec@1 99.688 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5015 \tValidation Prec@1 90.010 \tValidation Prec@5 99.590 \n",
            "\n",
            "lr: 0.004796500802411872\n",
            "o is 2.575985908508301,  o_a is 2.575985908508301\n",
            "TRAINING - Epoch: [864][0/196]\tTime 1.808 (1.808)\tData 0.846 (0.846)\tloss 0.0015 (0.0015)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [864][100/196]\tTime 0.347 (0.383)\tData 0.000 (0.009)\tloss 0.0091 (0.0109)\tPrec@1 99.609 (99.683)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [864][0/79]\tTime 0.964 (0.964)\tData 0.791 (0.791)\tloss 0.3411 (0.3411)\tPrec@1 93.750 (93.750)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:56\n",
            "\n",
            " Epoch: 865\n",
            "Training loss 0.0111 \tTraining Prec@1 99.662 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5298 \tValidation Prec@1 89.360 \tValidation Prec@5 99.670 \n",
            "\n",
            "lr: 0.004729321464491807\n",
            "o is 2.579056739807129,  o_a is 2.579056739807129\n",
            "TRAINING - Epoch: [865][0/196]\tTime 1.749 (1.749)\tData 0.779 (0.779)\tloss 0.0282 (0.0282)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [865][100/196]\tTime 0.348 (0.381)\tData 0.000 (0.009)\tloss 0.0192 (0.0118)\tPrec@1 99.609 (99.629)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [865][0/79]\tTime 0.846 (0.846)\tData 0.670 (0.670)\tloss 0.3293 (0.3293)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:32\n",
            "\n",
            " Epoch: 866\n",
            "Training loss 0.0112 \tTraining Prec@1 99.646 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5533 \tValidation Prec@1 89.340 \tValidation Prec@5 99.570 \n",
            "\n",
            "lr: 0.004662592544437297\n",
            "o is 2.5821280479431152,  o_a is 2.5821280479431152\n",
            "TRAINING - Epoch: [866][0/196]\tTime 1.855 (1.855)\tData 1.059 (1.059)\tloss 0.0097 (0.0097)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [866][100/196]\tTime 0.347 (0.382)\tData 0.000 (0.011)\tloss 0.0153 (0.0101)\tPrec@1 99.609 (99.725)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [866][0/79]\tTime 0.895 (0.895)\tData 0.680 (0.680)\tloss 0.3407 (0.3407)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:54\n",
            "\n",
            " Epoch: 867\n",
            "Training loss 0.0101 \tTraining Prec@1 99.704 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.4988 \tValidation Prec@1 89.830 \tValidation Prec@5 99.650 \n",
            "\n",
            "lr: 0.004596314706136345\n",
            "o is 2.5852010250091553,  o_a is 2.5852010250091553\n",
            "TRAINING - Epoch: [867][0/196]\tTime 1.918 (1.918)\tData 1.057 (1.057)\tloss 0.0133 (0.0133)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [867][100/196]\tTime 0.345 (0.384)\tData 0.000 (0.011)\tloss 0.0081 (0.0106)\tPrec@1 99.609 (99.691)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [867][0/79]\tTime 0.859 (0.859)\tData 0.702 (0.702)\tloss 0.4124 (0.4124)\tPrec@1 91.406 (91.406)\tPrec@5 98.438 (98.438)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:34\n",
            "\n",
            " Epoch: 868\n",
            "Training loss 0.0100 \tTraining Prec@1 99.716 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5003 \tValidation Prec@1 90.120 \tValidation Prec@5 99.580 \n",
            "\n",
            "lr: 0.004530488608989092\n",
            "o is 2.5882749557495117,  o_a is 2.5882749557495117\n",
            "TRAINING - Epoch: [868][0/196]\tTime 2.653 (2.653)\tData 1.652 (1.652)\tloss 0.0139 (0.0139)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [868][100/196]\tTime 0.448 (0.396)\tData 0.000 (0.017)\tloss 0.0177 (0.0101)\tPrec@1 99.219 (99.718)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [868][0/79]\tTime 0.904 (0.904)\tData 0.705 (0.705)\tloss 0.3341 (0.3341)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:25:42\n",
            "\n",
            " Epoch: 869\n",
            "Training loss 0.0101 \tTraining Prec@1 99.714 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5216 \tValidation Prec@1 89.570 \tValidation Prec@5 99.620 \n",
            "\n",
            "lr: 0.004465114907901314\n",
            "o is 2.5913496017456055,  o_a is 2.5913496017456055\n",
            "TRAINING - Epoch: [869][0/196]\tTime 1.814 (1.814)\tData 0.974 (0.974)\tloss 0.0102 (0.0102)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [869][100/196]\tTime 0.415 (0.384)\tData 0.000 (0.010)\tloss 0.0069 (0.0101)\tPrec@1 100.000 (99.687)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [869][0/79]\tTime 0.962 (0.962)\tData 0.764 (0.764)\tloss 0.3877 (0.3877)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:41\n",
            "\n",
            " Epoch: 870\n",
            "Training loss 0.0095 \tTraining Prec@1 99.742 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5519 \tValidation Prec@1 89.570 \tValidation Prec@5 99.690 \n",
            "\n",
            "lr: 0.004400194253277865\n",
            "o is 2.594425678253174,  o_a is 2.594425678253174\n",
            "TRAINING - Epoch: [870][0/196]\tTime 1.717 (1.717)\tData 0.671 (0.671)\tloss 0.0029 (0.0029)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [870][100/196]\tTime 0.346 (0.383)\tData 0.000 (0.008)\tloss 0.0121 (0.0104)\tPrec@1 99.219 (99.683)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [870][0/79]\tTime 0.831 (0.831)\tData 0.640 (0.640)\tloss 0.2903 (0.2903)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:20\n",
            "\n",
            " Epoch: 871\n",
            "Training loss 0.0101 \tTraining Prec@1 99.714 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5204 \tValidation Prec@1 89.570 \tValidation Prec@5 99.740 \n",
            "\n",
            "lr: 0.004335727291016259\n",
            "o is 2.5975022315979004,  o_a is 2.5975022315979004\n",
            "TRAINING - Epoch: [871][0/196]\tTime 1.830 (1.830)\tData 1.029 (1.029)\tloss 0.0056 (0.0056)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [871][100/196]\tTime 0.346 (0.382)\tData 0.000 (0.011)\tloss 0.0142 (0.0089)\tPrec@1 99.609 (99.729)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [871][0/79]\tTime 0.863 (0.863)\tData 0.685 (0.685)\tloss 0.3787 (0.3787)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:01\n",
            "\n",
            " Epoch: 872\n",
            "Training loss 0.0098 \tTraining Prec@1 99.702 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5490 \tValidation Prec@1 89.450 \tValidation Prec@5 99.590 \n",
            "\n",
            "lr: 0.004271714662500167\n",
            "o is 2.6005802154541016,  o_a is 2.6005802154541016\n",
            "TRAINING - Epoch: [872][0/196]\tTime 1.825 (1.825)\tData 1.004 (1.004)\tloss 0.0215 (0.0215)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [872][100/196]\tTime 0.353 (0.382)\tData 0.000 (0.011)\tloss 0.0104 (0.0101)\tPrec@1 99.609 (99.733)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [872][0/79]\tTime 0.844 (0.844)\tData 0.684 (0.684)\tloss 0.2732 (0.2732)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:01\n",
            "\n",
            " Epoch: 873\n",
            "Training loss 0.0101 \tTraining Prec@1 99.708 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5307 \tValidation Prec@1 89.390 \tValidation Prec@5 99.680 \n",
            "\n",
            "lr: 0.004208157004593109\n",
            "o is 2.60365891456604,  o_a is 2.60365891456604\n",
            "TRAINING - Epoch: [873][0/196]\tTime 1.847 (1.847)\tData 0.962 (0.962)\tloss 0.0200 (0.0200)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [873][100/196]\tTime 0.349 (0.383)\tData 0.000 (0.010)\tloss 0.0075 (0.0103)\tPrec@1 99.609 (99.706)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [873][0/79]\tTime 0.835 (0.835)\tData 0.626 (0.626)\tloss 0.3125 (0.3125)\tPrec@1 95.312 (95.312)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:46\n",
            "\n",
            " Epoch: 874\n",
            "Training loss 0.0102 \tTraining Prec@1 99.706 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5259 \tValidation Prec@1 89.830 \tValidation Prec@5 99.600 \n",
            "\n",
            "lr: 0.004145054949632094\n",
            "o is 2.606738567352295,  o_a is 2.606738567352295\n",
            "TRAINING - Epoch: [874][0/196]\tTime 1.835 (1.835)\tData 0.948 (0.948)\tloss 0.0131 (0.0131)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [874][100/196]\tTime 0.345 (0.382)\tData 0.000 (0.010)\tloss 0.0035 (0.0099)\tPrec@1 100.000 (99.760)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [874][0/79]\tTime 0.941 (0.941)\tData 0.723 (0.723)\tloss 0.3249 (0.3249)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:09\n",
            "\n",
            " Epoch: 875\n",
            "Training loss 0.0099 \tTraining Prec@1 99.724 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5132 \tValidation Prec@1 89.530 \tValidation Prec@5 99.610 \n",
            "\n",
            "lr: 0.0040824091254213065\n",
            "o is 2.6098194122314453,  o_a is 2.6098194122314453\n",
            "TRAINING - Epoch: [875][0/196]\tTime 1.795 (1.795)\tData 0.792 (0.792)\tloss 0.0041 (0.0041)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [875][100/196]\tTime 0.346 (0.383)\tData 0.000 (0.009)\tloss 0.0090 (0.0097)\tPrec@1 99.609 (99.729)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [875][0/79]\tTime 0.866 (0.866)\tData 0.681 (0.681)\tloss 0.2727 (0.2727)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:21\n",
            "\n",
            " Epoch: 876\n",
            "Training loss 0.0103 \tTraining Prec@1 99.686 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5105 \tValidation Prec@1 90.010 \tValidation Prec@5 99.540 \n",
            "\n",
            "lr: 0.004020220155225895\n",
            "o is 2.612900972366333,  o_a is 2.612900972366333\n",
            "TRAINING - Epoch: [876][0/196]\tTime 1.685 (1.685)\tData 0.834 (0.834)\tloss 0.0060 (0.0060)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [876][100/196]\tTime 0.348 (0.381)\tData 0.004 (0.009)\tloss 0.0238 (0.0093)\tPrec@1 98.828 (99.752)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [876][0/79]\tTime 0.919 (0.919)\tData 0.686 (0.686)\tloss 0.2367 (0.2367)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:09\n",
            "\n",
            " Epoch: 877\n",
            "Training loss 0.0092 \tTraining Prec@1 99.752 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5031 \tValidation Prec@1 90.140 \tValidation Prec@5 99.670 \n",
            "\n",
            "lr: 0.003958488657765722\n",
            "o is 2.615983724594116,  o_a is 2.615983724594116\n",
            "TRAINING - Epoch: [877][0/196]\tTime 1.717 (1.717)\tData 0.917 (0.917)\tloss 0.0168 (0.0168)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [877][100/196]\tTime 0.345 (0.382)\tData 0.000 (0.010)\tloss 0.0026 (0.0082)\tPrec@1 100.000 (99.795)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [877][0/79]\tTime 0.674 (0.674)\tData 0.462 (0.462)\tloss 0.2036 (0.2036)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:09\n",
            "\n",
            " Epoch: 878\n",
            "Training loss 0.0090 \tTraining Prec@1 99.752 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5296 \tValidation Prec@1 89.640 \tValidation Prec@5 99.560 \n",
            "\n",
            "lr: 0.0038972152472092772\n",
            "o is 2.619067430496216,  o_a is 2.619067430496216\n",
            "TRAINING - Epoch: [878][0/196]\tTime 1.791 (1.791)\tData 0.934 (0.934)\tloss 0.0096 (0.0096)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [878][100/196]\tTime 0.346 (0.382)\tData 0.000 (0.010)\tloss 0.0051 (0.0096)\tPrec@1 100.000 (99.725)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [878][0/79]\tTime 0.959 (0.959)\tData 0.779 (0.779)\tloss 0.2904 (0.2904)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:26\n",
            "\n",
            " Epoch: 879\n",
            "Training loss 0.0102 \tTraining Prec@1 99.712 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5065 \tValidation Prec@1 89.630 \tValidation Prec@5 99.690 \n",
            "\n",
            "lr: 0.0038364005331675195\n",
            "o is 2.6221518516540527,  o_a is 2.6221518516540527\n",
            "TRAINING - Epoch: [879][0/196]\tTime 1.839 (1.839)\tData 0.982 (0.982)\tloss 0.0059 (0.0059)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [879][100/196]\tTime 0.346 (0.382)\tData 0.000 (0.011)\tloss 0.0067 (0.0095)\tPrec@1 99.609 (99.718)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [879][0/79]\tTime 0.938 (0.938)\tData 0.709 (0.709)\tloss 0.2235 (0.2235)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:17\n",
            "\n",
            " Epoch: 880\n",
            "Training loss 0.0097 \tTraining Prec@1 99.726 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5312 \tValidation Prec@1 89.630 \tValidation Prec@5 99.640 \n",
            "\n",
            "lr: 0.003776045120687813\n",
            "o is 2.625237464904785,  o_a is 2.625237464904785\n",
            "TRAINING - Epoch: [880][0/196]\tTime 1.858 (1.858)\tData 1.068 (1.068)\tloss 0.0029 (0.0029)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [880][100/196]\tTime 0.348 (0.384)\tData 0.000 (0.011)\tloss 0.0104 (0.0097)\tPrec@1 99.609 (99.741)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [880][0/79]\tTime 0.891 (0.891)\tData 0.686 (0.686)\tloss 0.2044 (0.2044)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:18\n",
            "\n",
            " Epoch: 881\n",
            "Training loss 0.0091 \tTraining Prec@1 99.744 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.4981 \tValidation Prec@1 90.040 \tValidation Prec@5 99.650 \n",
            "\n",
            "lr: 0.0037161496102479192\n",
            "o is 2.628323793411255,  o_a is 2.628323793411255\n",
            "TRAINING - Epoch: [881][0/196]\tTime 1.725 (1.725)\tData 0.806 (0.806)\tloss 0.0027 (0.0027)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [881][100/196]\tTime 0.358 (0.380)\tData 0.000 (0.009)\tloss 0.0161 (0.0092)\tPrec@1 98.828 (99.737)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [881][0/79]\tTime 0.843 (0.843)\tData 0.624 (0.624)\tloss 0.2583 (0.2583)\tPrec@1 95.312 (95.312)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:31\n",
            "\n",
            " Epoch: 882\n",
            "Training loss 0.0089 \tTraining Prec@1 99.740 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5383 \tValidation Prec@1 89.750 \tValidation Prec@5 99.610 \n",
            "\n",
            "lr: 0.0036567145977500315\n",
            "o is 2.63141131401062,  o_a is 2.63141131401062\n",
            "TRAINING - Epoch: [882][0/196]\tTime 1.817 (1.817)\tData 0.928 (0.928)\tloss 0.0040 (0.0040)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [882][100/196]\tTime 0.347 (0.381)\tData 0.000 (0.010)\tloss 0.0079 (0.0099)\tPrec@1 100.000 (99.729)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [882][0/79]\tTime 0.850 (0.850)\tData 0.671 (0.671)\tloss 0.2306 (0.2306)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:37\n",
            "\n",
            " Epoch: 883\n",
            "Training loss 0.0098 \tTraining Prec@1 99.706 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5123 \tValidation Prec@1 89.810 \tValidation Prec@5 99.700 \n",
            "\n",
            "lr: 0.0035977406745148267\n",
            "o is 2.6344995498657227,  o_a is 2.6344995498657227\n",
            "TRAINING - Epoch: [883][0/196]\tTime 1.758 (1.758)\tData 0.895 (0.895)\tloss 0.0074 (0.0074)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [883][100/196]\tTime 0.348 (0.380)\tData 0.000 (0.010)\tloss 0.0039 (0.0085)\tPrec@1 100.000 (99.780)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [883][0/79]\tTime 0.896 (0.896)\tData 0.689 (0.689)\tloss 0.2611 (0.2611)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:35\n",
            "\n",
            " Epoch: 884\n",
            "Training loss 0.0095 \tTraining Prec@1 99.756 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5181 \tValidation Prec@1 90.100 \tValidation Prec@5 99.690 \n",
            "\n",
            "lr: 0.0035392284272755857\n",
            "o is 2.6375885009765625,  o_a is 2.6375885009765625\n",
            "TRAINING - Epoch: [884][0/196]\tTime 1.768 (1.768)\tData 0.833 (0.833)\tloss 0.0050 (0.0050)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [884][100/196]\tTime 0.352 (0.382)\tData 0.000 (0.009)\tloss 0.0233 (0.0089)\tPrec@1 99.219 (99.772)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [884][0/79]\tTime 0.711 (0.711)\tData 0.518 (0.518)\tloss 0.3251 (0.3251)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:04\n",
            "\n",
            " Epoch: 885\n",
            "Training loss 0.0089 \tTraining Prec@1 99.776 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5267 \tValidation Prec@1 89.840 \tValidation Prec@5 99.520 \n",
            "\n",
            "lr: 0.0034811784381723805\n",
            "o is 2.6406784057617188,  o_a is 2.6406784057617188\n",
            "TRAINING - Epoch: [885][0/196]\tTime 1.769 (1.769)\tData 0.871 (0.871)\tloss 0.0039 (0.0039)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [885][100/196]\tTime 0.348 (0.380)\tData 0.000 (0.009)\tloss 0.0038 (0.0096)\tPrec@1 100.000 (99.722)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [885][0/79]\tTime 0.830 (0.830)\tData 0.631 (0.631)\tloss 0.3259 (0.3259)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:34\n",
            "\n",
            " Epoch: 886\n",
            "Training loss 0.0096 \tTraining Prec@1 99.720 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5524 \tValidation Prec@1 89.630 \tValidation Prec@5 99.520 \n",
            "\n",
            "lr: 0.003423591284746258\n",
            "o is 2.6437692642211914,  o_a is 2.6437692642211914\n",
            "TRAINING - Epoch: [886][0/196]\tTime 1.716 (1.716)\tData 0.819 (0.819)\tloss 0.0104 (0.0104)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [886][100/196]\tTime 0.345 (0.381)\tData 0.000 (0.009)\tloss 0.0057 (0.0093)\tPrec@1 99.609 (99.733)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [886][0/79]\tTime 0.868 (0.868)\tData 0.680 (0.680)\tloss 0.2346 (0.2346)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:53\n",
            "\n",
            " Epoch: 887\n",
            "Training loss 0.0092 \tTraining Prec@1 99.740 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5174 \tValidation Prec@1 89.920 \tValidation Prec@5 99.530 \n",
            "\n",
            "lr: 0.0033664675399334696\n",
            "o is 2.6468613147735596,  o_a is 2.6468613147735596\n",
            "TRAINING - Epoch: [887][0/196]\tTime 1.818 (1.818)\tData 0.864 (0.864)\tloss 0.0099 (0.0099)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [887][100/196]\tTime 0.348 (0.382)\tData 0.000 (0.009)\tloss 0.0113 (0.0097)\tPrec@1 99.609 (99.702)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [887][0/79]\tTime 0.754 (0.754)\tData 0.555 (0.555)\tloss 0.2838 (0.2838)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:45\n",
            "\n",
            " Epoch: 888\n",
            "Training loss 0.0093 \tTraining Prec@1 99.730 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5028 \tValidation Prec@1 90.100 \tValidation Prec@5 99.680 \n",
            "\n",
            "lr: 0.0033098077720598276\n",
            "o is 2.649953842163086,  o_a is 2.649953842163086\n",
            "TRAINING - Epoch: [888][0/196]\tTime 1.770 (1.770)\tData 0.812 (0.812)\tloss 0.0024 (0.0024)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [888][100/196]\tTime 0.347 (0.382)\tData 0.001 (0.009)\tloss 0.0257 (0.0091)\tPrec@1 99.219 (99.749)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [888][0/79]\tTime 0.920 (0.920)\tData 0.722 (0.722)\tloss 0.3387 (0.3387)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:06\n",
            "\n",
            " Epoch: 889\n",
            "Training loss 0.0089 \tTraining Prec@1 99.758 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5254 \tValidation Prec@1 89.830 \tValidation Prec@5 99.590 \n",
            "\n",
            "lr: 0.003253612544835042\n",
            "o is 2.653047561645508,  o_a is 2.653047561645508\n",
            "TRAINING - Epoch: [889][0/196]\tTime 1.754 (1.754)\tData 0.816 (0.816)\tloss 0.0040 (0.0040)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [889][100/196]\tTime 0.345 (0.380)\tData 0.000 (0.009)\tloss 0.0027 (0.0081)\tPrec@1 100.000 (99.756)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [889][0/79]\tTime 0.942 (0.942)\tData 0.739 (0.739)\tloss 0.3091 (0.3091)\tPrec@1 94.531 (94.531)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:20\n",
            "\n",
            " Epoch: 890\n",
            "Training loss 0.0082 \tTraining Prec@1 99.782 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5211 \tValidation Prec@1 89.840 \tValidation Prec@5 99.610 \n",
            "\n",
            "lr: 0.003197882417347059\n",
            "o is 2.656141757965088,  o_a is 2.656141757965088\n",
            "TRAINING - Epoch: [890][0/196]\tTime 1.737 (1.737)\tData 0.816 (0.816)\tloss 0.0029 (0.0029)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [890][100/196]\tTime 0.344 (0.381)\tData 0.000 (0.009)\tloss 0.0187 (0.0095)\tPrec@1 99.219 (99.733)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [890][0/79]\tTime 0.820 (0.820)\tData 0.590 (0.590)\tloss 0.3494 (0.3494)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:52\n",
            "\n",
            " Epoch: 891\n",
            "Training loss 0.0088 \tTraining Prec@1 99.772 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5052 \tValidation Prec@1 90.160 \tValidation Prec@5 99.690 \n",
            "\n",
            "lr: 0.003142617944056558\n",
            "o is 2.6592369079589844,  o_a is 2.6592369079589844\n",
            "TRAINING - Epoch: [891][0/196]\tTime 1.915 (1.915)\tData 0.961 (0.961)\tloss 0.0050 (0.0050)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [891][100/196]\tTime 0.347 (0.382)\tData 0.000 (0.010)\tloss 0.0128 (0.0083)\tPrec@1 100.000 (99.791)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [891][0/79]\tTime 0.958 (0.958)\tData 0.693 (0.693)\tloss 0.2840 (0.2840)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:33\n",
            "\n",
            " Epoch: 892\n",
            "Training loss 0.0083 \tTraining Prec@1 99.778 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5074 \tValidation Prec@1 90.440 \tValidation Prec@5 99.600 \n",
            "\n",
            "lr: 0.0030878196747913807\n",
            "o is 2.6623330116271973,  o_a is 2.6623330116271973\n",
            "TRAINING - Epoch: [892][0/196]\tTime 1.794 (1.794)\tData 0.935 (0.935)\tloss 0.0098 (0.0098)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [892][100/196]\tTime 0.342 (0.381)\tData 0.000 (0.010)\tloss 0.0031 (0.0075)\tPrec@1 100.000 (99.814)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [892][0/79]\tTime 0.896 (0.896)\tData 0.669 (0.669)\tloss 0.2739 (0.2739)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:15\n",
            "\n",
            " Epoch: 893\n",
            "Training loss 0.0079 \tTraining Prec@1 99.786 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5292 \tValidation Prec@1 89.810 \tValidation Prec@5 99.580 \n",
            "\n",
            "lr: 0.003033488154741126\n",
            "o is 2.6654300689697266,  o_a is 2.6654300689697266\n",
            "TRAINING - Epoch: [893][0/196]\tTime 1.871 (1.871)\tData 1.008 (1.008)\tloss 0.0056 (0.0056)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [893][100/196]\tTime 0.345 (0.383)\tData 0.000 (0.011)\tloss 0.0072 (0.0078)\tPrec@1 100.000 (99.752)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [893][0/79]\tTime 0.911 (0.911)\tData 0.684 (0.684)\tloss 0.3135 (0.3135)\tPrec@1 93.750 (93.750)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:40\n",
            "\n",
            " Epoch: 894\n",
            "Training loss 0.0081 \tTraining Prec@1 99.762 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5252 \tValidation Prec@1 89.760 \tValidation Prec@5 99.660 \n",
            "\n",
            "lr: 0.00297962392445168\n",
            "o is 2.668527841567993,  o_a is 2.668527841567993\n",
            "TRAINING - Epoch: [894][0/196]\tTime 1.838 (1.838)\tData 0.934 (0.934)\tloss 0.0020 (0.0020)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [894][100/196]\tTime 0.345 (0.383)\tData 0.000 (0.010)\tloss 0.0101 (0.0089)\tPrec@1 99.609 (99.733)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [894][0/79]\tTime 0.849 (0.849)\tData 0.556 (0.556)\tloss 0.3172 (0.3172)\tPrec@1 92.969 (92.969)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:24\n",
            "\n",
            " Epoch: 895\n",
            "Training loss 0.0087 \tTraining Prec@1 99.756 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5091 \tValidation Prec@1 89.830 \tValidation Prec@5 99.590 \n",
            "\n",
            "lr: 0.0029262275198198343\n",
            "o is 2.671626329421997,  o_a is 2.671626329421997\n",
            "TRAINING - Epoch: [895][0/196]\tTime 1.819 (1.819)\tData 0.872 (0.872)\tloss 0.0032 (0.0032)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [895][100/196]\tTime 0.344 (0.383)\tData 0.000 (0.009)\tloss 0.0049 (0.0084)\tPrec@1 100.000 (99.752)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [895][0/79]\tTime 0.872 (0.872)\tData 0.661 (0.661)\tloss 0.5583 (0.5583)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:31\n",
            "\n",
            " Epoch: 896\n",
            "Training loss 0.0086 \tTraining Prec@1 99.746 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5209 \tValidation Prec@1 89.730 \tValidation Prec@5 99.700 \n",
            "\n",
            "lr: 0.0028732994720879973\n",
            "o is 2.6747260093688965,  o_a is 2.6747260093688965\n",
            "TRAINING - Epoch: [896][0/196]\tTime 1.714 (1.714)\tData 0.685 (0.685)\tloss 0.0036 (0.0036)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [896][100/196]\tTime 0.348 (0.384)\tData 0.000 (0.007)\tloss 0.0312 (0.0094)\tPrec@1 98.828 (99.733)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [896][0/79]\tTime 0.888 (0.888)\tData 0.672 (0.672)\tloss 0.3120 (0.3120)\tPrec@1 92.969 (92.969)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:25:19\n",
            "\n",
            " Epoch: 897\n",
            "Training loss 0.0089 \tTraining Prec@1 99.750 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5062 \tValidation Prec@1 90.190 \tValidation Prec@5 99.600 \n",
            "\n",
            "lr: 0.0028208403078388636\n",
            "o is 2.677825927734375,  o_a is 2.677825927734375\n",
            "TRAINING - Epoch: [897][0/196]\tTime 1.816 (1.816)\tData 0.902 (0.902)\tloss 0.0126 (0.0126)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [897][100/196]\tTime 0.348 (0.383)\tData 0.000 (0.010)\tloss 0.0048 (0.0087)\tPrec@1 100.000 (99.737)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [897][0/79]\tTime 0.883 (0.883)\tData 0.646 (0.646)\tloss 0.3117 (0.3117)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:25:11\n",
            "\n",
            " Epoch: 898\n",
            "Training loss 0.0086 \tTraining Prec@1 99.764 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5371 \tValidation Prec@1 90.000 \tValidation Prec@5 99.700 \n",
            "\n",
            "lr: 0.002768850548990174\n",
            "o is 2.68092679977417,  o_a is 2.68092679977417\n",
            "TRAINING - Epoch: [898][0/196]\tTime 1.862 (1.862)\tData 0.984 (0.984)\tloss 0.0054 (0.0054)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [898][100/196]\tTime 0.349 (0.384)\tData 0.000 (0.010)\tloss 0.0076 (0.0078)\tPrec@1 99.609 (99.810)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [898][0/79]\tTime 0.933 (0.933)\tData 0.736 (0.736)\tloss 0.3621 (0.3621)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:25:06\n",
            "\n",
            " Epoch: 899\n",
            "Training loss 0.0079 \tTraining Prec@1 99.798 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5363 \tValidation Prec@1 89.880 \tValidation Prec@5 99.630 \n",
            "\n",
            "lr: 0.0027173307127895696\n",
            "o is 2.6840286254882812,  o_a is 2.6840286254882812\n",
            "TRAINING - Epoch: [899][0/196]\tTime 1.852 (1.852)\tData 0.999 (0.999)\tloss 0.0028 (0.0028)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [899][100/196]\tTime 0.351 (0.385)\tData 0.000 (0.011)\tloss 0.0089 (0.0073)\tPrec@1 100.000 (99.845)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [899][0/79]\tTime 0.959 (0.959)\tData 0.762 (0.762)\tloss 0.2967 (0.2967)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:19\tTime of Finish: 2023-11-27 09:25:06\n",
            "\n",
            " Epoch: 900\n",
            "Training loss 0.0079 \tTraining Prec@1 99.800 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5282 \tValidation Prec@1 89.670 \tValidation Prec@5 99.630 \n",
            "\n",
            "lr: 0.002666281311809424\n",
            "o is 2.687130928039551,  o_a is 2.687130928039551\n",
            "TRAINING - Epoch: [900][0/196]\tTime 1.836 (1.836)\tData 0.914 (0.914)\tloss 0.0014 (0.0014)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [900][100/196]\tTime 0.345 (0.381)\tData 0.000 (0.010)\tloss 0.0092 (0.0080)\tPrec@1 99.609 (99.768)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [900][0/79]\tTime 0.928 (0.928)\tData 0.662 (0.662)\tloss 0.2089 (0.2089)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:57\n",
            "\n",
            " Epoch: 901\n",
            "Training loss 0.0083 \tTraining Prec@1 99.748 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5037 \tValidation Prec@1 90.140 \tValidation Prec@5 99.650 \n",
            "\n",
            "lr: 0.0026157028539417074\n",
            "o is 2.690234661102295,  o_a is 2.690234661102295\n",
            "TRAINING - Epoch: [901][0/196]\tTime 1.651 (1.651)\tData 0.627 (0.627)\tloss 0.0037 (0.0037)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [901][100/196]\tTime 0.357 (0.381)\tData 0.000 (0.007)\tloss 0.0099 (0.0082)\tPrec@1 99.609 (99.760)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [901][0/79]\tTime 0.839 (0.839)\tData 0.632 (0.632)\tloss 0.2803 (0.2803)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:39\n",
            "\n",
            " Epoch: 902\n",
            "Training loss 0.0079 \tTraining Prec@1 99.804 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5241 \tValidation Prec@1 90.030 \tValidation Prec@5 99.600 \n",
            "\n",
            "lr: 0.0025655958423929843\n",
            "o is 2.693338394165039,  o_a is 2.693338394165039\n",
            "TRAINING - Epoch: [902][0/196]\tTime 1.841 (1.841)\tData 1.017 (1.017)\tloss 0.0094 (0.0094)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [902][100/196]\tTime 0.347 (0.382)\tData 0.000 (0.011)\tloss 0.0120 (0.0089)\tPrec@1 99.609 (99.760)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [902][0/79]\tTime 0.930 (0.930)\tData 0.709 (0.709)\tloss 0.4800 (0.4800)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:06\n",
            "\n",
            " Epoch: 903\n",
            "Training loss 0.0088 \tTraining Prec@1 99.774 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5489 \tValidation Prec@1 89.700 \tValidation Prec@5 99.610 \n",
            "\n",
            "lr: 0.002515960775679364\n",
            "o is 2.6964433193206787,  o_a is 2.6964433193206787\n",
            "TRAINING - Epoch: [903][0/196]\tTime 1.723 (1.723)\tData 0.836 (0.836)\tloss 0.0238 (0.0238)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [903][100/196]\tTime 0.347 (0.381)\tData 0.004 (0.009)\tloss 0.0032 (0.0078)\tPrec@1 100.000 (99.783)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [903][0/79]\tTime 0.899 (0.899)\tData 0.642 (0.642)\tloss 0.2345 (0.2345)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:24\n",
            "\n",
            " Epoch: 904\n",
            "Training loss 0.0082 \tTraining Prec@1 99.778 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5022 \tValidation Prec@1 89.760 \tValidation Prec@5 99.660 \n",
            "\n",
            "lr: 0.002466798147621597\n",
            "o is 2.6995487213134766,  o_a is 2.6995487213134766\n",
            "TRAINING - Epoch: [904][0/196]\tTime 1.731 (1.731)\tData 0.788 (0.788)\tloss 0.0143 (0.0143)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [904][100/196]\tTime 0.346 (0.381)\tData 0.001 (0.009)\tloss 0.0050 (0.0078)\tPrec@1 100.000 (99.795)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [904][0/79]\tTime 0.828 (0.828)\tData 0.646 (0.646)\tloss 0.2917 (0.2917)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:43\n",
            "\n",
            " Epoch: 905\n",
            "Training loss 0.0071 \tTraining Prec@1 99.832 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5410 \tValidation Prec@1 89.940 \tValidation Prec@5 99.520 \n",
            "\n",
            "lr: 0.002418108447340101\n",
            "o is 2.702655076980591,  o_a is 2.702655076980591\n",
            "TRAINING - Epoch: [905][0/196]\tTime 1.737 (1.737)\tData 0.843 (0.843)\tloss 0.0073 (0.0073)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [905][100/196]\tTime 0.347 (0.380)\tData 0.002 (0.009)\tloss 0.0045 (0.0084)\tPrec@1 100.000 (99.745)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [905][0/79]\tTime 0.848 (0.848)\tData 0.627 (0.627)\tloss 0.2677 (0.2677)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:41\n",
            "\n",
            " Epoch: 906\n",
            "Training loss 0.0084 \tTraining Prec@1 99.762 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5263 \tValidation Prec@1 90.040 \tValidation Prec@5 99.630 \n",
            "\n",
            "lr: 0.002369892159250122\n",
            "o is 2.7057623863220215,  o_a is 2.7057623863220215\n",
            "TRAINING - Epoch: [906][0/196]\tTime 1.807 (1.807)\tData 0.873 (0.873)\tloss 0.0125 (0.0125)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [906][100/196]\tTime 0.357 (0.383)\tData 0.000 (0.009)\tloss 0.0017 (0.0088)\tPrec@1 100.000 (99.718)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [906][0/79]\tTime 0.875 (0.875)\tData 0.629 (0.629)\tloss 0.3092 (0.3092)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:24:09\n",
            "\n",
            " Epoch: 907\n",
            "Training loss 0.0085 \tTraining Prec@1 99.740 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5226 \tValidation Prec@1 90.120 \tValidation Prec@5 99.610 \n",
            "\n",
            "lr: 0.002322149763056941\n",
            "o is 2.7088699340820312,  o_a is 2.7088699340820312\n",
            "TRAINING - Epoch: [907][0/196]\tTime 1.788 (1.788)\tData 0.881 (0.881)\tloss 0.0086 (0.0086)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [907][100/196]\tTime 0.346 (0.379)\tData 0.000 (0.009)\tloss 0.0144 (0.0080)\tPrec@1 99.609 (99.776)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [907][0/79]\tTime 0.911 (0.911)\tData 0.693 (0.693)\tloss 0.4323 (0.4323)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:16\n",
            "\n",
            " Epoch: 908\n",
            "Training loss 0.0079 \tTraining Prec@1 99.774 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.4916 \tValidation Prec@1 90.300 \tValidation Prec@5 99.630 \n",
            "\n",
            "lr: 0.00227488173375104\n",
            "o is 2.7119784355163574,  o_a is 2.7119784355163574\n",
            "TRAINING - Epoch: [908][0/196]\tTime 1.643 (1.643)\tData 0.644 (0.644)\tloss 0.0091 (0.0091)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [908][100/196]\tTime 0.346 (0.379)\tData 0.000 (0.007)\tloss 0.0018 (0.0077)\tPrec@1 100.000 (99.834)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [908][0/79]\tTime 0.861 (0.861)\tData 0.638 (0.638)\tloss 0.2820 (0.2820)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:13\n",
            "\n",
            " Epoch: 909\n",
            "Training loss 0.0076 \tTraining Prec@1 99.838 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5308 \tValidation Prec@1 89.630 \tValidation Prec@5 99.640 \n",
            "\n",
            "lr: 0.0022280885416034227\n",
            "o is 2.715087413787842,  o_a is 2.715087413787842\n",
            "TRAINING - Epoch: [909][0/196]\tTime 1.767 (1.767)\tData 0.811 (0.811)\tloss 0.0176 (0.0176)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [909][100/196]\tTime 0.343 (0.381)\tData 0.000 (0.009)\tloss 0.0121 (0.0076)\tPrec@1 100.000 (99.783)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [909][0/79]\tTime 0.970 (0.970)\tData 0.761 (0.761)\tloss 0.2280 (0.2280)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:24\n",
            "\n",
            " Epoch: 910\n",
            "Training loss 0.0079 \tTraining Prec@1 99.782 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5029 \tValidation Prec@1 89.900 \tValidation Prec@5 99.610 \n",
            "\n",
            "lr: 0.0021817706521609285\n",
            "o is 2.718197822570801,  o_a is 2.718197822570801\n",
            "TRAINING - Epoch: [910][0/196]\tTime 1.727 (1.727)\tData 0.804 (0.804)\tloss 0.0052 (0.0052)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [910][100/196]\tTime 0.345 (0.378)\tData 0.000 (0.009)\tloss 0.0039 (0.0088)\tPrec@1 100.000 (99.737)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [910][0/79]\tTime 0.903 (0.903)\tData 0.717 (0.717)\tloss 0.3158 (0.3158)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:22:59\n",
            "\n",
            " Epoch: 911\n",
            "Training loss 0.0083 \tTraining Prec@1 99.748 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5240 \tValidation Prec@1 89.730 \tValidation Prec@5 99.660 \n",
            "\n",
            "lr: 0.002135928526241608\n",
            "o is 2.7213082313537598,  o_a is 2.7213082313537598\n",
            "TRAINING - Epoch: [911][0/196]\tTime 1.760 (1.760)\tData 0.870 (0.870)\tloss 0.0044 (0.0044)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [911][100/196]\tTime 0.356 (0.379)\tData 0.003 (0.009)\tloss 0.0143 (0.0082)\tPrec@1 99.219 (99.733)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [911][0/79]\tTime 0.939 (0.939)\tData 0.762 (0.762)\tloss 0.3674 (0.3674)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:23:08\n",
            "\n",
            " Epoch: 912\n",
            "Training loss 0.0081 \tTraining Prec@1 99.766 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5231 \tValidation Prec@1 89.880 \tValidation Prec@5 99.710 \n",
            "\n",
            "lr: 0.0020905626199301114\n",
            "o is 2.724419593811035,  o_a is 2.724419593811035\n",
            "TRAINING - Epoch: [912][0/196]\tTime 1.704 (1.704)\tData 0.968 (0.968)\tloss 0.0024 (0.0024)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [912][100/196]\tTime 0.347 (0.380)\tData 0.004 (0.010)\tloss 0.0073 (0.0069)\tPrec@1 99.609 (99.818)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [912][0/79]\tTime 0.944 (0.944)\tData 0.674 (0.674)\tloss 0.3263 (0.3263)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:36\n",
            "\n",
            " Epoch: 913\n",
            "Training loss 0.0073 \tTraining Prec@1 99.808 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5259 \tValidation Prec@1 89.930 \tValidation Prec@5 99.660 \n",
            "\n",
            "lr: 0.0020456733845731507\n",
            "o is 2.7275314331054688,  o_a is 2.7275314331054688\n",
            "TRAINING - Epoch: [913][0/196]\tTime 1.706 (1.706)\tData 0.724 (0.724)\tloss 0.0031 (0.0031)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [913][100/196]\tTime 0.347 (0.380)\tData 0.001 (0.008)\tloss 0.0068 (0.0066)\tPrec@1 99.609 (99.876)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [913][0/79]\tTime 0.731 (0.731)\tData 0.575 (0.575)\tloss 0.2663 (0.2663)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:20\n",
            "\n",
            " Epoch: 914\n",
            "Training loss 0.0071 \tTraining Prec@1 99.838 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5149 \tValidation Prec@1 89.890 \tValidation Prec@5 99.680 \n",
            "\n",
            "lr: 0.002001261266775055\n",
            "o is 2.7306439876556396,  o_a is 2.7306439876556396\n",
            "TRAINING - Epoch: [914][0/196]\tTime 1.753 (1.753)\tData 0.858 (0.858)\tloss 0.0092 (0.0092)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [914][100/196]\tTime 0.344 (0.380)\tData 0.000 (0.009)\tloss 0.0171 (0.0079)\tPrec@1 99.609 (99.780)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [914][0/79]\tTime 0.878 (0.878)\tData 0.654 (0.654)\tloss 0.1737 (0.1737)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:29\n",
            "\n",
            " Epoch: 915\n",
            "Training loss 0.0077 \tTraining Prec@1 99.806 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.4954 \tValidation Prec@1 90.240 \tValidation Prec@5 99.650 \n",
            "\n",
            "lr: 0.0019573267083932843\n",
            "o is 2.733757495880127,  o_a is 2.733757495880127\n",
            "TRAINING - Epoch: [915][0/196]\tTime 1.748 (1.748)\tData 0.852 (0.852)\tloss 0.0300 (0.0300)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [915][100/196]\tTime 0.347 (0.380)\tData 0.000 (0.009)\tloss 0.0050 (0.0082)\tPrec@1 100.000 (99.772)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [915][0/79]\tTime 0.926 (0.926)\tData 0.719 (0.719)\tloss 0.3404 (0.3404)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:40\n",
            "\n",
            " Epoch: 916\n",
            "Training loss 0.0076 \tTraining Prec@1 99.794 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5326 \tValidation Prec@1 89.850 \tValidation Prec@5 99.680 \n",
            "\n",
            "lr: 0.0019138701465340495\n",
            "o is 2.7368712425231934,  o_a is 2.7368712425231934\n",
            "TRAINING - Epoch: [916][0/196]\tTime 1.736 (1.736)\tData 0.842 (0.842)\tloss 0.0056 (0.0056)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [916][100/196]\tTime 0.345 (0.380)\tData 0.000 (0.009)\tloss 0.0161 (0.0070)\tPrec@1 99.219 (99.810)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [916][0/79]\tTime 0.863 (0.863)\tData 0.650 (0.650)\tloss 0.2560 (0.2560)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:47\n",
            "\n",
            " Epoch: 917\n",
            "Training loss 0.0072 \tTraining Prec@1 99.812 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5182 \tValidation Prec@1 89.840 \tValidation Prec@5 99.580 \n",
            "\n",
            "lr: 0.0018708920135479489\n",
            "o is 2.739985942840576,  o_a is 2.739985942840576\n",
            "TRAINING - Epoch: [917][0/196]\tTime 1.754 (1.754)\tData 1.049 (1.049)\tloss 0.0102 (0.0102)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [917][100/196]\tTime 0.344 (0.381)\tData 0.000 (0.011)\tloss 0.0049 (0.0069)\tPrec@1 100.000 (99.838)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [917][0/79]\tTime 0.941 (0.941)\tData 0.738 (0.738)\tloss 0.2377 (0.2377)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:57\n",
            "\n",
            " Epoch: 918\n",
            "Training loss 0.0071 \tTraining Prec@1 99.832 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5061 \tValidation Prec@1 90.060 \tValidation Prec@5 99.690 \n",
            "\n",
            "lr: 0.0018283927370256888\n",
            "o is 2.743101119995117,  o_a is 2.743101119995117\n",
            "TRAINING - Epoch: [918][0/196]\tTime 1.749 (1.749)\tData 0.771 (0.771)\tloss 0.0031 (0.0031)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [918][100/196]\tTime 0.349 (0.381)\tData 0.000 (0.008)\tloss 0.0113 (0.0067)\tPrec@1 99.609 (99.822)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [918][0/79]\tTime 0.972 (0.972)\tData 0.773 (0.773)\tloss 0.3121 (0.3121)\tPrec@1 92.188 (92.188)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:47\n",
            "\n",
            " Epoch: 919\n",
            "Training loss 0.0073 \tTraining Prec@1 99.804 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5128 \tValidation Prec@1 89.880 \tValidation Prec@5 99.660 \n",
            "\n",
            "lr: 0.001786372739793814\n",
            "o is 2.7462172508239746,  o_a is 2.7462172508239746\n",
            "TRAINING - Epoch: [919][0/196]\tTime 1.804 (1.804)\tData 0.943 (0.943)\tloss 0.0088 (0.0088)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [919][100/196]\tTime 0.345 (0.379)\tData 0.000 (0.010)\tloss 0.0052 (0.0068)\tPrec@1 100.000 (99.822)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [919][0/79]\tTime 0.924 (0.924)\tData 0.740 (0.740)\tloss 0.2547 (0.2547)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:17\n",
            "\n",
            " Epoch: 920\n",
            "Training loss 0.0074 \tTraining Prec@1 99.798 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5163 \tValidation Prec@1 89.950 \tValidation Prec@5 99.530 \n",
            "\n",
            "lr: 0.0017448324399105054\n",
            "o is 2.7493338584899902,  o_a is 2.7493338584899902\n",
            "TRAINING - Epoch: [920][0/196]\tTime 1.763 (1.763)\tData 0.995 (0.995)\tloss 0.0038 (0.0038)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [920][100/196]\tTime 0.346 (0.380)\tData 0.000 (0.011)\tloss 0.0112 (0.0079)\tPrec@1 99.609 (99.768)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [920][0/79]\tTime 0.957 (0.957)\tData 0.718 (0.718)\tloss 0.1946 (0.1946)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:34\n",
            "\n",
            " Epoch: 921\n",
            "Training loss 0.0073 \tTraining Prec@1 99.804 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5306 \tValidation Prec@1 89.680 \tValidation Prec@5 99.660 \n",
            "\n",
            "lr: 0.0017037722506614223\n",
            "o is 2.752450704574585,  o_a is 2.752450704574585\n",
            "TRAINING - Epoch: [921][0/196]\tTime 1.840 (1.840)\tData 0.972 (0.972)\tloss 0.0016 (0.0016)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [921][100/196]\tTime 0.348 (0.380)\tData 0.000 (0.010)\tloss 0.0087 (0.0072)\tPrec@1 99.609 (99.818)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [921][0/79]\tTime 0.754 (0.754)\tData 0.529 (0.529)\tloss 0.3581 (0.3581)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:26\n",
            "\n",
            " Epoch: 922\n",
            "Training loss 0.0075 \tTraining Prec@1 99.796 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5040 \tValidation Prec@1 89.800 \tValidation Prec@5 99.590 \n",
            "\n",
            "lr: 0.0016631925805556\n",
            "o is 2.755568504333496,  o_a is 2.755568504333496\n",
            "TRAINING - Epoch: [922][0/196]\tTime 1.766 (1.766)\tData 0.823 (0.823)\tloss 0.0187 (0.0187)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [922][100/196]\tTime 0.350 (0.383)\tData 0.001 (0.009)\tloss 0.0187 (0.0070)\tPrec@1 99.609 (99.814)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [922][0/79]\tTime 0.889 (0.889)\tData 0.670 (0.670)\tloss 0.2133 (0.2133)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:50\n",
            "\n",
            " Epoch: 923\n",
            "Training loss 0.0071 \tTraining Prec@1 99.808 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5059 \tValidation Prec@1 90.140 \tValidation Prec@5 99.630 \n",
            "\n",
            "lr: 0.0016230938333213474\n",
            "o is 2.7586865425109863,  o_a is 2.7586865425109863\n",
            "TRAINING - Epoch: [923][0/196]\tTime 1.719 (1.719)\tData 0.807 (0.807)\tloss 0.0039 (0.0039)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [923][100/196]\tTime 0.348 (0.379)\tData 0.000 (0.009)\tloss 0.0085 (0.0077)\tPrec@1 99.609 (99.814)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [923][0/79]\tTime 0.844 (0.844)\tData 0.598 (0.598)\tloss 0.3246 (0.3246)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:45\n",
            "\n",
            " Epoch: 924\n",
            "Training loss 0.0075 \tTraining Prec@1 99.800 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5120 \tValidation Prec@1 90.040 \tValidation Prec@5 99.680 \n",
            "\n",
            "lr: 0.001583476407902288\n",
            "o is 2.761806011199951,  o_a is 2.761806011199951\n",
            "TRAINING - Epoch: [924][0/196]\tTime 1.747 (1.747)\tData 0.802 (0.802)\tloss 0.0122 (0.0122)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [924][100/196]\tTime 0.344 (0.379)\tData 0.001 (0.009)\tloss 0.0041 (0.0066)\tPrec@1 100.000 (99.845)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [924][0/79]\tTime 0.894 (0.894)\tData 0.656 (0.656)\tloss 0.2129 (0.2129)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:23:05\n",
            "\n",
            " Epoch: 925\n",
            "Training loss 0.0068 \tTraining Prec@1 99.836 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5270 \tValidation Prec@1 90.150 \tValidation Prec@5 99.590 \n",
            "\n",
            "lr: 0.0015443406984533311\n",
            "o is 2.764925479888916,  o_a is 2.764925479888916\n",
            "TRAINING - Epoch: [925][0/196]\tTime 1.740 (1.740)\tData 0.920 (0.920)\tloss 0.0029 (0.0029)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [925][100/196]\tTime 0.348 (0.379)\tData 0.000 (0.010)\tloss 0.0024 (0.0078)\tPrec@1 100.000 (99.768)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [925][0/79]\tTime 0.932 (0.932)\tData 0.709 (0.709)\tloss 0.2424 (0.2424)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:23:10\n",
            "\n",
            " Epoch: 926\n",
            "Training loss 0.0075 \tTraining Prec@1 99.802 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5027 \tValidation Prec@1 90.200 \tValidation Prec@5 99.660 \n",
            "\n",
            "lr: 0.001505687094336813\n",
            "o is 2.768045425415039,  o_a is 2.768045425415039\n",
            "TRAINING - Epoch: [926][0/196]\tTime 1.731 (1.731)\tData 0.981 (0.981)\tloss 0.0101 (0.0101)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [926][100/196]\tTime 0.344 (0.380)\tData 0.003 (0.010)\tloss 0.0240 (0.0082)\tPrec@1 98.828 (99.760)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [926][0/79]\tTime 0.850 (0.850)\tData 0.581 (0.581)\tloss 0.2617 (0.2617)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:17\n",
            "\n",
            " Epoch: 927\n",
            "Training loss 0.0080 \tTraining Prec@1 99.782 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.4963 \tValidation Prec@1 90.410 \tValidation Prec@5 99.570 \n",
            "\n",
            "lr: 0.001467515980118566\n",
            "o is 2.7711660861968994,  o_a is 2.7711660861968994\n",
            "TRAINING - Epoch: [927][0/196]\tTime 1.778 (1.778)\tData 0.867 (0.867)\tloss 0.0120 (0.0120)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [927][100/196]\tTime 0.358 (0.381)\tData 0.000 (0.009)\tloss 0.0044 (0.0073)\tPrec@1 100.000 (99.799)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [927][0/79]\tTime 0.783 (0.783)\tData 0.553 (0.553)\tloss 0.3082 (0.3082)\tPrec@1 92.969 (92.969)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:29\n",
            "\n",
            " Epoch: 928\n",
            "Training loss 0.0072 \tTraining Prec@1 99.808 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5044 \tValidation Prec@1 90.360 \tValidation Prec@5 99.650 \n",
            "\n",
            "lr: 0.0014298277355641222\n",
            "o is 2.774287223815918,  o_a is 2.774287223815918\n",
            "TRAINING - Epoch: [928][0/196]\tTime 1.749 (1.749)\tData 0.799 (0.799)\tloss 0.0027 (0.0027)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [928][100/196]\tTime 0.343 (0.378)\tData 0.000 (0.009)\tloss 0.0113 (0.0062)\tPrec@1 99.609 (99.845)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [928][0/79]\tTime 0.869 (0.869)\tData 0.655 (0.655)\tloss 0.3309 (0.3309)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:23:11\n",
            "\n",
            " Epoch: 929\n",
            "Training loss 0.0066 \tTraining Prec@1 99.824 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5109 \tValidation Prec@1 90.360 \tValidation Prec@5 99.590 \n",
            "\n",
            "lr: 0.0013926227356349222\n",
            "o is 2.777409076690674,  o_a is 2.777409076690674\n",
            "TRAINING - Epoch: [929][0/196]\tTime 1.488 (1.488)\tData 0.537 (0.537)\tloss 0.0053 (0.0053)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [929][100/196]\tTime 0.354 (0.378)\tData 0.000 (0.006)\tloss 0.0061 (0.0061)\tPrec@1 100.000 (99.861)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [929][0/79]\tTime 0.940 (0.940)\tData 0.718 (0.718)\tloss 0.3344 (0.3344)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:23:00\n",
            "\n",
            " Epoch: 930\n",
            "Training loss 0.0064 \tTraining Prec@1 99.860 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5250 \tValidation Prec@1 89.860 \tValidation Prec@5 99.630 \n",
            "\n",
            "lr: 0.0013559013504846108\n",
            "o is 2.780531406402588,  o_a is 2.780531406402588\n",
            "TRAINING - Epoch: [930][0/196]\tTime 1.610 (1.610)\tData 0.719 (0.719)\tloss 0.0093 (0.0093)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [930][100/196]\tTime 0.341 (0.379)\tData 0.000 (0.008)\tloss 0.0048 (0.0070)\tPrec@1 100.000 (99.783)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [930][0/79]\tTime 0.914 (0.914)\tData 0.689 (0.689)\tloss 0.2837 (0.2837)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:23:11\n",
            "\n",
            " Epoch: 931\n",
            "Training loss 0.0072 \tTraining Prec@1 99.808 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5133 \tValidation Prec@1 90.040 \tValidation Prec@5 99.660 \n",
            "\n",
            "lr: 0.0013196639454553195\n",
            "o is 2.78365421295166,  o_a is 2.78365421295166\n",
            "TRAINING - Epoch: [931][0/196]\tTime 1.845 (1.845)\tData 0.932 (0.932)\tloss 0.0273 (0.0273)\tPrec@1 98.438 (98.438)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [931][100/196]\tTime 0.347 (0.379)\tData 0.000 (0.010)\tloss 0.0061 (0.0075)\tPrec@1 100.000 (99.791)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [931][0/79]\tTime 0.835 (0.835)\tData 0.607 (0.607)\tloss 0.2620 (0.2620)\tPrec@1 92.969 (92.969)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:23:05\n",
            "\n",
            " Epoch: 932\n",
            "Training loss 0.0068 \tTraining Prec@1 99.818 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5196 \tValidation Prec@1 89.760 \tValidation Prec@5 99.630 \n",
            "\n",
            "lr: 0.0012839108810740456\n",
            "o is 2.7867777347564697,  o_a is 2.7867777347564697\n",
            "TRAINING - Epoch: [932][0/196]\tTime 1.741 (1.741)\tData 0.945 (0.945)\tloss 0.0063 (0.0063)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [932][100/196]\tTime 0.345 (0.379)\tData 0.000 (0.010)\tloss 0.0058 (0.0064)\tPrec@1 100.000 (99.853)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [932][0/79]\tTime 0.976 (0.976)\tData 0.780 (0.780)\tloss 0.2529 (0.2529)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:28\n",
            "\n",
            " Epoch: 933\n",
            "Training loss 0.0066 \tTraining Prec@1 99.836 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5144 \tValidation Prec@1 90.240 \tValidation Prec@5 99.660 \n",
            "\n",
            "lr: 0.001248642513049089\n",
            "o is 2.7899017333984375,  o_a is 2.7899017333984375\n",
            "TRAINING - Epoch: [933][0/196]\tTime 1.796 (1.796)\tData 0.878 (0.878)\tloss 0.0050 (0.0050)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [933][100/196]\tTime 0.348 (0.379)\tData 0.000 (0.010)\tloss 0.0152 (0.0069)\tPrec@1 99.609 (99.807)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [933][0/79]\tTime 0.792 (0.792)\tData 0.564 (0.564)\tloss 0.3701 (0.3701)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:20\n",
            "\n",
            " Epoch: 934\n",
            "Training loss 0.0070 \tTraining Prec@1 99.810 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5306 \tValidation Prec@1 89.610 \tValidation Prec@5 99.620 \n",
            "\n",
            "lr: 0.001213859192266455\n",
            "o is 2.7930264472961426,  o_a is 2.7930264472961426\n",
            "TRAINING - Epoch: [934][0/196]\tTime 1.807 (1.807)\tData 1.025 (1.025)\tloss 0.0071 (0.0071)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [934][100/196]\tTime 0.347 (0.380)\tData 0.000 (0.011)\tloss 0.0046 (0.0062)\tPrec@1 100.000 (99.869)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [934][0/79]\tTime 0.877 (0.877)\tData 0.656 (0.656)\tloss 0.2674 (0.2674)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:34\n",
            "\n",
            " Epoch: 935\n",
            "Training loss 0.0064 \tTraining Prec@1 99.842 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5161 \tValidation Prec@1 89.960 \tValidation Prec@5 99.730 \n",
            "\n",
            "lr: 0.001179561264786434\n",
            "o is 2.7961511611938477,  o_a is 2.7961511611938477\n",
            "TRAINING - Epoch: [935][0/196]\tTime 1.696 (1.696)\tData 0.921 (0.921)\tloss 0.0042 (0.0042)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [935][100/196]\tTime 0.346 (0.378)\tData 0.000 (0.010)\tloss 0.0055 (0.0071)\tPrec@1 100.000 (99.795)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [935][0/79]\tTime 0.892 (0.892)\tData 0.665 (0.665)\tloss 0.2910 (0.2910)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:23:07\n",
            "\n",
            " Epoch: 936\n",
            "Training loss 0.0071 \tTraining Prec@1 99.804 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5458 \tValidation Prec@1 89.520 \tValidation Prec@5 99.640 \n",
            "\n",
            "lr: 0.0011457490718400994\n",
            "o is 2.79927659034729,  o_a is 2.79927659034729\n",
            "TRAINING - Epoch: [936][0/196]\tTime 1.778 (1.778)\tData 0.895 (0.895)\tloss 0.0095 (0.0095)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [936][100/196]\tTime 0.346 (0.380)\tData 0.000 (0.010)\tloss 0.0045 (0.0062)\tPrec@1 100.000 (99.872)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [936][0/79]\tTime 0.864 (0.864)\tData 0.684 (0.684)\tloss 0.3095 (0.3095)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:23:14\n",
            "\n",
            " Epoch: 937\n",
            "Training loss 0.0070 \tTraining Prec@1 99.826 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5052 \tValidation Prec@1 90.020 \tValidation Prec@5 99.670 \n",
            "\n",
            "lr: 0.0011124229498259595\n",
            "o is 2.8024024963378906,  o_a is 2.8024024963378906\n",
            "TRAINING - Epoch: [937][0/196]\tTime 1.824 (1.824)\tData 0.902 (0.902)\tloss 0.0036 (0.0036)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [937][100/196]\tTime 0.343 (0.378)\tData 0.000 (0.009)\tloss 0.0117 (0.0061)\tPrec@1 99.609 (99.853)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [937][0/79]\tTime 0.863 (0.863)\tData 0.644 (0.644)\tloss 0.3481 (0.3481)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:23:11\n",
            "\n",
            " Epoch: 938\n",
            "Training loss 0.0066 \tTraining Prec@1 99.838 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5230 \tValidation Prec@1 90.160 \tValidation Prec@5 99.630 \n",
            "\n",
            "lr: 0.001079583230306583\n",
            "o is 2.8055291175842285,  o_a is 2.8055291175842285\n",
            "TRAINING - Epoch: [938][0/196]\tTime 1.752 (1.752)\tData 0.740 (0.740)\tloss 0.0217 (0.0217)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [938][100/196]\tTime 0.346 (0.379)\tData 0.000 (0.008)\tloss 0.0209 (0.0077)\tPrec@1 99.219 (99.807)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [938][0/79]\tTime 0.909 (0.909)\tData 0.711 (0.711)\tloss 0.3239 (0.3239)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:15\n",
            "\n",
            " Epoch: 939\n",
            "Training loss 0.0075 \tTraining Prec@1 99.796 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5283 \tValidation Prec@1 89.790 \tValidation Prec@5 99.580 \n",
            "\n",
            "lr: 0.0010472302400052784\n",
            "o is 2.8086562156677246,  o_a is 2.8086562156677246\n",
            "TRAINING - Epoch: [939][0/196]\tTime 1.774 (1.774)\tData 0.845 (0.845)\tloss 0.0188 (0.0188)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [939][100/196]\tTime 0.344 (0.380)\tData 0.000 (0.009)\tloss 0.0063 (0.0073)\tPrec@1 100.000 (99.795)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [939][0/79]\tTime 0.852 (0.852)\tData 0.682 (0.682)\tloss 0.3072 (0.3072)\tPrec@1 94.531 (94.531)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:28\n",
            "\n",
            " Epoch: 940\n",
            "Training loss 0.0074 \tTraining Prec@1 99.792 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5188 \tValidation Prec@1 90.220 \tValidation Prec@5 99.620 \n",
            "\n",
            "lr: 0.0010153643008029088\n",
            "o is 2.8117833137512207,  o_a is 2.8117833137512207\n",
            "TRAINING - Epoch: [940][0/196]\tTime 1.744 (1.744)\tData 0.919 (0.919)\tloss 0.0040 (0.0040)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [940][100/196]\tTime 0.354 (0.379)\tData 0.000 (0.010)\tloss 0.0065 (0.0074)\tPrec@1 100.000 (99.791)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [940][0/79]\tTime 0.899 (0.899)\tData 0.695 (0.695)\tloss 0.3217 (0.3217)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:19\n",
            "\n",
            " Epoch: 941\n",
            "Training loss 0.0074 \tTraining Prec@1 99.812 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5152 \tValidation Prec@1 90.210 \tValidation Prec@5 99.620 \n",
            "\n",
            "lr: 0.0009839857297346318\n",
            "o is 2.814911365509033,  o_a is 2.814911365509033\n",
            "TRAINING - Epoch: [941][0/196]\tTime 1.752 (1.752)\tData 0.762 (0.762)\tloss 0.0054 (0.0054)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [941][100/196]\tTime 0.346 (0.379)\tData 0.001 (0.008)\tloss 0.0152 (0.0067)\tPrec@1 99.219 (99.853)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [941][0/79]\tTime 0.898 (0.898)\tData 0.687 (0.687)\tloss 0.3806 (0.3806)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:19\n",
            "\n",
            " Epoch: 942\n",
            "Training loss 0.0067 \tTraining Prec@1 99.836 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5066 \tValidation Prec@1 90.080 \tValidation Prec@5 99.680 \n",
            "\n",
            "lr: 0.0009530948389867752\n",
            "o is 2.818039655685425,  o_a is 2.818039655685425\n",
            "TRAINING - Epoch: [942][0/196]\tTime 1.639 (1.639)\tData 0.672 (0.672)\tloss 0.0077 (0.0077)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [942][100/196]\tTime 0.347 (0.380)\tData 0.000 (0.008)\tloss 0.0027 (0.0072)\tPrec@1 100.000 (99.799)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [942][0/79]\tTime 1.022 (1.022)\tData 0.830 (0.830)\tloss 0.2928 (0.2928)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:32\n",
            "\n",
            " Epoch: 943\n",
            "Training loss 0.0074 \tTraining Prec@1 99.786 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5264 \tValidation Prec@1 90.130 \tValidation Prec@5 99.620 \n",
            "\n",
            "lr: 0.0009226919358937056\n",
            "o is 2.8211684226989746,  o_a is 2.8211684226989746\n",
            "TRAINING - Epoch: [943][0/196]\tTime 1.637 (1.637)\tData 0.761 (0.761)\tloss 0.0038 (0.0038)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [943][100/196]\tTime 0.346 (0.379)\tData 0.003 (0.008)\tloss 0.0117 (0.0061)\tPrec@1 99.219 (99.857)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [943][0/79]\tTime 0.943 (0.943)\tData 0.735 (0.735)\tloss 0.2161 (0.2161)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:24\n",
            "\n",
            " Epoch: 944\n",
            "Training loss 0.0065 \tTraining Prec@1 99.844 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5194 \tValidation Prec@1 90.080 \tValidation Prec@5 99.540 \n",
            "\n",
            "lr: 0.0008927773229348031\n",
            "o is 2.8242979049682617,  o_a is 2.8242979049682617\n",
            "TRAINING - Epoch: [944][0/196]\tTime 1.762 (1.762)\tData 0.893 (0.893)\tloss 0.0061 (0.0061)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [944][100/196]\tTime 0.358 (0.381)\tData 0.000 (0.009)\tloss 0.0039 (0.0062)\tPrec@1 100.000 (99.853)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [944][0/79]\tTime 0.957 (0.957)\tData 0.759 (0.759)\tloss 0.2403 (0.2403)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:22\n",
            "\n",
            " Epoch: 945\n",
            "Training loss 0.0071 \tTraining Prec@1 99.828 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5035 \tValidation Prec@1 90.160 \tValidation Prec@5 99.540 \n",
            "\n",
            "lr: 0.0008633512977314192\n",
            "o is 2.827427387237549,  o_a is 2.827427387237549\n",
            "TRAINING - Epoch: [945][0/196]\tTime 1.814 (1.814)\tData 0.878 (0.878)\tloss 0.0153 (0.0153)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [945][100/196]\tTime 0.347 (0.380)\tData 0.001 (0.010)\tloss 0.0130 (0.0060)\tPrec@1 99.219 (99.826)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [945][0/79]\tTime 0.858 (0.858)\tData 0.627 (0.627)\tloss 0.2455 (0.2455)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:35\n",
            "\n",
            " Epoch: 946\n",
            "Training loss 0.0060 \tTraining Prec@1 99.842 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5113 \tValidation Prec@1 90.130 \tValidation Prec@5 99.620 \n",
            "\n",
            "lr: 0.0008344141530439508\n",
            "o is 2.830557346343994,  o_a is 2.830557346343994\n",
            "TRAINING - Epoch: [946][0/196]\tTime 1.822 (1.822)\tData 0.887 (0.887)\tloss 0.0070 (0.0070)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [946][100/196]\tTime 0.345 (0.379)\tData 0.000 (0.010)\tloss 0.0070 (0.0071)\tPrec@1 99.609 (99.830)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [946][0/79]\tTime 0.929 (0.929)\tData 0.713 (0.713)\tloss 0.2540 (0.2540)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:32\n",
            "\n",
            " Epoch: 947\n",
            "Training loss 0.0069 \tTraining Prec@1 99.832 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.4920 \tValidation Prec@1 90.300 \tValidation Prec@5 99.630 \n",
            "\n",
            "lr: 0.0008059661767688875\n",
            "o is 2.8336880207061768,  o_a is 2.8336880207061768\n",
            "TRAINING - Epoch: [947][0/196]\tTime 1.814 (1.814)\tData 0.978 (0.978)\tloss 0.0145 (0.0145)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [947][100/196]\tTime 0.343 (0.379)\tData 0.004 (0.011)\tloss 0.0045 (0.0070)\tPrec@1 100.000 (99.822)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [947][0/79]\tTime 0.923 (0.923)\tData 0.724 (0.724)\tloss 0.2646 (0.2646)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:22\n",
            "\n",
            " Epoch: 948\n",
            "Training loss 0.0072 \tTraining Prec@1 99.802 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5083 \tValidation Prec@1 90.160 \tValidation Prec@5 99.560 \n",
            "\n",
            "lr: 0.0007780076519359911\n",
            "o is 2.8368189334869385,  o_a is 2.8368189334869385\n",
            "TRAINING - Epoch: [948][0/196]\tTime 1.783 (1.783)\tData 0.948 (0.948)\tloss 0.0041 (0.0041)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [948][100/196]\tTime 0.345 (0.379)\tData 0.000 (0.010)\tloss 0.0228 (0.0075)\tPrec@1 99.609 (99.795)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [948][0/79]\tTime 0.893 (0.893)\tData 0.691 (0.691)\tloss 0.3136 (0.3136)\tPrec@1 93.750 (93.750)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:26\n",
            "\n",
            " Epoch: 949\n",
            "Training loss 0.0070 \tTraining Prec@1 99.816 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5249 \tValidation Prec@1 89.630 \tValidation Prec@5 99.660 \n",
            "\n",
            "lr: 0.0007505388567054261\n",
            "o is 2.8399500846862793,  o_a is 2.8399500846862793\n",
            "TRAINING - Epoch: [949][0/196]\tTime 1.562 (1.562)\tData 0.750 (0.750)\tloss 0.0009 (0.0009)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [949][100/196]\tTime 0.344 (0.379)\tData 0.000 (0.008)\tloss 0.0077 (0.0064)\tPrec@1 99.609 (99.865)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [949][0/79]\tTime 0.854 (0.854)\tData 0.644 (0.644)\tloss 0.2701 (0.2701)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:23:14\n",
            "\n",
            " Epoch: 950\n",
            "Training loss 0.0067 \tTraining Prec@1 99.846 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5107 \tValidation Prec@1 89.900 \tValidation Prec@5 99.640 \n",
            "\n",
            "lr: 0.00072356006436505\n",
            "o is 2.8430819511413574,  o_a is 2.8430819511413574\n",
            "TRAINING - Epoch: [950][0/196]\tTime 1.778 (1.778)\tData 0.929 (0.929)\tloss 0.0048 (0.0048)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [950][100/196]\tTime 0.345 (0.379)\tData 0.000 (0.010)\tloss 0.0188 (0.0072)\tPrec@1 98.828 (99.803)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [950][0/79]\tTime 0.804 (0.804)\tData 0.611 (0.611)\tloss 0.2737 (0.2737)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:21\n",
            "\n",
            " Epoch: 951\n",
            "Training loss 0.0069 \tTraining Prec@1 99.828 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5077 \tValidation Prec@1 90.160 \tValidation Prec@5 99.700 \n",
            "\n",
            "lr: 0.0006970715433276602\n",
            "o is 2.8462138175964355,  o_a is 2.8462138175964355\n",
            "TRAINING - Epoch: [951][0/196]\tTime 1.777 (1.777)\tData 0.822 (0.822)\tloss 0.0036 (0.0036)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [951][100/196]\tTime 0.347 (0.379)\tData 0.000 (0.009)\tloss 0.0023 (0.0069)\tPrec@1 100.000 (99.822)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [951][0/79]\tTime 0.808 (0.808)\tData 0.601 (0.601)\tloss 0.2684 (0.2684)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:17\n",
            "\n",
            " Epoch: 952\n",
            "Training loss 0.0071 \tTraining Prec@1 99.810 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5201 \tValidation Prec@1 90.070 \tValidation Prec@5 99.680 \n",
            "\n",
            "lr: 0.0006710735571283236\n",
            "o is 2.84934663772583,  o_a is 2.84934663772583\n",
            "TRAINING - Epoch: [952][0/196]\tTime 1.799 (1.799)\tData 0.868 (0.868)\tloss 0.0041 (0.0041)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [952][100/196]\tTime 0.345 (0.381)\tData 0.000 (0.009)\tloss 0.0026 (0.0069)\tPrec@1 100.000 (99.803)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [952][0/79]\tTime 0.953 (0.953)\tData 0.698 (0.698)\tloss 0.2417 (0.2417)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:31\n",
            "\n",
            " Epoch: 953\n",
            "Training loss 0.0065 \tTraining Prec@1 99.822 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5061 \tValidation Prec@1 90.260 \tValidation Prec@5 99.680 \n",
            "\n",
            "lr: 0.000645566364421768\n",
            "o is 2.8524794578552246,  o_a is 2.8524794578552246\n",
            "TRAINING - Epoch: [953][0/196]\tTime 1.725 (1.725)\tData 1.009 (1.009)\tloss 0.0084 (0.0084)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [953][100/196]\tTime 0.345 (0.380)\tData 0.000 (0.011)\tloss 0.0060 (0.0072)\tPrec@1 99.609 (99.799)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [953][0/79]\tTime 0.881 (0.881)\tData 0.676 (0.676)\tloss 0.1930 (0.1930)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:21\n",
            "\n",
            " Epoch: 954\n",
            "Training loss 0.0070 \tTraining Prec@1 99.814 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.4872 \tValidation Prec@1 90.140 \tValidation Prec@5 99.650 \n",
            "\n",
            "lr: 0.0006205502189797889\n",
            "o is 2.855612277984619,  o_a is 2.855612277984619\n",
            "TRAINING - Epoch: [954][0/196]\tTime 1.754 (1.754)\tData 0.808 (0.808)\tloss 0.0069 (0.0069)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [954][100/196]\tTime 0.343 (0.379)\tData 0.000 (0.009)\tloss 0.0114 (0.0073)\tPrec@1 99.609 (99.764)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [954][0/79]\tTime 0.866 (0.866)\tData 0.671 (0.671)\tloss 0.2503 (0.2503)\tPrec@1 95.312 (95.312)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:20\n",
            "\n",
            " Epoch: 955\n",
            "Training loss 0.0066 \tTraining Prec@1 99.818 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5128 \tValidation Prec@1 90.250 \tValidation Prec@5 99.620 \n",
            "\n",
            "lr: 0.0005960253696887631\n",
            "o is 2.85874605178833,  o_a is 2.85874605178833\n",
            "TRAINING - Epoch: [955][0/196]\tTime 1.737 (1.737)\tData 0.853 (0.853)\tloss 0.0041 (0.0041)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [955][100/196]\tTime 0.354 (0.381)\tData 0.000 (0.009)\tloss 0.0040 (0.0064)\tPrec@1 100.000 (99.845)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [955][0/79]\tTime 0.882 (0.882)\tData 0.687 (0.687)\tloss 0.2853 (0.2853)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:34\n",
            "\n",
            " Epoch: 956\n",
            "Training loss 0.0065 \tTraining Prec@1 99.828 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5006 \tValidation Prec@1 90.150 \tValidation Prec@5 99.620 \n",
            "\n",
            "lr: 0.0005719920605471336\n",
            "o is 2.86188006401062,  o_a is 2.86188006401062\n",
            "TRAINING - Epoch: [956][0/196]\tTime 1.708 (1.708)\tData 0.928 (0.928)\tloss 0.0103 (0.0103)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [956][100/196]\tTime 0.345 (0.380)\tData 0.000 (0.010)\tloss 0.0035 (0.0068)\tPrec@1 100.000 (99.826)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [956][0/79]\tTime 0.865 (0.865)\tData 0.655 (0.655)\tloss 0.3329 (0.3329)\tPrec@1 93.750 (93.750)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:23\n",
            "\n",
            " Epoch: 957\n",
            "Training loss 0.0069 \tTraining Prec@1 99.820 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.4977 \tValidation Prec@1 90.350 \tValidation Prec@5 99.640 \n",
            "\n",
            "lr: 0.0005484505306629895\n",
            "o is 2.8650143146514893,  o_a is 2.8650143146514893\n",
            "TRAINING - Epoch: [957][0/196]\tTime 1.808 (1.808)\tData 0.889 (0.889)\tloss 0.0052 (0.0052)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [957][100/196]\tTime 0.346 (0.382)\tData 0.000 (0.010)\tloss 0.0049 (0.0057)\tPrec@1 100.000 (99.845)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [957][0/79]\tTime 0.884 (0.884)\tData 0.685 (0.685)\tloss 0.2767 (0.2767)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:25\n",
            "\n",
            " Epoch: 958\n",
            "Training loss 0.0061 \tTraining Prec@1 99.834 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5177 \tValidation Prec@1 90.060 \tValidation Prec@5 99.680 \n",
            "\n",
            "lr: 0.0005254010142517007\n",
            "o is 2.8681490421295166,  o_a is 2.8681490421295166\n",
            "TRAINING - Epoch: [958][0/196]\tTime 1.650 (1.650)\tData 0.723 (0.723)\tloss 0.0032 (0.0032)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [958][100/196]\tTime 0.344 (0.379)\tData 0.000 (0.008)\tloss 0.0080 (0.0057)\tPrec@1 99.609 (99.876)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [958][0/79]\tTime 0.868 (0.868)\tData 0.636 (0.636)\tloss 0.3307 (0.3307)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:23:14\n",
            "\n",
            " Epoch: 959\n",
            "Training loss 0.0058 \tTraining Prec@1 99.874 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5343 \tValidation Prec@1 89.610 \tValidation Prec@5 99.640 \n",
            "\n",
            "lr: 0.0005028437406335925\n",
            "o is 2.871283769607544,  o_a is 2.871283769607544\n",
            "TRAINING - Epoch: [959][0/196]\tTime 1.771 (1.771)\tData 0.884 (0.884)\tloss 0.0026 (0.0026)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [959][100/196]\tTime 0.344 (0.380)\tData 0.000 (0.009)\tloss 0.0079 (0.0060)\tPrec@1 99.609 (99.884)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [959][0/79]\tTime 0.865 (0.865)\tData 0.643 (0.643)\tloss 0.2333 (0.2333)\tPrec@1 94.531 (94.531)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:23:16\n",
            "\n",
            " Epoch: 960\n",
            "Training loss 0.0063 \tTraining Prec@1 99.850 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.4984 \tValidation Prec@1 90.180 \tValidation Prec@5 99.610 \n",
            "\n",
            "lr: 0.0004807789342316247\n",
            "o is 2.8744189739227295,  o_a is 2.8744189739227295\n",
            "TRAINING - Epoch: [960][0/196]\tTime 1.750 (1.750)\tData 0.970 (0.970)\tloss 0.0135 (0.0135)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [960][100/196]\tTime 0.346 (0.379)\tData 0.000 (0.010)\tloss 0.0035 (0.0062)\tPrec@1 100.000 (99.841)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [960][0/79]\tTime 0.952 (0.952)\tData 0.729 (0.729)\tloss 0.2651 (0.2651)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:18\n",
            "\n",
            " Epoch: 961\n",
            "Training loss 0.0063 \tTraining Prec@1 99.826 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5044 \tValidation Prec@1 90.120 \tValidation Prec@5 99.610 \n",
            "\n",
            "lr: 0.00045920681456920997\n",
            "o is 2.8775546550750732,  o_a is 2.8775546550750732\n",
            "TRAINING - Epoch: [961][0/196]\tTime 1.960 (1.960)\tData 0.869 (0.869)\tloss 0.0058 (0.0058)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [961][100/196]\tTime 0.342 (0.380)\tData 0.000 (0.009)\tloss 0.0014 (0.0061)\tPrec@1 100.000 (99.834)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [961][0/79]\tTime 0.859 (0.859)\tData 0.608 (0.608)\tloss 0.2163 (0.2163)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:23:15\n",
            "\n",
            " Epoch: 962\n",
            "Training loss 0.0060 \tTraining Prec@1 99.840 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5187 \tValidation Prec@1 90.070 \tValidation Prec@5 99.640 \n",
            "\n",
            "lr: 0.0004381275962679991\n",
            "o is 2.880690574645996,  o_a is 2.880690574645996\n",
            "TRAINING - Epoch: [962][0/196]\tTime 1.790 (1.790)\tData 0.797 (0.797)\tloss 0.0060 (0.0060)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [962][100/196]\tTime 0.343 (0.379)\tData 0.001 (0.009)\tloss 0.0162 (0.0070)\tPrec@1 99.219 (99.780)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [962][0/79]\tTime 0.831 (0.831)\tData 0.672 (0.672)\tloss 0.2424 (0.2424)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:23\n",
            "\n",
            " Epoch: 963\n",
            "Training loss 0.0064 \tTraining Prec@1 99.824 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5168 \tValidation Prec@1 90.210 \tValidation Prec@5 99.610 \n",
            "\n",
            "lr: 0.0004175414890457434\n",
            "o is 2.883826732635498,  o_a is 2.883826732635498\n",
            "TRAINING - Epoch: [963][0/196]\tTime 1.729 (1.729)\tData 0.877 (0.877)\tloss 0.0154 (0.0154)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [963][100/196]\tTime 0.354 (0.379)\tData 0.000 (0.010)\tloss 0.0092 (0.0061)\tPrec@1 100.000 (99.892)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [963][0/79]\tTime 0.855 (0.855)\tData 0.610 (0.610)\tloss 0.2721 (0.2721)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:17\n",
            "\n",
            " Epoch: 964\n",
            "Training loss 0.0061 \tTraining Prec@1 99.868 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.4992 \tValidation Prec@1 90.340 \tValidation Prec@5 99.610 \n",
            "\n",
            "lr: 0.0003974486977142412\n",
            "o is 2.886962890625,  o_a is 2.886962890625\n",
            "TRAINING - Epoch: [964][0/196]\tTime 1.748 (1.748)\tData 0.843 (0.843)\tloss 0.0025 (0.0025)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [964][100/196]\tTime 0.343 (0.380)\tData 0.000 (0.009)\tloss 0.0107 (0.0068)\tPrec@1 99.609 (99.803)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [964][0/79]\tTime 0.886 (0.886)\tData 0.642 (0.642)\tloss 0.2880 (0.2880)\tPrec@1 92.188 (92.188)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:18\n",
            "\n",
            " Epoch: 965\n",
            "Training loss 0.0067 \tTraining Prec@1 99.812 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5092 \tValidation Prec@1 90.220 \tValidation Prec@5 99.670 \n",
            "\n",
            "lr: 0.0003778494221772445\n",
            "o is 2.89009952545166,  o_a is 2.89009952545166\n",
            "TRAINING - Epoch: [965][0/196]\tTime 1.788 (1.788)\tData 1.024 (1.024)\tloss 0.0059 (0.0059)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [965][100/196]\tTime 0.345 (0.379)\tData 0.000 (0.011)\tloss 0.0102 (0.0068)\tPrec@1 99.609 (99.810)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [965][0/79]\tTime 0.920 (0.920)\tData 0.717 (0.717)\tloss 0.2483 (0.2483)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:23:14\n",
            "\n",
            " Epoch: 966\n",
            "Training loss 0.0066 \tTraining Prec@1 99.826 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5340 \tValidation Prec@1 90.080 \tValidation Prec@5 99.630 \n",
            "\n",
            "lr: 0.0003587438574285329\n",
            "o is 2.8932366371154785,  o_a is 2.8932366371154785\n",
            "TRAINING - Epoch: [966][0/196]\tTime 1.753 (1.753)\tData 0.833 (0.833)\tloss 0.0026 (0.0026)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [966][100/196]\tTime 0.344 (0.377)\tData 0.000 (0.009)\tloss 0.0096 (0.0063)\tPrec@1 99.609 (99.849)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [966][0/79]\tTime 0.915 (0.915)\tData 0.666 (0.666)\tloss 0.2473 (0.2473)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:23:09\n",
            "\n",
            " Epoch: 967\n",
            "Training loss 0.0061 \tTraining Prec@1 99.846 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5238 \tValidation Prec@1 90.080 \tValidation Prec@5 99.670 \n",
            "\n",
            "lr: 0.0003401321935499208\n",
            "o is 2.896373987197876,  o_a is 2.896373987197876\n",
            "TRAINING - Epoch: [967][0/196]\tTime 1.758 (1.758)\tData 0.870 (0.870)\tloss 0.0031 (0.0031)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [967][100/196]\tTime 0.357 (0.380)\tData 0.000 (0.009)\tloss 0.0036 (0.0057)\tPrec@1 100.000 (99.876)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [967][0/79]\tTime 0.892 (0.892)\tData 0.697 (0.697)\tloss 0.3071 (0.3071)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:23:16\n",
            "\n",
            " Epoch: 968\n",
            "Training loss 0.0058 \tTraining Prec@1 99.868 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5112 \tValidation Prec@1 90.530 \tValidation Prec@5 99.650 \n",
            "\n",
            "lr: 0.0003220146157094029\n",
            "o is 2.8995113372802734,  o_a is 2.8995113372802734\n",
            "TRAINING - Epoch: [968][0/196]\tTime 1.765 (1.765)\tData 0.881 (0.881)\tloss 0.0101 (0.0101)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [968][100/196]\tTime 0.346 (0.380)\tData 0.000 (0.010)\tloss 0.0121 (0.0060)\tPrec@1 99.609 (99.865)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [968][0/79]\tTime 0.857 (0.857)\tData 0.636 (0.636)\tloss 0.3143 (0.3143)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:24\n",
            "\n",
            " Epoch: 969\n",
            "Training loss 0.0061 \tTraining Prec@1 99.854 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5265 \tValidation Prec@1 90.100 \tValidation Prec@5 99.650 \n",
            "\n",
            "lr: 0.00030439130415928933\n",
            "o is 2.902649164199829,  o_a is 2.902649164199829\n",
            "TRAINING - Epoch: [969][0/196]\tTime 1.684 (1.684)\tData 0.884 (0.884)\tloss 0.0037 (0.0037)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [969][100/196]\tTime 0.343 (0.380)\tData 0.003 (0.009)\tloss 0.0076 (0.0062)\tPrec@1 100.000 (99.849)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [969][0/79]\tTime 0.753 (0.753)\tData 0.548 (0.548)\tloss 0.3566 (0.3566)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:29\n",
            "\n",
            " Epoch: 970\n",
            "Training loss 0.0063 \tTraining Prec@1 99.850 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5026 \tValidation Prec@1 90.150 \tValidation Prec@5 99.650 \n",
            "\n",
            "lr: 0.00028726243423441783\n",
            "o is 2.905787467956543,  o_a is 2.905787467956543\n",
            "TRAINING - Epoch: [970][0/196]\tTime 1.725 (1.725)\tData 0.848 (0.848)\tloss 0.0128 (0.0128)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [970][100/196]\tTime 0.343 (0.381)\tData 0.001 (0.009)\tloss 0.0065 (0.0062)\tPrec@1 99.609 (99.841)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [970][0/79]\tTime 0.860 (0.860)\tData 0.655 (0.655)\tloss 0.2134 (0.2134)\tPrec@1 94.531 (94.531)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:27\n",
            "\n",
            " Epoch: 971\n",
            "Training loss 0.0063 \tTraining Prec@1 99.826 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5226 \tValidation Prec@1 90.040 \tValidation Prec@5 99.650 \n",
            "\n",
            "lr: 0.000270628176350422\n",
            "o is 2.9089255332946777,  o_a is 2.9089255332946777\n",
            "TRAINING - Epoch: [971][0/196]\tTime 1.704 (1.704)\tData 0.776 (0.776)\tloss 0.0124 (0.0124)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [971][100/196]\tTime 0.353 (0.382)\tData 0.003 (0.009)\tloss 0.0170 (0.0066)\tPrec@1 99.609 (99.826)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [971][0/79]\tTime 0.898 (0.898)\tData 0.669 (0.669)\tloss 0.3385 (0.3385)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:27\n",
            "\n",
            " Epoch: 972\n",
            "Training loss 0.0064 \tTraining Prec@1 99.840 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5106 \tValidation Prec@1 90.350 \tValidation Prec@5 99.700 \n",
            "\n",
            "lr: 0.00025448869600202113\n",
            "o is 2.9120640754699707,  o_a is 2.9120640754699707\n",
            "TRAINING - Epoch: [972][0/196]\tTime 1.834 (1.834)\tData 0.914 (0.914)\tloss 0.0063 (0.0063)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [972][100/196]\tTime 0.345 (0.381)\tData 0.000 (0.010)\tloss 0.0023 (0.0063)\tPrec@1 100.000 (99.853)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [972][0/79]\tTime 0.931 (0.931)\tData 0.702 (0.702)\tloss 0.3414 (0.3414)\tPrec@1 92.188 (92.188)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:22\n",
            "\n",
            " Epoch: 973\n",
            "Training loss 0.0062 \tTraining Prec@1 99.846 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5281 \tValidation Prec@1 90.070 \tValidation Prec@5 99.570 \n",
            "\n",
            "lr: 0.00023884415376137198\n",
            "o is 2.9152023792266846,  o_a is 2.9152023792266846\n",
            "TRAINING - Epoch: [973][0/196]\tTime 1.734 (1.734)\tData 0.850 (0.850)\tloss 0.0072 (0.0072)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [973][100/196]\tTime 0.369 (0.380)\tData 0.000 (0.009)\tloss 0.0101 (0.0060)\tPrec@1 99.609 (99.861)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [973][0/79]\tTime 0.888 (0.888)\tData 0.676 (0.676)\tloss 0.2075 (0.2075)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:19\n",
            "\n",
            " Epoch: 974\n",
            "Training loss 0.0056 \tTraining Prec@1 99.884 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5146 \tValidation Prec@1 89.960 \tValidation Prec@5 99.680 \n",
            "\n",
            "lr: 0.00022369470527649173\n",
            "o is 2.9183411598205566,  o_a is 2.9183411598205566\n",
            "TRAINING - Epoch: [974][0/196]\tTime 1.761 (1.761)\tData 0.837 (0.837)\tloss 0.0062 (0.0062)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [974][100/196]\tTime 0.344 (0.378)\tData 0.000 (0.009)\tloss 0.0037 (0.0072)\tPrec@1 100.000 (99.814)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [974][0/79]\tTime 0.849 (0.849)\tData 0.636 (0.636)\tloss 0.2078 (0.2078)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:23:12\n",
            "\n",
            " Epoch: 975\n",
            "Training loss 0.0068 \tTraining Prec@1 99.830 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5093 \tValidation Prec@1 90.280 \tValidation Prec@5 99.670 \n",
            "\n",
            "lr: 0.00020904050126967604\n",
            "o is 2.921480417251587,  o_a is 2.921480417251587\n",
            "TRAINING - Epoch: [975][0/196]\tTime 1.750 (1.750)\tData 0.883 (0.883)\tloss 0.0053 (0.0053)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [975][100/196]\tTime 0.345 (0.380)\tData 0.000 (0.009)\tloss 0.0052 (0.0064)\tPrec@1 100.000 (99.822)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [975][0/79]\tTime 0.904 (0.904)\tData 0.670 (0.670)\tloss 0.2173 (0.2173)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:21\n",
            "\n",
            " Epoch: 976\n",
            "Training loss 0.0059 \tTraining Prec@1 99.848 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5166 \tValidation Prec@1 90.200 \tValidation Prec@5 99.640 \n",
            "\n",
            "lr: 0.00019488168753603358\n",
            "o is 2.924619674682617,  o_a is 2.924619674682617\n",
            "TRAINING - Epoch: [976][0/196]\tTime 1.759 (1.759)\tData 0.961 (0.961)\tloss 0.0037 (0.0037)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [976][100/196]\tTime 0.344 (0.379)\tData 0.000 (0.010)\tloss 0.0015 (0.0069)\tPrec@1 100.000 (99.830)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [976][0/79]\tTime 0.880 (0.880)\tData 0.697 (0.697)\tloss 0.2214 (0.2214)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:19\n",
            "\n",
            " Epoch: 977\n",
            "Training loss 0.0064 \tTraining Prec@1 99.844 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5130 \tValidation Prec@1 90.210 \tValidation Prec@5 99.610 \n",
            "\n",
            "lr: 0.0001812184049420203\n",
            "o is 2.9277591705322266,  o_a is 2.9277591705322266\n",
            "TRAINING - Epoch: [977][0/196]\tTime 1.791 (1.791)\tData 0.943 (0.943)\tloss 0.0028 (0.0028)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [977][100/196]\tTime 0.353 (0.379)\tData 0.000 (0.010)\tloss 0.0030 (0.0062)\tPrec@1 100.000 (99.834)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [977][0/79]\tTime 0.864 (0.864)\tData 0.654 (0.654)\tloss 0.1941 (0.1941)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:22\n",
            "\n",
            " Epoch: 978\n",
            "Training loss 0.0064 \tTraining Prec@1 99.838 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.4958 \tValidation Prec@1 90.290 \tValidation Prec@5 99.650 \n",
            "\n",
            "lr: 0.0001680507894240351\n",
            "o is 2.930898666381836,  o_a is 2.930898666381836\n",
            "TRAINING - Epoch: [978][0/196]\tTime 1.733 (1.733)\tData 0.972 (0.972)\tloss 0.0126 (0.0126)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [978][100/196]\tTime 0.343 (0.381)\tData 0.000 (0.010)\tloss 0.0007 (0.0067)\tPrec@1 100.000 (99.803)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [978][0/79]\tTime 0.872 (0.872)\tData 0.668 (0.668)\tloss 0.2676 (0.2676)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:30\n",
            "\n",
            " Epoch: 979\n",
            "Training loss 0.0067 \tTraining Prec@1 99.814 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5298 \tValidation Prec@1 90.050 \tValidation Prec@5 99.650 \n",
            "\n",
            "lr: 0.00015537897198706526\n",
            "o is 2.9340386390686035,  o_a is 2.9340386390686035\n",
            "TRAINING - Epoch: [979][0/196]\tTime 1.820 (1.820)\tData 0.951 (0.951)\tloss 0.0088 (0.0088)\tPrec@1 99.219 (99.219)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [979][100/196]\tTime 0.343 (0.380)\tData 0.000 (0.010)\tloss 0.0027 (0.0065)\tPrec@1 100.000 (99.845)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [979][0/79]\tTime 0.881 (0.881)\tData 0.658 (0.658)\tloss 0.2885 (0.2885)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:21\n",
            "\n",
            " Epoch: 980\n",
            "Training loss 0.0066 \tTraining Prec@1 99.830 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5264 \tValidation Prec@1 89.970 \tValidation Prec@5 99.640 \n",
            "\n",
            "lr: 0.00014320307870339287\n",
            "o is 2.937178611755371,  o_a is 2.937178611755371\n",
            "TRAINING - Epoch: [980][0/196]\tTime 1.690 (1.690)\tData 0.761 (0.761)\tloss 0.0014 (0.0014)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [980][100/196]\tTime 0.346 (0.379)\tData 0.000 (0.008)\tloss 0.0152 (0.0065)\tPrec@1 99.219 (99.841)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [980][0/79]\tTime 0.912 (0.912)\tData 0.650 (0.650)\tloss 0.2166 (0.2166)\tPrec@1 92.969 (92.969)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:23:18\n",
            "\n",
            " Epoch: 981\n",
            "Training loss 0.0063 \tTraining Prec@1 99.856 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5132 \tValidation Prec@1 90.250 \tValidation Prec@5 99.610 \n",
            "\n",
            "lr: 0.00013152323071134045\n",
            "o is 2.9403185844421387,  o_a is 2.9403185844421387\n",
            "TRAINING - Epoch: [981][0/196]\tTime 1.655 (1.655)\tData 0.706 (0.706)\tloss 0.0033 (0.0033)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [981][100/196]\tTime 0.361 (0.379)\tData 0.000 (0.008)\tloss 0.0061 (0.0064)\tPrec@1 99.609 (99.841)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [981][0/79]\tTime 0.926 (0.926)\tData 0.689 (0.689)\tloss 0.2716 (0.2716)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:20\n",
            "\n",
            " Epoch: 982\n",
            "Training loss 0.0062 \tTraining Prec@1 99.856 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5004 \tValidation Prec@1 90.340 \tValidation Prec@5 99.660 \n",
            "\n",
            "lr: 0.00012033954421406058\n",
            "o is 2.9434590339660645,  o_a is 2.9434590339660645\n",
            "TRAINING - Epoch: [982][0/196]\tTime 1.789 (1.789)\tData 0.838 (0.838)\tloss 0.0106 (0.0106)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [982][100/196]\tTime 0.346 (0.379)\tData 0.000 (0.009)\tloss 0.0053 (0.0059)\tPrec@1 100.000 (99.857)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [982][0/79]\tTime 0.851 (0.851)\tData 0.657 (0.657)\tloss 0.3254 (0.3254)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:19\n",
            "\n",
            " Epoch: 983\n",
            "Training loss 0.0058 \tTraining Prec@1 99.858 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5061 \tValidation Prec@1 90.240 \tValidation Prec@5 99.630 \n",
            "\n",
            "lr: 0.00010965213047836464\n",
            "o is 2.946599245071411,  o_a is 2.946599245071411\n",
            "TRAINING - Epoch: [983][0/196]\tTime 1.731 (1.731)\tData 0.933 (0.933)\tloss 0.0043 (0.0043)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [983][100/196]\tTime 0.352 (0.379)\tData 0.000 (0.010)\tloss 0.0081 (0.0058)\tPrec@1 100.000 (99.869)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [983][0/79]\tTime 0.877 (0.877)\tData 0.680 (0.680)\tloss 0.2807 (0.2807)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:23:18\n",
            "\n",
            " Epoch: 984\n",
            "Training loss 0.0059 \tTraining Prec@1 99.856 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5184 \tValidation Prec@1 90.240 \tValidation Prec@5 99.680 \n",
            "\n",
            "lr: 9.946109583366254e-05\n",
            "o is 2.949739933013916,  o_a is 2.949739933013916\n",
            "TRAINING - Epoch: [984][0/196]\tTime 1.878 (1.878)\tData 1.002 (1.002)\tloss 0.0016 (0.0016)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [984][100/196]\tTime 0.345 (0.380)\tData 0.000 (0.011)\tloss 0.0046 (0.0061)\tPrec@1 100.000 (99.857)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [984][0/79]\tTime 0.850 (0.850)\tData 0.639 (0.639)\tloss 0.3109 (0.3109)\tPrec@1 89.844 (89.844)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:19\n",
            "\n",
            " Epoch: 985\n",
            "Training loss 0.0063 \tTraining Prec@1 99.846 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5156 \tValidation Prec@1 89.910 \tValidation Prec@5 99.680 \n",
            "\n",
            "lr: 8.976654167084127e-05\n",
            "o is 2.952880382537842,  o_a is 2.952880382537842\n",
            "TRAINING - Epoch: [985][0/196]\tTime 1.596 (1.596)\tData 0.618 (0.618)\tloss 0.0060 (0.0060)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [985][100/196]\tTime 0.349 (0.379)\tData 0.000 (0.007)\tloss 0.0113 (0.0062)\tPrec@1 99.609 (99.861)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [985][0/79]\tTime 1.042 (1.042)\tData 0.783 (0.783)\tloss 0.2531 (0.2531)\tPrec@1 92.969 (92.969)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:24\n",
            "\n",
            " Epoch: 986\n",
            "Training loss 0.0062 \tTraining Prec@1 99.850 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5309 \tValidation Prec@1 89.950 \tValidation Prec@5 99.600 \n",
            "\n",
            "lr: 8.056856444131013e-05\n",
            "o is 2.956021308898926,  o_a is 2.956021308898926\n",
            "TRAINING - Epoch: [986][0/196]\tTime 1.798 (1.798)\tData 0.971 (0.971)\tloss 0.0029 (0.0029)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [986][100/196]\tTime 0.346 (0.381)\tData 0.001 (0.010)\tloss 0.0071 (0.0059)\tPrec@1 99.609 (99.872)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [986][0/79]\tTime 0.861 (0.861)\tData 0.664 (0.664)\tloss 0.3012 (0.3012)\tPrec@1 94.531 (94.531)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:22\n",
            "\n",
            " Epoch: 987\n",
            "Training loss 0.0064 \tTraining Prec@1 99.838 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5191 \tValidation Prec@1 90.140 \tValidation Prec@5 99.690 \n",
            "\n",
            "lr: 7.186725565601258e-05\n",
            "o is 2.9591622352600098,  o_a is 2.9591622352600098\n",
            "TRAINING - Epoch: [987][0/196]\tTime 1.738 (1.738)\tData 0.858 (0.858)\tloss 0.0095 (0.0095)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [987][100/196]\tTime 0.345 (0.378)\tData 0.000 (0.009)\tloss 0.0030 (0.0066)\tPrec@1 100.000 (99.830)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [987][0/79]\tTime 0.837 (0.837)\tData 0.669 (0.669)\tloss 0.2901 (0.2901)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:23:19\n",
            "\n",
            " Epoch: 988\n",
            "Training loss 0.0063 \tTraining Prec@1 99.834 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5030 \tValidation Prec@1 90.350 \tValidation Prec@5 99.600 \n",
            "\n",
            "lr: 6.366270188452694e-05\n",
            "o is 2.9623031616210938,  o_a is 2.9623031616210938\n",
            "TRAINING - Epoch: [988][0/196]\tTime 1.744 (1.744)\tData 0.908 (0.908)\tloss 0.0035 (0.0035)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [988][100/196]\tTime 0.351 (0.378)\tData 0.001 (0.010)\tloss 0.0030 (0.0057)\tPrec@1 100.000 (99.869)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [988][0/79]\tTime 0.934 (0.934)\tData 0.687 (0.687)\tloss 0.2198 (0.2198)\tPrec@1 95.312 (95.312)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:23:19\n",
            "\n",
            " Epoch: 989\n",
            "Training loss 0.0061 \tTraining Prec@1 99.840 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5114 \tValidation Prec@1 90.460 \tValidation Prec@5 99.690 \n",
            "\n",
            "lr: 5.5954984754194814e-05\n",
            "o is 2.965444564819336,  o_a is 2.965444564819336\n",
            "TRAINING - Epoch: [989][0/196]\tTime 1.779 (1.779)\tData 0.873 (0.873)\tloss 0.0033 (0.0033)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [989][100/196]\tTime 0.343 (0.379)\tData 0.000 (0.009)\tloss 0.0142 (0.0059)\tPrec@1 99.609 (99.853)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [989][0/79]\tTime 0.870 (0.870)\tData 0.656 (0.656)\tloss 0.2710 (0.2710)\tPrec@1 96.094 (96.094)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:23:17\n",
            "\n",
            " Epoch: 990\n",
            "Training loss 0.0060 \tTraining Prec@1 99.838 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5028 \tValidation Prec@1 90.400 \tValidation Prec@5 99.680 \n",
            "\n",
            "lr: 4.8744180949327245e-05\n",
            "o is 2.96858549118042,  o_a is 2.96858549118042\n",
            "TRAINING - Epoch: [990][0/196]\tTime 1.720 (1.720)\tData 0.917 (0.917)\tloss 0.0042 (0.0042)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [990][100/196]\tTime 0.347 (0.377)\tData 0.000 (0.010)\tloss 0.0155 (0.0061)\tPrec@1 99.609 (99.857)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [990][0/79]\tTime 0.934 (0.934)\tData 0.768 (0.768)\tloss 0.3345 (0.3345)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:23:19\n",
            "\n",
            " Epoch: 991\n",
            "Training loss 0.0058 \tTraining Prec@1 99.862 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5195 \tValidation Prec@1 90.040 \tValidation Prec@5 99.660 \n",
            "\n",
            "lr: 4.2030362210410905e-05\n",
            "o is 2.971726894378662,  o_a is 2.971726894378662\n",
            "TRAINING - Epoch: [991][0/196]\tTime 1.767 (1.767)\tData 0.911 (0.911)\tloss 0.0050 (0.0050)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [991][100/196]\tTime 0.345 (0.380)\tData 0.000 (0.010)\tloss 0.0036 (0.0058)\tPrec@1 100.000 (99.865)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [991][0/79]\tTime 0.826 (0.826)\tData 0.600 (0.600)\tloss 0.2786 (0.2786)\tPrec@1 95.312 (95.312)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:20\n",
            "\n",
            " Epoch: 992\n",
            "Training loss 0.0057 \tTraining Prec@1 99.870 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5228 \tValidation Prec@1 90.120 \tValidation Prec@5 99.630 \n",
            "\n",
            "lr: 3.58135953334308e-05\n",
            "o is 2.974867820739746,  o_a is 2.974867820739746\n",
            "TRAINING - Epoch: [992][0/196]\tTime 1.717 (1.717)\tData 0.720 (0.720)\tloss 0.0065 (0.0065)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [992][100/196]\tTime 0.350 (0.379)\tData 0.000 (0.008)\tloss 0.0017 (0.0054)\tPrec@1 100.000 (99.884)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [992][0/79]\tTime 0.919 (0.919)\tData 0.738 (0.738)\tloss 0.2610 (0.2610)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:21\n",
            "\n",
            " Epoch: 993\n",
            "Training loss 0.0059 \tTraining Prec@1 99.854 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5067 \tValidation Prec@1 90.430 \tValidation Prec@5 99.610 \n",
            "\n",
            "lr: 3.0093942169187487e-05\n",
            "o is 2.9780092239379883,  o_a is 2.9780092239379883\n",
            "TRAINING - Epoch: [993][0/196]\tTime 1.761 (1.761)\tData 0.957 (0.957)\tloss 0.0198 (0.0198)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [993][100/196]\tTime 0.344 (0.379)\tData 0.000 (0.010)\tloss 0.0040 (0.0058)\tPrec@1 100.000 (99.869)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [993][0/79]\tTime 0.854 (0.854)\tData 0.673 (0.673)\tloss 0.2702 (0.2702)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:21\n",
            "\n",
            " Epoch: 994\n",
            "Training loss 0.0059 \tTraining Prec@1 99.870 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.4921 \tValidation Prec@1 90.230 \tValidation Prec@5 99.700 \n",
            "\n",
            "lr: 2.48714596226642e-05\n",
            "o is 2.9811506271362305,  o_a is 2.9811506271362305\n",
            "TRAINING - Epoch: [994][0/196]\tTime 1.686 (1.686)\tData 0.703 (0.703)\tloss 0.0022 (0.0022)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [994][100/196]\tTime 0.345 (0.378)\tData 0.000 (0.008)\tloss 0.0014 (0.0059)\tPrec@1 100.000 (99.861)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [994][0/79]\tTime 0.916 (0.916)\tData 0.717 (0.717)\tloss 0.2999 (0.2999)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:23:19\n",
            "\n",
            " Epoch: 995\n",
            "Training loss 0.0059 \tTraining Prec@1 99.858 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5140 \tValidation Prec@1 90.150 \tValidation Prec@5 99.680 \n",
            "\n",
            "lr: 2.0146199652510595e-05\n",
            "o is 2.9842922687530518,  o_a is 2.9842922687530518\n",
            "TRAINING - Epoch: [995][0/196]\tTime 1.763 (1.763)\tData 0.836 (0.836)\tloss 0.0035 (0.0035)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [995][100/196]\tTime 0.350 (0.381)\tData 0.001 (0.009)\tloss 0.0084 (0.0065)\tPrec@1 100.000 (99.814)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [995][0/79]\tTime 0.897 (0.897)\tData 0.678 (0.678)\tloss 0.2336 (0.2336)\tPrec@1 95.312 (95.312)\tPrec@5 99.219 (99.219)\n",
            "Time cost: 01:18\tTime of Finish: 2023-11-27 09:23:20\n",
            "\n",
            " Epoch: 996\n",
            "Training loss 0.0062 \tTraining Prec@1 99.826 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5021 \tValidation Prec@1 90.460 \tValidation Prec@5 99.610 \n",
            "\n",
            "lr: 1.591820927045985e-05\n",
            "o is 2.987433910369873,  o_a is 2.987433910369873\n",
            "TRAINING - Epoch: [996][0/196]\tTime 1.509 (1.509)\tData 0.629 (0.629)\tloss 0.0035 (0.0035)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [996][100/196]\tTime 0.344 (0.378)\tData 0.000 (0.007)\tloss 0.0047 (0.0063)\tPrec@1 100.000 (99.818)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [996][0/79]\tTime 0.764 (0.764)\tData 0.552 (0.552)\tloss 0.2916 (0.2916)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:23:19\n",
            "\n",
            " Epoch: 997\n",
            "Training loss 0.0061 \tTraining Prec@1 99.840 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5229 \tValidation Prec@1 89.960 \tValidation Prec@5 99.640 \n",
            "\n",
            "lr: 1.2187530540923423e-05\n",
            "o is 2.9905753135681152,  o_a is 2.9905753135681152\n",
            "TRAINING - Epoch: [997][0/196]\tTime 1.785 (1.785)\tData 0.917 (0.917)\tloss 0.0057 (0.0057)\tPrec@1 100.000 (100.000)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [997][100/196]\tTime 0.348 (0.379)\tData 0.000 (0.010)\tloss 0.0058 (0.0061)\tPrec@1 99.609 (99.869)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [997][0/79]\tTime 0.989 (0.989)\tData 0.791 (0.791)\tloss 0.3095 (0.3095)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:23:19\n",
            "\n",
            " Epoch: 998\n",
            "Training loss 0.0060 \tTraining Prec@1 99.862 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5140 \tValidation Prec@1 90.190 \tValidation Prec@5 99.600 \n",
            "\n",
            "lr: 8.954200580524735e-06\n",
            "o is 2.9937171936035156,  o_a is 2.9937171936035156\n",
            "TRAINING - Epoch: [998][0/196]\tTime 1.747 (1.747)\tData 0.929 (0.929)\tloss 0.0081 (0.0081)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [998][100/196]\tTime 0.355 (0.379)\tData 0.001 (0.010)\tloss 0.0073 (0.0065)\tPrec@1 99.609 (99.814)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [998][0/79]\tTime 0.935 (0.935)\tData 0.728 (0.728)\tloss 0.2591 (0.2591)\tPrec@1 93.750 (93.750)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:23:19\n",
            "\n",
            " Epoch: 999\n",
            "Training loss 0.0064 \tTraining Prec@1 99.850 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.5169 \tValidation Prec@1 90.220 \tValidation Prec@5 99.660 \n",
            "\n",
            "lr: 6.218251557766099e-06\n",
            "o is 2.996858596801758,  o_a is 2.996858596801758\n",
            "TRAINING - Epoch: [999][0/196]\tTime 1.815 (1.815)\tData 1.025 (1.025)\tloss 0.0037 (0.0037)\tPrec@1 99.609 (99.609)\tPrec@5 100.000 (100.000)\n",
            "TRAINING - Epoch: [999][100/196]\tTime 0.345 (0.380)\tData 0.001 (0.011)\tloss 0.0024 (0.0065)\tPrec@1 100.000 (99.818)\tPrec@5 100.000 (100.000)\n",
            "EVALUATING - Epoch: [999][0/79]\tTime 0.822 (0.822)\tData 0.597 (0.597)\tloss 0.3319 (0.3319)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\n",
            "Time cost: 01:17\tTime of Finish: 2023-11-27 09:23:19\n",
            "\n",
            " Epoch: 1000\n",
            "Training loss 0.0063 \tTraining Prec@1 99.832 \tTraining Prec@5 100.000 \n",
            "Validation loss 0.4924 \tValidation Prec@1 90.400 \tValidation Prec@5 99.660 \n",
            "\n",
            "**************************************************DONE**************************************************\n",
            "\n",
            " Best_Epoch: 968\tBest_Prec1 90.5300 \tBest_Loss 0.511 \t\n"
          ]
        }
      ]
    }
  ]
}