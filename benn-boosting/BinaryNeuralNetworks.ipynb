{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35097447-f476-4238-9672-c1cb6bfc0577",
   "metadata": {},
   "source": [
    "# Binary Neural Networks with ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c3fc47-7304-483d-a814-22c4f736eaee",
   "metadata": {},
   "source": [
    "## Libraries imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72de5392-70ff-41c3-8a40-531339739778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import math\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e604a84e-f8ec-412b-bfb8-3a7c1ed5ccd3",
   "metadata": {},
   "source": [
    "## Binary Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fbd9a77-f2ed-4f70-879d-d5ade95a0133",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinOp():\n",
    "    def __init__(self, model, quant_mode='FL_Full'):\n",
    "        \"\"\"\n",
    "        Initialize the binary operation class.\n",
    "        \n",
    "        Parameters:\n",
    "            model (nn.Module): The PyTorch model to binarize.\n",
    "            quant_mode (str): The quantization mode, either 'FL_Full' or 'FL_Binary'.\n",
    "        \"\"\"\n",
    "        # Count the number of target layers (Conv2d and Linear)\n",
    "        count_target_layers = 0\n",
    "        for layer in model.modules():\n",
    "            if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "                count_target_layers += 1\n",
    "\n",
    "        # Check if the quant_mode is valid\n",
    "        if quant_mode not in ['FL_Binary', 'FL_Full']:\n",
    "            raise ValueError(\"Invalid quant_mode! Use either 'FL_Full' or 'FL_Binary'.\")\n",
    "\n",
    "        # Set the range of layers to binarize based on quant_mode\n",
    "        if quant_mode == 'FL_Full':\n",
    "            start_range = 1\n",
    "            end_range = count_target_layers - 2\n",
    "        elif quant_mode == 'FL_Binary':\n",
    "            start_range = 0\n",
    "            end_range = count_target_layers - 1\n",
    "\n",
    "        self.bin_range = numpy.linspace(start_range, end_range, end_range - start_range + 1).astype('int').tolist()\n",
    "        self.num_of_params = len(self.bin_range)\n",
    "        self.saved_params = []  # To store original full-precision weights\n",
    "        self.target_modules = []  # Layers to be binarized\n",
    "\n",
    "        index = -1\n",
    "        for layer in model.modules():\n",
    "            if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "                index += 1\n",
    "                if index in self.bin_range:\n",
    "                    temp_weights = layer.weight.data.clone()\n",
    "                    self.saved_params.append(temp_weights)\n",
    "                    self.target_modules.append(layer.weight)\n",
    "\n",
    "    def binarization(self):\n",
    "        \"\"\"\n",
    "        Perform the complete binarization process.\n",
    "        \"\"\"\n",
    "        self.meancenterConvParams()\n",
    "        self.clampConvParams()\n",
    "        self.save_params()\n",
    "        self.binarizeConvParams()\n",
    "\n",
    "    def meancenterConvParams(self):\n",
    "        \"\"\"\n",
    "        Center the convolutional parameters by subtracting their mean.\n",
    "        \"\"\"\n",
    "        for index in range(self.num_of_params):\n",
    "            weights = self.target_modules[index].data\n",
    "            neg_mean = weights.mean(dim=1, keepdim=True).mul(-1).expand_as(weights)\n",
    "            self.target_modules[index].data.add_(neg_mean)\n",
    "\n",
    "    def clampConvParams(self):\n",
    "        \"\"\"\n",
    "        Clamp the convolutional parameters to the range [-1, 1].\n",
    "        \"\"\"\n",
    "        for index in range(self.num_of_params):\n",
    "            self.target_modules[index].data.clamp_(-1.0, 1.0)\n",
    "\n",
    "    def save_params(self):\n",
    "        \"\"\"\n",
    "        Save the current full-precision parameters.\n",
    "        \"\"\"\n",
    "        for index in range(self.num_of_params):\n",
    "            self.saved_params[index].copy_(self.target_modules[index].data)\n",
    "\n",
    "    def binarizeConvParams(self):\n",
    "        \"\"\"\n",
    "        Binarize the convolutional parameters.\n",
    "        \"\"\"\n",
    "        for index in range(self.num_of_params):\n",
    "            n = self.target_modules[index].data[0].nelement()\n",
    "            s = self.target_modules[index].data.size()\n",
    "            if len(s) == 4:\n",
    "                m = self.target_modules[index].data.norm(1, 3, keepdim=True)\\\n",
    "                        .sum(2, keepdim=True).sum(1, keepdim=True).div(n)\n",
    "            elif len(s) == 2:\n",
    "                m = self.target_modules[index].data.norm(1, 1, keepdim=True).div(n)\n",
    "            self.target_modules[index].data.sign_().mul_(m.expand(s))\n",
    "\n",
    "    def restore(self):\n",
    "        \"\"\"\n",
    "        Restore the original full-precision parameters.\n",
    "        \"\"\"\n",
    "        for index in range(self.num_of_params):\n",
    "            self.target_modules[index].data.copy_(self.saved_params[index])\n",
    "\n",
    "    def updateBinaryGradWeight(self):\n",
    "        \"\"\"\n",
    "        Update the gradients for the binary weights.\n",
    "        \"\"\"\n",
    "        for index in range(self.num_of_params):\n",
    "            weight = self.target_modules[index].data\n",
    "            n = weight[0].nelement()\n",
    "            s = weight.size()\n",
    "            if len(s) == 4:\n",
    "                m = weight.norm(1, 3, keepdim=True)\\\n",
    "                        .sum(2, keepdim=True).sum(1, keepdim=True).div(n).expand(s)\n",
    "            elif len(s) == 2:\n",
    "                m = weight.norm(1, 1, keepdim=True).div(n).expand(s)\n",
    "            m = m.clone()\n",
    "            m[weight.lt(-1.0)] = 0 \n",
    "            m[weight.gt(1.0)] = 0\n",
    "\n",
    "            m = m.mul(self.target_modules[index].grad.data)\n",
    "            m_add = weight.sign().mul(self.target_modules[index].grad.data)\n",
    "            if len(s) == 4:\n",
    "                m_add = m_add.sum(3, keepdim=True)\\\n",
    "                        .sum(2, keepdim=True).sum(1, keepdim=True).div(n).expand(s)\n",
    "            elif len(s) == 2:\n",
    "                m_add = m_add.sum(1, keepdim=True).div(n).expand(s)\n",
    "\n",
    "            m_add = m_add.mul(weight.sign())\n",
    "            self.target_modules[index].grad.data = m.add(m_add).mul(1.0-1.0/s[1]).mul(n)\n",
    "            self.target_modules[index].grad.data = self.target_modules[index].grad.data.mul(1e+9)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60c8027-0f68-4fd1-8159-f33c963e5c72",
   "metadata": {},
   "source": [
    "## Custom Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70cd1136-3d0a-4431-b84d-f900d7a93cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Custom Cross-Entropy Loss with support for instance-wise and class-wise weighting.\n",
    "    \n",
    "    Parameters:\n",
    "        aggregate (str): Specifies the aggregation mode for the loss. \n",
    "                         Must be one of ['normal_ce_mean', 's_ce_mean', 'sc_ce_mean'].\n",
    "                         \n",
    "    Attributes:\n",
    "        aggregate (str): The aggregation mode for the loss.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, aggregate='mean'):\n",
    "        super(WeightedLoss, self).__init__()\n",
    "        \n",
    "        # Validate the aggregation mode\n",
    "        valid_aggregate_modes = ['normal_ce_mean', 's_ce_mean', 'sc_ce_mean']\n",
    "        if aggregate not in valid_aggregate_modes:\n",
    "            raise ValueError(f\"Invalid aggregation mode! Choose from {valid_aggregate_modes}.\")\n",
    "        \n",
    "        self.aggregate = aggregate\n",
    "\n",
    "    def forward(self, input_logits, target_labels, weights=None):\n",
    "        \"\"\"\n",
    "        Compute the loss based on the aggregation mode.\n",
    "        \n",
    "        Parameters:\n",
    "            input_logits (torch.Tensor): The predicted logits from the model.\n",
    "            target_labels (torch.Tensor): The true labels.\n",
    "            weights (torch.Tensor, optional): The weights for instances or classes.\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: The computed loss.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Standard Cross-Entropy Loss\n",
    "        if self.aggregate == 'normal_ce_mean':\n",
    "            return F.cross_entropy(input_logits, target_labels)\n",
    "        \n",
    "        # Instance-wise Weighted Cross-Entropy Loss\n",
    "        elif self.aggregate == 's_ce_mean':\n",
    "            # Calculate loss for each instance without reduction\n",
    "            separate_loss = F.cross_entropy(input_logits, target_labels, reduction='none')\n",
    "            \n",
    "            # Ensure weight dimensions match\n",
    "            if separate_loss.shape != weights.shape:\n",
    "                raise ValueError(f\"Shape mismatch: separate_loss {separate_loss.shape}, weights {weights.shape}\")\n",
    "            \n",
    "            weights = weights.squeeze_()\n",
    "            return (separate_loss * Variable(weights.cuda().float())).mean()\n",
    "        \n",
    "        # Class-wise Weighted Cross-Entropy Loss\n",
    "        elif self.aggregate == 'sc_ce_mean':\n",
    "            batch_size = target_labels.data.nelement()\n",
    "            \n",
    "            # Extract weights corresponding to the target labels\n",
    "            class_weights = weights[:, target_labels.data.cpu().numpy()].diag()\n",
    "            \n",
    "            # Calculate loss for each instance without reduction\n",
    "            separate_loss = F.cross_entropy(input_logits, target_labels, reduction='none')\n",
    "            \n",
    "            # Ensure weight dimensions match\n",
    "            if separate_loss.shape != class_weights.shape:\n",
    "                raise ValueError(f\"Shape mismatch: separate_loss {separate_loss.shape}, class_weights {class_weights.shape}\")\n",
    "            \n",
    "            return (separate_loss * Variable(class_weights.cuda().float())).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaf253a-02df-4dbb-86ed-4f9c64174a5d",
   "metadata": {},
   "source": [
    "## ResNet Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "999e7421-3f0b-4e80-abdc-e6c834297a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinActive(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    This class implements a binarization activation function. \n",
    "    It binarizes the input activations using the sign function and allows gradients to pass during backpropagation.\n",
    "    \n",
    "    To use this class, simply call it as a function:\n",
    "        binarized_activation = BinActive()(input_tensor)\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, input_tensor):\n",
    "        \"\"\"\n",
    "        Forward pass to binarize the input.\n",
    "        \n",
    "        Args:\n",
    "            ctx: Context object to save tensors for backward pass.\n",
    "            input_tensor: Input tensor to be binarized.\n",
    "        \n",
    "        Returns:\n",
    "            Binarized tensor.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Save the input tensor for backward pass\n",
    "        ctx.save_for_backward(input_tensor)\n",
    "        \n",
    "        # Perform binarization\n",
    "        binarized_output = input_tensor.sign()\n",
    "        \n",
    "        return binarized_output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        Backward pass to allow gradients to pass through.\n",
    "        \n",
    "        Args:\n",
    "            ctx: Context object containing saved tensors.\n",
    "            grad_output: Gradient tensor from the next layer.\n",
    "        \n",
    "        Returns:\n",
    "            Gradient tensor to pass to the previous layer.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Retrieve the saved input tensor\n",
    "        input_tensor, = ctx.saved_tensors\n",
    "        \n",
    "        # Create a gradient tensor that allows gradients to pass \n",
    "        # only where the input tensor values are between -1 and 1\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input = grad_input * (input_tensor <= 1).float() * (input_tensor >= -1).float()\n",
    "        \n",
    "        return grad_input\n",
    "\n",
    "class BinConv2d(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements a binary convolutional layer.\n",
    "    \n",
    "    This class can act as a drop-in replacement for a standard nn.Conv2d layer.\n",
    "    The layer includes batch normalization and an activation function.\n",
    "    \n",
    "    Args:\n",
    "        input_channels (int): Number of input channels.\n",
    "        output_channels (int): Number of output channels.\n",
    "        kernel_size (int): Size of the convolutional kernel.\n",
    "        stride (int): Stride of the convolution.\n",
    "        padding (int): Padding added to the input.\n",
    "        groups (int): Number of blocked connections from input to output channels.\n",
    "        dropout (float): Dropout rate.\n",
    "        Linear (bool): Whether to use linear activation. Default is False.\n",
    "        is_ac (bool): Whether to apply activation function. Default is True.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_channels, output_channels, kernel_size, stride=1, padding=0, groups=1, dropout=0, Linear=False, is_ac=True):\n",
    "        super(BinConv2d, self).__init__()\n",
    "        \n",
    "        # Initialize layer parameters\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.groups = groups\n",
    "        self.dropout_rate = dropout\n",
    "        self.is_linear = Linear\n",
    "        self.is_ac = is_ac\n",
    "\n",
    "        # Batch Normalization\n",
    "        if not self.is_linear:\n",
    "            self.bn = nn.BatchNorm2d(input_channels, eps=1e-4, momentum=0.1, affine=True)\n",
    "            self.conv = nn.Conv2d(input_channels, output_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups)\n",
    "        else:\n",
    "            self.bn = nn.BatchNorm1d(input_channels, eps=1e-4, momentum=0.1, affine=True)\n",
    "            self.linear = nn.Linear(input_channels, output_channels)\n",
    "\n",
    "        # Activation Function\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # Dropout Layer\n",
    "        if self.dropout_rate != 0:\n",
    "            self.dropout = nn.Dropout(self.dropout_rate)\n",
    "        else:\n",
    "            self.dropout = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the layer.\n",
    "        \n",
    "        Args:\n",
    "            x (Tensor): Input tensor.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: Output of the layer.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Apply Batch Norm\n",
    "        x = self.bn(x)\n",
    "        \n",
    "        # Binarize the output\n",
    "        x = BinActive.apply(x)\n",
    "\n",
    "        # Apply Dropout if specified\n",
    "        if self.dropout is not None:\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        # Apply Convolution or Linear layer\n",
    "        if not self.is_linear:\n",
    "            x = self.conv(x)\n",
    "        else:\n",
    "            x = self.linear(x)\n",
    "        \n",
    "        # Apply Activation if specified\n",
    "        if self.is_ac:\n",
    "            x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class RealConv2d(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements a real-valued convolutional layer.\n",
    "    \n",
    "    This class can act as a drop-in replacement for a standard nn.Conv2d layer.\n",
    "    The layer includes batch normalization and an activation function.\n",
    "    \n",
    "    Args:\n",
    "        input_channels (int): Number of input channels.\n",
    "        output_channels (int): Number of output channels.\n",
    "        kernel_size (int): Size of the convolutional kernel.\n",
    "        stride (int): Stride of the convolution.\n",
    "        padding (int): Padding added to the input.\n",
    "        groups (int): Number of blocked connections from input to output channels.\n",
    "        dropout (float): Dropout rate.\n",
    "        Linear (bool): Whether to use linear activation. Default is False.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_channels, output_channels, kernel_size, stride=1, padding=0, groups=1, dropout=0, Linear=False):\n",
    "        super(RealConv2d, self).__init__()\n",
    "        \n",
    "        # Initialize layer parameters\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.groups = groups\n",
    "        self.dropout_rate = dropout\n",
    "        self.is_linear = Linear\n",
    "\n",
    "        # Batch Normalization\n",
    "        if not self.is_linear:\n",
    "            self.bn = nn.BatchNorm2d(input_channels, eps=1e-4, momentum=0.1, affine=True)\n",
    "            self.conv = nn.Conv2d(input_channels, output_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups)\n",
    "        else:\n",
    "            self.bn = nn.BatchNorm1d(input_channels, eps=1e-4, momentum=0.1, affine=True)\n",
    "            self.linear = nn.Linear(input_channels, output_channels)\n",
    "        \n",
    "        # Activation Function\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # Dropout Layer\n",
    "        if self.dropout_rate != 0:\n",
    "            self.dropout = nn.Dropout(self.dropout_rate)\n",
    "        else:\n",
    "            self.dropout = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the layer.\n",
    "        \n",
    "        Args:\n",
    "            x (Tensor): Input tensor.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: Output of the layer.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Apply Batch Norm\n",
    "        x = self.bn(x)\n",
    "        \n",
    "        # Apply Dropout if specified\n",
    "        if self.dropout is not None:\n",
    "            x = self.dropout(x)\n",
    "        \n",
    "        # Apply Convolution or Linear layer\n",
    "        if not self.is_linear:\n",
    "            x = self.conv(x)\n",
    "        else:\n",
    "            x = self.linear(x)\n",
    "        \n",
    "        # Apply Activation\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def binary_conv3x3(in_channels, out_channels, stride=1, is_activation=True):\n",
    "    \"\"\"\n",
    "    Factory function for creating a 3x3 binary convolutional layer with padding.\n",
    "    \n",
    "    Args:\n",
    "        in_channels (int): Number of input channels.\n",
    "        out_channels (int): Number of output channels.\n",
    "        stride (int): Stride of the convolution. Default is 1.\n",
    "        is_activation (bool): Whether or not to include an activation function. Default is True.\n",
    "        \n",
    "    Returns:\n",
    "        BinConv2d: 3x3 binary convolutional layer.\n",
    "    \"\"\"\n",
    "    return BinConv2d(in_channels, out_channels, kernel_size=3, stride=stride,\n",
    "                     padding=1, is_ac=is_activation)\n",
    "\n",
    "def standard_conv3x3(in_channels, out_channels, stride=1):\n",
    "    \"\"\"\n",
    "    Factory function for creating a standard 3x3 convolutional layer with padding.\n",
    "    \n",
    "    Args:\n",
    "        in_channels (int): Number of input channels.\n",
    "        out_channels (int): Number of output channels.\n",
    "        stride (int): Stride of the convolution. Default is 1.\n",
    "        \n",
    "    Returns:\n",
    "        nn.Conv2d: 3x3 standard convolutional layer.\n",
    "    \"\"\"\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride,\n",
    "                     padding=1)\n",
    "\n",
    "def initialize_model(model):\n",
    "    \"\"\"\n",
    "    Initialize model weights for BinConv2d and nn.BatchNorm2d layers.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The model to initialize.\n",
    "    \"\"\"\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, BinConv2d):\n",
    "            n = module.kernel_size[0] * module.kernel_size[1] * module.out_channels\n",
    "            module.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "        elif isinstance(module, nn.BatchNorm2d):\n",
    "            module.weight.data.fill_(1)\n",
    "            module.bias.data.zero_()\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    BasicBlock Class for ResNet.\n",
    "    \n",
    "    Attributes:\n",
    "        expansion (int): The expansion factor for the output. Default is 1.\n",
    "    \"\"\"\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        \"\"\"\n",
    "        Initialize a BasicBlock.\n",
    "        \n",
    "        Args:\n",
    "            in_channels (int): Number of input channels.\n",
    "            out_channels (int): Number of output channels.\n",
    "            stride (int): Stride of the convolutional layer. Default is 1.\n",
    "            downsample (nn.Module, optional): The downsample layer if needed.\n",
    "        \"\"\"\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        # First binary convolutional layer\n",
    "        self.conv1 = binary_conv3x3(in_channels, out_channels, stride=stride, is_activation=True)\n",
    "        \n",
    "        # Second binary convolutional layer\n",
    "        self.conv2 = binary_conv3x3(out_channels, out_channels, is_activation=False)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass for BasicBlock.\n",
    "        \n",
    "        Args:\n",
    "            x (Tensor): Input tensor.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: Output tensor.\n",
    "        \"\"\"\n",
    "        residual = x.clone()\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(residual)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"\n",
    "    Bottleneck Class for ResNet.\n",
    "    \n",
    "    Attributes:\n",
    "        expansion (int): The expansion factor for the output. Default is 4.\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        \"\"\"\n",
    "        Initialize a Bottleneck block.\n",
    "        \n",
    "        Args:\n",
    "            in_channels (int): Number of input channels.\n",
    "            out_channels (int): Number of output channels.\n",
    "            stride (int): Stride of the convolutional layer. Default is 1.\n",
    "            downsample (nn.Module, optional): The downsample layer if needed.\n",
    "        \"\"\"\n",
    "        super(Bottleneck, self).__init__()\n",
    "\n",
    "        # First binary convolutional layer\n",
    "        self.conv1 = BinConv2d(in_channels, out_channels, kernel_size=1, is_ac=True)\n",
    "        \n",
    "        # Second binary convolutional layer\n",
    "        self.conv2 = BinConv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, is_ac=True)\n",
    "        \n",
    "        # Third binary convolutional layer\n",
    "        self.conv3 = BinConv2d(out_channels, out_channels * self.expansion, kernel_size=1, is_ac=False)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass for Bottleneck.\n",
    "        \n",
    "        Args:\n",
    "            x (Tensor): Input tensor.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: Output tensor.\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \"\"\"Base class for ResNet models.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        \"\"\"Constructs a layer block for ResNet.\n",
    "        \n",
    "        Args:\n",
    "            block: The class for either BasicBlock or Bottleneck.\n",
    "            planes: The number of filters in the block.\n",
    "            blocks: The number of blocks in the layer.\n",
    "            stride: The stride of the first block.\n",
    "            \n",
    "        Returns:\n",
    "            nn.Sequential: A sequence of blocks.\n",
    "        \"\"\"\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = BinConv2d(self.inplanes, planes * block.expansion, kernel_size=1, stride=stride, is_ac=False)\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass for ResNet.\"\"\"\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)  # Changed from tanh1 to relu1 for clarity\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)  # Changed from tanh2 to relu2 for clarity\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNet_imagenet(ResNet):\n",
    "    \"\"\"ResNet class for the imagenet dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=1000, block=Bottleneck, layers=[3, 4, 23, 3]):\n",
    "        super(ResNet_imagenet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.bn2 = nn.BatchNorm1d(512 * block.expansion)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        # Removed regime as it should be part of the training script, not the model\n",
    "\n",
    "\n",
    "class ResNet_cifar10(ResNet):\n",
    "    \"\"\"ResNet class for the CIFAR-10 dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=10, block=BasicBlock, depth=18):\n",
    "        super(ResNet_cifar10, self).__init__()\n",
    "        self.inplanes = 16\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.Identity()  # No maxpooling for CIFAR-10\n",
    "        n = int((depth - 2) / 6)\n",
    "        self.layer1 = self._make_layer(block, 16, n)\n",
    "        self.layer2 = self._make_layer(block, 32, n, stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, n, stride=2)\n",
    "        self.layer4 = nn.Identity()  # No layer4 for CIFAR-10\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.bn2 = nn.BatchNorm1d(64 * block.expansion)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.fc = nn.Linear(64 * block.expansion, num_classes)\n",
    "        # Removed regime as it should be part of the training script, not the model\n",
    "\n",
    "\n",
    "def resnet_factory(model_name, pretrained=None, **kwargs):\n",
    "    \"\"\"Factory function for creating a ResNet model.\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): Name of the model to create.\n",
    "        pretrained (str, optional): Path to the pretrained model.\n",
    "        \n",
    "    Returns:\n",
    "        nn.Module: The ResNet model.\n",
    "    \"\"\"\n",
    "    assert model_name in ['ResNet_imagenet', 'ResNet_cifar10'], 'No such model!'\n",
    "    \n",
    "    if model_name == 'ResNet_imagenet':\n",
    "        model = ResNet_imagenet(**kwargs)\n",
    "    elif model_name == 'ResNet_cifar10':\n",
    "        model = ResNet_cifar10(**kwargs)\n",
    "\n",
    "    if pretrained is not None:\n",
    "        pretrained_model = torch.load(pretrained)\n",
    "        model.load_state_dict(pretrained_model['state_dict'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c2cbdd-5a0e-4e13-90c2-e9a67f03329f",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c512309c-b835-48cd-b331-4608b8331a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "[1, 100] loss: 2.035986831188202\n",
      "[1, 200] loss: 1.7703362202644348\n",
      "[1, 300] loss: 1.6634289240837097\n",
      "[2, 100] loss: 1.5233043467998504\n",
      "[2, 200] loss: 1.4896388387680053\n",
      "[2, 300] loss: 1.438075567483902\n",
      "[3, 100] loss: 1.3594909799098969\n",
      "[3, 200] loss: 1.3503964519500733\n",
      "[3, 300] loss: 1.3134811103343964\n",
      "[4, 100] loss: 1.273026579618454\n",
      "[4, 200] loss: 1.240743292570114\n",
      "[4, 300] loss: 1.2291901457309722\n",
      "[5, 100] loss: 1.1950393342971801\n",
      "[5, 200] loss: 1.191427518725395\n",
      "[5, 300] loss: 1.177057095170021\n",
      "[6, 100] loss: 1.1252627182006836\n",
      "[6, 200] loss: 1.1219073218107223\n",
      "[6, 300] loss: 1.1373453557491302\n",
      "[7, 100] loss: 1.074563329219818\n",
      "[7, 200] loss: 1.0975108408927918\n",
      "[7, 300] loss: 1.076580895781517\n",
      "[8, 100] loss: 1.044069054722786\n",
      "[8, 200] loss: 1.0645636653900146\n",
      "[8, 300] loss: 1.01597487449646\n",
      "[9, 100] loss: 1.0098686426877976\n",
      "[9, 200] loss: 1.0047188127040863\n",
      "[9, 300] loss: 1.0056624621152879\n",
      "[10, 100] loss: 0.9803256583213806\n",
      "[10, 200] loss: 0.9827095574140549\n",
      "[10, 300] loss: 0.9502353793382645\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:  truck   car  frog   car\n",
      "plane: 52.63%\n",
      "car: 0.02%\n",
      "bird: 12.45%\n",
      "cat: 0.56%\n",
      "deer: 2.66%\n",
      "dog: 0.25%\n",
      "frog: 0.08%\n",
      "horse: 0.66%\n",
      "ship: 30.41%\n",
      "truck: 0.27%\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAACwCAYAAACviAzDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABP1ElEQVR4nO29a3Bc1ZX3vU7fu9Wtbt1lWZIlGRtjjLnYDuDwBOeC8xCSTF6mZpIwIWTmSxhCBkLVcAlTFU+KYN58YJipGphJKgW8b4YXagaSSWYIwSRgyJDEYGzwBd+wbFnWXepWt/p+Oe8HHs7a/yWrsY3dvmj9qly1t/bROfvsvc/R8V5r/Zdl27ZNiqIoiqIoNcJ1pjugKIqiKMr8Qj8+FEVRFEWpKfrxoSiKoihKTdGPD0VRFEVRaop+fCiKoiiKUlP040NRFEVRlJqiHx+KoiiKotQU/fhQFEVRFKWm6MeHoiiKoig1RT8+FEVRFEWpKaft4+PRRx+l3t5eCgQCtGrVKnrttddO16UURVEURTmH8JyOkz7zzDN055130qOPPkof//jH6V//9V/p+uuvp927d1N3d3fV361UKjQ0NESRSIQsyzod3VMURVEU5RRj2zalUinq6Oggl6v63oZ1OhLLXXnllXTFFVfQY4895vzsoosuoi996Uu0cePGqr87ODhIXV1dp7pLiqIoiqLUgCNHjlBnZ2fVY075zkehUKCtW7fSvffeCz9fv349vf7667OOz+fzlM/nnfoH30Lf+c53yO/3n+ruKYqiKIpyGsjn8/QP//APFIlEPvTYU/7xMTExQeVymdra2uDnbW1tNDIyMuv4jRs30t///d/P+rnf79ePD0VRFEU5xzgel4nT5nAqL27b9jE7dN9999H09LTz78iRI6erS4qiKIqinAWc8p2P5uZmcrvds3Y5xsbGZu2GEOkOh6IoiqLMN075zofP56NVq1bRpk2b4OebNm2itWvXnurLKYqiKIpyjnFaQm3vuusuuvnmm2n16tV09dVX049+9CMaGBigW2+99SOfe/WXvwP1UrnolGVoj+1CM4/LMPt4xHeXyzh2lnXIqmDdCBCSh7qNPnjEibxWmdvcok2cyU18DZtEQJLlMtok+BPbNvuO17AqXK+48SwV8VlqnkYGSFUq3ChGataxdoWX3Kb/5x9oLobyR6H+3TsehHpbU4tTLpYz0PbsL/4/p7zlrS3YV/cM1A+8t88pX7rsf0HbV278ulNe2tMLbeFwHdTLFV6HhXwR2iJ19VyR42H2bdZkijVR5b8KI+PDTtnnC0Kb14M7i7axLuV8WeY1xfqdtdbdYtEYlMt85of/7x/MeRwRUca/l/vqbsBrGs9eOZ2DtsYQRsXVB5udcjI5CW1pK+6UB5MHoS1OKahHXWGnbCemoM3n5bn1RxrxGrlpp5yvYF8z6RjUr77ieqdcyeH6TZb4PIem0Qx94PA+qHe1LHTKnc0oYzA+PsHXmEhCW3NbC9TreqNO+cjIILQFbV4/vqIP2qIdC6Dun4zRXNx44418zkAI2vbt+A3Uf/3r3zrl6WQB2sbHR51ye3sHtJXL+Hx3tjc55UuWXAptAwM8lunSKLQVxPxRIeYUSzl8akoVni8KeqGtWA44ZbuE99zTswTqgRD/biiEz0F9Hc9Xf/9uaNtz8G2oD47y/MUT09BWLPL6TcTj0Nbe3gr1lka2VLjFu+myNZ+ij8pp+fj48pe/TJOTk/T973+fhoeHacWKFfT888/TokWLTsflFEVRFEU5hzgtHx9ERLfddhvddtttp+v0iqIoiqKco2huF0VRFEVRaspp2/k4XXg92GW3yzRGCV8E4VdhGX4dbhu/u9wuPu8sVVjh82E2e6Q/iOGP4XFhX02fD3KJc9rSP2Xu70K3YakXbi2z/FUqFeOa4pxu405K4hplUa8YNnypiWsbBsHiLJ8TcSL7+JbckYF+qG95C3MDrV/3v/mawmaeSbJ92+/G602m0b7f2MC27mIJz7Nn3y6n3NfdB21lG/0dcnkesUwKfT78bq7bNo60yziNJXwzCmU89tCBQ0751ddehbbtO9nuWxFL0u1GO73LvKhY7KYfhwyNd1dZo3LdmfXQh0x5fYjt8pG6ZmjzGvNn1+N41PnRLp5L840vv2QF9ifINvzEtjFoG51C/5DmCK+JSikAbRU3+x8EXOhbky8afhV+MXZ+FF0KVvi8qRT2p+Q2zmPjWpLvCbfhrDU0in5S1gz31ZtBvwlLPKflCo9tJo3jnMpzffEiHPNwVPg44FBiX6s4LdWF0B/iY1de5ZRfeWWLOJrvORKOQovXg75YlULWKWeEH5DXZYhbCl8Ru4zj5a6wH1A+kyeEj7W8OD9RQ2yrLoA+FdNT6E80Y7yaLr4EfWkSCV4jpm8IEVHOuEciosmpcacs/QVzeT42VIfvhaYmHMtshjtkzXZI+8jozoeiKIqiKDVFPz4URVEURakp55zZxSqloe7z8Va1TSL0T2zzmVuNlrAHuDymKUOYa4SJxjZMLXJby2eYgXwebHNbRvisjXvjchvUNr4LZQixeZcyBMoWAZFmXfbVNvpTEWaEsrjnimWOjzTKmOYsvK9ZVhdpJ5qDxPQQ1P/7189AvauTQ+wCHrH9bWyZLl2+DNr+5w0MsyyWeT1NTGK43YEDe5zy0Mrl0BYr4BZqPsfjlZnBMD1z3GMx3BbOGlumRw4dgrY/btkK9S1b/uiUB4/iFns2y9eUZhf5f4yKGWJ9jGDtuZCmwEqZ14E8i8tYB5/5X1dWPa/bxSYIj7iG381th0cwzDST2Q/1uhCHNLd14hZyc5jNBXILOZ3CMNRKHbd3LOjBzgYNU1MSt9/z6YRTjhdFqG0CzX0zU3xsnRdfw4cmedt8OjMBbZEArnWryOMcCOB56hv4nuOTGD5bFKGkxQyviWIe76suxGPpC6NpcM+7O6C+2H8VzYUZdl8u4zvE48H3T8Xo38zMOLRlsxwiOjJ2CNraWnDeiwWe20oFQ6Pb2tnUM3FArAHxELmJn9NyCU00Lrfx7BXwvgJevq/Wphi0vX1kF9RTWe5D9yIMI/cYf+cO7jsAbYNHMRzbNKGZobVEaA5taUMTpz+A5pzpOK9Zl5pdFEVRFEU519GPD0VRFEVRaop+fCiKoiiKUlPOOZ+P+Dja7ANBttv5/WgP9QVk2BXbwgIBtF0GjN+FUMRj1E3zV7GMtsGQh+1mPhHmCXZEF9rXqiF9Psz41VIRw+LKLrTNWYbfi1u6Wxhhe+5Z4tnScWCWI8GxqRIifCLk8ygLvPc9lBB+7pdPcaWE19y9f5tTrm/AEMfkDNrQy8b4TUyjLXV8jO3kE6m3oC2XwTURH+U++H1oW+5ezLLX/9effh7a/vg/rzjld7ahbPLkFNqhiyXDn8grfCM8/BxkMyJwWvjzmP5E0pJrgaw/romyPNpYwsUS2rrds4K158Y2wnsPH8UQa6vA4YAzCZSDHhrF+WpdwOGJu/biu6BplO3bbiGPbeewr6PTbOuuD2LIpavM/YnaeA2PbYTlFkSb8CMbHef77F6Atne7MrdvBIm6ywjH7mpcCG2xKIcwh9z4vpnxoA+Kbbzjmpvxmamv43uZGMOEoYkRfJ6oiog1pmHA+8jncZy3bX/DKQ+N4JpIp9lPyx/Ccc3nMZy23s/3lcrgPXsN/5l0Gq9fqGD/gh4jXN6FbZaH624XPnuJSU57kJ/Ba8Qn0W8rU2Dfkd+/vhnaWjvYx+3o8CFok/dVNP7OlcXfJ5+P129WpCsYyqLPWzrJ7fUh/Ft6KtCdD0VRFEVRaop+fCiKoiiKUlP040NRFEVRlJpyzvl8jA9hTLPb0I3w+dC27fGhfKzXsHsGfejzETLkfUMBlFQOi7rXx+exi8IOHmCtAU8QJYMNdxCqCPleW8RRV5O5Ni2OtlvItM/SNjHLsxOoO30TLbY81hjnyizNdENL5ENkPI5Xpte2ce6uWv1JqC9bcrFTLgubfVsb2/5ffe2/oW1oFG3WfkMjRGq/VEJs5x0YQVuuz0YbaD7Nk5sYQ9nkSoB9N/7tP/D6R95kX5JiAWPyy0GUsvb62DfA50cthmyWdQhKFZxNuyzqZlncs2XqtAifJY/wGzBP1NSIfZ0t0D83oXr2MRgR6dzzSb6vqEgz3tyIEtS2oV/i8eKzVy5zW34KZfRDhO+CYCzmlAP1+OyXDN+IthBeP51jn5RKTvic9GAKe7+Pz+uq4DNr+mqMptGHIS/eG3FjPU+78Z7JzfeV8eD6zVRwDMJ+7l+dhfNeyHAf5H1F/ejfVA1TF6YiNJk8Im1GLsfPwsKOHjyPoWMRa8Dr14fRXyVkvOfLFbxmOsNzYFnd0OZ247Po8fCz5/KINPUVlj732Tg/ZUNyf3waNapKRdQLCRh9jU+h/8XENNfTReGHJJ5Tl6Hf1NmNTjjZPPtxDAmtICkQVMhzPewP06lGdz4URVEURakp+vGhKIqiKEpNOefMLqkkbheaFgm3iCV1eXFL2e/hrfzGetw2D/l4S9DKY5bA6Wnc5jIv6pbhvGXergv6cOvZDF10lYQEdwW3RQNBPq8lwlenDTnoXBbP4wvh9pjHyJTq9qApwzKync4yhrhkeKZRtkWomWmiESeyxPet/N25KKXxuM7WC6C+YtnHnHJBSAh7PTzOe/fshLb9/SjR3dbB4YldCy6Ctooh7d3Q2AZtl118IdSDhkR2RshuFw0TRDqDUtF1rbylXfTimAcWdEB9YoLPM3R0D7SFDBNfxC+zU+Lacvu4r4E6XL9mdtFCAe+jXhy7atUqp9zdjdvWRWOL/X9efpGq4XUZfQ+jKaPZCJWMj+BWdMTXBPVAiI/15HFNvPU2Z0UeH8XQzfpWMQZGhtOkkO9ujHXycR24xX/ZZVc75bHRw9hX8b6xLeO+hPR6OM3zc2EMxyOyEOd24BCPiczomoyzOWCyhOvOHRMh6DnjnSfMfxMD/LuL21ZiX7tiUCf8VcBV4fUk5csnJxNQD/n5XqIL26Gtro7Nb9EYjkfbAhyvUIDvs5zHd6XHMG0vWnY1tLk8+Lckl+X1XMij+SSX43FOz2CG4kyax/XoIJpcx8Q9R0L8vimXhP3aNKcL03Uqi+unPhhzyl0dS6BtZGqA+zOAJk5LyDSYz5MrcJxSCyeA7nwoiqIoilJT9ONDURRFUZSaoh8fiqIoiqLUlHPO5yNTQvu1y7AdekS6do8IYfMYfhWJFIY5DQ6xDG5iEsPbkjPoZ9LTwTbIviVo6+4IcSiazxODtlSSbYUukXo+FBJhwV4M/zMxoyOzwo6ZL2Dd9ImxXDK8ja8pw7V8AREmbITfuS3hO2L4lZQJ50f6fFjHmcLdZWOI48iRBNS3vsm+G5kS+ui0N3DfPS70gVncjbbdy5dfavQN18+Lr7zqlBtiGF4X9tRDva+HfUB8AQyrDIV53Id3ot330BCvNXcIx7wzij4XfV29TjkWxfta0sdt+SyOeTyOfU9M8zV9EbSZX3r5au7rkfegrVTA52BBF/uk+KM4HqWs8JOqwrQhm37BBehL4zFs7VEv+jRIf6d8kf0finkMdw64eP1GRdhguCRs3cZzavli0FYknpNDpf3Q1mBI+VeKuCYTE9jXuno+b6QOw1cvquO5nBzF90BF+AK0rrjMKWfzuF6G44eccjSEPh4lfwzqfiO0vVjC81hFHjuXMP0HhJ9SpZrPR57nOT6D13ivH/1w3B6+UCKBfhTdPcuc8sWXXQ5tmSyed/dOfk9MTeF7vbeXx/naa9dBW0MDhnUXCrye3cIfxGVxX3M5nPeZJN/zrp1boW0i8QzUPR6+RrmA5/EFjXeu8PmoS+K7MhLgkHi3CCP3GD5UsXp83+TKeM3GFl4zkcjxpwM5XnTnQ1EURVGUmqIfH4qiKIqi1JRzzuwisw1aRjZNlw+3n2wht1k0wluHRDhkyth6HRzGbKIzCdy2jkR4i7lxEjNtNtSzEp7dinuUZnRZqSyyktq4rQUmEqFC6fXzdlg4Ju5ZKCCaaoC2MFmV81zPl3BLPT2N2SpNM5FHhOz66lu5HMLtd5kRWN7LXHztlr+Gut+NYZW2l+87GsUt0iZji7A+3AptC9tjUJ+a4PtesAD7vqSvyylbIgvx2zvehHr7Aja/SXXNkeEhp/zMf/wc2ippXlsBH/7ee4fQ7PGNb3zbKV959TpoO3CYTQBdC7ugjY6gKnDZ4nn316NCpC8cc8qNjTjmE1O4ft7ex1llWxaikmJ8GsP/qjE8xpmqPWIb32tkoG1pxv5QJQbVo2PGtrqF6+zqqz/tlHe8+TK0JSfRfOJK83pqasbQTX+dEbpZxndIyTD/uf34jLhd+KqN1LPppzQrc62RvdiN43HoMIbwBuvYRNTRjNlxvQ1cf3diCNoODw1AfUlXn1OuFPC9GQsbz4UwJ1WyCew7xWhOCnzs0CCaWSINOD6BMJsux6fQ7JL1sYnc33oNtA0fQPPW//v0v/PlReh4Vxc/J3lhor/i0iugbhvvv0AA3wU+Q/HaH0ITWmMbvxeuW4Qm+sZWNM/+58+fdsruHIZGZ42xI5HJvKUe31sh493odeNzEArwuuvswFB+V0Ao2xrr2ZSQOFXozoeiKIqiKDVFPz4URVEURakpJ/zx8eqrr9IXvvAF6ujoIMuy6Oc//zm027ZNGzZsoI6ODgoGg7Ru3TratWvXqeqvoiiKoijnOCfs85FOp+nSSy+lv/zLv6Q//dM/ndX+wx/+kB5++GF64oknaOnSpfTAAw/QddddR3v37qVIJHKMM54YxZK0jxqOFEIWuC6I17tgEdv4rqhHe5sp0zs9if4OhwaEHHPYGDZhrzW/5mTopstUyBVZY20hbVssG74aZWwzM5G6pJy58Mco20ZfPSJzro/74LMx/NAWNj7b8LUpCb+S7Az7Lbg8aPN0+dE+WpH27TkIC1+NivC5mDLCM0tTIstkmAe6//AhaEsl0X5cl2X7cST4CWjr7WEp6VwGfRgWormU2tp5/KJhDAmd3sPjFQ3iOI8nEk654sax+eSnPgX1y1evccpZF/r6NLayTHypItcSzldjI6/1ihvXy6F+9n/wiLjKaAfarOuiMac8nEI79Eicx0vkWp2F28drzRvA/w+FjdDATAqfw4P7RYZrP/+u24MhxBNBHoOjcfTTEsNODRaPbUmEcde5eX3bwm+rlOc1WqrgmHtEVtlUin010mkM+y8bIc0B8TzHjDEnIpo0wqjHRHhmZzcv0hiJ84hXf94Ikc+J/5KavmqJIcyE6m1Gn6G6WA/NRbnIayKbRp+GmSJKlvvcPAbBIMrqj8W5/tvXxHthDJ+9Cy7isNyPrfkYtGWyfI18Gdd6XKTxCBqZzUXSXyrZPHbZCs6B+RZt8uCTsGYtZupOzPCa+fWm/4A2V5l9WZrq8R3is0R6CWP+vB70GWoMsG9W2IXvavJIH0k+b6l06n0+Tvjj4/rrr6frr7/+mG22bdMjjzxC999/P914441ERPTkk09SW1sbPfXUU/TNb37zo/VWURRFUZRznlPq89Hf308jIyO0fv1652d+v5+uvfZaev3114/5O/l8npLJJPxTFEVRFOX85ZR+fIyMvK/e2NaGGUDb2tqcNsnGjRspGo06/8zwJ0VRFEVRzj9Oi86HZaHtyLbtWT/7gPvuu4/uuusup55MJqt/gAj/B7chqd7WFIO2NcuXQ31RJ9tAPUJ/wjLiuNvDaAvrbMHz5opsf0sLiWe/n3/XsvDbrgLp5LEtl8MY9BlD/t3nQ3st6GwIPQOpomH6WMgpsI3fFV2drc9h2LelZkHJsDlWSmjrtr1ok5X+B3PhraAscN6FNvNoHbePT6K9OOBjX5+E0BOYmTgI9Y9fyloIiRm0vYeb2H7c241rMiJSeQeM+PmWdvz4Lhnr5cILeqBtzJAwLwuZb8uNNuJ9hgT19t17oc0u8frtaEO9h8QE+rnMGNoiLX0oZ97Wzuu3sesCaEsT+plMp9h3YgRN5DSS5/XSR9Wx3Ty3i5fgNV0z7CdwZMduaKsP4Zpw+3m83t2HGinP/2aLU86kUGa7px11EjwBXgcVLz4YPh+v/XJZaHeEDI0f4aOUFWnYPR5DNj6KfhOVEq+lXCoBbWWhXWT6KowlRWp1Yz1fvgRnoWUK/Sj2GO+bpPBBCRupHpoa0I/O5T32e/1YJOIJp1wUaSAyop4r8hxVijhffsP/YugwBjMMHUWfj8uvWOuUV16+Etq8hj7HTAoXcAldQMg2fCc8fnwOPD7j3ejDefcGeOyKtvh7INJUXP3x65zy4DA+s+/u/B+n7BJaVw0NorOGf0ixgvcVirDfVqmIvnLm7xERBQzdLMsn/ENOAaf046O9/f2cJyMjI7RgAYvzjI2NzdoN+QC/309+/9x5TBRFURRFOb84pWaX3t5eam9vp02bNjk/KxQKtHnzZlq7dm2V31QURVEUZb5wwjsfMzMzdOAAyyr39/fT9u3bqbGxkbq7u+nOO++kBx98kJYsWUJLliyhBx98kEKhEN10002npMOWCCNsCPMW5bIO3Ar3VXAbspDlbSYriNtzpux3sYhhRTMzeB7b4i04twfPUyiYGQ5xG8s8j9uDuz2FgmvOY6MxvEbQMDWVROixLUJ4wRAjbDK2OZbCfGPZeF6rJA06TMUwpRSTGKZMNppZAsEPC7x8n6uW4va7DENNpdlMddA9DG3uAm9xr7/iKmgbfA/D1EqGrHLFi/LdvRdyWFqLyNpaFMPhNjKTFi2cg3CMf3eZyMKZNc6z/Q2UbB8aw7HsmeJMrb/8tyexP0Y60YUdKAmeSiag3rl4qVOOi6ytaWPt7ziAJquxLL4uRgfYtFHyo8S9ESFLfa3ChCcwZa/7RXbTBXW89l0iJNYtTHztC3n+Rsfx4OwMmxkKMzh5w0fw+Y5P8PrZ78bncvFiNgEsvgBDj1ta2OwSDqHpq6kJQ8d9xpC4xLM3Mclb7gNH0VducgKz9aaNFAluYQIZGDaeC7HF3t2Kz0GlxFvsw+8dgrY6I5uyX4SRewLC7IKWMODoGAcTTE6haafgwzUyNpTga4rlYwX5B/FpvK98Bp+95ib+mzA2hmHC3YYpdTqBz1o6g3PS29fD16hgh1xGaLZM62skwyW3eKfmRBb2UIjP8+lProe2mQTP+/gEpgMgdwKqZSNs2RdA005jB5v4EjPCXG3hc1ApGfdpVX+GT4YT/vh488036ZOf5PjkD/w1brnlFnriiSfo7rvvpmw2S7fddhvF43G68sor6cUXXzwlGh+KoiiKopz7nPDHx7p160DkSmJZFm3YsIE2bNjwUfqlKIqiKMp5iuZ2URRFURSlppyWUNvTiV+mczcMgp4KyiYnJyfFsfytFajrgbZCnm11ZWG38/nQP2MmzRK6hQoaOc1doYqN9lGXa+5vvXwe/UPGRtlGnS9gaJdt+CnkcmhHrFSkDK7RLmJtzers0Frc3ZIy7nhRHoNwAM/j8wr/h8jxLbnMu+9iPYm2XcuQuV4awXHea9jMd+7F8MyRPRii6jV8WUoLURrZ08ES/H0dPdAWrhNzm2Eb9rSwpXqMUMWVV1wNbZdczD4gV12IoeGWhWsraNTXrb4M2gan2L4/Oo7rfnISpaxzRkruyTKurbFB9gUYGcL07ekMrq2I4YfT2L0U2qYmDF+F1iupGu4ihyfGhzAEtHsRhwJ3LMRr7NjyDNSTkyy3vmRZD7TtbON12S/8DYgwPNLj4/sqF/G5HDnCvgGBID5P5qtp2YWYvsEr/p+XnWH/h6K4RjbF8xXwiWdW+LxZpo+ZSLUeN04bH0PfkcUZ7F+dEUq6XISRpww5gYFpXFuxRgwTbsblBPzqN39wyi0t6EM1JeS739495JQtwrai8Z4vVvCCzY0YEj96dMApj4zi2jrQyn44m156BdraFvRC/Ws338z9sfCd6zHCsX3CN6JY4DmxStjmEX8OPC6+z96eTmi7dh2nWvj9G/guzFZQmLNivNPcPiF94Of5a+iQzzPKPZQMP8SSjD2WroUnge58KIqiKIpSU/TjQ1EURVGUmqIfH4qiKIqi1JRzzudj8aIeqPs8bKf3+9B26iK0zbkMCXW3kLoNGL4jpRK25YXGRcXFdrRSQaQz9vKQBkOoaVEwbLJlmcI5gbbUo6Nsox0cSEBbOsP3WRASz5U82rMDhnpssYQ24WyOjzXl5YmIAj70abAN/fVCEX0jGhtY4+GSiy+CtvF+jEnP7t5Ox8Ou51+AensE7dANjSyVn8qiDdRnSFcvEjLtYX8M6iv6+DzpAI7l7n7WBWhrRRusR8jqBwp8zUoax9ky5to9g/ZZa3jQKV+WRylkbytqZwQb2U6/7LNfhLZ0he21iRk8z9FR1DA4MsRaGv1ZnPe9e/c55cHDOHfSRt2yaKFT9okIuPiI0HupQtDDdnuX8Fvo38N+J9EG1KboW4Y+IEf3/dEpJ46iH8eKxdzX5BBK7AsFdbr0ctbvGBpCDZmZFM/7iJDAtm32QyoX0GepXC6KY0vHLBMRpQ1J9WwGn+dKBW345vtmTMxzwJCbb2lEH4/+o6gXEnXzOsjmcUBKAa43NKOvRqGK/o/k0DC/46aFdlKmIDQwUoaWUUWkczC0jVxC/8fXhH3fv3+PUz4yiH4vW/7wllNubkYFbq9wgUvFjXdlGRvtEr9/IjGUIfeZ6SWE41wyge+CfNrwX3TjMxyN8Lsg4EEdn/gU6pcE63mNWG70GSrmd/I5o0KURfh1eP3cX48QiSrhn6uTQnc+FEVRFEWpKfrxoSiKoihKTTnnzC6rl2MWzkzyiFHB7aeSMCWUjK3PbArDrgIF3obMe1EKefP//B7qRwf5mpeuXAVtra28JSZDu6YMeWwS2SmzWdxmKxvb2O8dwO3voaFBmotcDk0iHQvZrJCIo3lifIz7Z4tMidF63PJ3G9uHLhHatfKS1U65q+ML0FbM4vZqEbJ0DtBcmBL+RER/KOB9dTXwOC8iHMuSETb4iQbcbi51oilsMs1b1YlDmAl1cZ7nYEEsBm1NLbhGQmFW8A2FUM23yejexLYt0OYyJLAbOjFMMNiM26s+m01IdiPeh9fPj7LLh235FfiYZ5K8Do+IsNxfv7XVKf+WMPRuuiRC8YwQ9IqQjl644NiJJI9FwZjbQARDJ11GGGw8i/9XGk+iCaKhiddsSjx72RyvicY6XC+JlJBXN6S2Uyk0r+WNrelLliyDtp5F/C4oFHBL2+3BbetIhE1Ik0ISYHCAzQOFAt5jvoTPXiDIcyvTQhQNM54l0wGIMO6xyYRTTqbxvXnhFWyyqnPj/GRcxx9zaVvc18kpDEePCxPEZJLrXj+a0IJBNm24xHs0lUBzUmsLP/8rL7kY2grG8y0zSg8OHYH69rfecMpr114DbY1RltKPRPHZ87j5nr1CakGGTZvpOAbEO37QCBkeHMDQ+cERNM35Qvw8dYhUC9EG7p8lZeLdWC8baTMqwoWhior+caM7H4qiKIqi1BT9+FAURVEUpabox4eiKIqiKDXlnPP5aBBS2qZZWtoRc0W0l7r8bEesCwnb5Qzb2w5M7YO23/9hM9QTcbYrmj4VRETt7WwfHRV255RpWxa2SmmUnY6zjS+TQpnrfI7lhRtjaGOMJ9B3JODn+4xG0SY8dJTvOTmNY2emmiciihg+D1GR4zpYx/brghv7E2rB1OKRNuO+X/sjzcW7CbRrbpvGMMKOaZ6D9fVC4tnLNuHDQlq8XnxvZ4psLw2K8L/Fw2z3rRcy9pG2dqj7jXBjl5CnLhuy/pUk3kfO5gXsFSHMYRHbWk7x3Jbj6ItQ9PL6sbwYXuwJ4DMT9rMO+LJ29M3o+sx1TnndZSuhbesRDFHdP8HrW2Qgp9bI8ft85Ip8X6UyjnOzEdo5IzSdR3bh68vnZ/t2Rzu2lYdZrrvej+eZGMX3xK5tbG+3LfQ36OjieW4SWuK2ze+XlmZcHy4Lr5lO8z3bJby+z8tjEA5jaOvRUZz3HTv53dAUxXlubeG+ZvNopc/n0H/HXeFnJtwUg7bxSX5GDorw695LFkOdqsirF3Lch6AXD+ztw/FK7dnllNMZfC5LhmSATFkxnUxAfcp4VzeJcONImMcnFMIw7n37dkJ9dIR9s2Zm8Blet+5ap3zlGkwl0NwQc8q28IvyCh8Ly83HNjbhO6TZmEuZCYPeFv47I+z7ODWE4+yz+RqXX7Ea2gpZ9DOZSfHYSUn5g8cfST8nuvOhKIqiKEpN0Y8PRVEURVFqyjlndjkyjvs9U6OHnPLkuFAjnEEzQ0OGtzeHRoegLW6oy72zD0MuW5pxO7Org7fo+g9jSCgZ2VZzGQxtdRthV0WRxTEjlAyzxvZ8Wz1u/WZSvK0eDOEWezqDoWZtCzh8MyIysVoV3n7PZLE/bR2o6NlshJYuaG2CtguWcsih243fs26RSddjHd/3rqcLt2EDIjwy0tnjlPfuxjkoZtjU4vHh9cJuXPJBQwEwFhCKtEneGp8q4NpKCaVSvxE66faJ0MAQj3NdGOcgEuNxlSqYWRvXRLSNTRl2Cuc9a2T9LeXQhEYZNOeUzTUTQEXGoM3js6IFw/RahQmg4SCbJ3eMY5h7Qpg8q2EbJqOSsEaOxFlFdKqAiqKxjm6o20Zm6LLI0Blr4DWRyeAWciGPW9wzhuprMILj07eEr+kq4z1OjPI6LGVxDrJCEbdc5GuYJhgioophCoynMFP39CSuu5KR1TabEwq5xtq3XSJ78SS+R6NBXvsLezDkO2mcN+IVqrteHJ9qNBsZcC1hgjBDfYmI6oy1lhXrORDge3FL04ULF1DBWBMH9mNG60qFjw2I56AonsVgkJ/hvXvfhrZ33n7TKS9fugLavvh5ViJevQbNHNJklDVCzuvq8T3R2b3IKbcvXAhtl12Kcg/TEwmn3H/wELQNj7I53+9C0+gFfahOPTRo/G4Fn6eDh/Hv58mgOx+KoiiKotQU/fhQFEVRFKWm6MeHoiiKoig15Zzz+RhLov0vacpDpzEkK+gR9r8M2znjo2gfHc2xHbFQQPtWVxPaS0uG/evIIbR9jU9yH0o22g1dhr+DXUSbZ1qEeVKR6+3NaN+3XSzf7fdgmOkly1H2u62J7XqLuvugbc3lVzvlcAQlwYOi7vOyzdMrQjndRuyXS0gGW8Ln43gJ96HPSZcMIzTs/RkxB9k428ldeZyDhA9tu5aH7yskYthiLvbdqC+grT0oZOz9hmx8oDEGbVPGHOWPoq29L8jHtgV80Db9+jaozxj32bJ4CbSFDF8SochN+TyuZ9c0j4lvBtvKQV7rGRHq2+DGef94L/dBmK/pnWGUp66K4ZsQqMeQR5chAZ06lMA24V/kMXwK8mm0i1tulizv6BBxwRb6Y1ywlGW4+y7Edbj/APudTIyjP0bZyDCdLGIGVZ8P57ZiZHHNp9G3p5zlZyYpfDysCvZ14UL2jejuRj8pj+F/lpnCa6RFOgfbCPn2iCypDe0sJ9ApJP/9Fv4JqSa7/ac3/olTfu13v4O27XswhHdBp3kdIRtvyMjbIpuy28Jn2Gus2eZGfIe0GNLrg0fxnjMJfB+PDrOvRCqB8778okud8tgY+iX9y7/+q1O+auc70Pbp666DesB49vbsR7/DgpE9PRpFv5tGUQ9HWN6gpw+f2bgRivzqa1uh7dKLLod6bzenMklOoc8bkfp8KIqiKIpyjqEfH4qiKIqi1BT9+FAURVEUpaaccz4foYCQizVskNMZlCGfTgkp6zzbUrN59EUYTbANNpMVdsQm9KMo22y/jU+ija9MrLMRDKGN0fSbiIRQM6FR6Go0NXJ7bx/qGXgNW25HM8Zq1zeg/a++jjUMfH70d3AZqeddQv/ClumfzTay52xzifT20iZ7vLhDqLnRaaN2hkU8luPCt8ftZaeHmI2y1oEy2szdRa6XhOT9hKEhMOlBm32giOMVyPHvjmYS0PbavnedcrKCvj6LDX2Qz3agT87aJtRT8Rl28UPD6FMQXcjPQXM76jSEhJ9LrsT3XCyiD5Vl6M+UxNjlxJow19Oazl5oM/UXDn6I5kepzHM7lcH+NNexH0exgPNjEfoxjGW4v648rpdohZ+ThhCOXXMzrtGREZaRX7wU590qsb0/Pop+AYWKcX0P+gX4hN6MqSIv3b0ODyaccmMEf6+rDX2xAjFeI1HxnpoY5/MMDqAPzkxSSJZnDV+Jeuz7ZVd9zClf3IVy6hNTwjdiHJ8vk9Wr2Dei/zD6NCzqWQT1BkPiPZeVeknGe0usyUoJ59Jj+JzZcj2nDV2NIL5vTAl3IqJiyfCREedZ2MH+RYEAvtc3v/qaU37muWehbdHSC6C+9uq1TnnwKKbm2LOX16TbhWvygj70/6qYGjIz+DxteZNl60fHBqDN5UF/q/omvpfjlGc6IXTnQ1EURVGUmnJCHx8bN26kNWvWUCQSodbWVvrSl75Ee/eiapxt27Rhwwbq6OigYDBI69ato127ds1xRkVRFEVR5hsnZHbZvHkzfetb36I1a9ZQqVSi+++/n9avX0+7d++muv8j3f3DH/6QHn74YXriiSdo6dKl9MADD9B1111He/fupYgI3zwZFrViaGk5dplTHiQMG9z+219BvWhoN2dFqGTCyDgbDqK5JJ5E+WVPkLejFi/CbchIlPvXKsLS2gx57MYGzPYaNbLGEhFFo3yNOtEflyEh7BZmjvIskwhvUVpV985ESGxFtFpmWW5/z30al3VyZphiFrfqiyJc1Gvcy3AOt98PF3nLtEPIP/fYGIrX4OJjAyKjqs84T1aETZdKeGzcxSFtL5axr0eNzKgNbZhZc7ch4zww8C60pdxohvlsE6+nQgpDMCfe5e3V4jBuUzf0oNnOY4QtF4q4vewyQkBDYnt5xoVjYBnhf0ER7udPGtvvwer/x6lkDZOnmMvxDI+lyxahyBN4n2HiNbOgCUNtI0GWtk5MvAptTTF8vgpGmOWuXZjJt7OLz5uv4Njt2MFb5fmcfBBwLLPGfRWEOalkyH43taM566qPrYH66ASbed/cjrLfGcOsEBXvkGALmqVs84EXpotKntfWVALTN7TGMKv36PjcIdYVQ1J98QV4X/2DaL4uGGaPQgGftYphupyVKdYjMjpDeLiQMzcy+xbF8+x24/h4DJNEfX0M2l57jU0rzcIMHgjx+2ZsEMNV94v/uK/7xCed8oIF+LfDsOhRIo7P/qA479gIt+cKGFIdN8xtOSEp4RLm6xEjBUm07tQbSU7o4+OFF16A+uOPP06tra20detW+sQnPkG2bdMjjzxC999/P914441ERPTkk09SW1sbPfXUU/TNb37z1PVcURRFUZRzko/0OTM9/f7/PBr/j7hPf38/jYyM0Pr1651j/H4/XXvttfT6668f8xz5fJ6SyST8UxRFURTl/OWkPz5s26a77rqLrrnmGlqx4v1MfiMj73uRm+aFD+oftEk2btxI0WjU+dfV1XXM4xRFURRFOT846VDb22+/nd555x36nZDJJZrtE2Db9pwy2/fddx/dddddTj2ZTFb9AImKFPJ5w07Vu/QaaPuTGPpjVAzDWamItrB8nm3NbpGW2eVFXxWvkZo+VofhSaEg1wN+tLN6PKYdUdhVq8iSH2s8nbJoc8lhNk47y1fjJKXP6eSiZ0/omtJXJFtE++TwCNsj40LuOG2GMYrU2Ef9aHtvMMKNOz3oD9Jm+AgFxXl8FaybUbp5IdPe1sYhkBdduAzaLOPYt/ehY/YLA4eg3ufmtdUp/Kcqhu/KVBxtwIk82ukbOjms21uH5ykJG7pJnUjLXvHxnPSP7Ia28QEj7P3iC6kaITcPnt+F17fzfF+luJAET6NfkL+e/XvKGfQHybg4JDVbQnv6G2+h7HVdmPszhUuLos3s/7BgIY7H4YNcjxdwfaTTeF/mcna78T76DL+ST3zq89CWF/4Yo6MHnHJnO4bauky/BSE7bqaaJyIam+I0FZYI5UxPc9vRgJBT9x6/H1/O8LHo68N388UjOF/bd/B6ygr/LzfcCvrdSJeymfzcob9eL4+PDNn1+wPiaD7xzAyuw4kJHp/UDO7cR+r5b0BZ+F/898//E+qXX8L+PJetQqnzfI7HIBLGMd/7LkpMeDw8R4WceE+5ebwqNr5TB/rRv2li6JBTbmlA3zkSIcUnw0l9fHz729+mX/ziF/Tqq69Sp/Eia29/P7fAyMgIOMyMjY3N2g35AL/fT36//5htiqIoiqKcf5yQ2cW2bbr99tvpueeeo9/+9rfU24sey729vdTe3k6bNm1yflYoFGjz5s20du1aeTpFURRFUeYhJ7Tz8a1vfYueeuop+s///E+KRCKOH0c0GqVgMEiWZdGdd95JDz74IC1ZsoSWLFlCDz74IIVCIbrppptOSYdldkjL4u0wy8bb6enDEFm3h7fc3Raex2VkZ6yIkEvLXSVsTphLzG2/kshcWzbVLWViTWk+MbYB5ZbgCamGnqRl5UwTDqM5KyCUbT3GmCxfvhzaskZYbjaLIdXTaZHNOMPtcZEO9pAx7E3CntVCqIhYNh4lOZfdi1i90dwpJCIqGWutdQoVeUdTuA36qwFWhVzehKHaDUaIYVMQ13ZEhCrmkrxV3yJC12OtvEOZxf1t6s/hlvKB4X6nPH2wH9qCHRiCWQ2X8VxkjKybREQxI8SxwcY1EIriGvFEeRs9KtRhg76YU56aRHPo0RHcee3q4vPGgkI912KTSKWIz2FrK9/H5CSORz6H5oGSoULpD+D8XL5iqVO+4ooroO35l34P9eZW3mH2udDEMDgy7pQPvof98bqw72PTKaMNx6NhIY9XsAcz5+46imu0lXA9meRy3L9CGc2f8r0+Pc32ruQ0rruGRn6v2za+G0slPK8pL2Ca3Ynw3SDfsfIZNt8/+Ty+J+ojbIIICmXmqUl+pqXUwZR43p999udO2e3G81SMd75bmHWDAZyvUB3fl+2V71FeW/VBNIcefG8f1H//+y1O+cLFGK6/9NKr6KNyQh8fjz32GBERrVu3Dn7++OOP0ze+8Q0iIrr77rspm83SbbfdRvF4nK688kp68cUXT4nGh6IoiqIo5z4n9PFxPP/jtiyLNmzYQBs2bDjZPimKoiiKch6juV0URVEURakp51xW21nhoob9y+NF22mpjHZWs9VFaLdzGSFbs3wshO+GGVdpybBcw67nFjZzjzW3X4C0Rx5vSOqJhMuebIbZM4G0AZeFH05rO9ueW1owxDBv2HKTIktqNoHy3dNGLOXYTALaxtJsa57ICsl0XFpkRicWhMSz37iXQBBD1sJG2PaFSezr64NHoX7A6E+kHm3Cg8YycCUwI2akiGukwZCYb0visY1Z9omZ8uPr4UAc406H9rCcd88Mrt9CY4yOl7LxPE0bYYtERCEjq+vCPpSbH8yhj0OixHNbL8JFP3EFS1cnxzATqzeEsvZlNz8nCzrQx6EpxplIh4Zw7PIlDv9e2IU+J+Ew9jU+yXMdDKBJeulilhoopoTs+AyGTfcfZjnz5OQgtKVy/MwcOToObbEQzm3KCGfNFfAZ8QwY77HWGLQFc1in2Nw+H/E4h9OOjuM894swT7Mu31tlw18kL9IuyLQHLiPE2AxBJcL3s3yPyvcN1KVPVzf7dLW3o6/TG2/+wSkXhJx5k3hGBo+wX87LL/8a2sxo0aLIEj0xhmvE9Du5bM3HoK2liTMLVwr4HOzc+QbUp+K8ZjoWoqz/qUB3PhRFURRFqSn68aEoiqIoSk3Rjw9FURRFUWrKOefzIe1/liFk4Xbjt5TLFv4Qhq1u9nmOedj757FOzTBV87k4Wanzc8mP40SQo1En4ufLRrr3irDzBg07b9CH/hczQp6/Lsbx+/Vp1IWZnEo45bjwFclNYT1dNvREiihpHDT8PKSN2py+uJAEz7uFhoyhLxCdxuu7G4xjbWyzJ9BXY8yQOhkW4+MeZvuxrx39Hbxp1Ey5wEhx78EM5JRqYtv/h/0Px/LyHFTKqMNipj1PdaLOR7gZ0zAk3jP8BAp41cy0kVvKxnH2+PDY/v6EU+7rQBnpRIKl67fvxBT2ZYsdgXoWxqDNttFObxlS9cODIu25mS7gwDbs264tUH/jXb7nkB/vI5nh/iTTuO4skS4gX+D1kxM6EsOT7BuwSPg+dS9Cqfo0SnIApl9bVpwnGEJfqIsuYg2KphbUtEkZaeGnhQZIuYRjaWqLyFes283vdeljJv31isYzLdNvmP4YCztQx2dffcwpHx0agDYzRQQRUcCY93wBfWKSKb7nSgXfd1JCfckS1j1yeXFNFAs8HolJvP6+fZgiwefj8ZEK5SJbwEmhOx+KoiiKotQU/fhQFEVRFKWmnHNml2p8mOnC3PabZa4wf1daMs6wRPn5alqphteFS9MjtkFtY5LKbhH3asroV/A8ZZEFk4w14SYhW+zhrdjGCJpkMg1o2kgkefs3kcJtfdMc6BVmjqIRxh0MoGnJJcYgaWSczY1i5trwKC9SESlOwnpD0IMihoAGMnyNaBHDZz0i9HbUCF08LDKq2ka25xaqzoyxje53of3GNkJCG9rRBDIj+pcf5zk4UsKt6M3bOGzZ7cL5WbmiAepDB3kdDB1GCex3du4x+oamApexjZ/ZgSGxPi+O80yB52vfkJCtH+C5vbAHTV3lIq67imEOiKfxGhUj3YTbK9YSIa6g2Y4LqD7Gc9u6YCG0NfbgvKffmdvu4vOxqamxAU0pMh13XT2vn0wGTTRJIyR9ZATnZ2xsBOrj4zyWiQTOu2mSKQlzjfxbYobpylQPCI5dMMih9LaN67VURlNcKBRzyssuxKy/W7ZwGGxZhNr6hclo3Hg3vLr5N9AWN8Jn09MYohsI4Xlu+Ox6oz+YwmLr7kP0UdGdD0VRFEVRaop+fCiKoiiKUlP040NRFEVRlJpyzvt8mP4QH5Z63qzPCrU9yVDXWiD7Nh98QNxiLksl9NVwGTZieaxpWZVhcV4RE5oyJIZlGKy5npqaYtBWF0Z7f7SBfULCcUzZPjHBMtw9Pb3QNjrMbdOTCWizStj3pNGfQS/aZ4PGsZZIM+4W68dvhH0GLPSN8Lt4nItF9DcY8aOte8zwUSk1oL9KyPCt+TCfj0ya7e11Ft6XETVNw/tRBn3vu0J+fhfLU5fRtYbGOmJOudmPjQub8Xny1/N9v7sbfQrIkELv6uyBpqgheW/lUM487MX1W5/mulVGX42j7x1wyt4iSq+XhaR8fZDntiTC0XNZQ4Y8i9f3hmNQb+tg3w2fkKbvu4BDmluaUDa+/733oO6pMtuxqOE3JefZI+YgZIRfC1+sQp7vpWMBhltPTuJ8TU6xD8jwMK6Xo0c51HRqCsPRs2Kcs1l8FkzMd1OphH4d5rtaptDwCGesRILfRbt3H4C2gJ99YPxePE8wgO+i+nr2YZpMop/LtOHzUcxjOoeVKy+C+uf+9+eccthfzc/l5NCdD0VRFEVRaop+fCiKoiiKUlPOebMLRMh+iDnCVK2TJho85+kxwZjnPV+z0Z4qcmLb0+tFc4k5f5aYSrNNZqeUYXKxWGzONnO9yDkw1RGJiMJGaGldGM0uwyMc+tZ/YD+0NTTwNvaBvbj1m5/B8L9MhfuwR2THnfHweioKE5XMymzucIdEBt6AYc6RIXwUxG39sJHBNCJMGZ4TWLMNDaye6EpjGOHgvkNO+eiRrdBmY9AwtddzKK6rDtdLPstjsFtkeB3FnWnye9gUVTQUKomIXF6u7+tHFcqr1rC6ZbAR+5aexNDbuiD374qLcZxTk4ed8pFDCWgbm8Lt/1gL33NBPAj5EQ579RVExu80rq3JYe6fVcF3U083m2S8IlO4X/z/tZrwpccw6QWE6SAcwPEK+vkZSksTiKHga9UJZVLCsOmQn9dhrA772tESc8oTUxgifHQMzTdxQ+04K5R+sxles3mhHJvJsWlDhtqWhRnGzMa9Z/8+aPMZz7cQLaVIBEPQ8yU+T3wK193MNNejYRzzq1ZiOG3YlAionPq/QbrzoSiKoihKTdGPD0VRFEVRaop+fCiKoiiKUlPOeZ8P07R8Iq4aZ3NoLVH1/s0HHxCvkIOW44F1HA/T56MoMsxKXxIzm2VdHfpqmNeQ55Ghv6ZPSsVGy3esgW2yRwdRFn3HO9ud8sTUKLR5bbxmwAjvnfGhf4ppPbYsDE20REifZWQtLQhfGjLk311CPjwkQjmDUb6vSBBDQqVMejUW9y11yokBHIPBwxwe6crjPS9avBTqS7oXcd/CeOy0i8d9NI72/UODmN2zvZN9NyYKQq57lP1y0iKz8eZXX3PKJTeGbccn0cciaISz3nDdKmjrWNDnlHcN7IG2wQz6G1yxaplT9gXR/yFX4iyl5TLe84zwrRkfZj+YtmbMYOo3snpPjeD8tC1aBPVxjN4EMjkeA68H12hDBNdaLm/IIpRl6Djfp3xPeL047y43P8MeH17TG+D129iCIbsdC9H/anyCfSWGR9CPYjrJ62D/fvTpisfxWJNKUaR6MDxmXFZFNBl18frPzOBc5nPcd78Yn8WLWNa+pRFTRuRESuLRIX4uQiL1w6lAdz4URVEURakp+vGhKIqiKEpN0Y8PRVEURVFqyjnv83G2+24oJ4ffjzbgWSmuvWy/LYkU0yVD22NmBo3QuZzQSTB0PqT2i1mXGiDV5PllPH+4ju2l0UgM2ha0J5zy2NQCaCsLnY90hW3E2QLai0tF9jGoCG0TS9iIzZG03HjPHsNGHBI+MGZ6cCKhbWKUiYj8JyDHnDA0MMZGEtAW8MSc8kXLUP7ZJTQe8sY66GlFG767Yug21KPtv65lGdTzKZa5vmAZppC/+uN83v7d/dA22n/EKTe2XwBtvsswhXxbe7tTborhfbz8/PNOecd76HOy7MoVUK+EWNfirZ3vQFs6yesnNYPrXrgsUd74gdTUMZYdlQu4tscn0V+GqIfmwuVlfyJLdqCEPjIRP4+Jx4XzlSvx2sqX8U9Y1is0bVy8+P1+PDbo5/VilYWOTyOu9a42nq/JLvQbO3Bo0CnveXc3tBVyfF9ucR+WeE8YrzTyCJ8Y0+fC58W2oB/Xj8/P89dQj/cRi/JzKvVBvH48NpXmd6eLTv3fWd35UBRFURSlppzQx8djjz1GK1eupPr6eqqvr6err76afvWrXznttm3Thg0bqKOjg4LBIK1bt4527dp1yjutKIqiKMq5ywmZXTo7O+mhhx6iCy54f0vxySefpD/5kz+hbdu20cUXX0w//OEP6eGHH6YnnniCli5dSg888ABdd911tHfvXopEIh9y9uNDZgY0t78/zARzsuGrtrgmnaRM+olQLQPvabmeuA15V+ZXalnGepm/J040+7zHN16WkIo2pc6JcAuz4sL5yRnmiqIwT4SERLg5f5kMmjnM7Wc5z3Jr2uOZ+1Ey58/txm3h9nbeQm4SGUNlll2zf/kCmpqKFT6vlFcvC0nsUskM6RMhzEYWYJ+QVw+KcDu/YYry+1Cq2S/k1qtx+D02X2SmcG3l0jy3nT0xaOsUJpGYn/veKsII0+NcnxzdC20VC7efJ0c47HRBK4ad9nSy1HhzAE1N0avXOuWZCq7flAjxpjzPwSv/tQma+g8OOGUriOdpasWt8be37XDK2QJeYybN6yeVxbBtt8ju7DXk3tsWYGbaYNDYqg/juE5Nj0E9hI8p0NzMY1cUYZ2pSTQLhUP8PFli7Ap5PjbgFiHefjFeZuZlC491GdmfK3l8nlIplM5PpLkP/iDOeyQac8qtDXiNkTE2m82kUcffJZ5hv8VrwidNREbYu3wXhoK4fsuGCSngw/PEIrx+wsLsEmpA02DQ+Jvd3tYKbTuGMRT5ZDihnY8vfOEL9LnPfY6WLl1KS5cupR/84AcUDofpD3/4A9m2TY888gjdf//9dOONN9KKFSvoySefpEwmQ0899dRH7qiiKIqiKOcHJ+3zUS6X6emnn6Z0Ok1XX3019ff308jICK1fv945xu/307XXXkuvv/76nOfJ5/OUTCbhn6IoiqIo5y8n/PGxY8cOCofD5Pf76dZbb6Wf/exntHz5choZeX97qa0Ntynb2tqctmOxceNGikajzr+urq45j1UURVEU5dznhENtL7zwQtq+fTslEgl69tln6ZZbbqHNmzc77dI2btt2Vb+I++67j+666y6nnkwmq36ASP8HmTLdpFroZDXkNYTHB7lrHN5bEzl1cQlbSHSb6Z/LQvoX5lf4akifAqpUS7rNSJ+B2fLqc7eZ4bMyRFZKn5u/Kv02zPXyYWvH7IM8Fn0+cFxNHyZ5H/I8pp9JQfp8GGF7UvpdzkHFXE9i3t1GiJ/0r/J40AckYIbTimmWYYXV8AXYnj2ZSUCbXeQT7937LrTtP7gD6pdfvMQpN69G34imCPsqNNehrTtXwrH0NBlp2Ys4BzMp7t/iJUugrd7T6JR/+eKL0DY1gbLkUbcROinCVy9ewfLqrYvwOUgmUZ5/4jD/x64oXlTmemk2QnuJiPxBDGUnYwzauhuhacFC/t2ADxfM9ADuVIfwMoAZWloR7zSf8CeqGG/d9EwCr2GEltoihX2xLNInBHgdloUPExlryxaRvxXh11EhPk8ghH1vMHwsmkO4Jrq6OpxyRoT5+4rY10qeZdr9AeFDFeL+2GLPwLbwvmyb32NlIUNQX8fzHqnH5yC2ACevIcJ9KIhn5FRwwh8fPp/PcThdvXo1vfHGG/SP//iPdM899xAR0cjICC1YwHoFY2Njs3ZDTPx+/wk5pymKoiiKcm7zkXU+bNumfD5Pvb291N7eTps2sed2oVCgzZs309q1a6ucQVEURVGU+cQJ7Xx897vfpeuvv566uroolUrR008/Ta+88gq98MILZFkW3XnnnfTggw/SkiVLaMmSJfTggw9SKBSim2666XT1X1EURVGUc4wT+vgYHR2lm2++mYaHhykajdLKlSvphRdeoOuuu46IiO6++27KZrN02223UTwepyuvvJJefPHFU6bxcaJIX4nj1QSZ5V9wkuc5l3CV0BfCJpnu2fBbsOfWWnEJX5GKkO+2j1PnQ/obzPb5mNvHwqyHw2i7LQkbsV3NV8I4TzVfjffPY4xBFf8QeR+mz5L8vWo+IC7RH68xP9IP6kTWaDU/l0oFnwOPZ24dlBPxU4q2sH+GnRYp0itskp1IJKCtTvjoeErcn/FR1GkgL/en0Y8+ZUkLJcJnKiyvvqQX5cw7u9kuPjODug39h/g8Xht1NK5YdinUG4P8TqwPor7CwTH2bVl+IWpuJONoe+/fzdovYxPof3HlmjVOedVVa6BN6sTs3vG2U75geR+0Le1iqfip6SPQlstJj7i5mY6zxL1FuH59wseiXOH7yubRNyIc5DUR9OEazbqE/k4ja+cUPXiNvJGKvlTGuQy40RXAbejYFItCqt7Q0QkLX42Q4X9WKOK7xy/OYxn+KoEw/s20PHzesniHloQBo2SIK1WEr4bPYz7f+PyUhSjTtJFmwFdBzaFTwQl9fPzkJz+p2m5ZFm3YsIE2bNjwUfqkKIqiKMp5jOZ2URRFURSlppzzWW1NPmx7uZq5xNxxkmFg0lJgts+SITdCTa0qMuQfRk3Ca42+FuK49WyLbTavh8MqLZEmtZhgiWUphWx1X4j1EMozz4Xc8p8dUs19KJVwO9M0nwRFSKGUyi8bob8yk6Q0M5h8WFjsXMdW+70Ps46Yph+vDAeHVLUitLaKiahaX2fdkwijrrq8jbbyhyzlljbeDm/xYbhfeorntrsbzSV1PpnVNuGUh0cxtLWnZ6VT7lvYA23b97wE9ZARQez3C1l/Qzb9wM73oC3q5ai+xWLdh4PY174ulobf+jbmvxo4yOGzK1d2QFtXJ4bBNrawFHu0GdsuXNbjlL0ufH5ahIT6ws5POeXUDJpvJsbZhBUzpMSJiJavQHNOdobmpGKEhHptYQ6wxTPsMsOEF0GbbZiI80U0leZLuNaLWcOUITK8Bgx5cTscg7ZCNivqbIIoplBS3pSxd4l3iMcI9bcrItS3gMfmSxxu7Bahx2Z4rUxh4RHvY6+b2z0+PA+orQvZg5IMrTdMTV63/FSYoo+K7nwoiqIoilJT9ONDURRFUZSaoh8fiqIoiqLUFMuuiXPB8ZNMJikajdK9996ryqeKoiiKco6Qz+fpoYceounpaaoX8u0S3flQFEVRFKWm6MeHoiiKoig1RT8+FEVRFEWpKfrxoSiKoihKTdGPD0VRFEVRaspZp3D6QfBNPn/qE9koiqIoinJ6+ODv9vEE0Z51obaDg4PU1dX14QcqiqIoinLWceTIEers7Kx6zFn38VGpVGhoaIhs26bu7m46cuTIh8YLz0eSySR1dXXp+MyBjk91dHyqo+NTHR2f6szX8bFtm1KpFHV0dFTNd0V0FppdXC4XdXZ2UjL5fnKj+vr6eTV5J4qOT3V0fKqj41MdHZ/q6PhUZz6OTzR6nMlDT3M/FEVRFEVRAP34UBRFURSlppy1Hx9+v5++973vaX6XOdDxqY6OT3V0fKqj41MdHZ/q6Ph8OGedw6miKIqiKOc3Z+3Oh6IoiqIo5yf68aEoiqIoSk3Rjw9FURRFUWqKfnwoiqIoilJT9ONDURRFUZSactZ+fDz66KPU29tLgUCAVq1aRa+99tqZ7lLN2bhxI61Zs4YikQi1trbSl770Jdq7dy8cY9s2bdiwgTo6OigYDNK6deto165dZ6jHZ5aNGzeSZVl05513Oj+b7+Nz9OhR+trXvkZNTU0UCoXosssuo61btzrt83l8SqUS/d3f/R319vZSMBikvr4++v73v0+VSsU5Zj6Nz6uvvkpf+MIXqKOjgyzLop///OfQfjxjkc/n6dvf/jY1NzdTXV0dffGLX6TBwcEa3sXpo9r4FItFuueee+iSSy6huro66ujooK9//es0NDQE5zifx+eEsc9Cnn76advr9do//vGP7d27d9t33HGHXVdXZx8+fPhMd62mfPazn7Uff/xxe+fOnfb27dvtG264we7u7rZnZmacYx566CE7EonYzz77rL1jxw77y1/+sr1gwQI7mUyewZ7Xni1bttg9PT32ypUr7TvuuMP5+Xwen6mpKXvRokX2N77xDfuPf/yj3d/fb7/00kv2gQMHnGPm8/g88MADdlNTk/1f//Vfdn9/v/3v//7vdjgcth955BHnmPk0Ps8//7x9//33288++6xNRPbPfvYzaD+esbj11lvthQsX2ps2bbLfeust+5Of/KR96aWX2qVSqcZ3c+qpNj6JRML+zGc+Yz/zzDP2nj177N///vf2lVdeaa9atQrOcT6Pz4lyVn58fOxjH7NvvfVW+NmyZcvse++99wz16OxgbGzMJiJ78+bNtm3bdqVSsdvb2+2HHnrIOSaXy9nRaNT+l3/5lzPVzZqTSqXsJUuW2Js2bbKvvfZa5+Njvo/PPffcY19zzTVzts/38bnhhhvsv/qrv4Kf3XjjjfbXvvY127bn9/jIP67HMxaJRML2er32008/7Rxz9OhR2+Vy2S+88ELN+l4LjvVxJtmyZYtNRM5/mufT+BwPZ53ZpVAo0NatW2n9+vXw8/Xr19Prr79+hnp1djA9PU1ERI2NjURE1N/fTyMjIzBWfr+frr322nk1Vt/61rfohhtuoM985jPw8/k+Pr/4xS9o9erV9Gd/9mfU2tpKl19+Of34xz922uf7+FxzzTX0m9/8hvbt20dERG+//Tb97ne/o8997nNEpONjcjxjsXXrVioWi3BMR0cHrVixYt6NF9H772vLsigWixGRjo/krMtqOzExQeVymdra2uDnbW1tNDIycoZ6deaxbZvuuusuuuaaa2jFihVERM54HGusDh8+XPM+ngmefvppeuutt+iNN96Y1Tbfx+fgwYP02GOP0V133UXf/e53acuWLfQ3f/M35Pf76etf//q8H5977rmHpqenadmyZeR2u6lcLtMPfvAD+upXv0pEun5MjmcsRkZGyOfzUUNDw6xj5tu7O5fL0b333ks33XSTk9VWxwc56z4+PsCyLKjbtj3rZ/OJ22+/nd555x363e9+N6ttvo7VkSNH6I477qAXX3yRAoHAnMfN1/GpVCq0evVqevDBB4mI6PLLL6ddu3bRY489Rl//+ted4+br+DzzzDP005/+lJ566im6+OKLafv27XTnnXdSR0cH3XLLLc5x83V8jsXJjMV8G69isUhf+cpXqFKp0KOPPvqhx8+38fmAs87s0tzcTG63e9aX4NjY2Kyv7vnCt7/9bfrFL35BL7/8MnV2djo/b29vJyKat2O1detWGhsbo1WrVpHH4yGPx0ObN2+mf/qnfyKPx+OMwXwdnwULFtDy5cvhZxdddBENDAwQka6fv/3bv6V7772XvvKVr9All1xCN998M33nO9+hjRs3EpGOj8nxjEV7ezsVCgWKx+NzHnO+UywW6c///M+pv7+fNm3a5Ox6EOn4SM66jw+fz0erVq2iTZs2wc83bdpEa9euPUO9OjPYtk233347Pffcc/Tb3/6Went7ob23t5fa29thrAqFAm3evHlejNWnP/1p2rFjB23fvt35t3r1avqLv/gL2r59O/X19c3r8fn4xz8+KzR73759tGjRIiLS9ZPJZMjlwleg2+12Qm3n+/iYHM9YrFq1irxeLxwzPDxMO3funBfj9cGHx/79++mll16ipqYmaJ/v4zOLM+XpWo0PQm1/8pOf2Lt377bvvPNOu66uzj506NCZ7lpN+eu//ms7Go3ar7zyij08POz8y2QyzjEPPfSQHY1G7eeee87esWOH/dWvfvW8DQU8HsxoF9ue3+OzZcsW2+Px2D/4wQ/s/fv32//2b/9mh0Ih+6c//alzzHwen1tuucVeuHChE2r73HPP2c3Nzfbdd9/tHDOfxieVStnbtm2zt23bZhOR/fDDD9vbtm1zojWOZyxuvfVWu7Oz037ppZfst956y/7Upz513oSSVhufYrFof/GLX7Q7Ozvt7du3w/s6n8875zifx+dEOSs/Pmzbtv/5n//ZXrRoke3z+ewrrrjCCS+dTxDRMf89/vjjzjGVSsX+3ve+Z7e3t9t+v9/+xCc+Ye/YsePMdfoMIz8+5vv4/PKXv7RXrFhh+/1+e9myZfaPfvQjaJ/P45NMJu077rjD7u7utgOBgN3X12fff//98MdiPo3Pyy+/fMz3zS233GLb9vGNRTabtW+//Xa7sbHRDgaD9uc//3l7YGDgDNzNqafa+PT398/5vn755Zedc5zP43OiWLZt27XbZ1EURVEUZb5z1vl8KIqiKIpyfqMfH4qiKIqi1BT9+FAURVEUpabox4eiKIqiKDVFPz4URVEURakp+vGhKIqiKEpN0Y8PRVEURVFqin58KIqiKIpSU/TjQ1EURVGUmqIfH4qiKIqi1BT9+FAURVEUpab8/22DXCRUurw7AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "epochs = 10\n",
    "lr = 0.001\n",
    "batch_size = 128\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = ResNet_cifar10().to(device)\n",
    "bin_op = BinOp(net)\n",
    "criterion = WeightedLoss(aggregate='normal_ce_mean')\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "# Data loading\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training function\n",
    "def train(trainloader, model, criterion, optimizer):\n",
    "    loss_list = []\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            \n",
    "            bin_op.binarization()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            bin_op.restore()\n",
    "            bin_op.updateBinaryGradWeight()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:\n",
    "                avg_loss = running_loss / 100\n",
    "                print(f\"[{epoch + 1}, {i + 1}] loss: {avg_loss}\")\n",
    "                loss_list.append(avg_loss)\n",
    "                running_loss = 0.0\n",
    "    return loss_list\n",
    "\n",
    "# Function to show images\n",
    "def imshow(img):\n",
    "    if isinstance(img, torch.Tensor):\n",
    "        img = img.numpy()\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    plt.imshow(numpy.transpose(img, (1, 2, 0)))\n",
    "\n",
    "# Function to display class probabilities\n",
    "def display_probabilities(output):\n",
    "    probabilities = torch.softmax(output, dim=1)[0] * 100\n",
    "    classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "    for i in range(10):\n",
    "        print(f'{classes[i]}: {probabilities[i].item():.2f}%')\n",
    "\n",
    "# Train the model\n",
    "loss_list = train(trainloader, net, criterion, optimizer)\n",
    "\n",
    "# Plotting the training loss\n",
    "plt.figure()\n",
    "plt.plot(loss_list)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "# Classes in CIFAR-10\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Show some test images and their class probabilities\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "imshow(torchvision.utils.make_grid(images[:4]))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "outputs = net(images[:4].to(device))\n",
    "display_probabilities(outputs.detach().cpu())\n",
    "\n",
    "print(\"Finished Training\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0816351-c896-4495-80c5-1455864a1c6b",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2043b020-978e-4a8f-af99-c3e61397257e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Accuracy of the network on the 10000 test images: 54.41%\n",
      "\n",
      "Image 1:\n",
      "plane: 1.75%\n",
      "car: 0.37%\n",
      "bird: 1.02%\n",
      "cat: 49.47%\n",
      "deer: 0.76%\n",
      "dog: 17.38%\n",
      "frog: 7.41%\n",
      "horse: 3.38%\n",
      "ship: 14.16%\n",
      "truck: 4.30%\n",
      "\n",
      "Image 2:\n",
      "plane: 5.22%\n",
      "car: 31.47%\n",
      "bird: 0.04%\n",
      "cat: 0.00%\n",
      "deer: 0.00%\n",
      "dog: 0.00%\n",
      "frog: 0.00%\n",
      "horse: 0.00%\n",
      "ship: 63.11%\n",
      "truck: 0.15%\n",
      "\n",
      "Image 3:\n",
      "plane: 3.74%\n",
      "car: 0.12%\n",
      "bird: 0.02%\n",
      "cat: 0.00%\n",
      "deer: 0.09%\n",
      "dog: 0.00%\n",
      "frog: 0.00%\n",
      "horse: 0.02%\n",
      "ship: 95.95%\n",
      "truck: 0.05%\n",
      "\n",
      "Image 4:\n",
      "plane: 50.88%\n",
      "car: 2.21%\n",
      "bird: 19.43%\n",
      "cat: 0.53%\n",
      "deer: 20.68%\n",
      "dog: 0.25%\n",
      "frog: 0.41%\n",
      "horse: 0.52%\n",
      "ship: 4.54%\n",
      "truck: 0.54%\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR-10 test dataset\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(testloader, model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_probs = []\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Get class probabilities for the first batch\n",
    "            if len(class_probs) == 0:\n",
    "                class_probs.append(torch.softmax(outputs, dim=1).cpu().numpy())\n",
    "    \n",
    "    print(f'Accuracy of the network on the 10000 test images: {(100 * correct / total):.2f}%')\n",
    "    \n",
    "    # Display class probabilities for some images in the first batch\n",
    "    batch_probs = class_probs[0]\n",
    "    for i in range(4):\n",
    "        print(f\"\\nImage {i+1}:\")\n",
    "        for j in range(10):\n",
    "            print(f'{classes[j]}: {batch_probs[i][j]*100:.2f}%')\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate(testloader, net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66e5cce8-ea92-4668-b30c-6b5aa4fe797b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 54.41%\n",
      "\n",
      "Image 1 (Ground Truth: cat):\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3wAAAGHCAYAAADr3lDRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABU4ElEQVR4nO3dd3hUZd7/8c/MZDLpCYRAAoTeBcUVS5SmgAjYVlcRfBZQwYLIIiiKgBDFRVEExbqsFFm7Prqu3ZUi0gQECwbpJEqQFtIgmXZ+f/hjHmOAc9NShvfruubSmfnM99znzEzIN6fcDsuyLAEAAAAAwo6zsgcAAAAAADg1aPgAAAAAIEzR8AEAAABAmKLhAwAAAIAwRcMHAAAAAGGKhg8AAAAAwhQNHwAAAACEKRo+AAAAAAhTNHwAAAAAEKZo+AAAAE6S7777TjfddJMaN26sqKgoxcXF6U9/+pOmTJmiffv2hXJdu3ZV165dK2+gR+BwOMrcEhMT1bVrV3344YcndTmDBg1SXFzcSa3ZtWtXtW3b1ijrcDg0ceLE0P2FCxfK4XBo4cKFoccmTpwoh8NR5nXPPfec5syZU67etm3b5HA4DvscUNkiKnsAAAAA4WDmzJkaOnSoWrZsqXvvvVdt2rSRz+fTqlWr9MILL2jZsmV69913K3uYtv7yl79o1KhRCgaD2rJliyZNmqQrrrhC//nPf9SnT5/KHt5JsWzZMtWvX/+omcGDB+uyyy4r89hzzz2nWrVqadCgQWUeT0tL07Jly9S0adOTPVTghNHwAQAAnKBly5bpjjvuUI8ePfTee+/J4/GEnuvRo4dGjRqlTz75pBJHaK5OnTq64IILJEkXXnihMjIy1KxZM02fPv2IDZ/P55PD4VBERPX41fLQ+h1N/fr1bZvCQzwej1FNoDJwSCcAAMAJ+vvf/y6Hw6F//OMfZZq9QyIjI3XllVcetUZmZqbOP/981axZUwkJCfrTn/6kl156SZZllcnNnz9fXbt2VXJysqKjo9WgQQNde+21OnDgQCjz/PPP66yzzlJcXJzi4+PVqlUrPfDAA8e1bk2bNlVKSoq2b98u6f8Of5w3b55GjRqlevXqyePxaNOmTZKkWbNm6ayzzlJUVJRq1qypP//5z8rKyjps7XXr1qlbt26KjY1VSkqKhg0bVmY9JOnZZ59V586dVbt2bcXGxqpdu3aaMmWKfD7fYWsuXrxYF1xwgaKjo1WvXj2NHz9egUCgTOaPh3Qezh8P6WzUqJHWrVunRYsWhQ55bdSokaQjH9K5ceNG9e/fX7Vr15bH41Hr1q317LPPlskEg0FNmjRJLVu2VHR0tJKSknTmmWfqqaeeOur4AFPV488wAAAAVVQgEND8+fN1zjnnKD09/bjrbNu2TbfddpsaNGggSVq+fLnuuusu/fLLL3rwwQdDmT59+qhTp06aNWuWkpKS9Msvv+iTTz6R1+tVTEyMXn/9dQ0dOlR33XWXnnjiCTmdTm3atEk//vjjcY0rLy9Pe/fuVfPmzcs8PmbMGGVkZOiFF16Q0+lU7dq1NXnyZD3wwAPq16+fJk+erL1792rixInKyMjQypUry9Tw+Xzq3bu3brvtNt1///1aunSpJk2apO3bt+s///lPKLd582b1799fjRs3VmRkpL799ls98sgjWr9+vWbNmlVmTDt37tQNN9yg+++/Xw899JA+/PBDTZo0SXl5eXrmmWeOa/0Peffdd/WXv/xFiYmJeu655yTpsM39IT/++KMuvPBCNWjQQFOnTlVqaqo+/fRTDR8+XHv27NGECRMkSVOmTNHEiRM1btw4de7cWT6fT+vXr9f+/ftPaLxAiAUAAIDjtnPnTkuSdcMNNxi/pkuXLlaXLl2O+HwgELB8Pp/10EMPWcnJyVYwGLQsy7LefvttS5K1du3aI7522LBhVlJSkvFYfk+SNXToUMvn81ler9fKysqyevXqZUmynn32WcuyLGvBggWWJKtz585lXpuXl2dFR0dbvXv3LvN4dna25fF4rP79+4ceGzhwoCXJeuqpp8pkH3nkEUuS9dVXXx12fIe2y8svv2y5XC5r3759oee6dOliSbL+/e9/l3nNkCFDLKfTaW3fvr3Mek6YMCF0/9A6LViwIPTYhAkTrD/+qnzGGWcc9n3bunWrJcmaPXt26LGePXta9evXt/Lz88tkhw0bZkVFRYXGfvnll1vt27c/7PoCJwOHdAIAAFQB8+fPV/fu3ZWYmCiXyyW3260HH3xQe/fu1a5duyRJ7du3V2RkpG699VbNnTtXW7ZsKVfnvPPO0/79+9WvXz/9+9//1p49e45pHM8995zcbrciIyPVunVrLV26VA899JCGDh1aJnfttdeWub9s2TIdPHiw3AVN0tPTdckll+iLL74ot6wbb7yxzP3+/ftLkhYsWBB6bM2aNbryyiuVnJwc2i4DBgxQIBDQhg0byrw+Pj6+3KGz/fv3VzAY1Jdffmm2AU6CkpISffHFF/rzn/+smJgY+f3+0K13794qKSnR8uXLJf32fn377bcaOnSoPv30UxUUFFTYOHF6oOEDAAA4AbVq1VJMTIy2bt163DW+/vprXXrppZJ+u9rnkiVLtHLlSo0dO1aSdPDgQUm/nU/33//+V7Vr19add96ppk2bqmnTpmXO9/rrX/+qWbNmafv27br22mtVu3ZtnX/++fr888+NxnL99ddr5cqVWrVqlX766Sft3btX48ePL5dLS0src3/v3r2HfVyS6tatG3r+kIiICCUnJ5d5LDU1tUyt7OxsderUSb/88oueeuopLV68WCtXrgydB3douxxSp06dcsv+Y82KsHfvXvn9fs2YMUNut7vMrXfv3pIUasTHjBmjJ554QsuXL1evXr2UnJysbt26adWqVRU2XoQ3zuEDAAA4AS6XS926ddPHH3+sn3/+2fjKjr/3+uuvy+1264MPPlBUVFTo8ffee69ctlOnTurUqZMCgYBWrVqlGTNmaMSIEapTp45uuOEGSdJNN92km266ScXFxfryyy81YcIEXX755dqwYYMaNmx41LGkpKSoQ4cOtmP+4xx1h5q33NzcctkdO3aoVq1aZR7z+/3au3dvmaZv586dZWq99957Ki4u1v/+7/+WGffatWsPO6Zff/213GN/rFkRatSoIZfLpb/+9a+68847D5tp3LixpN8a35EjR2rkyJHav3+//vvf/+qBBx5Qz549lZOTo5iYmAobN8ITe/gAAABO0JgxY2RZloYMGSKv11vueZ/PV+ZCJH90aEoDl8sVeuzgwYOaN2/eEV/jcrl0/vnnh/Z2ffPNN+UysbGx6tWrl8aOHSuv16t169Ydy2odk4yMDEVHR+tf//pXmcd//vlnzZ8/X926dSv3mldeeaXM/VdffVWSQpPSH2oqf39xFMuyNHPmzMOOobCwUO+//365mk6nU507dz62FToMj8dTbq/i4cTExOjiiy/WmjVrdOaZZ6pDhw7lbodrQJOSkvSXv/xFd955p/bt26dt27ad8JgB9vABAACcoIyMDD3//PMaOnSozjnnHN1xxx0644wz5PP5tGbNGv3jH/9Q27ZtdcUVVxz29X369NGTTz6p/v3769Zbb9XevXv1xBNPlLsK5AsvvKD58+erT58+atCggUpKSkJXquzevbskaciQIYqOjtZFF12ktLQ07dy5U5MnT1ZiYqLOPffcU7YNkpKSNH78eD3wwAMaMGCA+vXrp7179yozM1NRUVGhq1IeEhkZqalTp6qoqEjnnntu6CqdvXr1UseOHSX9NodhZGSk+vXrp9GjR6ukpETPP/+88vLyDjuG5ORk3XHHHcrOzlaLFi300UcfaebMmbrjjjtCVz89Ee3atdPrr7+uN954Q02aNFFUVJTatWt32OxTTz2ljh07qlOnTrrjjjvUqFEjFRYWatOmTfrPf/6j+fPnS5KuuOIKtW3bVh06dAhNfzF9+nQ1bNiw3JVRgeNBwwcAAHASDBkyROedd56mTZumxx57TDt37pTb7VaLFi3Uv39/DRs27IivveSSSzRr1iw99thjuuKKK1SvXj0NGTJEtWvX1i233BLKtW/fXp999pkmTJignTt3Ki4uTm3bttX7778fOgewU6dOmjNnjt58803l5eWpVq1a6tixo15++WWlpKSc0m0wZswY1a5dW08//bTeeOMNRUdHq2vXrvr73/9ernk5dAjr8OHDNWnSJEVHR2vIkCF6/PHHQ5lWrVrpnXfe0bhx43TNNdcoOTlZ/fv318iRI9WrV69yy09NTdWzzz6re+65R99//71q1qypBx54QJmZmSdl/TIzM5Wbm6shQ4aosLBQDRs2POJeuDZt2uibb77Rww8/rHHjxmnXrl1KSkpS8+bNQ+fxSdLFF1+sd955R//85z9VUFCg1NRU9ejRQ+PHj5fb7T4p48bpzWFZf5jNEwAAAAAQFjiHDwAAAADCFA0fAAAAAIQpGj4AAAAACFM0fAAAAAAQpmj4AAAAACBM0fABAAAAQJhiHj4AAGwEg0Ht2LFD8fHxcjgclT0cAABkWZYKCwtVt25dOZ1H3o9n3PDNvvtso5zDCtpmIt1mi3UcZeCHeL2lRrX8AZ9RLjIy0jYTCNqvoyRZQbMpDh3OgG3G6TIqJcsXa7882S9PktyRJUY5l8HHyOE02xaBoN8o5/PbvwfBoOEvZQ778fsDZrVKDZdpkgoafJckGf/y6fXafwcCAcPvpsHYnIafM6/h96nY4KNxwGu2zMff3GqUAw7ZsWOH0tPTK3sYAACUk5OTo/r16x/xefbwAQBgIz4+XtJv/6gmJCRU8mgAAJAKCgqUnp4e+jfqSGj4AACwcWhPekJCAg0fAKBKsTvai4u2AAAAAECYouEDAAAAgDBFwwcAAAAAYYqGDwAAAADCFA0fAAAAAIQpGj4AAAAACFM0fAAAAAAQpozn4fMa9oaWddA+FAwa1fIo1jbjlMuoVkREwCjnNFlNy6iUHG6zbVbq9dpm/EHD9bTsl+kyK6UIwz8HOII++5C/1KiWU2bvU9Bge3gdUUa1Ai6PfS3D7e8NmG00R9B+PR1Bv1GtKMPPWYTDPueMMPtwB3wG77nDbPyW4Xtu6ehzzEiSy8XfsAAAAH6P344AAAAAIEzR8AEAAABAmKLhAwAAAIAwZXwOHwAAp7u2Ez6V0xNzTK/Z9mifUzQaAADssYcPAAAAAMIUDR8AAAAAhCkaPgAAAAAIUzR8AAAAABCmjC/aYhlOAi3LfoJtK2BWyxGwn+w66LOftFySXNGGE2LLflJ404nLgwaTa0tSpNttm/Fb9hlJCvoMtpnhuPx+s5zDsp+s22kwIbwkOVyRRjnLZT+p+sGA/YTqkrRzr/0k4sVeswnJi4oMJiSX5LLst218lNkHLdJh/5mVpISYaNtMtMfsuxl02n/vnAYTpUuSy/ALZfIN8AXN3icAAIDTBXv4AABVRqNGjTR9+vTKHgYAAGGDhg8AAAAAwhQNHwAAAACEKRo+AECF6dq1q4YNG6Zhw4YpKSlJycnJGjdunKwjnAv85JNPql27doqNjVV6erqGDh2qoqKi0PNz5sxRUlKSPv30U7Vu3VpxcXG67LLLlJubW6bO7Nmz1bp1a0VFRalVq1Z67rnnTul6AgBQVdDwAQAq1Ny5cxUREaEVK1bo6aef1rRp0/TPf/7zsFmn06mnn35aP/zwg+bOnav58+dr9OjRZTIHDhzQE088oXnz5unLL79Udna27rnnntDzM2fO1NixY/XII48oKytLf//73zV+/HjNnTv3iGMsLS1VQUFBmRsAANWR8VU6AQA4GdLT0zVt2jQ5HA61bNlS33//vaZNm6YhQ4aUy44YMSL0/40bN9bDDz+sO+64o8weOp/PpxdeeEFNmzaVJA0bNkwPPfRQ6PmHH35YU6dO1TXXXBOq8+OPP+rFF1/UwIEDDzvGyZMnKzMz82SsLgAAlYo9fACACnXBBRfI4fi/aTsyMjK0ceNGBQLlpytZsGCBevTooXr16ik+Pl4DBgzQ3r17VVxcHMrExMSEmj1JSktL065duyRJu3fvVk5Ojm655RbFxcWFbpMmTdLmzZuPOMYxY8YoPz8/dMvJyTkZqw4AQIVjDx8AoEravn27evfurdtvv10PP/ywatasqa+++kq33HKLfL7/m/PS/Ye5TB0OR+icwGDwt3kqZ86cqfPPP79M7mhzQHo8Hnk8ZnN5AgBQldHwAQAq1PLly8vdb968ebkGbNWqVfL7/Zo6daqczt8OSHnzzTePaVl16tRRvXr1tGXLFt14440nNnAAAKoh44YvIlBqFnQd/kprv+cM+mwzkuRx+e1DEQ77jCQ5zY5edboMcvarKEnyBw2DTvt1cEdGG5VKbdTSNlOwf49RrT17Dxjl3BGRthmnzP5S7vWbfSQPWjG2maztu41qWZ5k24zPFWtUyxsXZZQryt9nm/nl1zyjWnFRZtsskLvfNtMg1f69lKTkePv3MyrCbFwOy+B7LinS4KsesMofEoiqJycnRyNHjtRtt92mb775RjNmzNDUqVPL5Zo2bSq/368ZM2boiiuu0JIlS/TCCy8c8/ImTpyo4cOHKyEhQb169VJpaalWrVqlvLw8jRw58mSsEgAAVRbn8AEAKtSAAQN08OBBnXfeebrzzjt111136dZbby2Xa9++vZ588kk99thjatu2rV555RVNnjz5mJc3ePBg/fOf/9ScOXPUrl07denSRXPmzFHjxo1PxuoAAFClOawjTX70B/8c1sqsoqvENuI2W6QSXPG2mVLTvWieI5+r8XsndQ+f32zPhckePmdknFGp1Doncw/fkS9o8HtGe/gswz18wZO3h+/7ytjDp5O3h89baLqHz+zvNoGDhbYZ8z189p/ZqAjDvW2Ge/j8QfvMQZ/ZMifO3WSUw8nXtWtXtW/fXtOnT6/soRyTgoICJSYmKn3Em3J67H/+/N62R/ucolEBAE5nh/5tys/PV0JCwhFz7OEDAAAAgDBFwwcAAAAAYYqrdAIAKszChQsrewgAAJxW2MMHAAAAAGGKhg8AAAAAwhSHdAIAYOiHzJ5HvRIaAABVzTE0fGYTnDsikuwzDrNafsv+OuxOp9kl3b1+r1Eu0mU/fUAgYHbpdytoeFl6g+0R6TbbGXt+9x62mdVLlxnV2mE4fUOxwWTp/oDZtBLbf95llNv68y+2GU+NNKNa9evYz8VleeynCJEkb4TZ9BPuuBTbjL+kyKjW3l07jHIxNeynn/i5aKdRrZKg/XezTrzbqFaM22zKlIDvgG3GaThlCgAAwOmCQzoBAAAAIEzR8AEAAABAmKLhAwAAAIAwRcMHAIChthM+VaP7P6zsYQAAYIyGDwAAAADCFA0fAAAAAIQpGj4AAAAACFM0fAAAAAAQpmj4AAAAACBMRZgGS53xRrn8A7G2mYC/xKhWjTi/bSbBFTCqFWFZRrmg32ubcZiVkhW0H78kOV32ffeBA3lGteZ/8G/bzK/7S41q/Vpk9veA7b/Yj237jhyjWq6oOKNcwJVgm4lNSDGq5Y6xX2ZEVLRRLY/DbJtFOe2/J3u8B41qpdVvYJQrOVhsm9myZadRrX377b/Drnpm72WjFLOcOxC0zTgCZt85AACA0wV7+AAAAAAgTNHwAQAAAECYouEDAJy2fD5fZQ8BAIBTioYPAFCtBINBPfbYY2rWrJk8Ho8aNGigRx55RJJ03333qUWLFoqJiVGTJk00fvz4Mk3dxIkT1b59e82aNUtNmjSRx+ORZXiONwAA1ZHxRVsAAKgKxowZo5kzZ2ratGnq2LGjcnNztX79eklSfHy85syZo7p16+r777/XkCFDFB8fr9GjR4dev2nTJr355pt655135HK5DruM0tJSlZb+3wWuCgoKTu1KAQBwitDwAQCqjcLCQj311FN65plnNHDgQElS06ZN1bFjR0nSuHHjQtlGjRpp1KhReuONN8o0fF6vV/PmzVNKypGv5Dt58mRlZmaeorUAAKDicEgnAKDayMrKUmlpqbp163bY599++2117NhRqampiouL0/jx45WdnV0m07Bhw6M2e9JvexHz8/NDt5wcs6llAACoamj4AADVRnT0kefEXL58uW644Qb16tVLH3zwgdasWaOxY8fK6y07v2psrP08mB6PRwkJCWVuAABURzR8AIBqo3nz5oqOjtYXX3xR7rklS5aoYcOGGjt2rDp06KDmzZtr+/btlTBKAACqDuNz+HYfPPyJ7X+0z5dkm1m0ZKFRrTYt7P8Ke/EZtYxq1XCZXYUtGAjYZpxHOMm/XM7pNsoFLPvLgjsMW/Ot27fYZvYd9BjVsmJqGuVccfG2GWdNswseRCclGeW8JSX2GUfQqFZCDfvPWUKcfUaSdu3caZQryNtnm4mPNPt6Rh1lj8fvZeftsc24E+oY1dqVa/9LdNzOQqNaqQlm44922G8Pf5BL7Ie7qKgo3XfffRo9erQiIyN10UUXaffu3Vq3bp2aNWum7Oxsvf766zr33HP14Ycf6t13363sIQMAUKnYwwcAqFbGjx+vUaNG6cEHH1Tr1q3Vt29f7dq1S1dddZXuvvtuDRs2TO3bt9fSpUs1fvz4yh4uAACViqt0AgCqFafTqbFjx2rs2LHlnpsyZYqmTJlS5rERI0aE/n/ixImaOHHiKR4hAABVB3v4AAAAACBM0fABAAAAQJii4QMAAACAMEXDBwAAAABhiou2AABg6IfMnkzCDgCoVtjDBwAAAABhyngPX0RiE6Pcgb32PaQvMsWo1r4D9hOcH/BGGdVKiPQa5YKW3yRkVMvlijHKlXjtJ57eXWpUSnsK7SeOj0lKNqpVI6WBUa44aD+pei2ZTa7tijLLed3272dJsdnE3yVF9uNvWMdsmx0wnCx9l/egbcbh9hjVyt93wCinoP1n42BRkVEpV6T9Z/vXgjyjWrn5JUa5hrXsfx44g0alAAAAThvs4QMAAACAMEXDBwAAAABhioYPAAAAAMIUV+kEAMBQ2wmfyuk5/Dms2x7tU8GjAQDAHnv4AAAAACBM0fABAAAAQJii4QMAAACAMEXDBwAAAABhioYPAAAAAMKU8VU6W555nlHu5+U/2WbiElOMap2Xcb5tJsa13aiWt7jQKOeMcNtmHO5oo1oBq4ZRLr52um1m7XcbjWrFJdWyzdRreIZRLcvpMcq53V7bTLB0r1EtrzdolDN5n1wOs4/3um+/tc0keOyXJ0kxsbFGudiYONvMjp2/GtXyBy2jnMtt/37WTDj81Qf/aH+ezzaTt88+I0lbc/ONcnXrpNpmIiLtP4uoPrp27ar27dtr+vTph32+UaNGGjFihEaMGHFMdSdOnKj33ntPa9euPeExAgBQ1TEtAwCgWlq5cqViDf/IAgDA6YqGDwBQLaWkHP1oEZ/PJ7fbbO88AADhinP4AABVlt/v17Bhw5SUlKTk5GSNGzdOlvXbYcyNGjUqc7inw+HQCy+8oKuuukqxsbGaNGmSJOnRRx9VnTp1FB8fr1tuuUUlJSWVsSoAAFQKGj4AQJU1d+5cRUREaMWKFXr66ac1bdo0/fOf/zxifsKECbrqqqv0/fff6+abb9abb76pCRMm6JFHHtGqVauUlpam5557zna5paWlKigoKHMDAKA64pBOAECVlZ6ermnTpsnhcKhly5b6/vvvNW3aNA0ZMuSw+f79++vmm28O3e/Xr59uvvlmDR48WJI0adIk/fe//7Xdyzd58mRlZmaevBUBAKCSsIcPAFBlXXDBBXI4HKH7GRkZ2rhxowKBwGHzHTp0KHM/KytLGRkZZR774/3DGTNmjPLz80O3nJyc4xg9AACVjz18AICwcbKu2unxeOTxmE1NAwBAVcYePgBAlbV8+fJy95s3by6Xy2X0+tatWx+2BgAApwsaPgBAlZWTk6ORI0fqp59+0muvvaYZM2bob3/7m/Hr//a3v2nWrFmaNWuWNmzYoAkTJmjdunWncMQAAFQtxod0xiQmG+UaNmlhmznoM1tmg8bNbDO1fJZRrf1btxnlfJbfNhPwxxjVOq/z1Ua5Bk062GYat9tmVGv1mm9tMzXiUo1q7di1xygXYUXaZjymc2GZvZ0qKi62zezft9eoVs04+7EZDkuBoFmyls38YZJU6rP/LErSnrx8o5zDZf/3nfg4s8PhIlz2Pzq8JQeMam3O+dkol1Ij2jbTvH68US1UHwMGDNDBgwd13nnnyeVy6a677tKtt95q/Pq+fftq8+bNuu+++1RSUqJrr71Wd9xxhz799NNTOGoAAKoOzuEDAFRJCxcuDP3/888/X+75bdu2lbl/aH6+P3rggQf0wAMPlHnsscceO+HxAQBQHXBIJwAAAACEKRo+AAAAAAhTNHwAAAAAEKZo+AAAAAAgTNHwAQAAAECY4iqdAAAY+iGzpxISEip7GAAAGGMPHwAAAACEKeM9fC5PnFFux69Ztpn255xrVCs20X6Cc1fhL0a1An6zCbEjIu03yZacQqNaHWs0Nsoppr5tJD7WbBLrqAj79yk60mzi+KhIj1FOwYBtpF7dNKNSP27ebJSLjIyyzRQUmr1PjdNb2GZatGpjVGvfvjyjXFxCkm1mx85dRrUcTpdRLqlGTdtMfoHZ+F0Gk7hHxyQZ1TpYaPbZ3pht/35GR/I3LAAAgN/jtyMAAAAACFM0fAAAAAAQprhoCwAAhtpO+FROj9lh8QAA/NG2R/tU+DLZwwcAAAAAYYqGDwAAAADCFA0fAAAAAIQpGj4AAAAACFM0fAAAAAAQpmj4AAAAACBMGU/L4I5KMMqVlHhtM6WlPrNlRtpf+jom1mxcsVHRRjmPy2+biYsoNao15x8vGeWu6DvMNuMu3mlUK9Jj38M7nfbrKEmNm9Qzyu3at8M2U1JUbFQrtXYto9y+ggO2mVKv/WdRkpo0a2abadqshVGt/DXfGOWKC4tsMwXF9usoSf5A0Ch38GCJbSYpKdGoVsAqtM0k1nAb1fJ7zT6PLqf99+7nHbuMagEAAJwu2MMHADhtTJw4Ue3bt6/sYQAAUGFo+AAAAAAgTNHwAQCqlWAwqMcee0zNmjWTx+NRgwYN9Mgjj0iS7rvvPrVo0UIxMTFq0qSJxo8fL5/vt9MI5syZo8zMTH377bdyOBxyOByaM2dOJa4JAACnnvE5fAAAVAVjxozRzJkzNW3aNHXs2FG5ublav369JCk+Pl5z5sxR3bp19f3332vIkCGKj4/X6NGj1bdvX/3www/65JNP9N///leSlJh4+PNWS0tLVVr6f+eNFhQUnPoVAwDgFKDhAwBUG4WFhXrqqaf0zDPPaODAgZKkpk2bqmPHjpKkcePGhbKNGjXSqFGj9MYbb2j06NGKjo5WXFycIiIilJqaetTlTJ48WZmZmaduRQAAqCAc0gkAqDaysrJUWlqqbt26Hfb5t99+Wx07dlRqaqri4uI0fvx4ZWdnH/NyxowZo/z8/NAtJyfnRIcOAECloOEDAFQb0dFHnmJn+fLluuGGG9SrVy998MEHWrNmjcaOHSuv4RQtv+fxeJSQkFDmBgBAdUTDBwCoNpo3b67o6Gh98cUX5Z5bsmSJGjZsqLFjx6pDhw5q3ry5tm/fXiYTGRmpQCBQUcMFAKDSGZ/D53CZTaJ8wGCC7ZIDB41qud0e20zhXsN/uF32k7hLklv7bTNpSS6jWhuzNhrldvy8yT50wH5yc0na/vM228zZqecZ1arX8OjnuBxSd1cd20zxpu22GUmq6UkyysUn2U/QvnnzVqNaaXXtJ5jfb3jBBp/hJOi/7t5rmwlaDqNaDpfZ1/iAwcTrDqfZ98lkZLFxsUa1FEw2ikU67H9uePfsNFsmqq2oqCjdd999Gj16tCIjI3XRRRdp9+7dWrdunZo1a6bs7Gy9/vrrOvfcc/Xhhx/q3XffLfP6Ro0aaevWrVq7dq3q16+v+Ph4eTz2/9YAAFBdsYcPAFCtjB8/XqNGjdKDDz6o1q1bq2/fvtq1a5euuuoq3X333Ro2bJjat2+vpUuXavz48WVee+211+qyyy7TxRdfrJSUFL322muVtBYAAFQMrtIJAKhWnE6nxo4dq7Fjx5Z7bsqUKZoyZUqZx0aMGBH6f4/Ho7fffvtUDxEAgCqDPXwAAAAAEKZo+AAAAAAgTNHwAQAAAECYouEDAAAAgDDFRVsAADD0Q2ZPJmEHAFQr7OEDAAAAgDBFwwcAAAAAYcr8kM6gZRRzWUHbTFqtZKNaMVEe28z87zYb1arhtx+XJDWv6bbNRHkCRrUiI0qMcrt3bbPNBEvzjGo1aNrYNuMy2K6SFJNQwyhXq05928zefUVGtfILDhjlAgZvQe3atY1qRbjtt0eJ129Uy+szyx0sKbXN+E1W8hhyJaVe+1p+s78BJdey37YOh/13SZIiHWbfE4/DftsGrBijWgAAAKcL9vABAAAAQJii4QMAAACAMMVVOgEAMNR2wqdyesoeOrzt0T6VNBoAAOyxhw8AAAAAwhQNHwAAAACEKRo+AAAAAAhTNHwAAAAAEKZo+AAAAAAgTNHwAQAAAECYMp6WwR3hMsolxkXbZpLi7TOS5Aj6bTMFVqxRrT15DqNcrXj7TRIb6TaqFXD6jHLbdmyzzdSpkWhUq2GzNraZErNh6evVWUa5X3LzbDPxcTWMarndUUa5dZuyDVJmf88IGuRKvfafRUkqKj5olEuqWdM247fMPrO5v+4yysXG23+GIlyWUa2YmBjbTGSkx6iWfHuNYoFi+89ZndrxZstEtdG1a1e1b99e06dPr+yhAABQLbGHDwAAAADCFA0fAOC05fV6K3sIAACcUjR8AIAqobi4WAMGDFBcXJzS0tI0derUMs97vV6NHj1a9erVU2xsrM4//3wtXLiwTGbp0qXq3LmzoqOjlZ6eruHDh6u4uDj0fKNGjTRp0iQNGjRIiYmJGjJkyGHHUlpaqoKCgjI3AACqIxo+AECVcO+992rBggV699139dlnn2nhwoVavXp16PmbbrpJS5Ys0euvv67vvvtO1113nS677DJt3LhRkvT999+rZ8+euuaaa/Tdd9/pjTfe0FdffaVhw4aVWc7jjz+utm3bavXq1Ro/fvxhxzJ58mQlJiaGbunp6aduxQEAOIWML9oCAMCpUlRUpJdeekkvv/yyevToIUmaO3eu6tevL0navHmzXnvtNf3888+qW7euJOmee+7RJ598otmzZ+vvf/+7Hn/8cfXv318jRoyQJDVv3lxPP/20unTpoueff15RUb9dFOqSSy7RPffcc9TxjBkzRiNHjgzdLygooOkDAFRLNHwAgEq3efNmeb1eZWRkhB6rWbOmWrZsKUn65ptvZFmWWrRoUeZ1paWlSk5OliStXr1amzZt0iuvvBJ63rIsBYNBbd26Va1bt5YkdejQwXY8Ho9HHo/hlWYBAKjCaPgAAJXOso4+JUgwGJTL5dLq1avlcpWdJiguLi6Uue222zR8+PByr2/QoEHo/2NjzabzAQAgHNDwAQAqXbNmzeR2u7V8+fJQc5aXl6cNGzaoS5cuOvvssxUIBLRr1y516tTpsDX+9Kc/ad26dWrWrFlFDh0AgCrNuOFzOcwmgU6tnWqwUMMJsUtKbTNp9Rsb1VplMLm5JO13pNhmLFexbUaSEmsFzHIJ9hO5u6PMJpRuZDDxelxislGt2bPmGeUOGLxPBQf3mdU6aLZt3Qaf3NQa9ttVkkr2bbfNFHtM30uzPQfrf9pom/n1191GtQoKi4xySUn2Gy0hNs6olsvy2WbcXrP30nXgF6NcSqz9MhOjzH5OoeqJi4vTLbfconvvvVfJycmqU6eOxo4dK6fzt38vWrRooRtvvFEDBgzQ1KlTdfbZZ2vPnj2aP3++2rVrp969e+u+++7TBRdcoDvvvFNDhgxRbGyssrKy9Pnnn2vGjBmVvIYAAFQO9vABAKqExx9/XEVFRbryyisVHx+vUaNGKT8/P/T87NmzNWnSJI0aNUq//PKLkpOTlZGRod69e0uSzjzzTC1atEhjx45Vp06dZFmWmjZtqr59+1bWKgEAUOlo+AAAVUJcXJzmzZunefP+7+iCe++9N/T/brdbmZmZyszMPGKNc889V5999tkRn9+2bdtJGSsAANUF8/ABAAAAQJii4QMAAACAMEXDBwAAAABhioYPAAAAAMIUF20BAMDQD5k9lZCQUNnDAADAGHv4AAAAACBM0fABAAAAQJgyPqQzMtJjlEuokWqb8QfMFuuJsF9mi8YNjGqtWh1vlCtwN7PNBB2FRrXq1HMb5X7MWmabubDLTUa1li1dbpspLi4wquXz7jHK7dqZY5Ay+9tCkc8sFyGfbaaGc59RrXrR9tsjf/dGo1p+Vw2jXJ3a9rlAwG9U6+DBEqNcycEDtplit9n33B8sss34Sn42qlXbfdAoVzcuxjZT6jerBQAAcLpgDx8AAAAAhCkaPgAAAAAIU1ylEwAAQ20nfCqnx/7wYkCStj3ap7KHAADs4QMAAACAcEXDBwAAAABhioYPAAAAAMIUDR8AAAAAhCkaPgAAAAAIUzR8AIBqp2vXrhoxYkRlDwMAgCrPeFqG2LhYo1yNWrVsM36H2WJLnJG2mai4BKNaSUmJRrnsnJ22mY7nnmFUq6QoaJSLid9lm8n95WejWps2bLDN+ANeo1pOl1FMxQX5tpn45DSjWvn5B4xyiXFRtpmWLdoZ1Vr57XrbzDdZW41qdby4t1HOHWl/WfctmzYa1dpfYLbNggZ/3yk5WGRUq2GdeNtMdKzZpetr1jT7DlsRftuM32sZ1QIAADhdsIcPAAAAAMIUDR8AoEorLi7WgAEDFBcXp7S0NE2dOrXM83l5eRowYIBq1KihmJgY9erVSxs3lt1DPnPmTKWnpysmJkZ//vOf9eSTTyopKakC1wIAgMpBwwcAqNLuvfdeLViwQO+++64+++wzLVy4UKtXrw49P2jQIK1atUrvv/++li1bJsuy1Lt3b/l8PknSkiVLdPvtt+tvf/ub1q5dqx49euiRRx456jJLS0tVUFBQ5gYAQHVkfA4fAAAVraioSC+99JJefvll9ejRQ5I0d+5c1a9fX5K0ceNGvf/++1qyZIkuvPBCSdIrr7yi9PR0vffee7ruuus0Y8YM9erVS/fcc48kqUWLFlq6dKk++OCDIy538uTJyszMPMVrBwDAqccePgBAlbV582Z5vV5lZGSEHqtZs6ZatmwpScrKylJERITOP//80PPJyclq2bKlsrKyJEk//fSTzjvvvDJ1/3j/j8aMGaP8/PzQLScn52StEgAAFYo9fACAKsuyjn7l1SM9b1mWHA5Huf83revxeOTxeI5hpAAAVE3s4QMAVFnNmjWT2+3W8uXLQ4/l5eVpw/+fgqZNmzby+/1asWJF6Pm9e/dqw4YNat26tSSpVatW+vrrr8vUXbVqVQWMHgCAyscePgBAlRUXF6dbbrlF9957r5KTk1WnTh2NHTtWTudvf69s3ry5rrrqKg0ZMkQvvvii4uPjdf/996tevXq66qqrJEl33XWXOnfurCeffFJXXHGF5s+fr48//rjcXj8AAMKRccMX9BtOiF0zzjZTfDBgVOtAwH4SZZfLbCdlg/T6RrkN6+wnu84/YDahelxsA6NcelP7zPYN241q/bJjh20mI+Po564ccuCA2STc8XXr2WZq1m1sVCt7n/0k6JJ0sNT+PYiMrWlUKyEl3TZzdrzZ52f37r1GuW3b19pmig94jWrtzzd7n2qnpNhmEi37z48kNYxLtl9egsuolttRbJTz+g7aZmL5BT4sPf744yoqKtKVV16p+Ph4jRo1Svn5+aHnZ8+erb/97W+6/PLL5fV61blzZ3300Udyu92SpIsuukgvvPCCMjMzNW7cOPXs2VN33323nnnmmcpaJQAAKgx7+AAAVVpcXJzmzZunefPmhR679957Q/9fo0YNvfzyy0etMWTIEA0ZMqTM/WbNmp38wQIAUMXQ8AEAwt4TTzyhHj16KDY2Vh9//LHmzp2r5557rrKHBQDAKUfDBwAIe19//bWmTJmiwsJCNWnSRE8//bQGDx5c2cMCAOCUo+EDAIS9N998s7KHAABApWBaBgAAAAAIU+zhAwDA0A+ZPZWQkFDZwwAAwBh7+AAAAAAgTNHwAQAAAECYouEDAAAAgDBlfA5f4d5co1y022ObKS3xGtVyBO2H53BYRrVq1Uw2ym1wbrHN7NpXbFRrrytolEuMS7XNtGqbaFRry7Zs24wvYFRK+wsOGOWaN29un2nc1KjW9tx8o9y6dd/bZvbuiTGqFemJs83UiIs3qvXzuvVGudw9BbYZhzPSqJYrymxsaelNbDMNHUal1CA+2jYT5fQb1SotMfueBINu24zPb7ZMAACA0wV7+AAAAAAgTHGVTgAADLWd8KmcHrOjB6q7bY/2qewhAABOAvbwAQAAAECYouEDAAAAgDBFwwcAAAAAYYqGDwAAAADCFA0fAAAAAIQpGj4AAAAACFPG0zJs2WQ/IbkkNWje2jYT5TSbeD3oPWibiYiKMqoVZZiLj7efhDsuIcGoVqtWLY1y//3sI9vMgfydRrVikuvYZjb9vMuoVnr9Bka5xi3/ZJvxRJp91Jo0MFvm/n15tpkfszYa1Qpa9pN1/5xn9pktOGg2q31JwGNfa7/ZxPe1U9ONctv32termZ5kVGuvx378Cppts/2Gk6VbEfaTvZcGS41qoXqwLEu33Xab3n77beXl5WnNmjVq3759ZQ8LAIBqhXn4AABV0ieffKI5c+Zo4cKFatKkiWrVqlXZQwIAoNqh4QMAVEmbN29WWlqaLrzwwsM+7/V6FRkZWcGjAgCgeuEcPgBAlTNo0CDdddddys7OlsPhUKNGjdS1a1cNGzZMI0eOVK1atdSjRw9J0qJFi3TeeefJ4/EoLS1N999/v/y/O1S4sLBQN954o2JjY5WWlqZp06apa9euGjFiRCWtHQAAFYeGDwBQ5Tz11FN66KGHVL9+feXm5mrlypWSpLlz5yoiIkJLlizRiy++qF9++UW9e/fWueeeq2+//VbPP/+8XnrpJU2aNClUa+TIkVqyZInef/99ff7551q8eLG++eaboy6/tLRUBQUFZW4AAFRHHNIJAKhyEhMTFR8fL5fLpdTU1NDjzZo105QpU0L3x44dq/T0dD3zzDNyOBxq1aqVduzYofvuu08PPvigiouLNXfuXL366qvq1q2bJGn27NmqW7fuUZc/efJkZWZmnpqVAwCgArGHDwBQbXTo0KHM/aysLGVkZMjhcIQeu+iii1RUVKSff/5ZW7Zskc/n03nnnRd6PjExUS1bHv0qymPGjFF+fn7olpOTc3JXBACACsIePgBAtREbG1vmvmVZZZq9Q49JksPhKPP/h8scicfjkcdk+hEAAKo49vABAKqtNm3aaOnSpWUauKVLlyo+Pl716tVT06ZN5Xa79fXXX4eeLygo0MaNZvN0AgBQ3dHwAQCqraFDhyonJ0d33XWX1q9fr3//+9+aMGGCRo4cKafTqfj4eA0cOFD33nuvFixYoHXr1unmm2+W0+kst9cPAIBwZHxI59pNu4xyDdqeZ5sJqtioluN3l9U+crGjH5ZzSEFhoVFu//49tpnkmu2NavW+7GKjXPuzWtlm3vzfd41qORwu20xiYg2jWvXq1jfKxSUk2WZcfrP3vGaq2UcyrbHPNpMfHWVU65u1a20zuUVmvxha7kSjXGJasm2mVjOzWq4Is/UMWPbr8JMVa5uRpE07A7aZSJfZNjtYUmKUKzb4ceAP2n/+EV7q1aunjz76SPfee6/OOuss1axZU7fccovGjRsXyjz55JO6/fbbdfnllyshIUGjR49WTk6OoqLMvjsAAFRnnMMHAKiSRowYUWauvIULFx4216VLlzKHbP5RfHy8XnnlldD94uJiZWZm6tZbbz1ZQwUAoMqi4QMAhLU1a9Zo/fr1Ou+885Sfn6+HHnpIknTVVVdV8sgAADj1aPgAAGHviSee0E8//aTIyEidc845Wrx4sWrVqlXZwwIA4JSj4QMAhLWzzz5bq1evruxhAABQKbhKJwAAAACEKfbwAQBg6IfMnkpISKjsYQAAYIw9fAAAAAAQpmj4AAAAACBM0fABAAAAQJgyPodvQ360UW5PIN42Y7lLjGo5vfn2tYIus1pOs1zdtNq2mU4X/smoVpQ7YJRr3LCebabPX24wqvX2ux/aZvbstN+ukpSbHzTKlZRsss1Eym9Ua99Bs9ym7TvtQ16fUS0rpZVtpkadGKNaQVlGOYfDbV8rynCZjkijnC9gP7b8gP24JCnKbb/MqAiHUa1ixwGjnM9tPzYraPaeAwAAnC7YwwcAAAAAYYqrdAIAYKjthE/l9JjtfT8R2x7tc8qXAQA4PbCHDwAAAADCFA0fAAAAAIQpGj4AAAAACFM0fAAAAAAQpmj4AAAAACBM0fABACpM165dNWLEiMoeBgAApw3jaRl+2m/WG/77q+9tM+0b1jKqlRoZa5uJcZutQlpqqlmuVoJtpmmT+ka1ZHmNYrm799pmZr1uP6G6JK1e+6NtprTEbFx+sznQJcv+s2EFzJYZ8Nhvf0kKOO0n4Y5QtFEtv8Nln3Ga1Yoy/UZZ9pOSl3jNvnOW02yC84iIKNuMKxg0W2aJ/YfDL7Na7qDZeroc9jmvz2xbAAAAnC7YwwcAqLZ8Pl9lDwEAgCqNhg8AUKGCwaBGjx6tmjVrKjU1VRMnTgw9l52drauuukpxcXFKSEjQ9ddfr19//TX0/MSJE9W+fXvNmjVLTZo0kcfjkWVZevvtt9WuXTtFR0crOTlZ3bt3V3Fxceh1s2fPVuvWrRUVFaVWrVrpueeeq8hVBgCg0hgf0gkAwMkwd+5cjRw5UitWrNCyZcs0aNAgXXTRRerevbuuvvpqxcbGatGiRfL7/Ro6dKj69u2rhQsXhl6/adMmvfnmm3rnnXfkcrm0c+dO9evXT1OmTNGf//xnFRYWavHixbIsS5I0c+ZMTZgwQc8884zOPvtsrVmzRkOGDFFsbKwGDhx42DGWlpaqtLQ0dL+goOCUbhMAAE4VGj4AQIU688wzNWHCBElS8+bN9cwzz+iLL76QJH333XfaunWr0tPTJUnz5s3TGWecoZUrV+rcc8+VJHm9Xs2bN08pKSmSpG+++UZ+v1/XXHONGjZsKElq165daHkPP/ywpk6dqmuuuUaS1LhxY/3444968cUXj9jwTZ48WZmZmadg7QEAqFgc0gkAqFBnnnlmmftpaWnatWuXsrKylJ6eHmr2JKlNmzZKSkpSVlZW6LGGDRuGmj1JOuuss9StWze1a9dO1113nWbOnKm8vDxJ0u7du5WTk6NbbrlFcXFxodukSZO0efPmI45xzJgxys/PD91ycnJO1uoDAFCh2MMHAKhQbnfZq+w6HA4Fg0FZliWHo/yVVv/4eGxs2Ss4u1wuff7551q6dKk+++wzzZgxQ2PHjtWKFSsUExMj6bfDOs8///xyrzsSj8cjj8dzzOsGAEBVwx4+AECV0KZNG2VnZ5fZm/bjjz8qPz9frVu3PuprHQ6HLrroImVmZmrNmjWKjIzUu+++qzp16qhevXrasmWLmjVrVubWuHHjU71KAABUOvbwAQCqhO7du+vMM8/UjTfeqOnTp4cu2tKlSxd16NDhiK9bsWKFvvjiC1166aWqXbu2VqxYod27d4eaxIkTJ2r48OFKSEhQr169VFpaqlWrVikvL08jR46sqNUDAKBS0PABAKoEh8Oh9957T3fddZc6d+4sp9Opyy67TDNmzDjq6xISEvTll19q+vTpKigoUMOGDTV16lT16tVLkjR48GDFxMTo8ccf1+jRoxUbG6t27dppxIgRFbBWAABULod16LrVNtL/50mziv5i20iDRLM+s9c5bWwzTesmGtXasu5ro1znc9vaZjp26mRUq9B35PNDfu+fb35mm3l3wVqjWsUHDhqkyp8jc9iUw+yI32DQ/iPkcPiNagWcZmPzBQ1qBQ1CknwB+5wjwuxcngiX2z4kyeRbFxFhVsvlMvs+/fG8p8OJVMColsEmU8BhNi6vSTFJfp/9Z8gdHW1Ua/ULQ41ywCEFBQVKTExU+og35fTEnPLlbXu0zylfBgCgejv0b1N+fr4SEhKOmOMcPgAAAAAIUzR8AAAAABCmaPgAAAAAIEzR8AEAAABAmKLhAwAAAIAwxbQMAAAY+iGz51GvhAYAQFXDHj4AAAAACFM0fAAAAAAQpmj4AAAAACBMGZ/Dl1wrxSi3L8+yzeTm7TeqtfTb9baZgK+hUS0p0iiVklrfNuNweYxqfb3qB6Pch/OX2WZKgzFGtRRhPzan8+T2+YFSr23GCtp/LiQpGAwY5SzLvl7AchjVckfYfw0cLpdRLbnMPmcRBvVcLrOvZ3x8nFHOZfC+uyyfUa2AZV8rKLdRLQWCRrG01ETbTHyCfQYAAOB0wkVbAAAw1HbCp3J6DP8Ahypr26N9KnsIAFBhOKQTAAAAAMIUDR8AAAAAhCkaPgAAAAAIUzR8AAAAABCmaPgAAAAAIEzR8AEAAABAmKLhAwBUG4MGDdLVV1991EyjRo00ffr0ChkPAABVnfE8fCYTRUuS220/8be/xGxy6q2/FthmSouzjGp1/lMLo1x0UpptJr/EbKLoRStWGeUOWn7bjM9vNiG2xxNlmwkGzcZ/4MABo5wJl8Pso+YwmytdMpjH3WM4cbnDaZAzyUhyGM7PFR0dbZuJMJgQXpJ8PvvPjyQVFhfbZgJBgw0rqdRv/xlKrFHLqFZqmlkuLsp+exwsLDSqhfC2cuVKxcbGVvYwAACoEph4HQAQVlJSUip7CAAAVBkc0gkAqHLefvtttWvXTtHR0UpOTlb37t1V/Lu91E888YTS0tKUnJysO++8Uz7f/x0F8cdDOh0Oh55//nn16tVL0dHRaty4sd56662KXB0AACoNDR8AoErJzc1Vv379dPPNNysrK0sLFy7UNddcI8v67ZDjBQsWaPPmzVqwYIHmzp2rOXPmaM6cOUetOX78eF177bX69ttv9T//8z/q16+fsrKOfEpAaWmpCgoKytwAAKiOaPgAAFVKbm6u/H6/rrnmGjVq1Ejt2rXT0KFDFRcXJ0mqUaOGnnnmGbVq1UqXX365+vTpoy+++OKoNa+77joNHjxYLVq00MMPP6wOHTpoxowZR8xPnjxZiYmJoVt6evpJXUcAACoKDR8AoEo566yz1K1bN7Vr107XXXedZs6cqby8vNDzZ5xxhly/u5BYWlqadu3addSaGRkZ5e4fbQ/fmDFjlJ+fH7rl5OQc59oAAFC5aPgAAFWKy+XS559/ro8//lht2rTRjBkz1LJlS23dulWS5Ha7y+QdDofx1Yf/+Loj8Xg8SkhIKHMDAKA6ouEDAFQ5DodDF110kTIzM7VmzRpFRkbq3XffPe56y5cvL3e/VatWJzpMAACqPKZlAABUKStWrNAXX3yhSy+9VLVr19aKFSu0e/dutW7dWt99991x1XzrrbfUoUMHdezYUa+88oq+/vprvfTSSyd55AAAVD00fACAKiUhIUFffvmlpk+froKCAjVs2FBTp05Vr1699MYbbxxXzczMTL3++usaOnSoUlNT9corr6hNmzYneeQAAFQ9xg1f0B8wC1r2R4kGXVFGpbxy2WZ+LSo1qvXNTzuMcr0PWLaZQqvQqNYveWa5qP9/5bmj8R+w3xaSVFJqvz1iYqKNakW4zT4eJst0OM3G73SY5dwR9mOznGbjtwyObHZ7zD6zRT6z74nXX2ybiY42e58OXareTqnf/hyn4hKvUa24pFq2mRopqUa1vH6zZa5fv9424w4a/pxClda6dWt98sknh33ucNMv/H7OPUnatm1buUzdunX12WefnYTRAQBQvXAOHwAAAACEKRo+AAAAAAhTnMMHAAhrpoc9AwAQjtjDBwAAAABhij18AAAY+iGzJ5OwAwCqFfbwAQAAAECYouEDAAAAgDBFwwcAAAAAYcr8HL6g4VXOLPvJnV0ut+Ei7SfhDjjNam3dZTYJ+qw3P7LNXNK1g9kyd+w2yhUHDCarN+zN3VGRthlXpH1GkmJcZsuMjLaflPxgof1E45Lk8/mNcpbBJOLuKLOPtyvC/nNmOi6Xy2zi+KDB9+nggaKTVksyG1tSjZpGtZLrpNlmdu/dZ1Rr/56dZrntG20zzZo0NqoFAABwumAPHwAAAACEKa7SCQCAobYTPpXTE1PZw9C2R/tU9hAAANUEe/gAAAAAIEzR8AEAAABAmKLhAwAAAIAwRcMHAAAAAGGKhg8AAAAAwhQNHwAgrG3btk0Oh0Nr166t7KEAAFDhaPgAAJWia9euGjFiRGUPAwCAsGY8D19yUpJRrqSk0DZTfNBrVCvSFW2b8fuDRrWcbo9RbtHX39lmtu7YYVRrf7HPKLev6KBtxm+2yRQbG2dfK2i2zTwes20WERlpm4mKDhjVcjldZst02y8zYPj3DH/Qss04DDKSZFlm6xnw2X82vD6zNz06KsooVys52TZTs1aaUS2vZb9tSyPNfrwc9Ni/l5IUdLttM8Ul9t8lVB+WZSkQCCgigiljAQA4XuzhAwBUuEGDBmnRokV66qmn5HA45HA4NGfOHDkcDn366afq0KGDPB6PFi9erEGDBunqq68u8/oRI0aoa9euofvBYFCPPfaYmjVrJo/HowYNGuiRRx457LKDwaCGDBmiFi1aaPv27adwLQEAqHz82RQAUOGeeuopbdiwQW3bttVDDz0kSVq3bp0kafTo0XriiSfUpEkTJRkeXTJmzBjNnDlT06ZNU8eOHZWbm6v169eXy3m9XvXv31+bN2/WV199pdq1ax+2XmlpqUpLS0P3CwoKjnENAQCoGmj4AAAVLjExUZGRkYqJiVFqaqokhRq0hx56SD169DCuVVhYqKeeekrPPPOMBg4cKElq2rSpOnbsWCZXVFSkPn366ODBg1q4cKESExOPWHPy5MnKzMw81tUCAKDK4ZBOAECV0qFDh2PKZ2VlqbS0VN26dTtqrl+/fioqKtJnn3121GZP+m2PYX5+fuiWk5NzTGMCAKCqoOEDAFQpsbGxZe47nU5ZVtkLJ/l+d+Gj6Gj7C3xJUu/evfXdd99p+fLltlmPx6OEhIQyNwAAqiMaPgBApYiMjFQgYH9l25SUFOXm5pZ57Pdz6jVv3lzR0dH64osvjlrnjjvu0KOPPqorr7xSixYtOq4xAwBQ3XAOHwCgUjRq1EgrVqzQtm3bFBcXp+ARpoy55JJL9Pjjj+vll19WRkaG/vWvf+mHH37Q2WefLUmKiorSfffdp9GjRysyMlIXXXSRdu/erXXr1umWW24pU+uuu+5SIBDQ5Zdfro8//rjceX4AAIQb9vABACrFPffcI5fLpTZt2iglJUXZ2dmHzfXs2VPjx4/X6NGjde6556qwsFADBgwokxk/frxGjRqlBx98UK1bt1bfvn21a9euw9YbMWKEMjMz1bt3by1duvSkrxcAAFWJw/rjiRFH0GP8+0YFf9lpf2J7cVGxUS2PwcTrlr/UNiNJkU6znHVgr22mQf1aRrV+3WdfS6r4idf/eH7MkZhOvO502v/dwHfAbELsqjrxesBw4nWf2ddJXm8lTLyekmKbOZkTr+/LLzSqtW/v4X8p/6PcrRtsM/VS7CeXl6T1b040ygGHFBQUKDExUekj3pTTE1PZw9G2R/tU9hAAAJXs0L9N+fn5Rz3X3PiQzpISs1/YPQa/Y5cG7H/ZlSS3y/6Xer9ZfyDLoCmRJGe0fcO0bcdus1oRZoPz++ybBL//8Ic6/VFJSYltprjYrOE2aeQks8YwNtJtVCs62qx5cTrtt4cnyqxhjY6xf8+9Xr9Rrd379hnlgrKvF+E22/41Eswa+NSaSfaZ1JpGtfYX2/8BpWB/nlGtovz9RrmkmvZj27N7j1EtAACA0wWHdAIAAABAmKLhAwAAAIAwRcMHAAAAAGGKhg8AAAAAwhTz8AEAYOiHzJ5HvRIaAABVDXv4AAAAACBM0fABAAAAQJii4QMAAACAMGV8Dl/pQfsJvSXJ43LYZmIMlxr02U/27jCceD0os4nLg5Z9LijDCdW99hOqS5IVsN9mlmVYyyAXDJptC9OJ1/P22U+wvc/gvZSkhHizScQTa9hPwp3gMht/lOwnew8E7Scal6QIR8Ao5/LYf4ZKS8yWGRVh//mRzMbmP5BvVMt/wH5sRfv3GtUK+rxGuSiP2zZT4jL8gQAAAHCaYA8fAAAAAIQpGj4AAAAACFM0fAAAAAAQpmj4AAAAACBM0fABAAAAQJii4QMAAACAMEXDBwAAAABhioYPAAAAAMKU8cTrAACcrizLkiQVFBRU8kgAAPjNoX+TDv0bdSQOyy4BAMBpbsuWLWratGllDwMAgHJycnJUv379Iz7PHj4AAGzUrFlTkpSdna3ExMRKHk31VFBQoPT0dOXk5CghIaGyh1NtsR1PHNvwxLENT44T3Y6WZamwsFB169Y9ao6GDwAAG07nb6e8JyYm8svNCUpISGAbngRsxxPHNjxxbMOT40S2o8kfIbloCwAAAACEKRo+AAAAAAhTNHwAANjweDyaMGGCPB5PZQ+l2mIbnhxsxxPHNjxxbMOTo6K2I1fpBAAAAIAwxR4+AAAAAAhTNHwAAAAAEKZo+AAAAAAgTNHwAQAAAECYouEDAEDSc889p8aNGysqKkrnnHOOFi9efNT8okWLdM455ygqKkpNmjTRCy+8UEEjrbqOZRvm5uaqf//+atmypZxOp0aMGFFxA63CjmUb/u///q969OihlJQUJSQkKCMjQ59++mkFjrbqOpbt+NVXX+miiy5ScnKyoqOj1apVK02bNq0CR1s1HevPxEOWLFmiiIgItW/f/tQOsJo4lu24cOFCORyOcrf169ef0Bho+AAAp7033nhDI0aM0NixY7VmzRp16tRJvXr1UnZ29mHzW7duVe/evdWpUyetWbNGDzzwgIYPH6533nmngkdedRzrNiwtLVVKSorGjh2rs846q4JHWzUd6zb88ssv1aNHD3300UdavXq1Lr74Yl1xxRVas2ZNBY+8ajnW7RgbG6thw4bpyy+/VFZWlsaNG6dx48bpH//4RwWPvOo41m14SH5+vgYMGKBu3bpV0EirtuPdjj/99JNyc3NDt+bNm5/QOJiWAQBw2jv//PP1pz/9Sc8//3zosdatW+vqq6/W5MmTy+Xvu+8+vf/++8rKygo9dvvtt+vbb7/VsmXLKmTMVc2xbsPf69q1q9q3b6/p06ef4lFWbSeyDQ8544wz1LdvXz344IOnaphV3snYjtdcc41iY2M1b968UzXMKu14t+ENN9yg5s2by+Vy6b333tPatWsrYLRV17Fux4ULF+riiy9WXl6ekpKSTto42MMHADiteb1erV69WpdeemmZxy+99FItXbr0sK9ZtmxZuXzPnj21atUq+Xy+UzbWqup4tiHKOhnbMBgMqrCwUDVr1jwVQ6wWTsZ2XLNmjZYuXaouXbqciiFWece7DWfPnq3NmzdrwoQJp3qI1cKJfBbPPvtspaWlqVu3blqwYMEJjyXihCsAAFCN7dmzR4FAQHXq1CnzeJ06dbRz587Dvmbnzp2Hzfv9fu3Zs0dpaWmnbLxV0fFsQ5R1Mrbh1KlTVVxcrOuvv/5UDLFaOJHtWL9+fe3evVt+v18TJ07U4MGDT+VQq6zj2YYbN27U/fffr8WLFysigvZCOr7tmJaWpn/84x8655xzVFpaqnnz5qlbt25auHChOnfufNxj4R0BAECSw+Eoc9+yrHKP2eUP9/jp5Fi3Ico73m342muvaeLEifr3v/+t2rVrn6rhVRvHsx0XL16soqIiLV++XPfff7+aNWumfv36ncphVmmm2zAQCKh///7KzMxUixYtKmp41caxfBZbtmypli1bhu5nZGQoJydHTzzxBA0fAADHq1atWnK5XOX+4rpr165yf5k9JDU19bD5iIgIJScnn7KxVlXHsw1R1olswzfeeEO33HKL3nrrLXXv3v1UDrPKO5Ht2LhxY0lSu3bt9Ouvv2rixImnZcN3rNuwsLBQq1at0po1azRs2DBJvx1ebFmWIiIi9Nlnn+mSSy6pkLFXJSfr5+IFF1ygf/3rXyc0Fs7hAwCc1iIjI3XOOefo888/L/P4559/rgsvvPCwr8nIyCiX/+yzz9ShQwe53e5TNtaq6ni2Ico63m342muvadCgQXr11VfVp0+fUz3MKu9kfRYty1JpaenJHl61cKzbMCEhQd9//73Wrl0but1+++1q2bKl1q5dq/PPP7+ihl6lnKzP4po1a078NAELAIDT3Ouvv2653W7rpZdesn788UdrxIgRVmxsrLVt2zbLsizr/vvvt/7617+G8lu2bLFiYmKsu+++2/rxxx+tl156yXK73dbbb79dWatQ6Y51G1qWZa1Zs8Zas2aNdc4551j9+/e31qxZY61bt64yhl8lHOs2fPXVV62IiAjr2WeftXJzc0O3/fv3V9YqVAnHuh2feeYZ6/3337c2bNhgbdiwwZo1a5aVkJBgjR07trJWodIdz/f59yZMmGCdddZZFTTaqutYt+O0adOsd99919qwYYP1ww8/WPfff78lyXrnnXdOaBwc0gkAOO317dtXe/fu1UMPPaTc3Fy1bdtWH330kRo2bCjpt0nCfz9vUuPGjfXRRx/p7rvv1rPPPqu6devq6aef1rXXXltZq1DpjnUbSr9die6Q1atX69VXX1XDhg21bdu2ihx6lXGs2/DFF1+U3+/XnXfeqTvvvDP0+MCBAzVnzpyKHn6VcazbMRgMasyYMdq6dasiIiLUtGlTPfroo7rtttsqaxUq3fF8n1HesW5Hr9ere+65R7/88ouio6N1xhln6MMPP1Tv3r1PaBzMwwcAAAAAYYpz+AAAAAAgTNHwAQAAAECYouEDAAAAgDBFwwcAAAAAYYqGDwAAAADCFA0fAAAAAIQpGj4AAAAACFM0fAAAAAAQpmj4AAAAcMwmTpyo9u3bn3Adh8Oh995774jPb9u2TQ6HQ2vXrpUkLVy4UA6HQ/v375ckzZkzR0lJSSc8DiBc0fABAACEuUGDBsnhcMjhcMjtdqtJkya65557VFxcXNlDs5Wenq7c3Fy1bdv2sM/37dtXGzZsCN0/WY0oEC4iKnsAAAAAOPUuu+wyzZ49Wz6fT4sXL9bgwYNVXFys559/vkzO5/PJ7XZX0ijLc7lcSk1NPeLz0dHRio6OrsARAdULe/gAAABOAx6PR6mpqUpPT1f//v1144036r333gvtEZs1a5aaNGkij8cjy7KUnZ2tq666SnFxcUpISND111+vX3/9tVzdF198Uenp6YqJidF1110XOtRSklauXKkePXqoVq1aSkxMVJcuXfTNN9+Uq5Gbm6tevXopOjpajRs31ltvvRV67o+HdP7R7w/pnDNnjjIzM/Xtt9+G9mjOmTNHN998sy6//PIyr/P7/UpNTdWsWbOOfWMC1QgNHwAAwGkoOjpaPp9PkrRp0ya9+eabeuedd0KN1dVXX619+/Zp0aJF+vzzz7V582b17du3TI1Dr/vPf/6jTz75RGvXrtWdd94Zer6wsFADBw7U4sWLtXz5cjVv3ly9e/dWYWFhmTrjx4/Xtddeq2+//Vb/8z//o379+ikrK+uY16lv374aNWqUzjjjDOXm5io3N1d9+/bV4MGD9cknnyg3NzeU/eijj1RUVKTrr7/+mJcDVCcc0gkAAHCa+frrr/Xqq6+qW7dukiSv16t58+YpJSVFkvT555/ru+++09atW5Weni5Jmjdvns444wytXLlS5557riSppKREc+fOVf369SVJM2bMUJ8+fTR16lSlpqbqkksuKbPcF198UTVq1NCiRYvK7HG77rrrNHjwYEnSww8/rM8//1wzZszQc889d0zrFR0drbi4OEVERJQ5DPTCCy9Uy5YtNW/ePI0ePVqSNHv2bF133XWKi4s7pmUA1Q17+AAAAE4DH3zwgeLi4hQVFaWMjAx17txZM2bMkCQ1bNgw1OxJUlZWltLT00PNniS1adNGSUlJZfa8NWjQINTsSVJGRoaCwaB++uknSdKuXbt0++23q0WLFkpMTFRiYqKKioqUnZ1dZmwZGRnl7h/PHr6jGTx4sGbPnh0a14cffqibb775pC4DqIrYwwcAAHAauPjii/X888/L7Xarbt26ZS7MEhsbWyZrWZYcDke5Gkd6/JBDzx3676BBg7R7925Nnz5dDRs2lMfjUUZGhrxer+14j7ac4zFgwADdf//9WrZsmZYtW6ZGjRqpU6dOJ3UZQFXEHj4AAIDTQGxsrJo1a6aGDRvaXoWzTZs2ys7OVk5OTuixH3/8Ufn5+WrdunXosezsbO3YsSN0f9myZXI6nWrRooUkafHixRo+fLh69+6tM844Qx6PR3v27Cm3vOXLl5e736pVq+Naz8jISAUCgXKPJycn6+qrr9bs2bM1e/Zs3XTTTcdVH6hu2MMHAACAMrp3764zzzxTN954o6ZPny6/36+hQ4eqS5cu6tChQygXFRWlgQMH6oknnlBBQYGGDx+u66+/PnT+XLNmzTRv3jx16NBBBQUFuvfeew87hcJbb72lDh06qGPHjnrllVf09ddf66WXXjqusTdq1Ehbt27V2rVrVb9+fcXHx8vj8Uj67bDOyy+/XIFAQAMHDjyu+kB1wx4+AAAAlOFwOPTee++pRo0a6ty5s7p3764mTZrojTfeKJNr1qyZrrnmGvXu3VuXXnqp2rZtW+ZCK7NmzVJeXp7OPvts/fWvf9Xw4cNVu3btcsvLzMzU66+/rjPPPFNz587VK6+8ojZt2hzX2K+99lpddtlluvjii5WSkqLXXnst9Fz37t2Vlpamnj17qm7dusdVH6huHJZlWZU9CAAAAOBUO3DggOrWratZs2bpmmuuqezhABWCQzoBAAAQ1oLBoHbu3KmpU6cqMTFRV155ZWUPCagwNHwAAAAIa9nZ2WrcuLHq16+vOXPmKCKCX4Fx+uCQTgAAAAAIU1y0BQAAAADCFA0fAAAAAIQpGj4AAAAACFM0fAAAAAAQpmj4AAAAACBM0fABAAAAQJii4QMAAACAMEXDBwAAAABh6v8Bup5OaO+eLnwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 2 (Ground Truth: ship):\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 3 (Ground Truth: ship):\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 4 (Ground Truth: plane):\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate function with image and class probabilities display\n",
    "def evaluate(testloader, model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_probs = []\n",
    "    sample_images = []\n",
    "    sample_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Get class probabilities for the first batch\n",
    "            if len(class_probs) == 0:\n",
    "                class_probs.append(torch.softmax(outputs, dim=1).cpu().numpy())\n",
    "                sample_images.append(images.cpu())\n",
    "                sample_labels.append(labels.cpu())\n",
    "    \n",
    "    print(f'Accuracy of the network on the 10000 test images: {(100 * correct / total):.2f}%')\n",
    "    \n",
    "    # Display class probabilities for some images in the first batch\n",
    "    batch_probs = class_probs[0]\n",
    "    sample_images = sample_images[0]\n",
    "    sample_labels = sample_labels[0]\n",
    "    for i in range(4):  # Change this to display more/fewer images\n",
    "        image = (sample_images[i] / 2 + 0.5).numpy().transpose((1, 2, 0))\n",
    "        print(f\"\\nImage {i+1} (Ground Truth: {classes[sample_labels[i]]}):\")\n",
    "        show_image_and_probs(image, batch_probs[i])\n",
    "\n",
    "# Function to show image along with class probabilities\n",
    "def show_image_and_probs(image, probs):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # Show image\n",
    "    ax1.imshow(image)\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # Show class probabilities\n",
    "    y_pos = numpy.arange(len(classes))\n",
    "    ax2.barh(y_pos, probs, align='center')\n",
    "    ax2.set_yticks(y_pos)\n",
    "    ax2.set_yticklabels(classes)\n",
    "    ax2.invert_yaxis()\n",
    "    ax2.set_xlabel('Probability')\n",
    "    ax2.set_title('Class Probabilities')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate(testloader, net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e9e265-59a0-47de-a307-2b932192fbe3",
   "metadata": {},
   "source": [
    "## Ensemble - Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afa3c857-f6b2-4443-9bc6-befc156caa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble evaluation function\n",
    "def evaluate_ensemble(valloader, ensemble, ensemble_weights):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in valloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            ensemble_output = torch.zeros([labels.shape[0], 10]).to(device)\n",
    "            for model, weight in zip(ensemble, ensemble_weights):\n",
    "                outputs = model(images)\n",
    "                ensemble_output += weight * outputs\n",
    "            _, predicted = torch.max(ensemble_output.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "def reset_model_weights(model):\n",
    "    for layer in model.children():\n",
    "        if hasattr(layer, 'reset_parameters'):\n",
    "            layer.reset_parameters()\n",
    "        else:\n",
    "            for sub_layer in layer.children():\n",
    "                if hasattr(sub_layer, 'reset_parameters'):\n",
    "                    sub_layer.reset_parameters()\n",
    "\n",
    "class IndexedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, original_dataset):\n",
    "        self.original_dataset = original_dataset\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data, label = self.original_dataset[index]\n",
    "        return data, label, index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.original_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6b32446-b064-4b02-a384-b26694ec116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epochs = 100\n",
    "lr = 0.001\n",
    "batch_size = 128\n",
    "n_ensemble = 15\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = ResNet_cifar10().to(device)\n",
    "bin_op = BinOp(net)\n",
    "criterion = WeightedLoss(aggregate='normal_ce_mean')\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "def train_with_ensemble(trainloader, valloader, model, criterion, optimizer, epochs, n_ensemble=3):\n",
    "    ensemble_models = []\n",
    "    ensemble_weights = []\n",
    "    best_ensemble_accuracy = 0.0\n",
    "    \n",
    "    weights = torch.ones(len(trainloader.dataset)).to(device)\n",
    "    \n",
    "    for ensemble_count in range(n_ensemble):\n",
    "        print(f\"Training model {ensemble_count + 1} in the ensemble...\")\n",
    "        \n",
    "        # Update the weighted random sampler\n",
    "        # new_trainloader = DataLoader(trainloader.dataset, batch_size=trainloader.batch_size, sampler=sampler)\n",
    "        sampler = WeightedRandomSampler(weights, len(trainloader.dataset))\n",
    "        indexed_train_dataset = IndexedDataset(trainloader.dataset)\n",
    "        new_trainloader = DataLoader(indexed_train_dataset, batch_size=trainloader.batch_size, sampler=sampler)\n",
    "        \n",
    "        # Reset model weights if needed\n",
    "        reset_model_weights(model)\n",
    "        \n",
    "        # Train the model\n",
    "        loss_list = []\n",
    "        for epoch in range(epochs):\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(new_trainloader, 0):\n",
    "                inputs, labels, indices = data[0].to(device), data[1].to(device), data[2]\n",
    "                # inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                \n",
    "                bin_op.binarization()\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                bin_op.restore()\n",
    "                bin_op.updateBinaryGradWeight()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                if i % 100 == 99:\n",
    "                    avg_loss = running_loss / 100\n",
    "                    print(f\"[{epoch + 1}, {i + 1}] loss: {avg_loss}\")\n",
    "                    loss_list.append(avg_loss)\n",
    "                    running_loss = 0.0\n",
    "        \n",
    "        # Evaluate the trained model\n",
    "        model_accuracy = evaluate_ensemble(valloader, [model], [1.0])\n",
    "        ensemble_weights.append(model_accuracy)\n",
    "        \n",
    "        # Save this model to the ensemble\n",
    "        ensemble_models.append(deepcopy(model.state_dict()))\n",
    "        \n",
    "        # Update the weights for misclassified samples\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(new_trainloader, 0):  # Use new_trainloader instead of trainloader\n",
    "                inputs, labels, indices = data[0].to(device), data[1].to(device), data[2].to(device)  # Get indices as well, and move to device\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                wrong_idx = (predicted != labels)\n",
    "                weights[indices[wrong_idx]] += 1.0  # Use indices to update weights\n",
    "\n",
    "        \n",
    "        # Evaluate the ensemble\n",
    "        temp_ensemble = [deepcopy(model) for _ in range(len(ensemble_models))]\n",
    "        for idx, state_dict in enumerate(ensemble_models):\n",
    "            temp_ensemble[idx].load_state_dict(state_dict)\n",
    "        \n",
    "        new_ensemble_accuracy = evaluate_ensemble(valloader, temp_ensemble, ensemble_weights)\n",
    "        \n",
    "        if new_ensemble_accuracy > best_ensemble_accuracy:\n",
    "            best_ensemble_accuracy = new_ensemble_accuracy\n",
    "        else:\n",
    "            ensemble_models.pop()\n",
    "            ensemble_weights.pop()\n",
    "        \n",
    "        # Normalize ensemble_weights\n",
    "        total_weight = sum(ensemble_weights)\n",
    "        ensemble_weights = [weight / total_weight for weight in ensemble_weights]\n",
    "        \n",
    "    return ensemble_models, ensemble_weights, loss_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ac7b49d-3093-4d7f-b1bd-eba698bca0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1 in the ensemble...\n",
      "[1, 100] loss: 2.006722775697708\n",
      "[1, 200] loss: 1.7332350504398346\n",
      "[1, 300] loss: 1.6074615716934204\n",
      "[2, 100] loss: 1.4906680417060851\n",
      "[2, 200] loss: 1.4518804669380188\n",
      "[2, 300] loss: 1.4290614938735962\n",
      "[3, 100] loss: 1.3502173840999603\n",
      "[3, 200] loss: 1.3122076559066773\n",
      "[3, 300] loss: 1.3172829377651214\n",
      "[4, 100] loss: 1.2734989786148072\n",
      "[4, 200] loss: 1.2571490693092346\n",
      "[4, 300] loss: 1.218780288696289\n",
      "[5, 100] loss: 1.1904665428400039\n",
      "[5, 200] loss: 1.159200234413147\n",
      "[5, 300] loss: 1.1502898907661439\n",
      "[6, 100] loss: 1.1237745624780655\n",
      "[6, 200] loss: 1.0963569784164429\n",
      "[6, 300] loss: 1.1009120672941208\n",
      "[7, 100] loss: 1.0797655946016311\n",
      "[7, 200] loss: 1.0900293576717377\n",
      "[7, 300] loss: 1.0432571029663087\n",
      "[8, 100] loss: 1.0391670686006547\n",
      "[8, 200] loss: 1.0500499820709228\n",
      "[8, 300] loss: 1.0195243161916734\n",
      "[9, 100] loss: 0.9964167886972427\n",
      "[9, 200] loss: 0.9954298990964889\n",
      "[9, 300] loss: 0.9954108536243439\n",
      "[10, 100] loss: 0.9712593585252762\n",
      "[10, 200] loss: 0.9531056910753251\n",
      "[10, 300] loss: 0.9619531154632568\n",
      "[11, 100] loss: 0.9550533854961395\n",
      "[11, 200] loss: 0.9475804597139359\n",
      "[11, 300] loss: 0.948477846980095\n",
      "[12, 100] loss: 0.94501021027565\n",
      "[12, 200] loss: 0.9306194967031479\n",
      "[12, 300] loss: 0.9243316924571991\n",
      "[13, 100] loss: 0.9135115897655487\n",
      "[13, 200] loss: 0.9130245929956436\n",
      "[13, 300] loss: 0.922678342461586\n",
      "[14, 100] loss: 0.9234513294696808\n",
      "[14, 200] loss: 0.9081124353408814\n",
      "[14, 300] loss: 0.9005094003677369\n",
      "[15, 100] loss: 0.8992944371700287\n",
      "[15, 200] loss: 0.8920071280002594\n",
      "[15, 300] loss: 0.8868879640102386\n",
      "[16, 100] loss: 0.87846744120121\n",
      "[16, 200] loss: 0.878916574716568\n",
      "[16, 300] loss: 0.8850010567903519\n",
      "[17, 100] loss: 0.8862333160638809\n",
      "[17, 200] loss: 0.8675326830148697\n",
      "[17, 300] loss: 0.8375166088342667\n",
      "[18, 100] loss: 0.8696473091840744\n",
      "[18, 200] loss: 0.854011579155922\n",
      "[18, 300] loss: 0.8522726833820343\n",
      "[19, 100] loss: 0.841956193447113\n",
      "[19, 200] loss: 0.8406405121088028\n",
      "[19, 300] loss: 0.8585343271493912\n",
      "[20, 100] loss: 0.8402776318788528\n",
      "[20, 200] loss: 0.8345997279882431\n",
      "[20, 300] loss: 0.8150677788257599\n",
      "[21, 100] loss: 0.8325006830692291\n",
      "[21, 200] loss: 0.805223612189293\n",
      "[21, 300] loss: 0.8156328773498536\n",
      "[22, 100] loss: 0.841244775056839\n",
      "[22, 200] loss: 0.8019380897283555\n",
      "[22, 300] loss: 0.811157488822937\n",
      "[23, 100] loss: 0.8101706463098526\n",
      "[23, 200] loss: 0.798348748087883\n",
      "[23, 300] loss: 0.8065321946144104\n",
      "[24, 100] loss: 0.8089990162849426\n",
      "[24, 200] loss: 0.8219597953557968\n",
      "[24, 300] loss: 0.7943671476840973\n",
      "[25, 100] loss: 0.7976776248216629\n",
      "[25, 200] loss: 0.802121787071228\n",
      "[25, 300] loss: 0.7997474026679993\n",
      "[26, 100] loss: 0.7819100975990295\n",
      "[26, 200] loss: 0.7911500227451325\n",
      "[26, 300] loss: 0.7846614027023315\n",
      "[27, 100] loss: 0.7788503217697144\n",
      "[27, 200] loss: 0.7728978288173676\n",
      "[27, 300] loss: 0.7574391490221024\n",
      "[28, 100] loss: 0.7624603962898254\n",
      "[28, 200] loss: 0.7730885583162308\n",
      "[28, 300] loss: 0.7711778032779694\n",
      "[29, 100] loss: 0.7675645345449448\n",
      "[29, 200] loss: 0.7506730425357818\n",
      "[29, 300] loss: 0.7655577516555786\n",
      "[30, 100] loss: 0.7619430738687515\n",
      "[30, 200] loss: 0.7467923474311828\n",
      "[30, 300] loss: 0.7584840559959412\n",
      "[31, 100] loss: 0.7552366083860398\n",
      "[31, 200] loss: 0.762770379781723\n",
      "[31, 300] loss: 0.746473098397255\n",
      "[32, 100] loss: 0.7696650451421738\n",
      "[32, 200] loss: 0.7552141225337983\n",
      "[32, 300] loss: 0.7676357799768447\n",
      "[33, 100] loss: 0.764251149892807\n",
      "[33, 200] loss: 0.7540641701221467\n",
      "[33, 300] loss: 0.7535985952615738\n",
      "[34, 100] loss: 0.7508577620983123\n",
      "[34, 200] loss: 0.7488600122928619\n",
      "[34, 300] loss: 0.7320806807279587\n",
      "[35, 100] loss: 0.7563969546556473\n",
      "[35, 200] loss: 0.749716208577156\n",
      "[35, 300] loss: 0.7430561101436615\n",
      "[36, 100] loss: 0.7470390409231186\n",
      "[36, 200] loss: 0.7306307548284531\n",
      "[36, 300] loss: 0.7347683995962143\n",
      "[37, 100] loss: 0.74145494222641\n",
      "[37, 200] loss: 0.7558814597129822\n",
      "[37, 300] loss: 0.7313699585199356\n",
      "[38, 100] loss: 0.7207793599367142\n",
      "[38, 200] loss: 0.7284715241193771\n",
      "[38, 300] loss: 0.7252656334638595\n",
      "[39, 100] loss: 0.713737781047821\n",
      "[39, 200] loss: 0.7229461079835892\n",
      "[39, 300] loss: 0.7230750185251236\n",
      "[40, 100] loss: 0.739565497636795\n",
      "[40, 200] loss: 0.7349912792444229\n",
      "[40, 300] loss: 0.7244191920757294\n",
      "[41, 100] loss: 0.7312265247106552\n",
      "[41, 200] loss: 0.7116385328769684\n",
      "[41, 300] loss: 0.7195898360013961\n",
      "[42, 100] loss: 0.7282140535116196\n",
      "[42, 200] loss: 0.7263935002684593\n",
      "[42, 300] loss: 0.7063334667682648\n",
      "[43, 100] loss: 0.7111118125915528\n",
      "[43, 200] loss: 0.7214632490277291\n",
      "[43, 300] loss: 0.7167012536525726\n",
      "[44, 100] loss: 0.7226410019397735\n",
      "[44, 200] loss: 0.6955991446971893\n",
      "[44, 300] loss: 0.7208794319629669\n",
      "[45, 100] loss: 0.7016499799489975\n",
      "[45, 200] loss: 0.7013212549686432\n",
      "[45, 300] loss: 0.6989694133400917\n",
      "[46, 100] loss: 0.6875034466385841\n",
      "[46, 200] loss: 0.7065081411600113\n",
      "[46, 300] loss: 0.6853608351945877\n",
      "[47, 100] loss: 0.6920593315362931\n",
      "[47, 200] loss: 0.7089727449417115\n",
      "[47, 300] loss: 0.6857706826925277\n",
      "[48, 100] loss: 0.6972514450550079\n",
      "[48, 200] loss: 0.6967105963826179\n",
      "[48, 300] loss: 0.6941173195838928\n",
      "[49, 100] loss: 0.6804865229129792\n",
      "[49, 200] loss: 0.6949722379446029\n",
      "[49, 300] loss: 0.7104650470614433\n",
      "[50, 100] loss: 0.682807754278183\n",
      "[50, 200] loss: 0.6982708391547203\n",
      "[50, 300] loss: 0.7026959979534149\n",
      "[51, 100] loss: 0.6875330710411072\n",
      "[51, 200] loss: 0.679961410164833\n",
      "[51, 300] loss: 0.674673290848732\n",
      "[52, 100] loss: 0.6729341393709183\n",
      "[52, 200] loss: 0.6683853158354759\n",
      "[52, 300] loss: 0.675549248456955\n",
      "[53, 100] loss: 0.6556977462768555\n",
      "[53, 200] loss: 0.6764541578292846\n",
      "[53, 300] loss: 0.665648255944252\n",
      "[54, 100] loss: 0.6699181520938873\n",
      "[54, 200] loss: 0.6695270764827729\n",
      "[54, 300] loss: 0.6708344802260399\n",
      "[55, 100] loss: 0.6762119114398957\n",
      "[55, 200] loss: 0.6781040751934051\n",
      "[55, 300] loss: 0.6668140721321106\n",
      "[56, 100] loss: 0.6632588443160057\n",
      "[56, 200] loss: 0.6658176919817924\n",
      "[56, 300] loss: 0.6742112225294113\n",
      "[57, 100] loss: 0.6758438590168953\n",
      "[57, 200] loss: 0.6440399473905564\n",
      "[57, 300] loss: 0.6770497381687164\n",
      "[58, 100] loss: 0.6633296573162079\n",
      "[58, 200] loss: 0.6479077181220054\n",
      "[58, 300] loss: 0.6529055094718933\n",
      "[59, 100] loss: 0.6517440113425255\n",
      "[59, 200] loss: 0.6600291693210601\n",
      "[59, 300] loss: 0.6543302175402641\n",
      "[60, 100] loss: 0.6743967890739441\n",
      "[60, 200] loss: 0.6649493032693863\n",
      "[60, 300] loss: 0.6450828212499619\n",
      "[61, 100] loss: 0.6544169068336487\n",
      "[61, 200] loss: 0.667202732861042\n",
      "[61, 300] loss: 0.6490067228674888\n",
      "[62, 100] loss: 0.6466507402062416\n",
      "[62, 200] loss: 0.6614749446511269\n",
      "[62, 300] loss: 0.6474624344706535\n",
      "[63, 100] loss: 0.6333633688092232\n",
      "[63, 200] loss: 0.6568898636102677\n",
      "[63, 300] loss: 0.6318854504823684\n",
      "[64, 100] loss: 0.6475478079915047\n",
      "[64, 200] loss: 0.6431508037447929\n",
      "[64, 300] loss: 0.6360587015748024\n",
      "[65, 100] loss: 0.6287364888191224\n",
      "[65, 200] loss: 0.647107971906662\n",
      "[65, 300] loss: 0.6301374545693398\n",
      "[66, 100] loss: 0.6353061702847481\n",
      "[66, 200] loss: 0.6264529794454574\n",
      "[66, 300] loss: 0.6317897418141365\n",
      "[67, 100] loss: 0.6507083278894424\n",
      "[67, 200] loss: 0.6407694280147552\n",
      "[67, 300] loss: 0.6423050075769424\n",
      "[68, 100] loss: 0.6160500153899193\n",
      "[68, 200] loss: 0.6361182981729507\n",
      "[68, 300] loss: 0.6540000206232071\n",
      "[69, 100] loss: 0.6261995726823807\n",
      "[69, 200] loss: 0.6194315442442894\n",
      "[69, 300] loss: 0.6313367953896523\n",
      "[70, 100] loss: 0.637959033548832\n",
      "[70, 200] loss: 0.6165284726023674\n",
      "[70, 300] loss: 0.6167591074109078\n",
      "[71, 100] loss: 0.6346832835674285\n",
      "[71, 200] loss: 0.6292180013656616\n",
      "[71, 300] loss: 0.6425884914398193\n",
      "[72, 100] loss: 0.6300297132134438\n",
      "[72, 200] loss: 0.6248757454752922\n",
      "[72, 300] loss: 0.6217143931984901\n",
      "[73, 100] loss: 0.614874477982521\n",
      "[73, 200] loss: 0.6208925196528434\n",
      "[73, 300] loss: 0.6280906504392624\n",
      "[74, 100] loss: 0.6215068298578262\n",
      "[74, 200] loss: 0.62313661724329\n",
      "[74, 300] loss: 0.6008894541859626\n",
      "[75, 100] loss: 0.6273992189764976\n",
      "[75, 200] loss: 0.6221451896429062\n",
      "[75, 300] loss: 0.6346649104356765\n",
      "[76, 100] loss: 0.5994075682759284\n",
      "[76, 200] loss: 0.6415836000442505\n",
      "[76, 300] loss: 0.6115449604392051\n",
      "[77, 100] loss: 0.6305436432361603\n",
      "[77, 200] loss: 0.6186630406975746\n",
      "[77, 300] loss: 0.6146426784992218\n",
      "[78, 100] loss: 0.621891798377037\n",
      "[78, 200] loss: 0.6165087360143662\n",
      "[78, 300] loss: 0.6107249665260315\n",
      "[79, 100] loss: 0.6033712410926819\n",
      "[79, 200] loss: 0.6099773272871971\n",
      "[79, 300] loss: 0.6082837235927582\n",
      "[80, 100] loss: 0.607519561946392\n",
      "[80, 200] loss: 0.6008738958835602\n",
      "[80, 300] loss: 0.6015074610710144\n",
      "[81, 100] loss: 0.6099461430311203\n",
      "[81, 200] loss: 0.6088184711337089\n",
      "[81, 300] loss: 0.5991027399897575\n",
      "[82, 100] loss: 0.6113504162430763\n",
      "[82, 200] loss: 0.6050289928913116\n",
      "[82, 300] loss: 0.6199711510539054\n",
      "[83, 100] loss: 0.6108378162980079\n",
      "[83, 200] loss: 0.605326344370842\n",
      "[83, 300] loss: 0.6124985048174858\n",
      "[84, 100] loss: 0.6064253604412079\n",
      "[84, 200] loss: 0.6028096011281013\n",
      "[84, 300] loss: 0.5896337097883224\n",
      "[85, 100] loss: 0.6036597031354904\n",
      "[85, 200] loss: 0.5990482518076896\n",
      "[85, 300] loss: 0.6072253301739693\n",
      "[86, 100] loss: 0.6102761721611023\n",
      "[86, 200] loss: 0.5794336000084876\n",
      "[86, 300] loss: 0.5865546095371247\n",
      "[87, 100] loss: 0.5914319840073585\n",
      "[87, 200] loss: 0.5802011248469353\n",
      "[87, 300] loss: 0.5917117509245873\n",
      "[88, 100] loss: 0.5869488447904587\n",
      "[88, 200] loss: 0.5927284577488899\n",
      "[88, 300] loss: 0.5987818190455436\n",
      "[89, 100] loss: 0.586038878262043\n",
      "[89, 200] loss: 0.6114720237255097\n",
      "[89, 300] loss: 0.59087477684021\n",
      "[90, 100] loss: 0.5951642292737961\n",
      "[90, 200] loss: 0.5984112358093262\n",
      "[90, 300] loss: 0.5856267136335372\n",
      "[91, 100] loss: 0.5910558620095253\n",
      "[91, 200] loss: 0.5854912215471267\n",
      "[91, 300] loss: 0.5820543286204338\n",
      "[92, 100] loss: 0.5777184280753136\n",
      "[92, 200] loss: 0.5855807521939278\n",
      "[92, 300] loss: 0.5815677824616432\n",
      "[93, 100] loss: 0.5788719493150711\n",
      "[93, 200] loss: 0.5862014716863633\n",
      "[93, 300] loss: 0.5754854026436805\n",
      "[94, 100] loss: 0.6065008199214935\n",
      "[94, 200] loss: 0.5822098243236542\n",
      "[94, 300] loss: 0.5947317805886269\n",
      "[95, 100] loss: 0.5881443130970001\n",
      "[95, 200] loss: 0.569342779815197\n",
      "[95, 300] loss: 0.5964440202713013\n",
      "[96, 100] loss: 0.5800827375054359\n",
      "[96, 200] loss: 0.5727450877428055\n",
      "[96, 300] loss: 0.5707436469197273\n",
      "[97, 100] loss: 0.594380176961422\n",
      "[97, 200] loss: 0.584030878841877\n",
      "[97, 300] loss: 0.574944229722023\n",
      "[98, 100] loss: 0.5755030462145805\n",
      "[98, 200] loss: 0.5737079203128814\n",
      "[98, 300] loss: 0.5898995417356491\n",
      "[99, 100] loss: 0.5780294561386108\n",
      "[99, 200] loss: 0.576986448764801\n",
      "[99, 300] loss: 0.5859028273820877\n",
      "[100, 100] loss: 0.5710233828425407\n",
      "[100, 200] loss: 0.5640710207819939\n",
      "[100, 300] loss: 0.5807848173379898\n",
      "Training model 2 in the ensemble...\n",
      "[1, 100] loss: 2.052220131158829\n",
      "[1, 200] loss: 1.7601978552341462\n",
      "[1, 300] loss: 1.645022600889206\n",
      "[2, 100] loss: 1.5048889708518982\n",
      "[2, 200] loss: 1.463409321308136\n",
      "[2, 300] loss: 1.4194400489330292\n",
      "[3, 100] loss: 1.3520776724815369\n",
      "[3, 200] loss: 1.3117234635353088\n",
      "[3, 300] loss: 1.2873592019081115\n",
      "[4, 100] loss: 1.248450096845627\n",
      "[4, 200] loss: 1.2073913276195527\n",
      "[4, 300] loss: 1.1990575611591339\n",
      "[5, 100] loss: 1.153853216767311\n",
      "[5, 200] loss: 1.1396883434057237\n",
      "[5, 300] loss: 1.1418741047382355\n",
      "[6, 100] loss: 1.1157221376895905\n",
      "[6, 200] loss: 1.1063670712709426\n",
      "[6, 300] loss: 1.0779158288240434\n",
      "[7, 100] loss: 1.0513894391059875\n",
      "[7, 200] loss: 1.0203818172216415\n",
      "[7, 300] loss: 1.0258809095621109\n",
      "[8, 100] loss: 1.0021698170900344\n",
      "[8, 200] loss: 1.0090457099676131\n",
      "[8, 300] loss: 0.990361955165863\n",
      "[9, 100] loss: 0.9706589889526367\n",
      "[9, 200] loss: 0.9687714326381683\n",
      "[9, 300] loss: 0.9724227052927017\n",
      "[10, 100] loss: 0.956842657327652\n",
      "[10, 200] loss: 0.9554274672269821\n",
      "[10, 300] loss: 0.9385806334018707\n",
      "[11, 100] loss: 0.9529741942882538\n",
      "[11, 200] loss: 0.9406601595878601\n",
      "[11, 300] loss: 0.9120968014001847\n",
      "[12, 100] loss: 0.906189523935318\n",
      "[12, 200] loss: 0.911083619594574\n",
      "[12, 300] loss: 0.9123027449846268\n",
      "[13, 100] loss: 0.9077713543176651\n",
      "[13, 200] loss: 0.8731270515918732\n",
      "[13, 300] loss: 0.9047533440589904\n",
      "[14, 100] loss: 0.8848893707990646\n",
      "[14, 200] loss: 0.8904292762279511\n",
      "[14, 300] loss: 0.8777427178621292\n",
      "[15, 100] loss: 0.876042726635933\n",
      "[15, 200] loss: 0.876205050945282\n",
      "[15, 300] loss: 0.8534123176336288\n",
      "[16, 100] loss: 0.8668249046802521\n",
      "[16, 200] loss: 0.8505765336751938\n",
      "[16, 300] loss: 0.8620993667840957\n",
      "[17, 100] loss: 0.8655221790075303\n",
      "[17, 200] loss: 0.8424324238300324\n",
      "[17, 300] loss: 0.8421520990133285\n",
      "[18, 100] loss: 0.8311350917816163\n",
      "[18, 200] loss: 0.8479687052965165\n",
      "[18, 300] loss: 0.8297172665596009\n",
      "[19, 100] loss: 0.8100358998775482\n",
      "[19, 200] loss: 0.8371840018033981\n",
      "[19, 300] loss: 0.8247420430183411\n",
      "[20, 100] loss: 0.8305325573682785\n",
      "[20, 200] loss: 0.8255627006292343\n",
      "[20, 300] loss: 0.8267113316059113\n",
      "[21, 100] loss: 0.8039909940958023\n",
      "[21, 200] loss: 0.8097098469734192\n",
      "[21, 300] loss: 0.8053196448087693\n",
      "[22, 100] loss: 0.7855138224363327\n",
      "[22, 200] loss: 0.7989276707172394\n",
      "[22, 300] loss: 0.8041026699542999\n",
      "[23, 100] loss: 0.7959471547603607\n",
      "[23, 200] loss: 0.7888175016641616\n",
      "[23, 300] loss: 0.7913015830516815\n",
      "[24, 100] loss: 0.7924647909402848\n",
      "[24, 200] loss: 0.7830953270196914\n",
      "[24, 300] loss: 0.7862311083078385\n",
      "[25, 100] loss: 0.7941738468408585\n",
      "[25, 200] loss: 0.8016447001695632\n",
      "[25, 300] loss: 0.7764494329690933\n",
      "[26, 100] loss: 0.7828269386291504\n",
      "[26, 200] loss: 0.7794334101676941\n",
      "[26, 300] loss: 0.779744400382042\n",
      "[27, 100] loss: 0.7720942360162735\n",
      "[27, 200] loss: 0.7688736802339554\n",
      "[27, 300] loss: 0.7820856058597565\n",
      "[28, 100] loss: 0.7737637239694596\n",
      "[28, 200] loss: 0.7717050129175186\n",
      "[28, 300] loss: 0.7630600398778915\n",
      "[29, 100] loss: 0.7672139298915863\n",
      "[29, 200] loss: 0.7745853465795517\n",
      "[29, 300] loss: 0.7814661026000976\n",
      "[30, 100] loss: 0.7540971475839615\n",
      "[30, 200] loss: 0.7541757225990295\n",
      "[30, 300] loss: 0.7682098257541656\n",
      "[31, 100] loss: 0.7708776861429214\n",
      "[31, 200] loss: 0.72912482380867\n",
      "[31, 300] loss: 0.7454796093702316\n",
      "[32, 100] loss: 0.7437223136425019\n",
      "[32, 200] loss: 0.7528810507059097\n",
      "[32, 300] loss: 0.7688865482807159\n",
      "[33, 100] loss: 0.7457867616415024\n",
      "[33, 200] loss: 0.7420511573553086\n",
      "[33, 300] loss: 0.7305058109760284\n",
      "[34, 100] loss: 0.7251773130893707\n",
      "[34, 200] loss: 0.734166020154953\n",
      "[34, 300] loss: 0.7353438973426819\n",
      "[35, 100] loss: 0.7289982843399048\n",
      "[35, 200] loss: 0.7549470883607864\n",
      "[35, 300] loss: 0.7436945939064026\n",
      "[36, 100] loss: 0.7324360400438309\n",
      "[36, 200] loss: 0.7323571878671646\n",
      "[36, 300] loss: 0.7187135300040245\n",
      "[37, 100] loss: 0.7525208270549775\n",
      "[37, 200] loss: 0.7366553634405136\n",
      "[37, 300] loss: 0.7406263887882233\n",
      "[38, 100] loss: 0.7381252855062485\n",
      "[38, 200] loss: 0.7352328529953956\n",
      "[38, 300] loss: 0.7253300380706788\n",
      "[39, 100] loss: 0.7329347079992294\n",
      "[39, 200] loss: 0.7252697962522506\n",
      "[39, 300] loss: 0.7230341058969497\n",
      "[40, 100] loss: 0.7034473574161529\n",
      "[40, 200] loss: 0.7318710458278656\n",
      "[40, 300] loss: 0.706668753027916\n",
      "[41, 100] loss: 0.732284562587738\n",
      "[41, 200] loss: 0.7307341068983078\n",
      "[41, 300] loss: 0.7175970277190209\n",
      "[42, 100] loss: 0.7201551634073258\n",
      "[42, 200] loss: 0.7011517930030823\n",
      "[42, 300] loss: 0.7244341593980789\n",
      "[43, 100] loss: 0.7277735191583633\n",
      "[43, 200] loss: 0.7001033425331116\n",
      "[43, 300] loss: 0.7302427214384078\n",
      "[44, 100] loss: 0.7184050220251084\n",
      "[44, 200] loss: 0.7066437923908233\n",
      "[44, 300] loss: 0.7113152915239334\n",
      "[45, 100] loss: 0.7139451289176941\n",
      "[45, 200] loss: 0.6992268639802933\n",
      "[45, 300] loss: 0.7063083177804947\n",
      "[46, 100] loss: 0.7254921612143517\n",
      "[46, 200] loss: 0.7231537407636642\n",
      "[46, 300] loss: 0.7065439665317536\n",
      "[47, 100] loss: 0.6989279299974441\n",
      "[47, 200] loss: 0.7067711526155471\n",
      "[47, 300] loss: 0.6928031921386719\n",
      "[48, 100] loss: 0.7063353192806244\n",
      "[48, 200] loss: 0.7047806280851364\n",
      "[48, 300] loss: 0.7042482441663742\n",
      "[49, 100] loss: 0.6994481274485588\n",
      "[49, 200] loss: 0.7091729629039765\n",
      "[49, 300] loss: 0.697303619980812\n",
      "[50, 100] loss: 0.7137490209937095\n",
      "[50, 200] loss: 0.7160036492347718\n",
      "[50, 300] loss: 0.701127921640873\n",
      "[51, 100] loss: 0.7139542305469513\n",
      "[51, 200] loss: 0.698551197052002\n",
      "[51, 300] loss: 0.6938276427984238\n",
      "[52, 100] loss: 0.6861797881126404\n",
      "[52, 200] loss: 0.6921125334501267\n",
      "[52, 300] loss: 0.7007810866832733\n",
      "[53, 100] loss: 0.7012229830026626\n",
      "[53, 200] loss: 0.6856157857179642\n",
      "[53, 300] loss: 0.6949629133939743\n",
      "[54, 100] loss: 0.6912875056266785\n",
      "[54, 200] loss: 0.7070343375205994\n",
      "[54, 300] loss: 0.708030996620655\n",
      "[55, 100] loss: 0.7140165400505066\n",
      "[55, 200] loss: 0.6991377609968186\n",
      "[55, 300] loss: 0.6998373275995254\n",
      "[56, 100] loss: 0.6925761914253235\n",
      "[56, 200] loss: 0.6970261773467064\n",
      "[56, 300] loss: 0.7003415662050247\n",
      "[57, 100] loss: 0.7054008856415749\n",
      "[57, 200] loss: 0.6882284781336785\n",
      "[57, 300] loss: 0.6885819727182388\n",
      "[58, 100] loss: 0.6979493486881256\n",
      "[58, 200] loss: 0.6822500231862069\n",
      "[58, 300] loss: 0.6986061069369316\n",
      "[59, 100] loss: 0.6985177147388458\n",
      "[59, 200] loss: 0.6890622854232789\n",
      "[59, 300] loss: 0.6913848423957825\n",
      "[60, 100] loss: 0.6931843641400337\n",
      "[60, 200] loss: 0.6833438622951508\n",
      "[60, 300] loss: 0.6960614860057831\n",
      "[61, 100] loss: 0.6996059700846672\n",
      "[61, 200] loss: 0.6942773300409317\n",
      "[61, 300] loss: 0.6937615621089935\n",
      "[62, 100] loss: 0.680548897087574\n",
      "[62, 200] loss: 0.6964191967248916\n",
      "[62, 300] loss: 0.6905879256129265\n",
      "[63, 100] loss: 0.6872348660230636\n",
      "[63, 200] loss: 0.690031361579895\n",
      "[63, 300] loss: 0.6940125906467438\n",
      "[64, 100] loss: 0.6973485252261162\n",
      "[64, 200] loss: 0.6761637929081917\n",
      "[64, 300] loss: 0.6922623685002327\n",
      "[65, 100] loss: 0.6944392198324203\n",
      "[65, 200] loss: 0.6780676224827766\n",
      "[65, 300] loss: 0.7069137179851532\n",
      "[66, 100] loss: 0.6887613290548324\n",
      "[66, 200] loss: 0.6796124738454818\n",
      "[66, 300] loss: 0.6843527200818061\n",
      "[67, 100] loss: 0.6658761721849441\n",
      "[67, 200] loss: 0.693921247124672\n",
      "[67, 300] loss: 0.7002493286132813\n",
      "[68, 100] loss: 0.6638255327939987\n",
      "[68, 200] loss: 0.6745893615484237\n",
      "[68, 300] loss: 0.690904156267643\n",
      "[69, 100] loss: 0.6638463199138641\n",
      "[69, 200] loss: 0.6824406060576439\n",
      "[69, 300] loss: 0.6935306137800217\n",
      "[70, 100] loss: 0.6768089693784713\n",
      "[70, 200] loss: 0.6833623075485229\n",
      "[70, 300] loss: 0.692726234793663\n",
      "[71, 100] loss: 0.6810049122571945\n",
      "[71, 200] loss: 0.6703521490097046\n",
      "[71, 300] loss: 0.6701651123166085\n",
      "[72, 100] loss: 0.6750345492362976\n",
      "[72, 200] loss: 0.6921269753575325\n",
      "[72, 300] loss: 0.671785153746605\n",
      "[73, 100] loss: 0.6928174144029617\n",
      "[73, 200] loss: 0.667933902144432\n",
      "[73, 300] loss: 0.670214638710022\n",
      "[74, 100] loss: 0.6664309278130531\n",
      "[74, 200] loss: 0.6860278668999672\n",
      "[74, 300] loss: 0.6723677861690521\n",
      "[75, 100] loss: 0.6681332695484161\n",
      "[75, 200] loss: 0.6726838862895965\n",
      "[75, 300] loss: 0.6749663591384888\n",
      "[76, 100] loss: 0.6882684114575386\n",
      "[76, 200] loss: 0.6567388960719108\n",
      "[76, 300] loss: 0.664099708199501\n",
      "[77, 100] loss: 0.6818818074464797\n",
      "[77, 200] loss: 0.6709553396701813\n",
      "[77, 300] loss: 0.6512037193775178\n",
      "[78, 100] loss: 0.6624349886178971\n",
      "[78, 200] loss: 0.6745316752791405\n",
      "[78, 300] loss: 0.6664531576633453\n",
      "[79, 100] loss: 0.6646138867735862\n",
      "[79, 200] loss: 0.6628596812486649\n",
      "[79, 300] loss: 0.6636511558294296\n",
      "[80, 100] loss: 0.6528320920467376\n",
      "[80, 200] loss: 0.6616304710507392\n",
      "[80, 300] loss: 0.6869138380885125\n",
      "[81, 100] loss: 0.6607351589202881\n",
      "[81, 200] loss: 0.6584269377589226\n",
      "[81, 300] loss: 0.6501911583542824\n",
      "[82, 100] loss: 0.6495263081789017\n",
      "[82, 200] loss: 0.666486918926239\n",
      "[82, 300] loss: 0.6800523218512535\n",
      "[83, 100] loss: 0.6671071276068687\n",
      "[83, 200] loss: 0.6722136989235878\n",
      "[83, 300] loss: 0.6649320086836815\n",
      "[84, 100] loss: 0.659311974644661\n",
      "[84, 200] loss: 0.6679473465681076\n",
      "[84, 300] loss: 0.6672108852863312\n",
      "[85, 100] loss: 0.669429498910904\n",
      "[85, 200] loss: 0.6573755902051925\n",
      "[85, 300] loss: 0.6518042731285095\n",
      "[86, 100] loss: 0.6654801553487778\n",
      "[86, 200] loss: 0.661583548784256\n",
      "[86, 300] loss: 0.658762241601944\n",
      "[87, 100] loss: 0.6457472279667854\n",
      "[87, 200] loss: 0.6570992329716683\n",
      "[87, 300] loss: 0.6529180252552033\n",
      "[88, 100] loss: 0.637273428440094\n",
      "[88, 200] loss: 0.667080237865448\n",
      "[88, 300] loss: 0.672506814301014\n",
      "[89, 100] loss: 0.6407157251238823\n",
      "[89, 200] loss: 0.6521182197332382\n",
      "[89, 300] loss: 0.6647772258520126\n",
      "[90, 100] loss: 0.6490657415986061\n",
      "[90, 200] loss: 0.653232425749302\n",
      "[90, 300] loss: 0.6478879350423813\n",
      "[91, 100] loss: 0.6628192955255509\n",
      "[91, 200] loss: 0.658746063709259\n",
      "[91, 300] loss: 0.6640485775470734\n",
      "[92, 100] loss: 0.6434044164419174\n",
      "[92, 200] loss: 0.6617643156647682\n",
      "[92, 300] loss: 0.6609211724996567\n",
      "[93, 100] loss: 0.6597133350372314\n",
      "[93, 200] loss: 0.6541793352365494\n",
      "[93, 300] loss: 0.6468765673041343\n",
      "[94, 100] loss: 0.6633170986175537\n",
      "[94, 200] loss: 0.6546306076645851\n",
      "[94, 300] loss: 0.6507269582152366\n",
      "[95, 100] loss: 0.6483480313420296\n",
      "[95, 200] loss: 0.6660603553056716\n",
      "[95, 300] loss: 0.6633999979496003\n",
      "[96, 100] loss: 0.6446848332881927\n",
      "[96, 200] loss: 0.6566366025805473\n",
      "[96, 300] loss: 0.6699331903457642\n",
      "[97, 100] loss: 0.661901960670948\n",
      "[97, 200] loss: 0.6365853670239449\n",
      "[97, 300] loss: 0.6608525639772416\n",
      "[98, 100] loss: 0.6734362176060676\n",
      "[98, 200] loss: 0.6619963198900223\n",
      "[98, 300] loss: 0.6584713950753212\n",
      "[99, 100] loss: 0.6492733040452003\n",
      "[99, 200] loss: 0.6757513764500618\n",
      "[99, 300] loss: 0.657183688879013\n",
      "[100, 100] loss: 0.6617508020997047\n",
      "[100, 200] loss: 0.6560906380414963\n",
      "[100, 300] loss: 0.6601439708471298\n",
      "Training model 3 in the ensemble...\n",
      "[1, 100] loss: 2.0511277961730956\n",
      "[1, 200] loss: 1.758008030653\n",
      "[1, 300] loss: 1.6633600401878357\n",
      "[2, 100] loss: 1.5063150870800017\n",
      "[2, 200] loss: 1.420097098350525\n",
      "[2, 300] loss: 1.3617195308208465\n",
      "[3, 100] loss: 1.262712482213974\n",
      "[3, 200] loss: 1.1971141922473907\n",
      "[3, 300] loss: 1.1741332572698593\n",
      "[4, 100] loss: 1.123347145318985\n",
      "[4, 200] loss: 1.0859710109233855\n",
      "[4, 300] loss: 1.0644152170419694\n",
      "[5, 100] loss: 1.0397037851810456\n",
      "[5, 200] loss: 1.0137624806165695\n",
      "[5, 300] loss: 1.005838018655777\n",
      "[6, 100] loss: 0.9717164194583893\n",
      "[6, 200] loss: 0.9797427517175674\n",
      "[6, 300] loss: 0.9624446201324462\n",
      "[7, 100] loss: 0.9421786332130432\n",
      "[7, 200] loss: 0.9289525359869003\n",
      "[7, 300] loss: 0.9387843763828277\n",
      "[8, 100] loss: 0.9171069484949111\n",
      "[8, 200] loss: 0.9128812247514725\n",
      "[8, 300] loss: 0.9057917869091034\n",
      "[9, 100] loss: 0.8972284561395645\n",
      "[9, 200] loss: 0.8991323328018188\n",
      "[9, 300] loss: 0.9128217953443527\n",
      "[10, 100] loss: 0.8917847943305969\n",
      "[10, 200] loss: 0.8708168566226959\n",
      "[10, 300] loss: 0.8729378128051758\n",
      "[11, 100] loss: 0.8595427072048187\n",
      "[11, 200] loss: 0.8578425234556198\n",
      "[11, 300] loss: 0.8732751935720444\n",
      "[12, 100] loss: 0.8652989411354065\n",
      "[12, 200] loss: 0.8503156065940857\n",
      "[12, 300] loss: 0.8636522483825684\n",
      "[13, 100] loss: 0.8563155990839004\n",
      "[13, 200] loss: 0.8441854965686798\n",
      "[13, 300] loss: 0.8412048846483231\n",
      "[14, 100] loss: 0.8298922508955002\n",
      "[14, 200] loss: 0.8344204533100128\n",
      "[14, 300] loss: 0.8371467232704163\n",
      "[15, 100] loss: 0.8463547855615616\n",
      "[15, 200] loss: 0.8406028288602829\n",
      "[15, 300] loss: 0.8216110211610794\n",
      "[16, 100] loss: 0.8299396163225174\n",
      "[16, 200] loss: 0.8332651716470718\n",
      "[16, 300] loss: 0.8231419920921326\n",
      "[17, 100] loss: 0.8329474222660065\n",
      "[17, 200] loss: 0.8037492620944977\n",
      "[17, 300] loss: 0.8275906074047089\n",
      "[18, 100] loss: 0.8211497759819031\n",
      "[18, 200] loss: 0.8193929278850556\n",
      "[18, 300] loss: 0.8013554799556732\n",
      "[19, 100] loss: 0.8369165658950806\n",
      "[19, 200] loss: 0.8080378311872483\n",
      "[19, 300] loss: 0.8131854665279389\n",
      "[20, 100] loss: 0.7973087173700333\n",
      "[20, 200] loss: 0.8000653290748596\n",
      "[20, 300] loss: 0.8124926215410233\n",
      "[21, 100] loss: 0.8211958593130112\n",
      "[21, 200] loss: 0.8067346334457397\n",
      "[21, 300] loss: 0.8041925942897796\n",
      "[22, 100] loss: 0.8046374988555908\n",
      "[22, 200] loss: 0.8086225414276123\n",
      "[22, 300] loss: 0.8073439157009125\n",
      "[23, 100] loss: 0.7974515795707703\n",
      "[23, 200] loss: 0.7858603191375733\n",
      "[23, 300] loss: 0.7902282428741455\n",
      "[24, 100] loss: 0.7835546720027924\n",
      "[24, 200] loss: 0.8012947684526444\n",
      "[24, 300] loss: 0.80687992811203\n",
      "[25, 100] loss: 0.7946060132980347\n",
      "[25, 200] loss: 0.8068433713912964\n",
      "[25, 300] loss: 0.7717478704452515\n",
      "[26, 100] loss: 0.7819293302297592\n",
      "[26, 200] loss: 0.7962972790002822\n",
      "[26, 300] loss: 0.7888916480541229\n",
      "[27, 100] loss: 0.7836416751146317\n",
      "[27, 200] loss: 0.8071306258440017\n",
      "[27, 300] loss: 0.793489191532135\n",
      "[28, 100] loss: 0.7918085896968842\n",
      "[28, 200] loss: 0.7774827295541763\n",
      "[28, 300] loss: 0.7949581313133239\n",
      "[29, 100] loss: 0.7895515823364258\n",
      "[29, 200] loss: 0.7741803449392318\n",
      "[29, 300] loss: 0.7792358535528183\n",
      "[30, 100] loss: 0.7898097211122512\n",
      "[30, 200] loss: 0.7730059540271759\n",
      "[30, 300] loss: 0.7776281887292862\n",
      "[31, 100] loss: 0.7786310321092605\n",
      "[31, 200] loss: 0.7924352729320526\n",
      "[31, 300] loss: 0.7891086786985397\n",
      "[32, 100] loss: 0.7800602942705155\n",
      "[32, 200] loss: 0.754396020770073\n",
      "[32, 300] loss: 0.7649563306570053\n",
      "[33, 100] loss: 0.7687636440992356\n",
      "[33, 200] loss: 0.7650143122673034\n",
      "[33, 300] loss: 0.7689027965068818\n",
      "[34, 100] loss: 0.7712965565919876\n",
      "[34, 200] loss: 0.7848025965690613\n",
      "[34, 300] loss: 0.7768642026185989\n",
      "[35, 100] loss: 0.7590795797109604\n",
      "[35, 200] loss: 0.7589591580629349\n",
      "[35, 300] loss: 0.7670071667432785\n",
      "[36, 100] loss: 0.7715829986333848\n",
      "[36, 200] loss: 0.7673647207021713\n",
      "[36, 300] loss: 0.7758949571847915\n",
      "[37, 100] loss: 0.7644455236196518\n",
      "[37, 200] loss: 0.7828864312171936\n",
      "[37, 300] loss: 0.7533440762758254\n",
      "[38, 100] loss: 0.7596737849712372\n",
      "[38, 200] loss: 0.759585068821907\n",
      "[38, 300] loss: 0.7667189139127731\n",
      "[39, 100] loss: 0.7719401293992996\n",
      "[39, 200] loss: 0.7778784155845642\n",
      "[39, 300] loss: 0.7614645224809646\n",
      "[40, 100] loss: 0.7396488785743713\n",
      "[40, 200] loss: 0.7429597759246827\n",
      "[40, 300] loss: 0.7587298077344894\n",
      "[41, 100] loss: 0.7583690190315246\n",
      "[41, 200] loss: 0.7609072679281235\n",
      "[41, 300] loss: 0.7564299142360688\n",
      "[42, 100] loss: 0.767824102640152\n",
      "[42, 200] loss: 0.7420989519357681\n",
      "[42, 300] loss: 0.7486966437101364\n",
      "[43, 100] loss: 0.7624292594194412\n",
      "[43, 200] loss: 0.7409455025196076\n",
      "[43, 300] loss: 0.7404780155420303\n",
      "[44, 100] loss: 0.7589253455400466\n",
      "[44, 200] loss: 0.757953342795372\n",
      "[44, 300] loss: 0.7495032620429992\n",
      "[45, 100] loss: 0.7511428815126419\n",
      "[45, 200] loss: 0.7371443605422974\n",
      "[45, 300] loss: 0.7647812730073928\n",
      "[46, 100] loss: 0.7511400943994522\n",
      "[46, 200] loss: 0.756183517575264\n",
      "[46, 300] loss: 0.7467901957035065\n",
      "[47, 100] loss: 0.7438205581903458\n",
      "[47, 200] loss: 0.7488686293363571\n",
      "[47, 300] loss: 0.7463090920448303\n",
      "[48, 100] loss: 0.7413595044612884\n",
      "[48, 200] loss: 0.7598452657461167\n",
      "[48, 300] loss: 0.7487081420421601\n",
      "[49, 100] loss: 0.7546256572008133\n",
      "[49, 200] loss: 0.7485492724180222\n",
      "[49, 300] loss: 0.7482387036085129\n",
      "[50, 100] loss: 0.7404644453525543\n",
      "[50, 200] loss: 0.7457152915000915\n",
      "[50, 300] loss: 0.7473882466554642\n",
      "[51, 100] loss: 0.7316800385713578\n",
      "[51, 200] loss: 0.7553095340728759\n",
      "[51, 300] loss: 0.7413211786746978\n",
      "[52, 100] loss: 0.7523280358314515\n",
      "[52, 200] loss: 0.7506430900096893\n",
      "[52, 300] loss: 0.7503990489244461\n",
      "[53, 100] loss: 0.7332112666964531\n",
      "[53, 200] loss: 0.7279180866479874\n",
      "[53, 300] loss: 0.7362370416522026\n",
      "[54, 100] loss: 0.7453802758455277\n",
      "[54, 200] loss: 0.7447480636835099\n",
      "[54, 300] loss: 0.7288967236876488\n",
      "[55, 100] loss: 0.7466024148464203\n",
      "[55, 200] loss: 0.762643768787384\n",
      "[55, 300] loss: 0.738170103430748\n",
      "[56, 100] loss: 0.7356458193063736\n",
      "[56, 200] loss: 0.7346000164747238\n",
      "[56, 300] loss: 0.7319847249984741\n",
      "[57, 100] loss: 0.738526006937027\n",
      "[57, 200] loss: 0.7342597717046737\n",
      "[57, 300] loss: 0.7199003946781158\n",
      "[58, 100] loss: 0.7480555665493012\n",
      "[58, 200] loss: 0.7384922808408737\n",
      "[58, 300] loss: 0.730818235874176\n",
      "[59, 100] loss: 0.7078680968284607\n",
      "[59, 200] loss: 0.7416847658157348\n",
      "[59, 300] loss: 0.7121098151803017\n",
      "[60, 100] loss: 0.7226170951128006\n",
      "[60, 200] loss: 0.732750962972641\n",
      "[60, 300] loss: 0.7328211516141891\n",
      "[61, 100] loss: 0.739338083267212\n",
      "[61, 200] loss: 0.7332389914989471\n",
      "[61, 300] loss: 0.7401382803916932\n",
      "[62, 100] loss: 0.7386383175849914\n",
      "[62, 200] loss: 0.7272784167528152\n",
      "[62, 300] loss: 0.7079822063446045\n",
      "[63, 100] loss: 0.7112489932775498\n",
      "[63, 200] loss: 0.7141933023929596\n",
      "[63, 300] loss: 0.7258932191133499\n",
      "[64, 100] loss: 0.7032193487882614\n",
      "[64, 200] loss: 0.7108505070209503\n",
      "[64, 300] loss: 0.7227621108293534\n",
      "[65, 100] loss: 0.7433376133441925\n",
      "[65, 200] loss: 0.7191219681501388\n",
      "[65, 300] loss: 0.719709697663784\n",
      "[66, 100] loss: 0.7410945659875869\n",
      "[66, 200] loss: 0.7061522167921066\n",
      "[66, 300] loss: 0.7278982639312744\n",
      "[67, 100] loss: 0.7149543535709381\n",
      "[67, 200] loss: 0.7222802150249481\n",
      "[67, 300] loss: 0.7139023745059967\n",
      "[68, 100] loss: 0.7165273833274841\n",
      "[68, 200] loss: 0.7162054944038391\n",
      "[68, 300] loss: 0.7254431813955307\n",
      "[69, 100] loss: 0.7355794471502304\n",
      "[69, 200] loss: 0.7276824849843979\n",
      "[69, 300] loss: 0.7093636238574982\n",
      "[70, 100] loss: 0.7364480912685394\n",
      "[70, 200] loss: 0.7153043538331986\n",
      "[70, 300] loss: 0.7103522151708603\n",
      "[71, 100] loss: 0.724030613899231\n",
      "[71, 200] loss: 0.7203171843290329\n",
      "[71, 300] loss: 0.7143776476383209\n",
      "[72, 100] loss: 0.7334366989135742\n",
      "[72, 200] loss: 0.7174312686920166\n",
      "[72, 300] loss: 0.7104813069105148\n",
      "[73, 100] loss: 0.6995336258411408\n",
      "[73, 200] loss: 0.7076384633779526\n",
      "[73, 300] loss: 0.6996740627288819\n",
      "[74, 100] loss: 0.7178744268417359\n",
      "[74, 200] loss: 0.7192079544067382\n",
      "[74, 300] loss: 0.7120616352558136\n",
      "[75, 100] loss: 0.7108607184886933\n",
      "[75, 200] loss: 0.7185733580589294\n",
      "[75, 300] loss: 0.7304992669820786\n",
      "[76, 100] loss: 0.7022096943855286\n",
      "[76, 200] loss: 0.7195070466399193\n",
      "[76, 300] loss: 0.7255062687397004\n",
      "[77, 100] loss: 0.7119845536351204\n",
      "[77, 200] loss: 0.722307739853859\n",
      "[77, 300] loss: 0.7245370724797249\n",
      "[78, 100] loss: 0.6993198865652084\n",
      "[78, 200] loss: 0.7096056699752807\n",
      "[78, 300] loss: 0.7223816853761673\n",
      "[79, 100] loss: 0.7011231064796448\n",
      "[79, 200] loss: 0.7003577277064323\n",
      "[79, 300] loss: 0.708429656624794\n",
      "[80, 100] loss: 0.7206457030773162\n",
      "[80, 200] loss: 0.7356792080402375\n",
      "[80, 300] loss: 0.7086787921190262\n",
      "[81, 100] loss: 0.7124418205022812\n",
      "[81, 200] loss: 0.7209515368938446\n",
      "[81, 300] loss: 0.72142846763134\n",
      "[82, 100] loss: 0.7072479927539825\n",
      "[82, 200] loss: 0.7186287444829941\n",
      "[82, 300] loss: 0.6996976372599601\n",
      "[83, 100] loss: 0.7170347028970718\n",
      "[83, 200] loss: 0.7047226601839065\n",
      "[83, 300] loss: 0.6939470815658569\n",
      "[84, 100] loss: 0.7236251330375671\n",
      "[84, 200] loss: 0.7152210867404938\n",
      "[84, 300] loss: 0.7056327193975449\n",
      "[85, 100] loss: 0.7260293227434158\n",
      "[85, 200] loss: 0.7322159266471863\n",
      "[85, 300] loss: 0.707989182472229\n",
      "[86, 100] loss: 0.7447905749082565\n",
      "[86, 200] loss: 0.7126652729511261\n",
      "[86, 300] loss: 0.7236750721931458\n",
      "[87, 100] loss: 0.7099469810724258\n",
      "[87, 200] loss: 0.6945005041360856\n",
      "[87, 300] loss: 0.711596766114235\n",
      "[88, 100] loss: 0.7016756248474121\n",
      "[88, 200] loss: 0.6989855518937111\n",
      "[88, 300] loss: 0.7040393149852753\n",
      "[89, 100] loss: 0.7038993728160858\n",
      "[89, 200] loss: 0.7104093271493912\n",
      "[89, 300] loss: 0.7109386020898819\n",
      "[90, 100] loss: 0.7186739248037338\n",
      "[90, 200] loss: 0.7048512053489685\n",
      "[90, 300] loss: 0.7144733464717865\n",
      "[91, 100] loss: 0.7074608850479126\n",
      "[91, 200] loss: 0.7194767409563064\n",
      "[91, 300] loss: 0.6968243563175202\n",
      "[92, 100] loss: 0.7205690163373947\n",
      "[92, 200] loss: 0.7018670254945755\n",
      "[92, 300] loss: 0.7034441345930099\n",
      "[93, 100] loss: 0.7120406001806259\n",
      "[93, 200] loss: 0.6979033404588699\n",
      "[93, 300] loss: 0.6999780994653702\n",
      "[94, 100] loss: 0.6925128322839736\n",
      "[94, 200] loss: 0.7033515107631684\n",
      "[94, 300] loss: 0.7095953279733658\n",
      "[95, 100] loss: 0.7078443524241448\n",
      "[95, 200] loss: 0.6929613786935807\n",
      "[95, 300] loss: 0.7133856284618377\n",
      "[96, 100] loss: 0.7004406893253327\n",
      "[96, 200] loss: 0.704537364244461\n",
      "[96, 300] loss: 0.7325531357526779\n",
      "[97, 100] loss: 0.6902373513579368\n",
      "[97, 200] loss: 0.7098383790254593\n",
      "[97, 300] loss: 0.6986897867918015\n",
      "[98, 100] loss: 0.6944579043984414\n",
      "[98, 200] loss: 0.7026116615533828\n",
      "[98, 300] loss: 0.6890096002817154\n",
      "[99, 100] loss: 0.7090670293569565\n",
      "[99, 200] loss: 0.7140632525086403\n",
      "[99, 300] loss: 0.697703685760498\n",
      "[100, 100] loss: 0.6987339848279953\n",
      "[100, 200] loss: 0.6878575053811073\n",
      "[100, 300] loss: 0.690596053302288\n",
      "Training model 4 in the ensemble...\n",
      "[1, 100] loss: 2.0912915050983427\n",
      "[1, 200] loss: 1.8628571367263793\n",
      "[1, 300] loss: 1.7650868451595307\n",
      "[2, 100] loss: 1.6736289656162262\n",
      "[2, 200] loss: 1.6370787966251372\n",
      "[2, 300] loss: 1.589856251478195\n",
      "[3, 100] loss: 1.5324889957904815\n",
      "[3, 200] loss: 1.4875953567028046\n",
      "[3, 300] loss: 1.4385382103919984\n",
      "[4, 100] loss: 1.3675704729557037\n",
      "[4, 200] loss: 1.3408105397224426\n",
      "[4, 300] loss: 1.2967621636390687\n",
      "[5, 100] loss: 1.263873666524887\n",
      "[5, 200] loss: 1.2215953719615937\n",
      "[5, 300] loss: 1.2155834460258483\n",
      "[6, 100] loss: 1.1800548779964446\n",
      "[6, 200] loss: 1.1456553936004639\n",
      "[6, 300] loss: 1.1279347324371338\n",
      "[7, 100] loss: 1.104211347103119\n",
      "[7, 200] loss: 1.086511828303337\n",
      "[7, 300] loss: 1.0680796724557877\n",
      "[8, 100] loss: 1.044223309159279\n",
      "[8, 200] loss: 1.0274048608541488\n",
      "[8, 300] loss: 1.0281637120246887\n",
      "[9, 100] loss: 0.9970317506790161\n",
      "[9, 200] loss: 0.9973985522985458\n",
      "[9, 300] loss: 0.9970693469047547\n",
      "[10, 100] loss: 0.9911520618200302\n",
      "[10, 200] loss: 0.9491389185190201\n",
      "[10, 300] loss: 0.9700874197483063\n",
      "[11, 100] loss: 0.9325501519441605\n",
      "[11, 200] loss: 0.9433469468355179\n",
      "[11, 300] loss: 0.9457328194379806\n",
      "[12, 100] loss: 0.9383347827196121\n",
      "[12, 200] loss: 0.9233361035585403\n",
      "[12, 300] loss: 0.9057397866249084\n",
      "[13, 100] loss: 0.9126804077625275\n",
      "[13, 200] loss: 0.8940257918834686\n",
      "[13, 300] loss: 0.8998593264818191\n",
      "[14, 100] loss: 0.8759886610507965\n",
      "[14, 200] loss: 0.8723114055395126\n",
      "[14, 300] loss: 0.8661768054962158\n",
      "[15, 100] loss: 0.8757763820886612\n",
      "[15, 200] loss: 0.8802156120538711\n",
      "[15, 300] loss: 0.8566905117034912\n",
      "[16, 100] loss: 0.8517219066619873\n",
      "[16, 200] loss: 0.88233323097229\n",
      "[16, 300] loss: 0.847127326130867\n",
      "[17, 100] loss: 0.8650839936733246\n",
      "[17, 200] loss: 0.8612227749824524\n",
      "[17, 300] loss: 0.8556981271505356\n",
      "[18, 100] loss: 0.8371134054660797\n",
      "[18, 200] loss: 0.8390885537862778\n",
      "[18, 300] loss: 0.8411414128541946\n",
      "[19, 100] loss: 0.842497108578682\n",
      "[19, 200] loss: 0.8425764328241349\n",
      "[19, 300] loss: 0.8495299345254899\n",
      "[20, 100] loss: 0.8146776950359345\n",
      "[20, 200] loss: 0.8361843132972717\n",
      "[20, 300] loss: 0.8176848381757736\n",
      "[21, 100] loss: 0.8389314156770706\n",
      "[21, 200] loss: 0.8341572344303131\n",
      "[21, 300] loss: 0.8295710861682892\n",
      "[22, 100] loss: 0.8314998471736907\n",
      "[22, 200] loss: 0.8515596723556519\n",
      "[22, 300] loss: 0.8177776002883911\n",
      "[23, 100] loss: 0.8231839030981064\n",
      "[23, 200] loss: 0.8142550355195999\n",
      "[23, 300] loss: 0.827278071641922\n",
      "[24, 100] loss: 0.8196378946304321\n",
      "[24, 200] loss: 0.8065171092748642\n",
      "[24, 300] loss: 0.8146313315629959\n",
      "[25, 100] loss: 0.8149758744239807\n",
      "[25, 200] loss: 0.8220852416753769\n",
      "[25, 300] loss: 0.8138023179769516\n",
      "[26, 100] loss: 0.8127718007564545\n",
      "[26, 200] loss: 0.8141005063056945\n",
      "[26, 300] loss: 0.8215327137708663\n",
      "[27, 100] loss: 0.8002541238069534\n",
      "[27, 200] loss: 0.8071769803762436\n",
      "[27, 300] loss: 0.7907999676465988\n",
      "[28, 100] loss: 0.8098602193593979\n",
      "[28, 200] loss: 0.8040562963485718\n",
      "[28, 300] loss: 0.8030788737535477\n",
      "[29, 100] loss: 0.7857931363582611\n",
      "[29, 200] loss: 0.8042823261022568\n",
      "[29, 300] loss: 0.7737229925394058\n",
      "[30, 100] loss: 0.7927488112449645\n",
      "[30, 200] loss: 0.7913442951440811\n",
      "[30, 300] loss: 0.7749719399213791\n",
      "[31, 100] loss: 0.8024941343069076\n",
      "[31, 200] loss: 0.7946572369337082\n",
      "[31, 300] loss: 0.7891051769256592\n",
      "[32, 100] loss: 0.7759543788433075\n",
      "[32, 200] loss: 0.7891370445489884\n",
      "[32, 300] loss: 0.7986639595031738\n",
      "[33, 100] loss: 0.8072842198610306\n",
      "[33, 200] loss: 0.7711935514211654\n",
      "[33, 300] loss: 0.7917725121974946\n",
      "[34, 100] loss: 0.7832998389005661\n",
      "[34, 200] loss: 0.8072773718833923\n",
      "[34, 300] loss: 0.7756464189291\n",
      "[35, 100] loss: 0.7932267141342163\n",
      "[35, 200] loss: 0.7733680987358094\n",
      "[35, 300] loss: 0.7746885859966278\n",
      "[36, 100] loss: 0.7744594252109528\n",
      "[36, 200] loss: 0.7863353562355041\n",
      "[36, 300] loss: 0.779017580151558\n",
      "[37, 100] loss: 0.7734912711381913\n",
      "[37, 200] loss: 0.8064032310247421\n",
      "[37, 300] loss: 0.7770818394422531\n",
      "[38, 100] loss: 0.7738763290643692\n",
      "[38, 200] loss: 0.7783698254823684\n",
      "[38, 300] loss: 0.767886421084404\n",
      "[39, 100] loss: 0.7672122383117675\n",
      "[39, 200] loss: 0.7885656195878983\n",
      "[39, 300] loss: 0.8013872754573822\n",
      "[40, 100] loss: 0.7725859224796295\n",
      "[40, 200] loss: 0.7941718804836273\n",
      "[40, 300] loss: 0.7821779954433441\n",
      "[41, 100] loss: 0.7765788888931274\n",
      "[41, 200] loss: 0.7704981350898743\n",
      "[41, 300] loss: 0.7709629011154174\n",
      "[42, 100] loss: 0.7713047677278518\n",
      "[42, 200] loss: 0.777649735212326\n",
      "[42, 300] loss: 0.7868814253807068\n",
      "[43, 100] loss: 0.7910631310939789\n",
      "[43, 200] loss: 0.7741548675298691\n",
      "[43, 300] loss: 0.7884543943405151\n",
      "[44, 100] loss: 0.7856437623500824\n",
      "[44, 200] loss: 0.778894053697586\n",
      "[44, 300] loss: 0.7620626503229141\n",
      "[45, 100] loss: 0.7703822070360183\n",
      "[45, 200] loss: 0.7744381678104401\n",
      "[45, 300] loss: 0.7937245464324951\n",
      "[46, 100] loss: 0.7839631873369217\n",
      "[46, 200] loss: 0.7725125682353974\n",
      "[46, 300] loss: 0.7726707202196121\n",
      "[47, 100] loss: 0.781081702709198\n",
      "[47, 200] loss: 0.7746054822206497\n",
      "[47, 300] loss: 0.7823558902740478\n",
      "[48, 100] loss: 0.7632897728681565\n",
      "[48, 200] loss: 0.7729745131731033\n",
      "[48, 300] loss: 0.762462785243988\n",
      "[49, 100] loss: 0.7603499561548233\n",
      "[49, 200] loss: 0.7503002893924713\n",
      "[49, 300] loss: 0.7705799782276154\n",
      "[50, 100] loss: 0.770306665301323\n",
      "[50, 200] loss: 0.7713452070951462\n",
      "[50, 300] loss: 0.7786422818899155\n",
      "[51, 100] loss: 0.7566779422760009\n",
      "[51, 200] loss: 0.7777217799425125\n",
      "[51, 300] loss: 0.7874910336732864\n",
      "[52, 100] loss: 0.76487697660923\n",
      "[52, 200] loss: 0.7640931802988052\n",
      "[52, 300] loss: 0.76706287920475\n",
      "[53, 100] loss: 0.7493745988607406\n",
      "[53, 200] loss: 0.7594459068775177\n",
      "[53, 300] loss: 0.7680721431970596\n",
      "[54, 100] loss: 0.7532683217525482\n",
      "[54, 200] loss: 0.7585757803916932\n",
      "[54, 300] loss: 0.7449813932180405\n",
      "[55, 100] loss: 0.7675961953401566\n",
      "[55, 200] loss: 0.7666756325960159\n",
      "[55, 300] loss: 0.7624756306409836\n",
      "[56, 100] loss: 0.7691264897584915\n",
      "[56, 200] loss: 0.75897345662117\n",
      "[56, 300] loss: 0.7623935341835022\n",
      "[57, 100] loss: 0.7758191013336182\n",
      "[57, 200] loss: 0.7717986685037613\n",
      "[57, 300] loss: 0.758211275935173\n",
      "[58, 100] loss: 0.748192121386528\n",
      "[58, 200] loss: 0.7545013421773911\n",
      "[58, 300] loss: 0.7489486473798752\n",
      "[59, 100] loss: 0.7677242183685302\n",
      "[59, 200] loss: 0.7541503095626831\n",
      "[59, 300] loss: 0.7556469213962554\n",
      "[60, 100] loss: 0.7700949782133102\n",
      "[60, 200] loss: 0.7632747399806976\n",
      "[60, 300] loss: 0.7732662838697434\n",
      "[61, 100] loss: 0.7720550209283829\n",
      "[61, 200] loss: 0.7520053911209107\n",
      "[61, 300] loss: 0.7527404016256333\n",
      "[62, 100] loss: 0.7504316025972366\n",
      "[62, 200] loss: 0.7607069045305253\n",
      "[62, 300] loss: 0.7629131603240967\n",
      "[63, 100] loss: 0.7512705928087234\n",
      "[63, 200] loss: 0.7725482499599456\n",
      "[63, 300] loss: 0.769339668750763\n",
      "[64, 100] loss: 0.770466246008873\n",
      "[64, 200] loss: 0.7430053204298019\n",
      "[64, 300] loss: 0.7429331248998642\n",
      "[65, 100] loss: 0.7636879694461822\n",
      "[65, 200] loss: 0.7639973157644272\n",
      "[65, 300] loss: 0.7491289836168289\n",
      "[66, 100] loss: 0.7410577642917633\n",
      "[66, 200] loss: 0.7509724092483521\n",
      "[66, 300] loss: 0.7666393840312957\n",
      "[67, 100] loss: 0.7663144242763519\n",
      "[67, 200] loss: 0.7408940172195435\n",
      "[67, 300] loss: 0.7693561679124832\n",
      "[68, 100] loss: 0.7531219637393951\n",
      "[68, 200] loss: 0.7389388591051101\n",
      "[68, 300] loss: 0.752016333937645\n",
      "[69, 100] loss: 0.7661476117372513\n",
      "[69, 200] loss: 0.7652352476119995\n",
      "[69, 300] loss: 0.7596453160047532\n",
      "[70, 100] loss: 0.7427458399534226\n",
      "[70, 200] loss: 0.7530612045526505\n",
      "[70, 300] loss: 0.7611581665277481\n",
      "[71, 100] loss: 0.757281733751297\n",
      "[71, 200] loss: 0.7507897126674652\n",
      "[71, 300] loss: 0.755046620965004\n",
      "[72, 100] loss: 0.7656311953067779\n",
      "[72, 200] loss: 0.7648046410083771\n",
      "[72, 300] loss: 0.7714462375640869\n",
      "[73, 100] loss: 0.7691488772630691\n",
      "[73, 200] loss: 0.7703564715385437\n",
      "[73, 300] loss: 0.7787335485219955\n",
      "[74, 100] loss: 0.751970402598381\n",
      "[74, 200] loss: 0.7652215218544006\n",
      "[74, 300] loss: 0.7768236672878266\n",
      "[75, 100] loss: 0.7580652558803558\n",
      "[75, 200] loss: 0.7759304720163346\n",
      "[75, 300] loss: 0.7760740345716477\n",
      "[76, 100] loss: 0.7490595656633378\n",
      "[76, 200] loss: 0.7554724937677384\n",
      "[76, 300] loss: 0.7553217363357544\n",
      "[77, 100] loss: 0.7468513709306717\n",
      "[77, 200] loss: 0.7420744448900223\n",
      "[77, 300] loss: 0.7456907588243484\n",
      "[78, 100] loss: 0.7425934940576553\n",
      "[78, 200] loss: 0.7528004688024521\n",
      "[78, 300] loss: 0.7521995544433594\n",
      "[79, 100] loss: 0.7496139961481094\n",
      "[79, 200] loss: 0.7489033055305481\n",
      "[79, 300] loss: 0.7560917550325393\n",
      "[80, 100] loss: 0.7672767800092697\n",
      "[80, 200] loss: 0.7485838425159455\n",
      "[80, 300] loss: 0.7538402819633484\n",
      "[81, 100] loss: 0.7544666689634323\n",
      "[81, 200] loss: 0.7660167610645294\n",
      "[81, 300] loss: 0.7401860791444779\n",
      "[82, 100] loss: 0.7634270685911179\n",
      "[82, 200] loss: 0.764355520606041\n",
      "[82, 300] loss: 0.7701162469387054\n",
      "[83, 100] loss: 0.7418644624948502\n",
      "[83, 200] loss: 0.7552851682901383\n",
      "[83, 300] loss: 0.7644449347257614\n",
      "[84, 100] loss: 0.7533972573280334\n",
      "[84, 200] loss: 0.7428072339296341\n",
      "[84, 300] loss: 0.7465383076667785\n",
      "[85, 100] loss: 0.7809769022464752\n",
      "[85, 200] loss: 0.7469396126270295\n",
      "[85, 300] loss: 0.7520798522233964\n",
      "[86, 100] loss: 0.7456055146455765\n",
      "[86, 200] loss: 0.7735181957483291\n",
      "[86, 300] loss: 0.759854010939598\n",
      "[87, 100] loss: 0.7554872435331345\n",
      "[87, 200] loss: 0.7579152578115463\n",
      "[87, 300] loss: 0.7434500801563263\n",
      "[88, 100] loss: 0.7552299785614014\n",
      "[88, 200] loss: 0.7429234743118286\n",
      "[88, 300] loss: 0.7548296135663987\n",
      "[89, 100] loss: 0.7451141348481178\n",
      "[89, 200] loss: 0.7372925102710723\n",
      "[89, 300] loss: 0.750514708161354\n",
      "[90, 100] loss: 0.7444244897365571\n",
      "[90, 200] loss: 0.7738809013366699\n",
      "[90, 300] loss: 0.7486998772621155\n",
      "[91, 100] loss: 0.7403239452838898\n",
      "[91, 200] loss: 0.7224092048406601\n",
      "[91, 300] loss: 0.7368251329660416\n",
      "[92, 100] loss: 0.7282507288455963\n",
      "[92, 200] loss: 0.7402909371256828\n",
      "[92, 300] loss: 0.744026443362236\n",
      "[93, 100] loss: 0.7328423631191253\n",
      "[93, 200] loss: 0.7549715280532837\n",
      "[93, 300] loss: 0.7278078216314315\n",
      "[94, 100] loss: 0.7509603083133698\n",
      "[94, 200] loss: 0.7542125356197357\n",
      "[94, 300] loss: 0.7333132696151733\n",
      "[95, 100] loss: 0.7413467264175415\n",
      "[95, 200] loss: 0.7377614772319794\n",
      "[95, 300] loss: 0.7464456379413604\n",
      "[96, 100] loss: 0.7531138575077057\n",
      "[96, 200] loss: 0.7485581970214844\n",
      "[96, 300] loss: 0.7663549792766571\n",
      "[97, 100] loss: 0.7361628717184067\n",
      "[97, 200] loss: 0.7292445516586303\n",
      "[97, 300] loss: 0.7534362250566482\n",
      "[98, 100] loss: 0.7618993687629699\n",
      "[98, 200] loss: 0.7554204255342484\n",
      "[98, 300] loss: 0.7494943326711655\n",
      "[99, 100] loss: 0.7393783915042877\n",
      "[99, 200] loss: 0.7494584733247757\n",
      "[99, 300] loss: 0.7629646325111389\n",
      "[100, 100] loss: 0.7460086292028427\n",
      "[100, 200] loss: 0.7316387099027634\n",
      "[100, 300] loss: 0.7643215280771255\n",
      "Training model 5 in the ensemble...\n",
      "[1, 100] loss: 2.1124841630458833\n",
      "[1, 200] loss: 1.890515580177307\n",
      "[1, 300] loss: 1.8119473350048065\n",
      "[2, 100] loss: 1.7065761756896973\n",
      "[2, 200] loss: 1.6939810967445375\n",
      "[2, 300] loss: 1.6710556578636169\n",
      "[3, 100] loss: 1.629867559671402\n",
      "[3, 200] loss: 1.5951333808898926\n",
      "[3, 300] loss: 1.5704033398628234\n",
      "[4, 100] loss: 1.5327893614768981\n",
      "[4, 200] loss: 1.4969107294082642\n",
      "[4, 300] loss: 1.4801776695251465\n",
      "[5, 100] loss: 1.4709229469299316\n",
      "[5, 200] loss: 1.4502835249900818\n",
      "[5, 300] loss: 1.4337217688560486\n",
      "[6, 100] loss: 1.4348928654193878\n",
      "[6, 200] loss: 1.3802746868133544\n",
      "[6, 300] loss: 1.3659473514556886\n",
      "[7, 100] loss: 1.3505833482742309\n",
      "[7, 200] loss: 1.3466371512413025\n",
      "[7, 300] loss: 1.322077113389969\n",
      "[8, 100] loss: 1.2862434601783752\n",
      "[8, 200] loss: 1.2815377712249756\n",
      "[8, 300] loss: 1.285048362016678\n",
      "[9, 100] loss: 1.2666577458381654\n",
      "[9, 200] loss: 1.2523379862308501\n",
      "[9, 300] loss: 1.232821568250656\n",
      "[10, 100] loss: 1.2220161825418472\n",
      "[10, 200] loss: 1.2159430873394013\n",
      "[10, 300] loss: 1.2001249694824219\n",
      "[11, 100] loss: 1.2010066241025925\n",
      "[11, 200] loss: 1.207005175948143\n",
      "[11, 300] loss: 1.1933778947591782\n",
      "[12, 100] loss: 1.1572644418478013\n",
      "[12, 200] loss: 1.1703385961055757\n",
      "[12, 300] loss: 1.166269227862358\n",
      "[13, 100] loss: 1.1507879173755646\n",
      "[13, 200] loss: 1.1450638675689697\n",
      "[13, 300] loss: 1.1375031125545503\n",
      "[14, 100] loss: 1.1314813113212585\n",
      "[14, 200] loss: 1.1226800763607026\n",
      "[14, 300] loss: 1.1152217137813567\n",
      "[15, 100] loss: 1.1089113569259643\n",
      "[15, 200] loss: 1.0915226113796235\n",
      "[15, 300] loss: 1.1025735306739808\n",
      "[16, 100] loss: 1.101044956445694\n",
      "[16, 200] loss: 1.0954861974716186\n",
      "[16, 300] loss: 1.0713358807563782\n",
      "[17, 100] loss: 1.0721353387832642\n",
      "[17, 200] loss: 1.0767035067081452\n",
      "[17, 300] loss: 1.0731122106313706\n",
      "[18, 100] loss: 1.074154490828514\n",
      "[18, 200] loss: 1.0697679334878922\n",
      "[18, 300] loss: 1.0717860090732574\n",
      "[19, 100] loss: 1.0641504371166228\n",
      "[19, 200] loss: 1.0518393838405609\n",
      "[19, 300] loss: 1.0626758360862731\n",
      "[20, 100] loss: 1.0458262079954148\n",
      "[20, 200] loss: 1.050334216952324\n",
      "[20, 300] loss: 1.0666515004634858\n",
      "[21, 100] loss: 1.0352007818222047\n",
      "[21, 200] loss: 1.0338059455156325\n",
      "[21, 300] loss: 1.0310524135828019\n",
      "[22, 100] loss: 1.0286506128311157\n",
      "[22, 200] loss: 1.0218307822942734\n",
      "[22, 300] loss: 1.009535140991211\n",
      "[23, 100] loss: 0.9921026128530502\n",
      "[23, 200] loss: 1.0154835760593415\n",
      "[23, 300] loss: 1.025247749686241\n",
      "[24, 100] loss: 1.0288719379901885\n",
      "[24, 200] loss: 1.0121799778938294\n",
      "[24, 300] loss: 1.0096896636486052\n",
      "[25, 100] loss: 1.000308607816696\n",
      "[25, 200] loss: 1.0196834552288054\n",
      "[25, 300] loss: 1.030101329088211\n",
      "[26, 100] loss: 1.011681861281395\n",
      "[26, 200] loss: 0.9921891242265701\n",
      "[26, 300] loss: 1.0027137577533722\n",
      "[27, 100] loss: 1.014097767472267\n",
      "[27, 200] loss: 0.9786326533555985\n",
      "[27, 300] loss: 0.9810457694530487\n",
      "[28, 100] loss: 0.98613425552845\n",
      "[28, 200] loss: 0.9843237239122391\n",
      "[28, 300] loss: 0.9924089443683625\n",
      "[29, 100] loss: 0.9872014057636261\n",
      "[29, 200] loss: 0.9735052239894867\n",
      "[29, 300] loss: 0.979396967291832\n",
      "[30, 100] loss: 0.9710816937685013\n",
      "[30, 200] loss: 0.9675625360012055\n",
      "[30, 300] loss: 0.9759457343816758\n",
      "[31, 100] loss: 0.9709900879859924\n",
      "[31, 200] loss: 0.9716478168964386\n",
      "[31, 300] loss: 0.9717746704816819\n",
      "[32, 100] loss: 0.9469729822874069\n",
      "[32, 200] loss: 0.9521864360570907\n",
      "[32, 300] loss: 0.9479310739040375\n",
      "[33, 100] loss: 0.9612586706876755\n",
      "[33, 200] loss: 0.94966024518013\n",
      "[33, 300] loss: 0.9306342899799347\n",
      "[34, 100] loss: 0.9502361357212067\n",
      "[34, 200] loss: 0.9659495902061462\n",
      "[34, 300] loss: 0.9360231178998947\n",
      "[35, 100] loss: 0.9605205374956131\n",
      "[35, 200] loss: 0.9414958208799362\n",
      "[35, 300] loss: 0.9537448185682297\n",
      "[36, 100] loss: 0.9295920634269714\n",
      "[36, 200] loss: 0.9295629447698593\n",
      "[36, 300] loss: 0.9143100816011429\n",
      "[37, 100] loss: 0.9192726558446884\n",
      "[37, 200] loss: 0.9527800804376603\n",
      "[37, 300] loss: 0.9314649015665054\n",
      "[38, 100] loss: 0.9447680574655533\n",
      "[38, 200] loss: 0.9276968598365783\n",
      "[38, 300] loss: 0.9377390950918197\n",
      "[39, 100] loss: 0.9328570020198822\n",
      "[39, 200] loss: 0.9325990414619446\n",
      "[39, 300] loss: 0.950109390616417\n",
      "[40, 100] loss: 0.9504730612039566\n",
      "[40, 200] loss: 0.9430365788936615\n",
      "[40, 300] loss: 0.9294905596971512\n",
      "[41, 100] loss: 0.9206664884090423\n",
      "[41, 200] loss: 0.8955843847990036\n",
      "[41, 300] loss: 0.9205925023555755\n",
      "[42, 100] loss: 0.9236361837387085\n",
      "[42, 200] loss: 0.9108556216955185\n",
      "[42, 300] loss: 0.9231985116004944\n",
      "[43, 100] loss: 0.900198741555214\n",
      "[43, 200] loss: 0.9232636451721191\n",
      "[43, 300] loss: 0.9217410510778428\n",
      "[44, 100] loss: 0.9040447497367858\n",
      "[44, 200] loss: 0.9066280806064606\n",
      "[44, 300] loss: 0.9213466310501098\n",
      "[45, 100] loss: 0.8955134028196334\n",
      "[45, 200] loss: 0.9091718465089798\n",
      "[45, 300] loss: 0.8968143981695175\n",
      "[46, 100] loss: 0.8827921009063721\n",
      "[46, 200] loss: 0.8996885275840759\n",
      "[46, 300] loss: 0.8935767769813537\n",
      "[47, 100] loss: 0.9141935873031616\n",
      "[47, 200] loss: 0.8983675980567932\n",
      "[47, 300] loss: 0.8997609192132949\n",
      "[48, 100] loss: 0.9118438482284545\n",
      "[48, 200] loss: 0.8933202302455903\n",
      "[48, 300] loss: 0.9053251397609711\n",
      "[49, 100] loss: 0.9081232106685638\n",
      "[49, 200] loss: 0.9044794696569443\n",
      "[49, 300] loss: 0.890627121925354\n",
      "[50, 100] loss: 0.8848515200614929\n",
      "[50, 200] loss: 0.8895459115505219\n",
      "[50, 300] loss: 0.8837965899705886\n",
      "[51, 100] loss: 0.8855741369724274\n",
      "[51, 200] loss: 0.8893481135368347\n",
      "[51, 300] loss: 0.8740805339813232\n",
      "[52, 100] loss: 0.8979361915588379\n",
      "[52, 200] loss: 0.8929511296749115\n",
      "[52, 300] loss: 0.8841605466604233\n",
      "[53, 100] loss: 0.8795564299821854\n",
      "[53, 200] loss: 0.8939752870798111\n",
      "[53, 300] loss: 0.8892033404111862\n",
      "[54, 100] loss: 0.8872814530134201\n",
      "[54, 200] loss: 0.872677395939827\n",
      "[54, 300] loss: 0.889553000330925\n",
      "[55, 100] loss: 0.8844810372591019\n",
      "[55, 200] loss: 0.8778696662187576\n",
      "[55, 300] loss: 0.8885300523042678\n",
      "[56, 100] loss: 0.8921587508916855\n",
      "[56, 200] loss: 0.872382527589798\n",
      "[56, 300] loss: 0.8630637609958649\n",
      "[57, 100] loss: 0.8721491450071335\n",
      "[57, 200] loss: 0.8803982496261596\n",
      "[57, 300] loss: 0.8701807862520218\n",
      "[58, 100] loss: 0.8557158339023591\n",
      "[58, 200] loss: 0.8694805628061295\n",
      "[58, 300] loss: 0.895157420039177\n",
      "[59, 100] loss: 0.8824826067686081\n",
      "[59, 200] loss: 0.893851945400238\n",
      "[59, 300] loss: 0.8835004460811615\n",
      "[60, 100] loss: 0.8768318766355514\n",
      "[60, 200] loss: 0.853505784869194\n",
      "[60, 300] loss: 0.8553923004865647\n",
      "[61, 100] loss: 0.873080580830574\n",
      "[61, 200] loss: 0.8600086313486099\n",
      "[61, 300] loss: 0.8724079328775406\n",
      "[62, 100] loss: 0.8578685408830643\n",
      "[62, 200] loss: 0.854172658920288\n",
      "[62, 300] loss: 0.8714377301931381\n",
      "[63, 100] loss: 0.8624675983190536\n",
      "[63, 200] loss: 0.8798118329048157\n",
      "[63, 300] loss: 0.8540713310241699\n",
      "[64, 100] loss: 0.8834234821796417\n",
      "[64, 200] loss: 0.8657126325368881\n",
      "[64, 300] loss: 0.8656627082824707\n",
      "[65, 100] loss: 0.8529965823888779\n",
      "[65, 200] loss: 0.8455856156349182\n",
      "[65, 300] loss: 0.8511449086666107\n",
      "[66, 100] loss: 0.8488122779130935\n",
      "[66, 200] loss: 0.8596236038208008\n",
      "[66, 300] loss: 0.8559168606996537\n",
      "[67, 100] loss: 0.8625665783882142\n",
      "[67, 200] loss: 0.8636932402849198\n",
      "[67, 300] loss: 0.867926721572876\n",
      "[68, 100] loss: 0.8632601982355118\n",
      "[68, 200] loss: 0.8634151458740235\n",
      "[68, 300] loss: 0.8243431925773621\n",
      "[69, 100] loss: 0.8570552378892898\n",
      "[69, 200] loss: 0.8378637969493866\n",
      "[69, 300] loss: 0.8533154475688934\n",
      "[70, 100] loss: 0.8640301012992859\n",
      "[70, 200] loss: 0.8522897082567215\n",
      "[70, 300] loss: 0.852980164885521\n",
      "[71, 100] loss: 0.8326619374752045\n",
      "[71, 200] loss: 0.8559569162130356\n",
      "[71, 300] loss: 0.8495635330677033\n",
      "[72, 100] loss: 0.8401892977952957\n",
      "[72, 200] loss: 0.8486676156520844\n",
      "[72, 300] loss: 0.8607663065195084\n",
      "[73, 100] loss: 0.844150682091713\n",
      "[73, 200] loss: 0.8394883686304092\n",
      "[73, 300] loss: 0.8489575427770615\n",
      "[74, 100] loss: 0.8548477303981781\n",
      "[74, 200] loss: 0.8331027942895889\n",
      "[74, 300] loss: 0.8432781618833541\n",
      "[75, 100] loss: 0.8388172990083694\n",
      "[75, 200] loss: 0.8450180107355117\n",
      "[75, 300] loss: 0.836847978234291\n",
      "[76, 100] loss: 0.8490708470344543\n",
      "[76, 200] loss: 0.8521370422840119\n",
      "[76, 300] loss: 0.8532960480451584\n",
      "[77, 100] loss: 0.8236109435558319\n",
      "[77, 200] loss: 0.8333543390035629\n",
      "[77, 300] loss: 0.8376512646675109\n",
      "[78, 100] loss: 0.8358238118886948\n",
      "[78, 200] loss: 0.8299625861644745\n",
      "[78, 300] loss: 0.8472585439682007\n",
      "[79, 100] loss: 0.8298349606990815\n",
      "[79, 200] loss: 0.8421935677528382\n",
      "[79, 300] loss: 0.8375339859724045\n",
      "[80, 100] loss: 0.8514162415266037\n",
      "[80, 200] loss: 0.8185515993833542\n",
      "[80, 300] loss: 0.8378700852394104\n",
      "[81, 100] loss: 0.8195120310783386\n",
      "[81, 200] loss: 0.8307430654764175\n",
      "[81, 300] loss: 0.8280299484729767\n",
      "[82, 100] loss: 0.8537053352594376\n",
      "[82, 200] loss: 0.8493862867355346\n",
      "[82, 300] loss: 0.8129595798254013\n",
      "[83, 100] loss: 0.8339778089523315\n",
      "[83, 200] loss: 0.8340699100494384\n",
      "[83, 300] loss: 0.8303180825710297\n",
      "[84, 100] loss: 0.8281715351343155\n",
      "[84, 200] loss: 0.8346934854984284\n",
      "[84, 300] loss: 0.8464871895313263\n",
      "[85, 100] loss: 0.8329547584056854\n",
      "[85, 200] loss: 0.8497051894664764\n",
      "[85, 300] loss: 0.813264149427414\n",
      "[86, 100] loss: 0.8527400565147399\n",
      "[86, 200] loss: 0.8372372204065323\n",
      "[86, 300] loss: 0.8255600279569626\n",
      "[87, 100] loss: 0.8405338197946548\n",
      "[87, 200] loss: 0.830356542468071\n",
      "[87, 300] loss: 0.835691402554512\n",
      "[88, 100] loss: 0.836414452791214\n",
      "[88, 200] loss: 0.8226609754562378\n",
      "[88, 300] loss: 0.8319756883382797\n",
      "[89, 100] loss: 0.8256445717811585\n",
      "[89, 200] loss: 0.8285308045148849\n",
      "[89, 300] loss: 0.7897374963760376\n",
      "[90, 100] loss: 0.8400364077091217\n",
      "[90, 200] loss: 0.8383347165584564\n",
      "[90, 300] loss: 0.829580352306366\n",
      "[91, 100] loss: 0.8194591474533081\n",
      "[91, 200] loss: 0.8409208983182908\n",
      "[91, 300] loss: 0.8239768445491791\n",
      "[92, 100] loss: 0.826981833577156\n",
      "[92, 200] loss: 0.822629908323288\n",
      "[92, 300] loss: 0.8210619753599167\n",
      "[93, 100] loss: 0.8293161165714263\n",
      "[93, 200] loss: 0.816052051782608\n",
      "[93, 300] loss: 0.8122578638792038\n",
      "[94, 100] loss: 0.8227665805816651\n",
      "[94, 200] loss: 0.8209042745828629\n",
      "[94, 300] loss: 0.8180502790212631\n",
      "[95, 100] loss: 0.8326560223102569\n",
      "[95, 200] loss: 0.8090031039714813\n",
      "[95, 300] loss: 0.8307044172286987\n",
      "[96, 100] loss: 0.8361829644441605\n",
      "[96, 200] loss: 0.8177933114767074\n",
      "[96, 300] loss: 0.8131210714578628\n",
      "[97, 100] loss: 0.81935855448246\n",
      "[97, 200] loss: 0.8393378311395645\n",
      "[97, 300] loss: 0.8075662910938263\n",
      "[98, 100] loss: 0.8154406398534775\n",
      "[98, 200] loss: 0.8021404677629471\n",
      "[98, 300] loss: 0.8137017327547074\n",
      "[99, 100] loss: 0.8328818452358245\n",
      "[99, 200] loss: 0.8155755573511123\n",
      "[99, 300] loss: 0.8187676388025283\n",
      "[100, 100] loss: 0.8316627311706543\n",
      "[100, 200] loss: 0.8351479399204255\n",
      "[100, 300] loss: 0.8188642948865891\n",
      "Training model 6 in the ensemble...\n",
      "[1, 100] loss: 2.128898048400879\n",
      "[1, 200] loss: 1.9267067003250122\n",
      "[1, 300] loss: 1.8525523328781128\n",
      "[2, 100] loss: 1.7883643221855163\n",
      "[2, 200] loss: 1.7586011755466462\n",
      "[2, 300] loss: 1.734922330379486\n",
      "[3, 100] loss: 1.703274736404419\n",
      "[3, 200] loss: 1.67107897400856\n",
      "[3, 300] loss: 1.6586834287643433\n",
      "[4, 100] loss: 1.605198974609375\n",
      "[4, 200] loss: 1.6143581402301788\n",
      "[4, 300] loss: 1.596294071674347\n",
      "[5, 100] loss: 1.5507264411449433\n",
      "[5, 200] loss: 1.530731737613678\n",
      "[5, 300] loss: 1.5265760612487793\n",
      "[6, 100] loss: 1.5047046363353729\n",
      "[6, 200] loss: 1.4998553347587587\n",
      "[6, 300] loss: 1.4817809581756591\n",
      "[7, 100] loss: 1.4488140797615052\n",
      "[7, 200] loss: 1.4385869359970094\n",
      "[7, 300] loss: 1.441855937242508\n",
      "[8, 100] loss: 1.4117189133167267\n",
      "[8, 200] loss: 1.4032738769054414\n",
      "[8, 300] loss: 1.3912171339988708\n",
      "[9, 100] loss: 1.3617143547534942\n",
      "[9, 200] loss: 1.373451966047287\n",
      "[9, 300] loss: 1.3283469021320342\n",
      "[10, 100] loss: 1.3193143832683563\n",
      "[10, 200] loss: 1.320609337091446\n",
      "[10, 300] loss: 1.3130060732364655\n",
      "[11, 100] loss: 1.2880859744548798\n",
      "[11, 200] loss: 1.281544394493103\n",
      "[11, 300] loss: 1.276970283985138\n",
      "[12, 100] loss: 1.2540111166238785\n",
      "[12, 200] loss: 1.2532777321338653\n",
      "[12, 300] loss: 1.2450591623783112\n",
      "[13, 100] loss: 1.2448034536838533\n",
      "[13, 200] loss: 1.2253208005428313\n",
      "[13, 300] loss: 1.2056151312589645\n",
      "[14, 100] loss: 1.2126476538181306\n",
      "[14, 200] loss: 1.185678592324257\n",
      "[14, 300] loss: 1.1822870868444442\n",
      "[15, 100] loss: 1.1697689759731293\n",
      "[15, 200] loss: 1.1792275071144105\n",
      "[15, 300] loss: 1.1806638270616532\n",
      "[16, 100] loss: 1.1343545937538146\n",
      "[16, 200] loss: 1.152272533774376\n",
      "[16, 300] loss: 1.151334711909294\n",
      "[17, 100] loss: 1.124851151704788\n",
      "[17, 200] loss: 1.1335523462295531\n",
      "[17, 300] loss: 1.10788587808609\n",
      "[18, 100] loss: 1.106098965406418\n",
      "[18, 200] loss: 1.1000568985939025\n",
      "[18, 300] loss: 1.116143114566803\n",
      "[19, 100] loss: 1.105864155292511\n",
      "[19, 200] loss: 1.1104385101795196\n",
      "[19, 300] loss: 1.093272601366043\n",
      "[20, 100] loss: 1.0861642915010452\n",
      "[20, 200] loss: 1.0864208817481995\n",
      "[20, 300] loss: 1.091022630929947\n",
      "[21, 100] loss: 1.0719344371557236\n",
      "[21, 200] loss: 1.0744637018442154\n",
      "[21, 300] loss: 1.071106731891632\n",
      "[22, 100] loss: 1.0854065203666687\n",
      "[22, 200] loss: 1.0524956250190736\n",
      "[22, 300] loss: 1.0780573904514312\n",
      "[23, 100] loss: 1.0455258345603944\n",
      "[23, 200] loss: 1.0513538974523544\n",
      "[23, 300] loss: 1.043596831560135\n",
      "[24, 100] loss: 1.057547816634178\n",
      "[24, 200] loss: 1.0373155057430268\n",
      "[24, 300] loss: 1.0187980824708938\n",
      "[25, 100] loss: 1.030395411849022\n",
      "[25, 200] loss: 1.0260813331604004\n",
      "[25, 300] loss: 1.0268488520383834\n",
      "[26, 100] loss: 1.0188806623220443\n",
      "[26, 200] loss: 1.0140589106082916\n",
      "[26, 300] loss: 1.0266854971647263\n",
      "[27, 100] loss: 1.0252665680646897\n",
      "[27, 200] loss: 1.0052622640132904\n",
      "[27, 300] loss: 1.0105008637905122\n",
      "[28, 100] loss: 1.0149591094255448\n",
      "[28, 200] loss: 0.9973199480772018\n",
      "[28, 300] loss: 1.0043780064582826\n",
      "[29, 100] loss: 1.0037279880046845\n",
      "[29, 200] loss: 0.9760406219959259\n",
      "[29, 300] loss: 0.9880381196737289\n",
      "[30, 100] loss: 1.0074145847558975\n",
      "[30, 200] loss: 1.005466114282608\n",
      "[30, 300] loss: 0.9818373316526413\n",
      "[31, 100] loss: 0.9675314080715179\n",
      "[31, 200] loss: 1.0026905876398087\n",
      "[31, 300] loss: 0.9564783138036728\n",
      "[32, 100] loss: 0.98065593957901\n",
      "[32, 200] loss: 0.9761276477575302\n",
      "[32, 300] loss: 0.9860502249002456\n",
      "[33, 100] loss: 0.9793661862611771\n",
      "[33, 200] loss: 0.963853787779808\n",
      "[33, 300] loss: 0.9599052315950394\n",
      "[34, 100] loss: 0.9808958822488785\n",
      "[34, 200] loss: 0.9820038431882858\n",
      "[34, 300] loss: 0.9586628121137619\n",
      "[35, 100] loss: 0.9657284331321716\n",
      "[35, 200] loss: 0.9454673045873642\n",
      "[35, 300] loss: 0.9661226963996887\n",
      "[36, 100] loss: 0.9661297762393951\n",
      "[36, 200] loss: 0.9619528639316559\n",
      "[36, 300] loss: 0.974157030582428\n",
      "[37, 100] loss: 0.9527848941087723\n",
      "[37, 200] loss: 0.9750332885980606\n",
      "[37, 300] loss: 0.9660791051387787\n",
      "[38, 100] loss: 0.9493498706817627\n",
      "[38, 200] loss: 0.9537381744384765\n",
      "[38, 300] loss: 0.9487076687812805\n",
      "[39, 100] loss: 0.9429729998111724\n",
      "[39, 200] loss: 0.9517397367954255\n",
      "[39, 300] loss: 0.9450347220897675\n",
      "[40, 100] loss: 0.9381602495908737\n",
      "[40, 200] loss: 0.9353464770317078\n",
      "[40, 300] loss: 0.9384849655628205\n",
      "[41, 100] loss: 0.9507452654838562\n",
      "[41, 200] loss: 0.9594734668731689\n",
      "[41, 300] loss: 0.9585334485769272\n",
      "[42, 100] loss: 0.9274804711341857\n",
      "[42, 200] loss: 0.9279636281728745\n",
      "[42, 300] loss: 0.9590140438079834\n",
      "[43, 100] loss: 0.9327743822336196\n",
      "[43, 200] loss: 0.9400660139322281\n",
      "[43, 300] loss: 0.9319481962919235\n",
      "[44, 100] loss: 0.9243483090400696\n",
      "[44, 200] loss: 0.9250302278995514\n",
      "[44, 300] loss: 0.9326510548591613\n",
      "[45, 100] loss: 0.9403439950942993\n",
      "[45, 200] loss: 0.9476004678010941\n",
      "[45, 300] loss: 0.9438864278793335\n",
      "[46, 100] loss: 0.9291986346244812\n",
      "[46, 200] loss: 0.9237848597764969\n",
      "[46, 300] loss: 0.9253269106149673\n",
      "[47, 100] loss: 0.9253860169649124\n",
      "[47, 200] loss: 0.9264981883764267\n",
      "[47, 300] loss: 0.9265354120731354\n",
      "[48, 100] loss: 0.9213549208641052\n",
      "[48, 200] loss: 0.9093362438678741\n",
      "[48, 300] loss: 0.9145706290006638\n",
      "[49, 100] loss: 0.9274841088056565\n",
      "[49, 200] loss: 0.9109280741214753\n",
      "[49, 300] loss: 0.9212752509117127\n",
      "[50, 100] loss: 0.9087263095378876\n",
      "[50, 200] loss: 0.908717257976532\n",
      "[50, 300] loss: 0.913805968761444\n",
      "[51, 100] loss: 0.8867690980434417\n",
      "[51, 200] loss: 0.9091944080591202\n",
      "[51, 300] loss: 0.9001977694034576\n",
      "[52, 100] loss: 0.9019495904445648\n",
      "[52, 200] loss: 0.9018276393413543\n",
      "[52, 300] loss: 0.9088456833362579\n",
      "[53, 100] loss: 0.9068389385938644\n",
      "[53, 200] loss: 0.9089859437942505\n",
      "[53, 300] loss: 0.9007350099086762\n",
      "[54, 100] loss: 0.8965876168012619\n",
      "[54, 200] loss: 0.9074484884738923\n",
      "[54, 300] loss: 0.8976891434192658\n",
      "[55, 100] loss: 0.9051341509819031\n",
      "[55, 200] loss: 0.8960168677568435\n",
      "[55, 300] loss: 0.9024491971731186\n",
      "[56, 100] loss: 0.9020646566152573\n",
      "[56, 200] loss: 0.8909321027994156\n",
      "[56, 300] loss: 0.9270210182666778\n",
      "[57, 100] loss: 0.9041927462816238\n",
      "[57, 200] loss: 0.8951040148735047\n",
      "[57, 300] loss: 0.8892618507146836\n",
      "[58, 100] loss: 0.9057331430912018\n",
      "[58, 200] loss: 0.9002420526742935\n",
      "[58, 300] loss: 0.8989400655031204\n",
      "[59, 100] loss: 0.8893400412797928\n",
      "[59, 200] loss: 0.8912636482715607\n",
      "[59, 300] loss: 0.8909711486101151\n",
      "[60, 100] loss: 0.8912853169441223\n",
      "[60, 200] loss: 0.8862458479404449\n",
      "[60, 300] loss: 0.8987687414884568\n",
      "[61, 100] loss: 0.879135907292366\n",
      "[61, 200] loss: 0.8687546283006669\n",
      "[61, 300] loss: 0.8903950697183609\n",
      "[62, 100] loss: 0.8853855395317077\n",
      "[62, 200] loss: 0.880792663693428\n",
      "[62, 300] loss: 0.8735572308301925\n",
      "[63, 100] loss: 0.8941514450311661\n",
      "[63, 200] loss: 0.8906375032663345\n",
      "[63, 300] loss: 0.8767645072937011\n",
      "[64, 100] loss: 0.8736705529689789\n",
      "[64, 200] loss: 0.883608125448227\n",
      "[64, 300] loss: 0.8823030316829681\n",
      "[65, 100] loss: 0.876141574382782\n",
      "[65, 200] loss: 0.8817643427848816\n",
      "[65, 300] loss: 0.863553181886673\n",
      "[66, 100] loss: 0.8915338099002839\n",
      "[66, 200] loss: 0.8853311848640442\n",
      "[66, 300] loss: 0.8874761474132538\n",
      "[67, 100] loss: 0.8552118253707885\n",
      "[67, 200] loss: 0.8882070684432983\n",
      "[67, 300] loss: 0.8775244182348252\n",
      "[68, 100] loss: 0.8851640921831131\n",
      "[68, 200] loss: 0.8802202618122101\n",
      "[68, 300] loss: 0.8895914363861084\n",
      "[69, 100] loss: 0.8603247362375259\n",
      "[69, 200] loss: 0.8698261761665345\n",
      "[69, 300] loss: 0.8776943367719651\n",
      "[70, 100] loss: 0.9028017127513885\n",
      "[70, 200] loss: 0.8667641103267669\n",
      "[70, 300] loss: 0.8573001772165298\n",
      "[71, 100] loss: 0.8740834724903107\n",
      "[71, 200] loss: 0.8751320225000382\n",
      "[71, 300] loss: 0.8646105468273163\n",
      "[72, 100] loss: 0.8697612923383713\n",
      "[72, 200] loss: 0.8794714605808258\n",
      "[72, 300] loss: 0.877036200761795\n",
      "[73, 100] loss: 0.8783702349662781\n",
      "[73, 200] loss: 0.8712467277050018\n",
      "[73, 300] loss: 0.8627573704719543\n",
      "[74, 100] loss: 0.8780375254154206\n",
      "[74, 200] loss: 0.8615623134374618\n",
      "[74, 300] loss: 0.8484841829538345\n",
      "[75, 100] loss: 0.858124298453331\n",
      "[75, 200] loss: 0.8709804928302765\n",
      "[75, 300] loss: 0.8522107404470444\n",
      "[76, 100] loss: 0.8517841839790344\n",
      "[76, 200] loss: 0.8563183796405792\n",
      "[76, 300] loss: 0.8675830912590027\n",
      "[77, 100] loss: 0.8619532382488251\n",
      "[77, 200] loss: 0.8424959391355514\n",
      "[77, 300] loss: 0.8747081357240677\n",
      "[78, 100] loss: 0.8500298273563385\n",
      "[78, 200] loss: 0.866291314959526\n",
      "[78, 300] loss: 0.8662529373168946\n",
      "[79, 100] loss: 0.849965472817421\n",
      "[79, 200] loss: 0.864875255227089\n",
      "[79, 300] loss: 0.8459294581413269\n",
      "[80, 100] loss: 0.8717757892608643\n",
      "[80, 200] loss: 0.8683885729312897\n",
      "[80, 300] loss: 0.8570354783535004\n",
      "[81, 100] loss: 0.8324486154317856\n",
      "[81, 200] loss: 0.851786321401596\n",
      "[81, 300] loss: 0.8349208903312683\n",
      "[82, 100] loss: 0.8621993255615235\n",
      "[82, 200] loss: 0.8496833497285843\n",
      "[82, 300] loss: 0.8539667397737503\n",
      "[83, 100] loss: 0.8686691439151764\n",
      "[83, 200] loss: 0.8445366621017456\n",
      "[83, 300] loss: 0.8488954287767411\n",
      "[84, 100] loss: 0.8419195127487182\n",
      "[84, 200] loss: 0.869930939078331\n",
      "[84, 300] loss: 0.8422742384672165\n",
      "[85, 100] loss: 0.8353422528505325\n",
      "[85, 200] loss: 0.8642785859107971\n",
      "[85, 300] loss: 0.8583584064245224\n",
      "[86, 100] loss: 0.8645300054550171\n",
      "[86, 200] loss: 0.8489983755350113\n",
      "[86, 300] loss: 0.8653895145654679\n",
      "[87, 100] loss: 0.8688812857866287\n",
      "[87, 200] loss: 0.8510019505023956\n",
      "[87, 300] loss: 0.841048087477684\n",
      "[88, 100] loss: 0.8310467457771301\n",
      "[88, 200] loss: 0.8650983536243438\n",
      "[88, 300] loss: 0.8262945330142974\n",
      "[89, 100] loss: 0.8632066380977631\n",
      "[89, 200] loss: 0.8429613000154496\n",
      "[89, 300] loss: 0.8349949014186859\n",
      "[90, 100] loss: 0.8395792073011399\n",
      "[90, 200] loss: 0.8571509623527527\n",
      "[90, 300] loss: 0.8362276870012283\n",
      "[91, 100] loss: 0.8538542383909226\n",
      "[91, 200] loss: 0.8503387767076492\n",
      "[91, 300] loss: 0.8429027134180069\n",
      "[92, 100] loss: 0.8593192040920258\n",
      "[92, 200] loss: 0.8529161536693572\n",
      "[92, 300] loss: 0.8514899760484695\n",
      "[93, 100] loss: 0.8470425492525101\n",
      "[93, 200] loss: 0.8589108997583389\n",
      "[93, 300] loss: 0.8355372321605682\n",
      "[94, 100] loss: 0.8458925855159759\n",
      "[94, 200] loss: 0.8506671857833862\n",
      "[94, 300] loss: 0.8617187708616256\n",
      "[95, 100] loss: 0.8297904425859451\n",
      "[95, 200] loss: 0.8385056412220001\n",
      "[95, 300] loss: 0.8586050480604172\n",
      "[96, 100] loss: 0.835888643860817\n",
      "[96, 200] loss: 0.828217556476593\n",
      "[96, 300] loss: 0.8398094236850738\n",
      "[97, 100] loss: 0.8397177028656005\n",
      "[97, 200] loss: 0.8518819010257721\n",
      "[97, 300] loss: 0.8650101292133331\n",
      "[98, 100] loss: 0.8178070145845413\n",
      "[98, 200] loss: 0.8343680441379547\n",
      "[98, 300] loss: 0.8320625525712967\n",
      "[99, 100] loss: 0.8567149305343628\n",
      "[99, 200] loss: 0.8349845904111862\n",
      "[99, 300] loss: 0.8395158910751342\n",
      "[100, 100] loss: 0.8121118909120559\n",
      "[100, 200] loss: 0.8445762795209885\n",
      "[100, 300] loss: 0.8521199494600296\n",
      "Training model 7 in the ensemble...\n",
      "[1, 100] loss: 2.134340962171555\n",
      "[1, 200] loss: 1.9461946856975556\n",
      "[1, 300] loss: 1.8788497292995452\n",
      "[2, 100] loss: 1.8053046488761901\n",
      "[2, 200] loss: 1.787232724428177\n",
      "[2, 300] loss: 1.7382855606079102\n",
      "[3, 100] loss: 1.6795034873485566\n",
      "[3, 200] loss: 1.6562902975082396\n",
      "[3, 300] loss: 1.625136786699295\n",
      "[4, 100] loss: 1.5675439631938934\n",
      "[4, 200] loss: 1.561741783618927\n",
      "[4, 300] loss: 1.5535966956615448\n",
      "[5, 100] loss: 1.5192587673664093\n",
      "[5, 200] loss: 1.5141762864589692\n",
      "[5, 300] loss: 1.5093599486351013\n",
      "[6, 100] loss: 1.4770389115810394\n",
      "[6, 200] loss: 1.471342569589615\n",
      "[6, 300] loss: 1.4434688591957092\n",
      "[7, 100] loss: 1.41498730301857\n",
      "[7, 200] loss: 1.4320381677150726\n",
      "[7, 300] loss: 1.4184428358078003\n",
      "[8, 100] loss: 1.400807377099991\n",
      "[8, 200] loss: 1.3627486431598663\n",
      "[8, 300] loss: 1.361447592973709\n",
      "[9, 100] loss: 1.3545748448371888\n",
      "[9, 200] loss: 1.3406405436992646\n",
      "[9, 300] loss: 1.314200247526169\n",
      "[10, 100] loss: 1.3163828110694886\n",
      "[10, 200] loss: 1.2880998432636261\n",
      "[10, 300] loss: 1.2932572340965272\n",
      "[11, 100] loss: 1.276474995613098\n",
      "[11, 200] loss: 1.2700680959224702\n",
      "[11, 300] loss: 1.2344547080993653\n",
      "[12, 100] loss: 1.233332462310791\n",
      "[12, 200] loss: 1.2134879410266877\n",
      "[12, 300] loss: 1.2325894165039062\n",
      "[13, 100] loss: 1.2233759689331054\n",
      "[13, 200] loss: 1.2085726010799407\n",
      "[13, 300] loss: 1.199705762863159\n",
      "[14, 100] loss: 1.1776072853803634\n",
      "[14, 200] loss: 1.1874408966302872\n",
      "[14, 300] loss: 1.186043136715889\n",
      "[15, 100] loss: 1.1712431055307388\n",
      "[15, 200] loss: 1.154936850667\n",
      "[15, 300] loss: 1.1483441311120988\n",
      "[16, 100] loss: 1.1498557543754577\n",
      "[16, 200] loss: 1.1264897406101226\n",
      "[16, 300] loss: 1.1288061386346817\n",
      "[17, 100] loss: 1.1128864467144013\n",
      "[17, 200] loss: 1.1484157979488372\n",
      "[17, 300] loss: 1.1183674657344818\n",
      "[18, 100] loss: 1.105154309272766\n",
      "[18, 200] loss: 1.1158702713251114\n",
      "[18, 300] loss: 1.0936289888620376\n",
      "[19, 100] loss: 1.0950947678089142\n",
      "[19, 200] loss: 1.0950051635503768\n",
      "[19, 300] loss: 1.0904914963245391\n",
      "[20, 100] loss: 1.0933674365282058\n",
      "[20, 200] loss: 1.082361347079277\n",
      "[20, 300] loss: 1.0705974262952804\n",
      "[21, 100] loss: 1.0731033819913864\n",
      "[21, 200] loss: 1.0761309045553207\n",
      "[21, 300] loss: 1.0430255830287933\n",
      "[22, 100] loss: 1.0785982400178908\n",
      "[22, 200] loss: 1.0576599854230881\n",
      "[22, 300] loss: 1.0581335091590882\n",
      "[23, 100] loss: 1.0509601938724518\n",
      "[23, 200] loss: 1.0417196321487427\n",
      "[23, 300] loss: 1.0428895902633668\n",
      "[24, 100] loss: 1.0433644378185272\n",
      "[24, 200] loss: 1.0082097280025482\n",
      "[24, 300] loss: 1.0195248240232468\n",
      "[25, 100] loss: 1.036309729218483\n",
      "[25, 200] loss: 1.0301837080717087\n",
      "[25, 300] loss: 1.0162735629081725\n",
      "[26, 100] loss: 1.0259576445817948\n",
      "[26, 200] loss: 1.0275208777189255\n",
      "[26, 300] loss: 1.0118324249982833\n",
      "[27, 100] loss: 1.017383688688278\n",
      "[27, 200] loss: 1.018450963497162\n",
      "[27, 300] loss: 0.9888359713554382\n",
      "[28, 100] loss: 1.0289065515995026\n",
      "[28, 200] loss: 1.0001918971538544\n",
      "[28, 300] loss: 1.010365543961525\n",
      "[29, 100] loss: 0.9922330349683761\n",
      "[29, 200] loss: 0.9936614429950714\n",
      "[29, 300] loss: 0.9942505186796189\n",
      "[30, 100] loss: 0.9777914482355118\n",
      "[30, 200] loss: 0.9864302808046341\n",
      "[30, 300] loss: 1.0088610112667085\n",
      "[31, 100] loss: 0.9903094136714935\n",
      "[31, 200] loss: 0.9800280946493148\n",
      "[31, 300] loss: 0.99041468501091\n",
      "[32, 100] loss: 0.9732396471500396\n",
      "[32, 200] loss: 0.9761177551746368\n",
      "[32, 300] loss: 0.9950845295190811\n",
      "[33, 100] loss: 0.9834280151128769\n",
      "[33, 200] loss: 0.9755110347270965\n",
      "[33, 300] loss: 0.9719509291648865\n",
      "[34, 100] loss: 0.9840848046541214\n",
      "[34, 200] loss: 0.9550564831495285\n",
      "[34, 300] loss: 0.9766318047046662\n",
      "[35, 100] loss: 0.9745334303379058\n",
      "[35, 200] loss: 0.9727572280168534\n",
      "[35, 300] loss: 0.9703343206644058\n",
      "[36, 100] loss: 0.9698032164573669\n",
      "[36, 200] loss: 0.9645545297861099\n",
      "[36, 300] loss: 0.9746547770500184\n",
      "[37, 100] loss: 0.9763151353597641\n",
      "[37, 200] loss: 0.9552524876594544\n",
      "[37, 300] loss: 0.9535471284389496\n",
      "[38, 100] loss: 0.9701826363801956\n",
      "[38, 200] loss: 0.949891357421875\n",
      "[38, 300] loss: 0.9587348866462707\n",
      "[39, 100] loss: 0.9718721997737885\n",
      "[39, 200] loss: 0.9666381341218948\n",
      "[39, 300] loss: 0.9513505983352661\n",
      "[40, 100] loss: 0.9652950942516327\n",
      "[40, 200] loss: 0.9526656472682953\n",
      "[40, 300] loss: 0.9493796592950821\n",
      "[41, 100] loss: 0.9476946926116944\n",
      "[41, 200] loss: 0.9501584166288376\n",
      "[41, 300] loss: 0.9643676954507828\n",
      "[42, 100] loss: 0.9552072584629059\n",
      "[42, 200] loss: 0.9489452278614045\n",
      "[42, 300] loss: 0.9263174742460251\n",
      "[43, 100] loss: 0.9585285240411758\n",
      "[43, 200] loss: 0.9238479536771774\n",
      "[43, 300] loss: 0.9453980189561844\n",
      "[44, 100] loss: 0.9543282294273376\n",
      "[44, 200] loss: 0.9404286521673203\n",
      "[44, 300] loss: 0.9473705971240998\n",
      "[45, 100] loss: 0.9242521375417709\n",
      "[45, 200] loss: 0.9559586310386657\n",
      "[45, 300] loss: 0.9317575514316558\n",
      "[46, 100] loss: 0.9287942016124725\n",
      "[46, 200] loss: 0.9358289408683776\n",
      "[46, 300] loss: 0.9357255750894546\n",
      "[47, 100] loss: 0.9219975471496582\n",
      "[47, 200] loss: 0.9448796516656875\n",
      "[47, 300] loss: 0.9290294992923737\n",
      "[48, 100] loss: 0.9217199224233628\n",
      "[48, 200] loss: 0.927619788646698\n",
      "[48, 300] loss: 0.9347428983449936\n",
      "[49, 100] loss: 0.9042187762260437\n",
      "[49, 200] loss: 0.9158496379852294\n",
      "[49, 300] loss: 0.9220789229869842\n",
      "[50, 100] loss: 0.9056850552558899\n",
      "[50, 200] loss: 0.955583621263504\n",
      "[50, 300] loss: 0.9196619725227356\n",
      "[51, 100] loss: 0.9204001325368881\n",
      "[51, 200] loss: 0.9226289385557175\n",
      "[51, 300] loss: 0.9203254741430282\n",
      "[52, 100] loss: 0.9242073267698288\n",
      "[52, 200] loss: 0.9262855482101441\n",
      "[52, 300] loss: 0.9165718597173691\n",
      "[53, 100] loss: 0.9250345820188522\n",
      "[53, 200] loss: 0.9036357307434082\n",
      "[53, 300] loss: 0.9334577816724777\n",
      "[54, 100] loss: 0.9336936259269715\n",
      "[54, 200] loss: 0.9080339729785919\n",
      "[54, 300] loss: 0.9057961809635162\n",
      "[55, 100] loss: 0.900977709889412\n",
      "[55, 200] loss: 0.9116315031051636\n",
      "[55, 300] loss: 0.9045271742343902\n",
      "[56, 100] loss: 0.8960626488924026\n",
      "[56, 200] loss: 0.9074167197942734\n",
      "[56, 300] loss: 0.9076187324523926\n",
      "[57, 100] loss: 0.9428326636552811\n",
      "[57, 200] loss: 0.9074187928438187\n",
      "[57, 300] loss: 0.900601754784584\n",
      "[58, 100] loss: 0.8948283982276917\n",
      "[58, 200] loss: 0.895425677895546\n",
      "[58, 300] loss: 0.8862525165081024\n",
      "[59, 100] loss: 0.8880308961868286\n",
      "[59, 200] loss: 0.8909073847532273\n",
      "[59, 300] loss: 0.9026181042194367\n",
      "[60, 100] loss: 0.9133379685878754\n",
      "[60, 200] loss: 0.8901321989297867\n",
      "[60, 300] loss: 0.9005970281362533\n",
      "[61, 100] loss: 0.8974870890378952\n",
      "[61, 200] loss: 0.9036768162250519\n",
      "[61, 300] loss: 0.8873345798254013\n",
      "[62, 100] loss: 0.9092987251281738\n",
      "[62, 200] loss: 0.9077429950237275\n",
      "[62, 300] loss: 0.8950369244813919\n",
      "[63, 100] loss: 0.9091158103942871\n",
      "[63, 200] loss: 0.90923593044281\n",
      "[63, 300] loss: 0.9078745120763778\n",
      "[64, 100] loss: 0.8831759810447692\n",
      "[64, 200] loss: 0.8943041008710861\n",
      "[64, 300] loss: 0.8865645337104797\n",
      "[65, 100] loss: 0.8999464601278305\n",
      "[65, 200] loss: 0.8944463700056076\n",
      "[65, 300] loss: 0.8777032166719436\n",
      "[66, 100] loss: 0.8902847051620484\n",
      "[66, 200] loss: 0.8885031819343567\n",
      "[66, 300] loss: 0.8776917099952698\n",
      "[67, 100] loss: 0.8896630400419235\n",
      "[67, 200] loss: 0.8919984894990921\n",
      "[67, 300] loss: 0.894614709019661\n",
      "[68, 100] loss: 0.8973987406492233\n",
      "[68, 200] loss: 0.8926114690303802\n",
      "[68, 300] loss: 0.8894125908613205\n",
      "[69, 100] loss: 0.8910630667209625\n",
      "[69, 200] loss: 0.8929360163211822\n",
      "[69, 300] loss: 0.8765369892120362\n",
      "[70, 100] loss: 0.8932331639528275\n",
      "[70, 200] loss: 0.8619041234254837\n",
      "[70, 300] loss: 0.8815449213981629\n",
      "[71, 100] loss: 0.8742033141851425\n",
      "[71, 200] loss: 0.8839273011684418\n",
      "[71, 300] loss: 0.8830443722009659\n",
      "[72, 100] loss: 0.8789267867803574\n",
      "[72, 200] loss: 0.8953892225027085\n",
      "[72, 300] loss: 0.881349983215332\n",
      "[73, 100] loss: 0.8795062232017518\n",
      "[73, 200] loss: 0.8885049760341645\n",
      "[73, 300] loss: 0.8834198540449143\n",
      "[74, 100] loss: 0.8640020680427551\n",
      "[74, 200] loss: 0.8802485156059265\n",
      "[74, 300] loss: 0.8839914244413376\n",
      "[75, 100] loss: 0.8828415095806121\n",
      "[75, 200] loss: 0.8741243642568588\n",
      "[75, 300] loss: 0.874995351433754\n",
      "[76, 100] loss: 0.8530600154399872\n",
      "[76, 200] loss: 0.8892067790031433\n",
      "[76, 300] loss: 0.8919388556480408\n",
      "[77, 100] loss: 0.879262877702713\n",
      "[77, 200] loss: 0.8739677685499191\n",
      "[77, 300] loss: 0.8772998261451721\n",
      "[78, 100] loss: 0.8698808217048645\n",
      "[78, 200] loss: 0.8643544679880142\n",
      "[78, 300] loss: 0.887356979250908\n",
      "[79, 100] loss: 0.877358792424202\n",
      "[79, 200] loss: 0.8912432754039764\n",
      "[79, 300] loss: 0.8656970971822738\n",
      "[80, 100] loss: 0.8756146377325058\n",
      "[80, 200] loss: 0.8796612751483918\n",
      "[80, 300] loss: 0.8761485362052918\n",
      "[81, 100] loss: 0.8671466338634491\n",
      "[81, 200] loss: 0.868312041759491\n",
      "[81, 300] loss: 0.8714510697126389\n",
      "[82, 100] loss: 0.8858946216106415\n",
      "[82, 200] loss: 0.86462282538414\n",
      "[82, 300] loss: 0.87226995408535\n",
      "[83, 100] loss: 0.8703511679172515\n",
      "[83, 200] loss: 0.8850845670700074\n",
      "[83, 300] loss: 0.8605564332008362\n",
      "[84, 100] loss: 0.8563079088926315\n",
      "[84, 200] loss: 0.8691744410991669\n",
      "[84, 300] loss: 0.8620222616195679\n",
      "[85, 100] loss: 0.8750399303436279\n",
      "[85, 200] loss: 0.8785166376829148\n",
      "[85, 300] loss: 0.8658058315515518\n",
      "[86, 100] loss: 0.8676770454645157\n",
      "[86, 200] loss: 0.8783288180828095\n",
      "[86, 300] loss: 0.8654816001653671\n",
      "[87, 100] loss: 0.8889966702461243\n",
      "[87, 200] loss: 0.8644926953315735\n",
      "[87, 300] loss: 0.8526397639513016\n",
      "[88, 100] loss: 0.8717156952619552\n",
      "[88, 200] loss: 0.8829215085506439\n",
      "[88, 300] loss: 0.8874603784084321\n",
      "[89, 100] loss: 0.8823044317960739\n",
      "[89, 200] loss: 0.8531578934192657\n",
      "[89, 300] loss: 0.8639119935035705\n",
      "[90, 100] loss: 0.8637373596429825\n",
      "[90, 200] loss: 0.8598005992174148\n",
      "[90, 300] loss: 0.8891706156730652\n",
      "[91, 100] loss: 0.8801980030536651\n",
      "[91, 200] loss: 0.8401221203804016\n",
      "[91, 300] loss: 0.8507609409093857\n",
      "[92, 100] loss: 0.8861533915996551\n",
      "[92, 200] loss: 0.8721141278743744\n",
      "[92, 300] loss: 0.8592123103141784\n",
      "[93, 100] loss: 0.8645524519681931\n",
      "[93, 200] loss: 0.8724373638629913\n",
      "[93, 300] loss: 0.8593838268518448\n",
      "[94, 100] loss: 0.8912230986356735\n",
      "[94, 200] loss: 0.8734048795700073\n",
      "[94, 300] loss: 0.8603599965572357\n",
      "[95, 100] loss: 0.8775640648603439\n",
      "[95, 200] loss: 0.8680064898729324\n",
      "[95, 300] loss: 0.8740988445281982\n",
      "[96, 100] loss: 0.8771884119510651\n",
      "[96, 200] loss: 0.8676337248086929\n",
      "[96, 300] loss: 0.8592703771591187\n",
      "[97, 100] loss: 0.8842836296558381\n",
      "[97, 200] loss: 0.8613670337200164\n",
      "[97, 300] loss: 0.8754552239179612\n",
      "[98, 100] loss: 0.8619085592031479\n",
      "[98, 200] loss: 0.8619517374038697\n",
      "[98, 300] loss: 0.8807877659797668\n",
      "[99, 100] loss: 0.8601506757736206\n",
      "[99, 200] loss: 0.8442408871650696\n",
      "[99, 300] loss: 0.8367943567037582\n",
      "[100, 100] loss: 0.8670626747608184\n",
      "[100, 200] loss: 0.8548566377162934\n",
      "[100, 300] loss: 0.8590535360574723\n",
      "Training model 8 in the ensemble...\n",
      "[1, 100] loss: 2.152298381328583\n",
      "[1, 200] loss: 1.959416345357895\n",
      "[1, 300] loss: 1.880350991487503\n",
      "[2, 100] loss: 1.7778703200817108\n",
      "[2, 200] loss: 1.7399145758152008\n",
      "[2, 300] loss: 1.7022858488559722\n",
      "[3, 100] loss: 1.6243979907035828\n",
      "[3, 200] loss: 1.5767561280727387\n",
      "[3, 300] loss: 1.5328036010265351\n",
      "[4, 100] loss: 1.451400203704834\n",
      "[4, 200] loss: 1.3986446809768678\n",
      "[4, 300] loss: 1.3792548060417176\n",
      "[5, 100] loss: 1.3035672664642335\n",
      "[5, 200] loss: 1.2632854104042053\n",
      "[5, 300] loss: 1.237490884065628\n",
      "[6, 100] loss: 1.195983048081398\n",
      "[6, 200] loss: 1.1781855195760726\n",
      "[6, 300] loss: 1.1508519500494003\n",
      "[7, 100] loss: 1.1241688299179078\n",
      "[7, 200] loss: 1.1028838020563125\n",
      "[7, 300] loss: 1.1009850072860718\n",
      "[8, 100] loss: 1.0707202488183976\n",
      "[8, 200] loss: 1.0705469471216202\n",
      "[8, 300] loss: 1.05326558470726\n",
      "[9, 100] loss: 1.0387192475795746\n",
      "[9, 200] loss: 1.03863008081913\n",
      "[9, 300] loss: 1.0209361410140991\n",
      "[10, 100] loss: 1.0371576297283172\n",
      "[10, 200] loss: 0.999271924495697\n",
      "[10, 300] loss: 1.0168102133274077\n",
      "[11, 100] loss: 0.9875595670938492\n",
      "[11, 200] loss: 0.9942309886217118\n",
      "[11, 300] loss: 1.0020818269252778\n",
      "[12, 100] loss: 0.9964924234151841\n",
      "[12, 200] loss: 0.9823242247104644\n",
      "[12, 300] loss: 0.9676665169000626\n",
      "[13, 100] loss: 0.9720778435468673\n",
      "[13, 200] loss: 0.9546079188585281\n",
      "[13, 300] loss: 0.9721251744031906\n",
      "[14, 100] loss: 0.9684528017044067\n",
      "[14, 200] loss: 0.9618527275323868\n",
      "[14, 300] loss: 0.9537707591056823\n",
      "[15, 100] loss: 0.9748105639219284\n",
      "[15, 200] loss: 0.9567013543844223\n",
      "[15, 300] loss: 0.9345701271295548\n",
      "[16, 100] loss: 0.9645087271928787\n",
      "[16, 200] loss: 0.9361028814315796\n",
      "[16, 300] loss: 0.9488078451156616\n",
      "[17, 100] loss: 0.9256371158361435\n",
      "[17, 200] loss: 0.9394778627157211\n",
      "[17, 300] loss: 0.9445879369974136\n",
      "[18, 100] loss: 0.9189382123947144\n",
      "[18, 200] loss: 0.9490740168094635\n",
      "[18, 300] loss: 0.9258227944374084\n",
      "[19, 100] loss: 0.9234426468610764\n",
      "[19, 200] loss: 0.9331549906730652\n",
      "[19, 300] loss: 0.9340156978368759\n",
      "[20, 100] loss: 0.9289250236749649\n",
      "[20, 200] loss: 0.9162368923425674\n",
      "[20, 300] loss: 0.928062098622322\n",
      "[21, 100] loss: 0.9136112117767334\n",
      "[21, 200] loss: 0.914057714343071\n",
      "[21, 300] loss: 0.9418927609920502\n",
      "[22, 100] loss: 0.9026984602212906\n",
      "[22, 200] loss: 0.9119571810960769\n",
      "[22, 300] loss: 0.9169923061132431\n",
      "[23, 100] loss: 0.9270935744047165\n",
      "[23, 200] loss: 0.9054084432125091\n",
      "[23, 300] loss: 0.912166211605072\n",
      "[24, 100] loss: 0.8990768724679947\n",
      "[24, 200] loss: 0.9348884290456771\n",
      "[24, 300] loss: 0.9173600214719773\n",
      "[25, 100] loss: 0.9194435054063796\n",
      "[25, 200] loss: 0.9040815734863281\n",
      "[25, 300] loss: 0.9049917960166931\n",
      "[26, 100] loss: 0.9151454985141754\n",
      "[26, 200] loss: 0.8930453759431839\n",
      "[26, 300] loss: 0.9161682403087616\n",
      "[27, 100] loss: 0.9190120977163315\n",
      "[27, 200] loss: 0.9027124691009522\n",
      "[27, 300] loss: 0.9157596212625504\n",
      "[28, 100] loss: 0.9002664172649384\n",
      "[28, 200] loss: 0.9072977900505066\n",
      "[28, 300] loss: 0.9028628277778625\n",
      "[29, 100] loss: 0.9168315356969834\n",
      "[29, 200] loss: 0.9053601217269898\n",
      "[29, 300] loss: 0.9006724917888641\n",
      "[30, 100] loss: 0.9128695690631866\n",
      "[30, 200] loss: 0.9046492230892181\n",
      "[30, 300] loss: 0.9101496118307114\n",
      "[31, 100] loss: 0.8963864493370056\n",
      "[31, 200] loss: 0.9275324481725693\n",
      "[31, 300] loss: 0.911842445731163\n",
      "[32, 100] loss: 0.910443018078804\n",
      "[32, 200] loss: 0.8994022989273072\n",
      "[32, 300] loss: 0.8977587240934372\n",
      "[33, 100] loss: 0.8925520604848862\n",
      "[33, 200] loss: 0.9095182627439499\n",
      "[33, 300] loss: 0.9040067636966705\n",
      "[34, 100] loss: 0.8901716238260269\n",
      "[34, 200] loss: 0.9092719382047654\n",
      "[34, 300] loss: 0.9036267554759979\n",
      "[35, 100] loss: 0.9034208101034165\n",
      "[35, 200] loss: 0.8885813993215561\n",
      "[35, 300] loss: 0.8969040775299072\n",
      "[36, 100] loss: 0.8869227874279022\n",
      "[36, 200] loss: 0.9029242360591888\n",
      "[36, 300] loss: 0.8868454706668853\n",
      "[37, 100] loss: 0.8869534820318222\n",
      "[37, 200] loss: 0.9170128703117371\n",
      "[37, 300] loss: 0.8957426482439041\n",
      "[38, 100] loss: 0.9127661001682281\n",
      "[38, 200] loss: 0.9111374205350876\n",
      "[38, 300] loss: 0.90149598300457\n",
      "[39, 100] loss: 0.8981212586164474\n",
      "[39, 200] loss: 0.8875006210803985\n",
      "[39, 300] loss: 0.87772365629673\n",
      "[40, 100] loss: 0.9075006669759751\n",
      "[40, 200] loss: 0.8786019748449325\n",
      "[40, 300] loss: 0.9087478947639466\n",
      "[41, 100] loss: 0.9028114259243012\n",
      "[41, 200] loss: 0.8847084325551987\n",
      "[41, 300] loss: 0.8891579961776733\n",
      "[42, 100] loss: 0.8962436932325363\n",
      "[42, 200] loss: 0.896861110329628\n",
      "[42, 300] loss: 0.8937731623649597\n",
      "[43, 100] loss: 0.8922419863939285\n",
      "[43, 200] loss: 0.884188888669014\n",
      "[43, 300] loss: 0.8941567367315293\n",
      "[44, 100] loss: 0.8920382452011109\n",
      "[44, 200] loss: 0.8946984589099884\n",
      "[44, 300] loss: 0.8824168848991394\n",
      "[45, 100] loss: 0.9012925291061401\n",
      "[45, 200] loss: 0.8820453035831451\n",
      "[45, 300] loss: 0.8849326938390731\n",
      "[46, 100] loss: 0.8770179533958435\n",
      "[46, 200] loss: 0.9114782798290253\n",
      "[46, 300] loss: 0.8899581241607666\n",
      "[47, 100] loss: 0.876376200914383\n",
      "[47, 200] loss: 0.8616433209180832\n",
      "[47, 300] loss: 0.8808454066514969\n",
      "[48, 100] loss: 0.8708025228977203\n",
      "[48, 200] loss: 0.8933087933063507\n",
      "[48, 300] loss: 0.8683396685123443\n",
      "[49, 100] loss: 0.8603624105453491\n",
      "[49, 200] loss: 0.8823537480831146\n",
      "[49, 300] loss: 0.8832706338167191\n",
      "[50, 100] loss: 0.9003574270009994\n",
      "[50, 200] loss: 0.8793221926689148\n",
      "[50, 300] loss: 0.8588097947835922\n",
      "[51, 100] loss: 0.8969745022058487\n",
      "[51, 200] loss: 0.8981169974803924\n",
      "[51, 300] loss: 0.8580038022994995\n",
      "[52, 100] loss: 0.8815636849403381\n",
      "[52, 200] loss: 0.8672120785713195\n",
      "[52, 300] loss: 0.88313696205616\n",
      "[53, 100] loss: 0.8877553695440292\n",
      "[53, 200] loss: 0.8665359616279602\n",
      "[53, 300] loss: 0.8704541999101639\n",
      "[54, 100] loss: 0.8849865591526032\n",
      "[54, 200] loss: 0.8864609009027481\n",
      "[54, 300] loss: 0.8867301887273789\n",
      "[55, 100] loss: 0.8900986403226853\n",
      "[55, 200] loss: 0.881758668422699\n",
      "[55, 300] loss: 0.8743942391872406\n",
      "[56, 100] loss: 0.8762548887729644\n",
      "[56, 200] loss: 0.8732901132106781\n",
      "[56, 300] loss: 0.8665054315328597\n",
      "[57, 100] loss: 0.8697104352712631\n",
      "[57, 200] loss: 0.8771504008769989\n",
      "[57, 300] loss: 0.8746484297513962\n",
      "[58, 100] loss: 0.8817062014341355\n",
      "[58, 200] loss: 0.8593922173976898\n",
      "[58, 300] loss: 0.8794779342412948\n",
      "[59, 100] loss: 0.8656468880176544\n",
      "[59, 200] loss: 0.886835720539093\n",
      "[59, 300] loss: 0.8765182644128799\n",
      "[60, 100] loss: 0.8864038026332856\n",
      "[60, 200] loss: 0.862741659283638\n",
      "[60, 300] loss: 0.8875892037153243\n",
      "[61, 100] loss: 0.8648671126365661\n",
      "[61, 200] loss: 0.8748016601800919\n",
      "[61, 300] loss: 0.8725071203708649\n",
      "[62, 100] loss: 0.8759836286306382\n",
      "[62, 200] loss: 0.8787015575170517\n",
      "[62, 300] loss: 0.8944416069984436\n",
      "[63, 100] loss: 0.8705934458971023\n",
      "[63, 200] loss: 0.8839740967750549\n",
      "[63, 300] loss: 0.8935119611024857\n",
      "[64, 100] loss: 0.8521389502286911\n",
      "[64, 200] loss: 0.857288533449173\n",
      "[64, 300] loss: 0.853309143781662\n",
      "[65, 100] loss: 0.857293256521225\n",
      "[65, 200] loss: 0.8575053399801255\n",
      "[65, 300] loss: 0.8883908957242965\n",
      "[66, 100] loss: 0.8603747761249543\n",
      "[66, 200] loss: 0.8657002544403076\n",
      "[66, 300] loss: 0.8635611736774444\n",
      "[67, 100] loss: 0.8594310140609741\n",
      "[67, 200] loss: 0.8420827436447144\n",
      "[67, 300] loss: 0.8777340078353881\n",
      "[68, 100] loss: 0.8819444197416305\n",
      "[68, 200] loss: 0.876897155046463\n",
      "[68, 300] loss: 0.870450844168663\n",
      "[69, 100] loss: 0.8730905646085739\n",
      "[69, 200] loss: 0.8652531433105469\n",
      "[69, 300] loss: 0.8688862085342407\n",
      "[70, 100] loss: 0.8689266806840896\n",
      "[70, 200] loss: 0.8720475727319718\n",
      "[70, 300] loss: 0.8706423836946487\n",
      "[71, 100] loss: 0.8797276788949966\n",
      "[71, 200] loss: 0.8633956694602967\n",
      "[71, 300] loss: 0.866625964641571\n",
      "[72, 100] loss: 0.8627975130081177\n",
      "[72, 200] loss: 0.8634141576290131\n",
      "[72, 300] loss: 0.8714771604537964\n",
      "[73, 100] loss: 0.8637485319375992\n",
      "[73, 200] loss: 0.8734064871072769\n",
      "[73, 300] loss: 0.8659942859411239\n",
      "[74, 100] loss: 0.8710586524009705\n",
      "[74, 200] loss: 0.8664298862218857\n",
      "[74, 300] loss: 0.8670227020978928\n",
      "[75, 100] loss: 0.8662614393234253\n",
      "[75, 200] loss: 0.8694577467441559\n",
      "[75, 300] loss: 0.8664153903722763\n",
      "[76, 100] loss: 0.8584244358539581\n",
      "[76, 200] loss: 0.8446280539035798\n",
      "[76, 300] loss: 0.8636157506704331\n",
      "[77, 100] loss: 0.8678777444362641\n",
      "[77, 200] loss: 0.8643725061416626\n",
      "[77, 300] loss: 0.8352015924453735\n",
      "[78, 100] loss: 0.8607012385129929\n",
      "[78, 200] loss: 0.8686451017856598\n",
      "[78, 300] loss: 0.85555329144001\n",
      "[79, 100] loss: 0.869405512213707\n",
      "[79, 200] loss: 0.8636169803142547\n",
      "[79, 300] loss: 0.8554962819814682\n",
      "[80, 100] loss: 0.8771646094322204\n",
      "[80, 200] loss: 0.8764694857597352\n",
      "[80, 300] loss: 0.853210061788559\n",
      "[81, 100] loss: 0.8665073126554489\n",
      "[81, 200] loss: 0.8734311759471893\n",
      "[81, 300] loss: 0.8748583388328552\n",
      "[82, 100] loss: 0.8530457997322083\n",
      "[82, 200] loss: 0.8393860632181167\n",
      "[82, 300] loss: 0.8478613835573197\n",
      "[83, 100] loss: 0.8555357331037521\n",
      "[83, 200] loss: 0.8576230907440185\n",
      "[83, 300] loss: 0.8643138539791108\n",
      "[84, 100] loss: 0.8609400957822799\n",
      "[84, 200] loss: 0.8678343039751053\n",
      "[84, 300] loss: 0.86817567050457\n",
      "[85, 100] loss: 0.8530887758731842\n",
      "[85, 200] loss: 0.8927383542060852\n",
      "[85, 300] loss: 0.8722415900230408\n",
      "[86, 100] loss: 0.8567524087429047\n",
      "[86, 200] loss: 0.8590318715572357\n",
      "[86, 300] loss: 0.8548377215862274\n",
      "[87, 100] loss: 0.854928719997406\n",
      "[87, 200] loss: 0.8604030281305313\n",
      "[87, 300] loss: 0.885288057923317\n",
      "[88, 100] loss: 0.8560314780473709\n",
      "[88, 200] loss: 0.8553778618574143\n",
      "[88, 300] loss: 0.8806996721029282\n",
      "[89, 100] loss: 0.8775387883186341\n",
      "[89, 200] loss: 0.8785727095603942\n",
      "[89, 300] loss: 0.8472725480794907\n",
      "[90, 100] loss: 0.8645836675167083\n",
      "[90, 200] loss: 0.8627195227146148\n",
      "[90, 300] loss: 0.862190094590187\n",
      "[91, 100] loss: 0.8459698700904846\n",
      "[91, 200] loss: 0.8756257057189941\n",
      "[91, 300] loss: 0.8830035614967346\n",
      "[92, 100] loss: 0.863204185962677\n",
      "[92, 200] loss: 0.8626871943473816\n",
      "[92, 300] loss: 0.8538996464014054\n",
      "[93, 100] loss: 0.8803382509946823\n",
      "[93, 200] loss: 0.8722838205099106\n",
      "[93, 300] loss: 0.8574418050050735\n",
      "[94, 100] loss: 0.8588735830783844\n",
      "[94, 200] loss: 0.8751387000083923\n",
      "[94, 300] loss: 0.8718210560083389\n",
      "[95, 100] loss: 0.8622950351238251\n",
      "[95, 200] loss: 0.8419355762004852\n",
      "[95, 300] loss: 0.8637421327829361\n",
      "[96, 100] loss: 0.8687681359052658\n",
      "[96, 200] loss: 0.8593287318944931\n",
      "[96, 300] loss: 0.8562198859453202\n",
      "[97, 100] loss: 0.8568685632944107\n",
      "[97, 200] loss: 0.8411137807369232\n",
      "[97, 300] loss: 0.8511675596237183\n",
      "[98, 100] loss: 0.851493148803711\n",
      "[98, 200] loss: 0.858330220580101\n",
      "[98, 300] loss: 0.8259814596176147\n",
      "[99, 100] loss: 0.8550599080324173\n",
      "[99, 200] loss: 0.8631058275699616\n",
      "[99, 300] loss: 0.8385127723217011\n",
      "[100, 100] loss: 0.8653651976585388\n",
      "[100, 200] loss: 0.8650004559755325\n",
      "[100, 300] loss: 0.8655000847578048\n",
      "Training model 9 in the ensemble...\n",
      "[1, 100] loss: 2.1498010468482973\n",
      "[1, 200] loss: 1.9663418316841126\n",
      "[1, 300] loss: 1.886161313056946\n",
      "[2, 100] loss: 1.8193852519989013\n",
      "[2, 200] loss: 1.7919019079208374\n",
      "[2, 300] loss: 1.7709148859977721\n",
      "[3, 100] loss: 1.7123999857902528\n",
      "[3, 200] loss: 1.6673916137218476\n",
      "[3, 300] loss: 1.63500084400177\n",
      "[4, 100] loss: 1.5988910460472108\n",
      "[4, 200] loss: 1.5658373260498046\n",
      "[4, 300] loss: 1.54429655790329\n",
      "[5, 100] loss: 1.4794100177288056\n",
      "[5, 200] loss: 1.457772114276886\n",
      "[5, 300] loss: 1.453591616153717\n",
      "[6, 100] loss: 1.4029650902748108\n",
      "[6, 200] loss: 1.3840921378135682\n",
      "[6, 300] loss: 1.3670983958244323\n",
      "[7, 100] loss: 1.344705821275711\n",
      "[7, 200] loss: 1.3197589457035064\n",
      "[7, 300] loss: 1.2963121771812438\n",
      "[8, 100] loss: 1.2669159662723541\n",
      "[8, 200] loss: 1.2604008507728577\n",
      "[8, 300] loss: 1.232216578722\n",
      "[9, 100] loss: 1.2276855063438417\n",
      "[9, 200] loss: 1.213590024113655\n",
      "[9, 300] loss: 1.178414136171341\n",
      "[10, 100] loss: 1.1593013852834702\n",
      "[10, 200] loss: 1.1414886873960495\n",
      "[10, 300] loss: 1.1556823337078095\n",
      "[11, 100] loss: 1.1282791149616243\n",
      "[11, 200] loss: 1.1151188737154007\n",
      "[11, 300] loss: 1.1102572858333588\n",
      "[12, 100] loss: 1.0922832882404327\n",
      "[12, 200] loss: 1.0798653995990752\n",
      "[12, 300] loss: 1.0770954447984695\n",
      "[13, 100] loss: 1.0401904845237733\n",
      "[13, 200] loss: 1.049612299799919\n",
      "[13, 300] loss: 1.0429141056537627\n",
      "[14, 100] loss: 1.0172603452205657\n",
      "[14, 200] loss: 1.0149319052696228\n",
      "[14, 300] loss: 1.0301713228225708\n",
      "[15, 100] loss: 1.016303415298462\n",
      "[15, 200] loss: 1.026006749868393\n",
      "[15, 300] loss: 1.000576490163803\n",
      "[16, 100] loss: 1.0113658481836318\n",
      "[16, 200] loss: 0.9980886018276215\n",
      "[16, 300] loss: 0.9953091597557068\n",
      "[17, 100] loss: 0.9932024532556534\n",
      "[17, 200] loss: 1.0101737415790557\n",
      "[17, 300] loss: 0.9950811564922333\n",
      "[18, 100] loss: 0.9774069792032242\n",
      "[18, 200] loss: 0.9832654923200608\n",
      "[18, 300] loss: 0.99091362118721\n",
      "[19, 100] loss: 0.9770421856641769\n",
      "[19, 200] loss: 0.9962401157617569\n",
      "[19, 300] loss: 0.9902090376615524\n",
      "[20, 100] loss: 0.9772092825174332\n",
      "[20, 200] loss: 0.9666647863388061\n",
      "[20, 300] loss: 0.973661242723465\n",
      "[21, 100] loss: 0.9650392937660217\n",
      "[21, 200] loss: 0.9375827926397323\n",
      "[21, 300] loss: 0.9619485753774643\n",
      "[22, 100] loss: 0.9607451164722443\n",
      "[22, 200] loss: 0.9438061463832855\n",
      "[22, 300] loss: 0.9476932996511459\n",
      "[23, 100] loss: 0.9462101089954377\n",
      "[23, 200] loss: 0.9409979033470154\n",
      "[23, 300] loss: 0.9530551427602768\n",
      "[24, 100] loss: 0.9370415329933166\n",
      "[24, 200] loss: 0.9301851052045822\n",
      "[24, 300] loss: 0.9249970960617065\n",
      "[25, 100] loss: 0.9538563001155853\n",
      "[25, 200] loss: 0.9425566411018371\n",
      "[25, 300] loss: 0.9155213570594788\n",
      "[26, 100] loss: 0.930782504081726\n",
      "[26, 200] loss: 0.9393830645084381\n",
      "[26, 300] loss: 0.9418369269371033\n",
      "[27, 100] loss: 0.9351824331283569\n",
      "[27, 200] loss: 0.9226207894086838\n",
      "[27, 300] loss: 0.936820849776268\n",
      "[28, 100] loss: 0.9159977000951767\n",
      "[28, 200] loss: 0.921938208937645\n",
      "[28, 300] loss: 0.9091498351097107\n",
      "[29, 100] loss: 0.924980435371399\n",
      "[29, 200] loss: 0.9149641275405884\n",
      "[29, 300] loss: 0.9241886919736862\n",
      "[30, 100] loss: 0.9140258884429932\n",
      "[30, 200] loss: 0.8992087203264236\n",
      "[30, 300] loss: 0.9162967532873154\n",
      "[31, 100] loss: 0.9202624607086182\n",
      "[31, 200] loss: 0.8933107733726502\n",
      "[31, 300] loss: 0.9309638452529907\n",
      "[32, 100] loss: 0.9098905211687088\n",
      "[32, 200] loss: 0.9088882946968079\n",
      "[32, 300] loss: 0.9172828894853592\n",
      "[33, 100] loss: 0.9158253198862076\n",
      "[33, 200] loss: 0.9167459106445313\n",
      "[33, 300] loss: 0.9096400934457779\n",
      "[34, 100] loss: 0.9006515401601791\n",
      "[34, 200] loss: 0.9067980051040649\n",
      "[34, 300] loss: 0.8954372781515122\n",
      "[35, 100] loss: 0.9148235946893692\n",
      "[35, 200] loss: 0.8991645216941834\n",
      "[35, 300] loss: 0.9042520481348038\n",
      "[36, 100] loss: 0.902778941988945\n",
      "[36, 200] loss: 0.8904042232036591\n",
      "[36, 300] loss: 0.8984949457645416\n",
      "[37, 100] loss: 0.9063958770036697\n",
      "[37, 200] loss: 0.9218092834949494\n",
      "[37, 300] loss: 0.8927809852361679\n",
      "[38, 100] loss: 0.8950259625911713\n",
      "[38, 200] loss: 0.9013136321306229\n",
      "[38, 300] loss: 0.9063017165660858\n",
      "[39, 100] loss: 0.8980857187509537\n",
      "[39, 200] loss: 0.9016478347778321\n",
      "[39, 300] loss: 0.8833205848932266\n",
      "[40, 100] loss: 0.9115424603223801\n",
      "[40, 200] loss: 0.8998085349798203\n",
      "[40, 300] loss: 0.8997397446632385\n",
      "[41, 100] loss: 0.8902256643772125\n",
      "[41, 200] loss: 0.908255210518837\n",
      "[41, 300] loss: 0.8719387936592102\n",
      "[42, 100] loss: 0.9009775829315185\n",
      "[42, 200] loss: 0.8748414385318756\n",
      "[42, 300] loss: 0.8959156554937363\n",
      "[43, 100] loss: 0.8978532385826111\n",
      "[43, 200] loss: 0.8885953372716904\n",
      "[43, 300] loss: 0.8979375249147415\n",
      "[44, 100] loss: 0.9015087294578552\n",
      "[44, 200] loss: 0.8857067769765854\n",
      "[44, 300] loss: 0.902689038515091\n",
      "[45, 100] loss: 0.8947370654344559\n",
      "[45, 200] loss: 0.8959662240743637\n",
      "[45, 300] loss: 0.9143650656938553\n",
      "[46, 100] loss: 0.8997962743043899\n",
      "[46, 200] loss: 0.8909014886617661\n",
      "[46, 300] loss: 0.8868305784463882\n",
      "[47, 100] loss: 0.8803598564863205\n",
      "[47, 200] loss: 0.8910652416944503\n",
      "[47, 300] loss: 0.8827384549379349\n",
      "[48, 100] loss: 0.9033542537689209\n",
      "[48, 200] loss: 0.9133584946393967\n",
      "[48, 300] loss: 0.8879689908027649\n",
      "[49, 100] loss: 0.9146523863077164\n",
      "[49, 200] loss: 0.8919264245033264\n",
      "[49, 300] loss: 0.9095199662446976\n",
      "[50, 100] loss: 0.8873782873153686\n",
      "[50, 200] loss: 0.9011597943305969\n",
      "[50, 300] loss: 0.87568778693676\n",
      "[51, 100] loss: 0.8957037478685379\n",
      "[51, 200] loss: 0.8862265157699585\n",
      "[51, 300] loss: 0.8897083121538162\n",
      "[52, 100] loss: 0.8898127150535583\n",
      "[52, 200] loss: 0.8533758848905564\n",
      "[52, 300] loss: 0.8811637926101684\n",
      "[53, 100] loss: 0.883222621679306\n",
      "[53, 200] loss: 0.8997686201334\n",
      "[53, 300] loss: 0.9033126366138459\n",
      "[54, 100] loss: 0.9022983175516128\n",
      "[54, 200] loss: 0.884140418767929\n",
      "[54, 300] loss: 0.8818369966745376\n",
      "[55, 100] loss: 0.8847156435251236\n",
      "[55, 200] loss: 0.8903807324171066\n",
      "[55, 300] loss: 0.8783727180957794\n",
      "[56, 100] loss: 0.885604077577591\n",
      "[56, 200] loss: 0.8849929690361023\n",
      "[56, 300] loss: 0.8705952227115631\n",
      "[57, 100] loss: 0.8857780134677887\n",
      "[57, 200] loss: 0.8843494254350662\n",
      "[57, 300] loss: 0.879797312617302\n",
      "[58, 100] loss: 0.8791002231836319\n",
      "[58, 200] loss: 0.8730080723762512\n",
      "[58, 300] loss: 0.8819735658168792\n",
      "[59, 100] loss: 0.8981583118438721\n",
      "[59, 200] loss: 0.9081613785028457\n",
      "[59, 300] loss: 0.87793386220932\n",
      "[60, 100] loss: 0.8774985885620117\n",
      "[60, 200] loss: 0.8806121677160264\n",
      "[60, 300] loss: 0.8893424457311631\n",
      "[61, 100] loss: 0.8868343442678451\n",
      "[61, 200] loss: 0.869344699382782\n",
      "[61, 300] loss: 0.8929132032394409\n",
      "[62, 100] loss: 0.8743818295001984\n",
      "[62, 200] loss: 0.8856052094697953\n",
      "[62, 300] loss: 0.8643469488620759\n",
      "[63, 100] loss: 0.894695098400116\n",
      "[63, 200] loss: 0.9020153111219407\n",
      "[63, 300] loss: 0.8738428151607514\n",
      "[64, 100] loss: 0.8748672288656235\n",
      "[64, 200] loss: 0.8696552759408951\n",
      "[64, 300] loss: 0.888121337890625\n",
      "[65, 100] loss: 0.8777812671661377\n",
      "[65, 200] loss: 0.8809471863508225\n",
      "[65, 300] loss: 0.884846814274788\n",
      "[66, 100] loss: 0.8837201625108719\n",
      "[66, 200] loss: 0.8865225613117218\n",
      "[66, 300] loss: 0.8645630085468292\n",
      "[67, 100] loss: 0.8930832999944687\n",
      "[67, 200] loss: 0.8816848027706147\n",
      "[67, 300] loss: 0.8881818920373916\n",
      "[68, 100] loss: 0.8825262200832367\n",
      "[68, 200] loss: 0.8706897926330567\n",
      "[68, 300] loss: 0.8759867841005325\n",
      "[69, 100] loss: 0.8850188386440277\n",
      "[69, 200] loss: 0.8726250612735749\n",
      "[69, 300] loss: 0.8761656790971756\n",
      "[70, 100] loss: 0.8762059777975082\n",
      "[70, 200] loss: 0.8638969397544861\n",
      "[70, 300] loss: 0.8645746904611588\n",
      "[71, 100] loss: 0.8507008028030395\n",
      "[71, 200] loss: 0.8713070130348206\n",
      "[71, 300] loss: 0.8648099559545517\n",
      "[72, 100] loss: 0.871356052160263\n",
      "[72, 200] loss: 0.8655492830276489\n",
      "[72, 300] loss: 0.86282585978508\n",
      "[73, 100] loss: 0.8892161166667938\n",
      "[73, 200] loss: 0.8757744735479355\n",
      "[73, 300] loss: 0.8881782847642898\n",
      "[74, 100] loss: 0.8913372939825058\n",
      "[74, 200] loss: 0.8791631162166595\n",
      "[74, 300] loss: 0.870308324098587\n",
      "[75, 100] loss: 0.863052886724472\n",
      "[75, 200] loss: 0.8937768632173538\n",
      "[75, 300] loss: 0.8695182210206985\n",
      "[76, 100] loss: 0.8659731423854828\n",
      "[76, 200] loss: 0.8689855486154556\n",
      "[76, 300] loss: 0.8682405757904053\n",
      "[77, 100] loss: 0.8469371259212494\n",
      "[77, 200] loss: 0.860904552936554\n",
      "[77, 300] loss: 0.8723003178834915\n",
      "[78, 100] loss: 0.873496237397194\n",
      "[78, 200] loss: 0.8873991996049881\n",
      "[78, 300] loss: 0.8617806261777878\n",
      "[79, 100] loss: 0.8976878821849823\n",
      "[79, 200] loss: 0.8746291154623032\n",
      "[79, 300] loss: 0.8793773025274276\n",
      "[80, 100] loss: 0.8606738257408142\n",
      "[80, 200] loss: 0.8576583421230316\n",
      "[80, 300] loss: 0.8711793786287307\n",
      "[81, 100] loss: 0.8835773646831513\n",
      "[81, 200] loss: 0.8537637686729431\n",
      "[81, 300] loss: 0.8602955466508866\n",
      "[82, 100] loss: 0.8720350748300553\n",
      "[82, 200] loss: 0.8532767421007157\n",
      "[82, 300] loss: 0.844143055677414\n",
      "[83, 100] loss: 0.8709926849603653\n",
      "[83, 200] loss: 0.8681566298007966\n",
      "[83, 300] loss: 0.862844540476799\n",
      "[84, 100] loss: 0.8751548153162002\n",
      "[84, 200] loss: 0.8694319331645965\n",
      "[84, 300] loss: 0.8687396293878555\n",
      "[85, 100] loss: 0.8734797984361649\n",
      "[85, 200] loss: 0.8619416999816895\n",
      "[85, 300] loss: 0.8499681276082992\n",
      "[86, 100] loss: 0.8850030100345612\n",
      "[86, 200] loss: 0.8663582837581635\n",
      "[86, 300] loss: 0.863337208032608\n",
      "[87, 100] loss: 0.874249411225319\n",
      "[87, 200] loss: 0.870591009259224\n",
      "[87, 300] loss: 0.856838031411171\n",
      "[88, 100] loss: 0.8733699256181717\n",
      "[88, 200] loss: 0.8783098208904266\n",
      "[88, 300] loss: 0.8531696808338165\n",
      "[89, 100] loss: 0.8665767246484757\n",
      "[89, 200] loss: 0.8680561822652817\n",
      "[89, 300] loss: 0.864752306342125\n",
      "[90, 100] loss: 0.8687704235315323\n",
      "[90, 200] loss: 0.8684457576274872\n",
      "[90, 300] loss: 0.8640612530708313\n",
      "[91, 100] loss: 0.8757387530803681\n",
      "[91, 200] loss: 0.8580936640501022\n",
      "[91, 300] loss: 0.881300967335701\n",
      "[92, 100] loss: 0.8730131644010544\n",
      "[92, 200] loss: 0.8728150594234466\n",
      "[92, 300] loss: 0.8776737648248673\n",
      "[93, 100] loss: 0.8545762771368026\n",
      "[93, 200] loss: 0.8567917943000793\n",
      "[93, 300] loss: 0.8593974232673645\n",
      "[94, 100] loss: 0.8586385172605514\n",
      "[94, 200] loss: 0.8528769117593765\n",
      "[94, 300] loss: 0.8842643427848816\n",
      "[95, 100] loss: 0.8674243611097335\n",
      "[95, 200] loss: 0.8710883617401123\n",
      "[95, 300] loss: 0.8666865468025208\n",
      "[96, 100] loss: 0.8541568487882614\n",
      "[96, 200] loss: 0.8502896451950073\n",
      "[96, 300] loss: 0.8658048951625824\n",
      "[97, 100] loss: 0.8670555567741394\n",
      "[97, 200] loss: 0.8607991707324981\n",
      "[97, 300] loss: 0.8711284506320953\n",
      "[98, 100] loss: 0.8653780019283295\n",
      "[98, 200] loss: 0.8536996865272521\n",
      "[98, 300] loss: 0.8629114896059036\n",
      "[99, 100] loss: 0.8584659951925278\n",
      "[99, 200] loss: 0.8600511544942856\n",
      "[99, 300] loss: 0.8677749985456467\n",
      "[100, 100] loss: 0.8535006928443909\n",
      "[100, 200] loss: 0.852606390118599\n",
      "[100, 300] loss: 0.8574448567628861\n",
      "Training model 10 in the ensemble...\n",
      "[1, 100] loss: 2.156154179573059\n",
      "[1, 200] loss: 1.974894357919693\n",
      "[1, 300] loss: 1.92759250998497\n",
      "[2, 100] loss: 1.8469538688659668\n",
      "[2, 200] loss: 1.809243493080139\n",
      "[2, 300] loss: 1.7924723863601684\n",
      "[3, 100] loss: 1.7513684928417206\n",
      "[3, 200] loss: 1.7343847227096558\n",
      "[3, 300] loss: 1.705560952425003\n",
      "[4, 100] loss: 1.67810116648674\n",
      "[4, 200] loss: 1.6530354309082032\n",
      "[4, 300] loss: 1.642588995695114\n",
      "[5, 100] loss: 1.609453341960907\n",
      "[5, 200] loss: 1.590748199224472\n",
      "[5, 300] loss: 1.5954931485652923\n",
      "[6, 100] loss: 1.5633646023273469\n",
      "[6, 200] loss: 1.542551280260086\n",
      "[6, 300] loss: 1.549764437675476\n",
      "[7, 100] loss: 1.5072517132759093\n",
      "[7, 200] loss: 1.5033137357234956\n",
      "[7, 300] loss: 1.4612595224380494\n",
      "[8, 100] loss: 1.4329085528850556\n",
      "[8, 200] loss: 1.4066239702701568\n",
      "[8, 300] loss: 1.3881937706470489\n",
      "[9, 100] loss: 1.3665863287448883\n",
      "[9, 200] loss: 1.353052089214325\n",
      "[9, 300] loss: 1.335174766778946\n",
      "[10, 100] loss: 1.3055575847625733\n",
      "[10, 200] loss: 1.2927905416488648\n",
      "[10, 300] loss: 1.2691997241973878\n",
      "[11, 100] loss: 1.2377334821224213\n",
      "[11, 200] loss: 1.2218302965164185\n",
      "[11, 300] loss: 1.2139043092727662\n",
      "[12, 100] loss: 1.1826591843366623\n",
      "[12, 200] loss: 1.1616862034797668\n",
      "[12, 300] loss: 1.1440393406152725\n",
      "[13, 100] loss: 1.1271698361635207\n",
      "[13, 200] loss: 1.141660383939743\n",
      "[13, 300] loss: 1.115626271367073\n",
      "[14, 100] loss: 1.1142352306842804\n",
      "[14, 200] loss: 1.0966845589876175\n",
      "[14, 300] loss: 1.0976066887378693\n",
      "[15, 100] loss: 1.0638772928714753\n",
      "[15, 200] loss: 1.0692547017335892\n",
      "[15, 300] loss: 1.056762957572937\n",
      "[16, 100] loss: 1.0400942081212998\n",
      "[16, 200] loss: 1.0322185474634171\n",
      "[16, 300] loss: 1.0365204745531083\n",
      "[17, 100] loss: 1.0382839608192445\n",
      "[17, 200] loss: 1.009410765171051\n",
      "[17, 300] loss: 1.010258850455284\n",
      "[18, 100] loss: 1.0000915318727492\n",
      "[18, 200] loss: 1.0028557014465331\n",
      "[18, 300] loss: 0.9911058962345123\n",
      "[19, 100] loss: 0.9814443308115005\n",
      "[19, 200] loss: 0.9757535982131958\n",
      "[19, 300] loss: 0.9728443491458892\n",
      "[20, 100] loss: 0.9782314288616181\n",
      "[20, 200] loss: 0.9653720313310623\n",
      "[20, 300] loss: 0.9709807926416397\n",
      "[21, 100] loss: 0.9552274298667908\n",
      "[21, 200] loss: 0.9570834165811539\n",
      "[21, 300] loss: 0.9483187317848205\n",
      "[22, 100] loss: 0.9524195551872253\n",
      "[22, 200] loss: 0.9309170293807983\n",
      "[22, 300] loss: 0.9496749579906464\n",
      "[23, 100] loss: 0.9398434901237488\n",
      "[23, 200] loss: 0.9508306890726089\n",
      "[23, 300] loss: 0.9348328334093093\n",
      "[24, 100] loss: 0.9264368277788162\n",
      "[24, 200] loss: 0.9437133276462555\n",
      "[24, 300] loss: 0.9320365053415298\n",
      "[25, 100] loss: 0.930746648311615\n",
      "[25, 200] loss: 0.9258170348405838\n",
      "[25, 300] loss: 0.9413596749305725\n",
      "[26, 100] loss: 0.9476870769262313\n",
      "[26, 200] loss: 0.9401359951496124\n",
      "[26, 300] loss: 0.9284687393903732\n",
      "[27, 100] loss: 0.9307559889554977\n",
      "[27, 200] loss: 0.9325876486301422\n",
      "[27, 300] loss: 0.9286059707403183\n",
      "[28, 100] loss: 0.9111826556921006\n",
      "[28, 200] loss: 0.9177270019054413\n",
      "[28, 300] loss: 0.9224416601657868\n",
      "[29, 100] loss: 0.9078859877586365\n",
      "[29, 200] loss: 0.9372366952896118\n",
      "[29, 300] loss: 0.9206750643253326\n",
      "[30, 100] loss: 0.9177964287996292\n",
      "[30, 200] loss: 0.9257358944416046\n",
      "[30, 300] loss: 0.9128889805078506\n",
      "[31, 100] loss: 0.896599218249321\n",
      "[31, 200] loss: 0.9042850989103317\n",
      "[31, 300] loss: 0.9203036105632783\n",
      "[32, 100] loss: 0.9296351736783981\n",
      "[32, 200] loss: 0.9059308612346649\n",
      "[32, 300] loss: 0.9163387340307235\n",
      "[33, 100] loss: 0.898200073838234\n",
      "[33, 200] loss: 0.9144443571567535\n",
      "[33, 300] loss: 0.8985933148860932\n",
      "[34, 100] loss: 0.8869570982456207\n",
      "[34, 200] loss: 0.9104226243495941\n",
      "[34, 300] loss: 0.8971792757511139\n",
      "[35, 100] loss: 0.9188053119182586\n",
      "[35, 200] loss: 0.8958240538835526\n",
      "[35, 300] loss: 0.9099422687292099\n",
      "[36, 100] loss: 0.9030778241157532\n",
      "[36, 200] loss: 0.8942121958732605\n",
      "[36, 300] loss: 0.8961589848995208\n",
      "[37, 100] loss: 0.9248687195777893\n",
      "[37, 200] loss: 0.8893341940641403\n",
      "[37, 300] loss: 0.9128400617837906\n",
      "[38, 100] loss: 0.8882133311033249\n",
      "[38, 200] loss: 0.8990337812900543\n",
      "[38, 300] loss: 0.8968917173147202\n",
      "[39, 100] loss: 0.8937602853775024\n",
      "[39, 200] loss: 0.8772528737783432\n",
      "[39, 300] loss: 0.9031055420637131\n",
      "[40, 100] loss: 0.8876783353090286\n",
      "[40, 200] loss: 0.878728067278862\n",
      "[40, 300] loss: 0.8774322849512101\n",
      "[41, 100] loss: 0.9085717350244522\n",
      "[41, 200] loss: 0.8902629661560059\n",
      "[41, 300] loss: 0.8997916090488434\n",
      "[42, 100] loss: 0.8921295779943467\n",
      "[42, 200] loss: 0.905377134680748\n",
      "[42, 300] loss: 0.8856603199243546\n",
      "[43, 100] loss: 0.8922719919681549\n",
      "[43, 200] loss: 0.8877498465776443\n",
      "[43, 300] loss: 0.8680254077911377\n",
      "[44, 100] loss: 0.9061019420623779\n",
      "[44, 200] loss: 0.9068397098779678\n",
      "[44, 300] loss: 0.8756056618690491\n",
      "[45, 100] loss: 0.8833523488044739\n",
      "[45, 200] loss: 0.8777776783704758\n",
      "[45, 300] loss: 0.8765218317508697\n",
      "[46, 100] loss: 0.8945415085554123\n",
      "[46, 200] loss: 0.8806745684146882\n",
      "[46, 300] loss: 0.8832396388053894\n",
      "[47, 100] loss: 0.8789135330915451\n",
      "[47, 200] loss: 0.883118599653244\n",
      "[47, 300] loss: 0.8825072133541108\n",
      "[48, 100] loss: 0.8810870325565339\n",
      "[48, 200] loss: 0.8702524304389954\n",
      "[48, 300] loss: 0.8627159357070923\n",
      "[49, 100] loss: 0.8937141239643097\n",
      "[49, 200] loss: 0.8915329915285111\n",
      "[49, 300] loss: 0.8732976198196412\n",
      "[50, 100] loss: 0.8848575347661972\n",
      "[50, 200] loss: 0.8737411451339722\n",
      "[50, 300] loss: 0.8829731488227844\n",
      "[51, 100] loss: 0.8959879893064499\n",
      "[51, 200] loss: 0.8734906738996506\n",
      "[51, 300] loss: 0.9198881369829178\n",
      "[52, 100] loss: 0.8959869438409805\n",
      "[52, 200] loss: 0.8797405999898911\n",
      "[52, 300] loss: 0.8902199029922485\n",
      "[53, 100] loss: 0.8825439667701721\n",
      "[53, 200] loss: 0.8837323504686355\n",
      "[53, 300] loss: 0.8804330694675445\n",
      "[54, 100] loss: 0.8576466882228851\n",
      "[54, 200] loss: 0.8698450034856796\n",
      "[54, 300] loss: 0.8908192443847657\n",
      "[55, 100] loss: 0.8754481118917465\n",
      "[55, 200] loss: 0.8861484098434448\n",
      "[55, 300] loss: 0.875687375664711\n",
      "[56, 100] loss: 0.8871282958984374\n",
      "[56, 200] loss: 0.8820601189136505\n",
      "[56, 300] loss: 0.8830182808637619\n",
      "[57, 100] loss: 0.8734932678937912\n",
      "[57, 200] loss: 0.8670024234056473\n",
      "[57, 300] loss: 0.8901780033111573\n",
      "[58, 100] loss: 0.8844224655628204\n",
      "[58, 200] loss: 0.8826133650541306\n",
      "[58, 300] loss: 0.8928082638978958\n",
      "[59, 100] loss: 0.8799884325265884\n",
      "[59, 200] loss: 0.8751192998886108\n",
      "[59, 300] loss: 0.873586305975914\n",
      "[60, 100] loss: 0.8948123425245285\n",
      "[60, 200] loss: 0.8918770092725754\n",
      "[60, 300] loss: 0.8814951545000076\n",
      "[61, 100] loss: 0.8685676610469818\n",
      "[61, 200] loss: 0.8764906066656113\n",
      "[61, 300] loss: 0.8723482078313828\n",
      "[62, 100] loss: 0.8836256754398346\n",
      "[62, 200] loss: 0.8618740755319595\n",
      "[62, 300] loss: 0.8715303069353104\n",
      "[63, 100] loss: 0.8681288093328476\n",
      "[63, 200] loss: 0.8677035361528397\n",
      "[63, 300] loss: 0.8652362143993377\n",
      "[64, 100] loss: 0.8600705397129059\n",
      "[64, 200] loss: 0.8611182451248169\n",
      "[64, 300] loss: 0.8716843765974045\n",
      "[65, 100] loss: 0.8790027916431427\n",
      "[65, 200] loss: 0.863008371591568\n",
      "[65, 300] loss: 0.8808633071184159\n",
      "[66, 100] loss: 0.8675206172466278\n",
      "[66, 200] loss: 0.884281508922577\n",
      "[66, 300] loss: 0.8908426249027253\n",
      "[67, 100] loss: 0.8678945899009705\n",
      "[67, 200] loss: 0.8767978745698929\n",
      "[67, 300] loss: 0.8725253474712372\n",
      "[68, 100] loss: 0.8574790948629379\n",
      "[68, 200] loss: 0.8728127682209015\n",
      "[68, 300] loss: 0.8871059197187424\n",
      "[69, 100] loss: 0.8683150327205658\n",
      "[69, 200] loss: 0.8830396723747254\n",
      "[69, 300] loss: 0.8683706498146058\n",
      "[70, 100] loss: 0.8822907310724258\n",
      "[70, 200] loss: 0.8931386417150498\n",
      "[70, 300] loss: 0.8754539459943771\n",
      "[71, 100] loss: 0.8589863270521164\n",
      "[71, 200] loss: 0.8776787191629409\n",
      "[71, 300] loss: 0.8887871998548508\n",
      "[72, 100] loss: 0.8538701730966568\n",
      "[72, 200] loss: 0.8758041489124299\n",
      "[72, 300] loss: 0.8564484357833863\n",
      "[73, 100] loss: 0.8648211175203323\n",
      "[73, 200] loss: 0.874156146645546\n",
      "[73, 300] loss: 0.8622948080301285\n",
      "[74, 100] loss: 0.8576012855768204\n",
      "[74, 200] loss: 0.8791931319236755\n",
      "[74, 300] loss: 0.8677100759744644\n",
      "[75, 100] loss: 0.8844210028648376\n",
      "[75, 200] loss: 0.8742030400037766\n",
      "[75, 300] loss: 0.8814684373140335\n",
      "[76, 100] loss: 0.8729324340820312\n",
      "[76, 200] loss: 0.8714448666572571\n",
      "[76, 300] loss: 0.8634366303682327\n",
      "[77, 100] loss: 0.8604094880819321\n",
      "[77, 200] loss: 0.8634867680072784\n",
      "[77, 300] loss: 0.8523758095502854\n",
      "[78, 100] loss: 0.8779032373428345\n",
      "[78, 200] loss: 0.8630351799726487\n",
      "[78, 300] loss: 0.8696031200885773\n",
      "[79, 100] loss: 0.875704151391983\n",
      "[79, 200] loss: 0.8757338964939118\n",
      "[79, 300] loss: 0.8760553795099258\n",
      "[80, 100] loss: 0.8691865277290344\n",
      "[80, 200] loss: 0.8753820890188218\n",
      "[80, 300] loss: 0.874438544511795\n",
      "[81, 100] loss: 0.8849223029613494\n",
      "[81, 200] loss: 0.8585173398256302\n",
      "[81, 300] loss: 0.8515883588790893\n",
      "[82, 100] loss: 0.8736075007915497\n",
      "[82, 200] loss: 0.8617453759908676\n",
      "[82, 300] loss: 0.8941996186971665\n",
      "[83, 100] loss: 0.8651610952615738\n",
      "[83, 200] loss: 0.8649825602769852\n",
      "[83, 300] loss: 0.8602178460359573\n",
      "[84, 100] loss: 0.8711924183368683\n",
      "[84, 200] loss: 0.8707910865545273\n",
      "[84, 300] loss: 0.8719394659996033\n",
      "[85, 100] loss: 0.8794006717205047\n",
      "[85, 200] loss: 0.8549027502536773\n",
      "[85, 300] loss: 0.870953009724617\n",
      "[86, 100] loss: 0.8636285370588302\n",
      "[86, 200] loss: 0.8616838133335114\n",
      "[86, 300] loss: 0.8528281044960022\n",
      "[87, 100] loss: 0.8604711425304413\n",
      "[87, 200] loss: 0.8711273539066314\n",
      "[87, 300] loss: 0.8524582773447037\n",
      "[88, 100] loss: 0.8649101650714874\n",
      "[88, 200] loss: 0.8713250988721848\n",
      "[88, 300] loss: 0.8549213993549347\n",
      "[89, 100] loss: 0.863886467218399\n",
      "[89, 200] loss: 0.8804481756687165\n",
      "[89, 300] loss: 0.8667135524749756\n",
      "[90, 100] loss: 0.8661892944574356\n",
      "[90, 200] loss: 0.8593855464458465\n",
      "[90, 300] loss: 0.864759413599968\n",
      "[91, 100] loss: 0.8762017637491226\n",
      "[91, 200] loss: 0.8763807010650635\n",
      "[91, 300] loss: 0.8797975718975067\n",
      "[92, 100] loss: 0.8600320363044739\n",
      "[92, 200] loss: 0.8767557430267334\n",
      "[92, 300] loss: 0.8589005154371262\n",
      "[93, 100] loss: 0.8481584078073502\n",
      "[93, 200] loss: 0.8591023820638657\n",
      "[93, 300] loss: 0.8555594849586486\n",
      "[94, 100] loss: 0.8650755470991135\n",
      "[94, 200] loss: 0.8662183552980423\n",
      "[94, 300] loss: 0.8775431162118912\n",
      "[95, 100] loss: 0.8599956417083741\n",
      "[95, 200] loss: 0.8645658469200135\n",
      "[95, 300] loss: 0.86764393389225\n",
      "[96, 100] loss: 0.8651108109951019\n",
      "[96, 200] loss: 0.8594923001527787\n",
      "[96, 300] loss: 0.8374097985029221\n",
      "[97, 100] loss: 0.8550880533456803\n",
      "[97, 200] loss: 0.854069498181343\n",
      "[97, 300] loss: 0.8670629698038101\n",
      "[98, 100] loss: 0.8500730872154236\n",
      "[98, 200] loss: 0.8599924528598786\n",
      "[98, 300] loss: 0.8751312798261642\n",
      "[99, 100] loss: 0.870903657078743\n",
      "[99, 200] loss: 0.8680132627487183\n",
      "[99, 300] loss: 0.8712044203281403\n",
      "[100, 100] loss: 0.8547220772504807\n",
      "[100, 200] loss: 0.8518784439563751\n",
      "[100, 300] loss: 0.8617493575811386\n",
      "Training model 11 in the ensemble...\n",
      "[1, 100] loss: 2.1048816323280333\n",
      "[1, 200] loss: 1.939283745288849\n",
      "[1, 300] loss: 1.8691878008842469\n",
      "[2, 100] loss: 1.7818064606189727\n",
      "[2, 200] loss: 1.7611971139907836\n",
      "[2, 300] loss: 1.7412190294265748\n",
      "[3, 100] loss: 1.6560004794597625\n",
      "[3, 200] loss: 1.6176509964466095\n",
      "[3, 300] loss: 1.6121001136302948\n",
      "[4, 100] loss: 1.5527630984783172\n",
      "[4, 200] loss: 1.5263929665088654\n",
      "[4, 300] loss: 1.488864425420761\n",
      "[5, 100] loss: 1.4359942650794983\n",
      "[5, 200] loss: 1.4448134887218476\n",
      "[5, 300] loss: 1.4074857139587402\n",
      "[6, 100] loss: 1.3513677871227265\n",
      "[6, 200] loss: 1.3246771240234374\n",
      "[6, 300] loss: 1.3069152879714965\n",
      "[7, 100] loss: 1.270505827665329\n",
      "[7, 200] loss: 1.2524838638305664\n",
      "[7, 300] loss: 1.2370964431762694\n",
      "[8, 100] loss: 1.2129605877399445\n",
      "[8, 200] loss: 1.1796745985746384\n",
      "[8, 300] loss: 1.1803653806447982\n",
      "[9, 100] loss: 1.1349874502420425\n",
      "[9, 200] loss: 1.1312542682886124\n",
      "[9, 300] loss: 1.115408970117569\n",
      "[10, 100] loss: 1.0919335037469864\n",
      "[10, 200] loss: 1.0874889558553695\n",
      "[10, 300] loss: 1.0820104157924653\n",
      "[11, 100] loss: 1.0596517688035965\n",
      "[11, 200] loss: 1.0696753710508347\n",
      "[11, 300] loss: 1.049633241891861\n",
      "[12, 100] loss: 1.020774058699608\n",
      "[12, 200] loss: 1.0026528966426849\n",
      "[12, 300] loss: 1.0154372638463973\n",
      "[13, 100] loss: 1.001041929125786\n",
      "[13, 200] loss: 1.0042742723226548\n",
      "[13, 300] loss: 0.9962027126550674\n",
      "[14, 100] loss: 0.9835632652044296\n",
      "[14, 200] loss: 0.9789226192235947\n",
      "[14, 300] loss: 0.9779141390323639\n",
      "[15, 100] loss: 0.9693923974037171\n",
      "[15, 200] loss: 0.9828591239452362\n",
      "[15, 300] loss: 0.9727396684885025\n",
      "[16, 100] loss: 0.9628061616420746\n",
      "[16, 200] loss: 0.9694663995504379\n",
      "[16, 300] loss: 0.9663458812236786\n",
      "[17, 100] loss: 0.9577971231937409\n",
      "[17, 200] loss: 0.9519356751441955\n",
      "[17, 300] loss: 0.944002982378006\n",
      "[18, 100] loss: 0.9657726383209229\n",
      "[18, 200] loss: 0.9598086631298065\n",
      "[18, 300] loss: 0.9525986528396606\n",
      "[19, 100] loss: 0.9560270947217941\n",
      "[19, 200] loss: 0.9366131728887558\n",
      "[19, 300] loss: 0.9398293167352676\n",
      "[20, 100] loss: 0.9379641664028168\n",
      "[20, 200] loss: 0.9551250684261322\n",
      "[20, 300] loss: 0.9431065547466279\n",
      "[21, 100] loss: 0.9422155666351318\n",
      "[21, 200] loss: 0.9295144349336624\n",
      "[21, 300] loss: 0.9490204119682312\n",
      "[22, 100] loss: 0.9400358152389526\n",
      "[22, 200] loss: 0.9416221475601196\n",
      "[22, 300] loss: 0.9328099352121353\n",
      "[23, 100] loss: 0.9135898023843765\n",
      "[23, 200] loss: 0.9269909566640854\n",
      "[23, 300] loss: 0.9530468714237214\n",
      "[24, 100] loss: 0.9125125586986542\n",
      "[24, 200] loss: 0.9420041781663895\n",
      "[24, 300] loss: 0.9334236192703247\n",
      "[25, 100] loss: 0.9304641562700272\n",
      "[25, 200] loss: 0.916668347120285\n",
      "[25, 300] loss: 0.8957753801345825\n",
      "[26, 100] loss: 0.9078945821523666\n",
      "[26, 200] loss: 0.9338111054897308\n",
      "[26, 300] loss: 0.9226059633493423\n",
      "[27, 100] loss: 0.9168019324541092\n",
      "[27, 200] loss: 0.9124905449151993\n",
      "[27, 300] loss: 0.9163962769508361\n",
      "[28, 100] loss: 0.931717699766159\n",
      "[28, 200] loss: 0.9221641504764557\n",
      "[28, 300] loss: 0.9226045215129852\n",
      "[29, 100] loss: 0.9226136314868927\n",
      "[29, 200] loss: 0.9118343740701675\n",
      "[29, 300] loss: 0.9211286550760269\n",
      "[30, 100] loss: 0.9315980887413025\n",
      "[30, 200] loss: 0.9133494889736176\n",
      "[30, 300] loss: 0.9256103378534317\n",
      "[31, 100] loss: 0.9208066958189011\n",
      "[31, 200] loss: 0.9069708752632141\n",
      "[31, 300] loss: 0.9131398904323578\n",
      "[32, 100] loss: 0.9143679481744766\n",
      "[32, 200] loss: 0.9032639938592911\n",
      "[32, 300] loss: 0.9160952603816986\n",
      "[33, 100] loss: 0.9203428041934967\n",
      "[33, 200] loss: 0.9096940124034881\n",
      "[33, 300] loss: 0.9356854808330536\n",
      "[34, 100] loss: 0.9263726907968521\n",
      "[34, 200] loss: 0.9199052363634109\n",
      "[34, 300] loss: 0.9318799412250519\n",
      "[35, 100] loss: 0.9169290524721145\n",
      "[35, 200] loss: 0.9066253966093063\n",
      "[35, 300] loss: 0.9080492889881134\n",
      "[36, 100] loss: 0.9313833278417587\n",
      "[36, 200] loss: 0.9312521123886108\n",
      "[36, 300] loss: 0.9030390667915345\n",
      "[37, 100] loss: 0.9181143039464951\n",
      "[37, 200] loss: 0.9184180057048797\n",
      "[37, 300] loss: 0.8951018446683884\n",
      "[38, 100] loss: 0.9214659744501114\n",
      "[38, 200] loss: 0.9281504708528518\n",
      "[38, 300] loss: 0.9122558015584946\n",
      "[39, 100] loss: 0.9275941997766495\n",
      "[39, 200] loss: 0.9163196629285812\n",
      "[39, 300] loss: 0.903001356124878\n",
      "[40, 100] loss: 0.9151815390586853\n",
      "[40, 200] loss: 0.9213307452201843\n",
      "[40, 300] loss: 0.8989785921573639\n",
      "[41, 100] loss: 0.9188721477985382\n",
      "[41, 200] loss: 0.8987882781028748\n",
      "[41, 300] loss: 0.8967435675859451\n",
      "[42, 100] loss: 0.9024463242292404\n",
      "[42, 200] loss: 0.9076419818401337\n",
      "[42, 300] loss: 0.9121485644578934\n",
      "[43, 100] loss: 0.8948162025213242\n",
      "[43, 200] loss: 0.8931209397315979\n",
      "[43, 300] loss: 0.913328949213028\n",
      "[44, 100] loss: 0.9173071420192719\n",
      "[44, 200] loss: 0.8973304373025894\n",
      "[44, 300] loss: 0.9149346661567688\n",
      "[45, 100] loss: 0.9048996621370315\n",
      "[45, 200] loss: 0.9026164346933365\n",
      "[45, 300] loss: 0.9042436784505844\n",
      "[46, 100] loss: 0.8863632023334503\n",
      "[46, 200] loss: 0.9147306281328201\n",
      "[46, 300] loss: 0.898253213763237\n",
      "[47, 100] loss: 0.8986646831035614\n",
      "[47, 200] loss: 0.9236323404312133\n",
      "[47, 300] loss: 0.8999946475028991\n",
      "[48, 100] loss: 0.8972966361045838\n",
      "[48, 200] loss: 0.8877368611097336\n",
      "[48, 300] loss: 0.8974572157859803\n",
      "[49, 100] loss: 0.8928085660934448\n",
      "[49, 200] loss: 0.8979822170734405\n",
      "[49, 300] loss: 0.9007319778203964\n",
      "[50, 100] loss: 0.9007024592161179\n",
      "[50, 200] loss: 0.9112029892206192\n",
      "[50, 300] loss: 0.8869588720798492\n",
      "[51, 100] loss: 0.9107211470603943\n",
      "[51, 200] loss: 0.9010470569133758\n",
      "[51, 300] loss: 0.892394847869873\n",
      "[52, 100] loss: 0.9036901015043258\n",
      "[52, 200] loss: 0.8920057517290115\n",
      "[52, 300] loss: 0.8876904815435409\n",
      "[53, 100] loss: 0.8900306475162506\n",
      "[53, 200] loss: 0.9150553101301193\n",
      "[53, 300] loss: 0.9112237030267716\n",
      "[54, 100] loss: 0.9161908185482025\n",
      "[54, 200] loss: 0.9193821293115616\n",
      "[54, 300] loss: 0.890657233595848\n",
      "[55, 100] loss: 0.8960390847921371\n",
      "[55, 200] loss: 0.9130482602119446\n",
      "[55, 300] loss: 0.9136681759357452\n",
      "[56, 100] loss: 0.9196256846189499\n",
      "[56, 200] loss: 0.9091239207983017\n",
      "[56, 300] loss: 0.9068330919742584\n",
      "[57, 100] loss: 0.9069323819875718\n",
      "[57, 200] loss: 0.9004467207193375\n",
      "[57, 300] loss: 0.91736503303051\n",
      "[58, 100] loss: 0.9133690321445465\n",
      "[58, 200] loss: 0.8993228894472122\n",
      "[58, 300] loss: 0.9019011282920837\n",
      "[59, 100] loss: 0.9036211627721786\n",
      "[59, 200] loss: 0.8957884001731873\n",
      "[59, 300] loss: 0.8964212012290954\n",
      "[60, 100] loss: 0.8832733017206192\n",
      "[60, 200] loss: 0.9092233371734619\n",
      "[60, 300] loss: 0.8995320332050324\n",
      "[61, 100] loss: 0.8821783828735351\n",
      "[61, 200] loss: 0.9083175754547119\n",
      "[61, 300] loss: 0.9099854755401612\n",
      "[62, 100] loss: 0.9017402291297912\n",
      "[62, 200] loss: 0.8873793649673462\n",
      "[62, 300] loss: 0.9099322855472565\n",
      "[63, 100] loss: 0.9026428937911988\n",
      "[63, 200] loss: 0.8792966127395629\n",
      "[63, 300] loss: 0.8804764997959137\n",
      "[64, 100] loss: 0.8861164963245391\n",
      "[64, 200] loss: 0.9043434566259384\n",
      "[64, 300] loss: 0.8781720781326294\n",
      "[65, 100] loss: 0.8995310634374618\n",
      "[65, 200] loss: 0.8939388936758041\n",
      "[65, 300] loss: 0.9010512161254883\n",
      "[66, 100] loss: 0.8737328827381134\n",
      "[66, 200] loss: 0.8887945878505706\n",
      "[66, 300] loss: 0.8968759685754776\n",
      "[67, 100] loss: 0.8995226490497589\n",
      "[67, 200] loss: 0.8963924133777619\n",
      "[67, 300] loss: 0.8771708005666733\n",
      "[68, 100] loss: 0.9018163764476776\n",
      "[68, 200] loss: 0.9140575051307678\n",
      "[68, 300] loss: 0.8786561703681945\n",
      "[69, 100] loss: 0.8905566793680191\n",
      "[69, 200] loss: 0.8860952985286713\n",
      "[69, 300] loss: 0.8969844454526901\n",
      "[70, 100] loss: 0.8764085763692856\n",
      "[70, 200] loss: 0.8723696404695511\n",
      "[70, 300] loss: 0.9000367707014084\n",
      "[71, 100] loss: 0.9101137924194336\n",
      "[71, 200] loss: 0.9002554225921631\n",
      "[71, 300] loss: 0.8972709244489669\n",
      "[72, 100] loss: 0.8861141055822372\n",
      "[72, 200] loss: 0.8929254132509231\n",
      "[72, 300] loss: 0.8942149817943573\n",
      "[73, 100] loss: 0.8937059557437896\n",
      "[73, 200] loss: 0.8874120587110519\n",
      "[73, 300] loss: 0.8845836102962494\n",
      "[74, 100] loss: 0.9024015235900879\n",
      "[74, 200] loss: 0.8987604105472564\n",
      "[74, 300] loss: 0.8907332795858384\n",
      "[75, 100] loss: 0.8791462123394013\n",
      "[75, 200] loss: 0.8952972632646561\n",
      "[75, 300] loss: 0.8871086913347245\n",
      "[76, 100] loss: 0.9095779407024384\n",
      "[76, 200] loss: 0.895528147816658\n",
      "[76, 300] loss: 0.8956592845916748\n",
      "[77, 100] loss: 0.8730712634325027\n",
      "[77, 200] loss: 0.8833891695737839\n",
      "[77, 300] loss: 0.906080555319786\n",
      "[78, 100] loss: 0.8931992685794831\n",
      "[78, 200] loss: 0.8889877766370773\n",
      "[78, 300] loss: 0.8948680132627487\n",
      "[79, 100] loss: 0.8915119844675065\n",
      "[79, 200] loss: 0.86104625582695\n",
      "[79, 300] loss: 0.8765608876943588\n",
      "[80, 100] loss: 0.8867841625213623\n",
      "[80, 200] loss: 0.8873327630758285\n",
      "[80, 300] loss: 0.8915353459119797\n",
      "[81, 100] loss: 0.8992210149765014\n",
      "[81, 200] loss: 0.8878483390808105\n",
      "[81, 300] loss: 0.8918278282880783\n",
      "[82, 100] loss: 0.8868700695037842\n",
      "[82, 200] loss: 0.8797401744127273\n",
      "[82, 300] loss: 0.8763166773319244\n",
      "[83, 100] loss: 0.8700670576095582\n",
      "[83, 200] loss: 0.8832372200489044\n",
      "[83, 300] loss: 0.8890163320302963\n",
      "[84, 100] loss: 0.8963217329978943\n",
      "[84, 200] loss: 0.8955757266283035\n",
      "[84, 300] loss: 0.8857303458452225\n",
      "[85, 100] loss: 0.8846479451656342\n",
      "[85, 200] loss: 0.8896851199865341\n",
      "[85, 300] loss: 0.8862476044893265\n",
      "[86, 100] loss: 0.9048410630226136\n",
      "[86, 200] loss: 0.8795308417081833\n",
      "[86, 300] loss: 0.899723909497261\n",
      "[87, 100] loss: 0.8862469261884689\n",
      "[87, 200] loss: 0.890478720664978\n",
      "[87, 300] loss: 0.8920642769336701\n",
      "[88, 100] loss: 0.8915565586090088\n",
      "[88, 200] loss: 0.9091678917407989\n",
      "[88, 300] loss: 0.9038413488864898\n",
      "[89, 100] loss: 0.8842822742462159\n",
      "[89, 200] loss: 0.8944188672304153\n",
      "[89, 300] loss: 0.896269657611847\n",
      "[90, 100] loss: 0.8921692478656769\n",
      "[90, 200] loss: 0.8914966559410096\n",
      "[90, 300] loss: 0.9050722426176071\n",
      "[91, 100] loss: 0.8815635126829148\n",
      "[91, 200] loss: 0.8731030601263047\n",
      "[91, 300] loss: 0.8898749643564224\n",
      "[92, 100] loss: 0.9104472583532334\n",
      "[92, 200] loss: 0.8832563841342926\n",
      "[92, 300] loss: 0.9008983165025711\n",
      "[93, 100] loss: 0.8921369498968125\n",
      "[93, 200] loss: 0.8945318567752838\n",
      "[93, 300] loss: 0.9173330837488174\n",
      "[94, 100] loss: 0.9076518177986145\n",
      "[94, 200] loss: 0.9088278657197952\n",
      "[94, 300] loss: 0.9065941905975342\n",
      "[95, 100] loss: 0.9054596364498139\n",
      "[95, 200] loss: 0.8862138545513153\n",
      "[95, 300] loss: 0.904807960987091\n",
      "[96, 100] loss: 0.8943953490257264\n",
      "[96, 200] loss: 0.8971110355854034\n",
      "[96, 300] loss: 0.9068581372499466\n",
      "[97, 100] loss: 0.8828533118963242\n",
      "[97, 200] loss: 0.8796001410484314\n",
      "[97, 300] loss: 0.9052162653207779\n",
      "[98, 100] loss: 0.8893845188617706\n",
      "[98, 200] loss: 0.8861006897687912\n",
      "[98, 300] loss: 0.8713181179761886\n",
      "[99, 100] loss: 0.8966508555412293\n",
      "[99, 200] loss: 0.8882612580060959\n",
      "[99, 300] loss: 0.9102331113815307\n",
      "[100, 100] loss: 0.8892425882816315\n",
      "[100, 200] loss: 0.8934697645902634\n",
      "[100, 300] loss: 0.8919606739282608\n",
      "Training model 12 in the ensemble...\n",
      "[1, 100] loss: 2.1779199504852294\n",
      "[1, 200] loss: 1.9738517796993256\n",
      "[1, 300] loss: 1.900155314207077\n",
      "[2, 100] loss: 1.8124546539783477\n",
      "[2, 200] loss: 1.757491819858551\n",
      "[2, 300] loss: 1.7068961775302887\n",
      "[3, 100] loss: 1.656603571176529\n",
      "[3, 200] loss: 1.6083842098712922\n",
      "[3, 300] loss: 1.5531412911415101\n",
      "[4, 100] loss: 1.4670388805866241\n",
      "[4, 200] loss: 1.436306449174881\n",
      "[4, 300] loss: 1.3715648174285888\n",
      "[5, 100] loss: 1.3063477623462676\n",
      "[5, 200] loss: 1.262044652700424\n",
      "[5, 300] loss: 1.2148061549663545\n",
      "[6, 100] loss: 1.181601828932762\n",
      "[6, 200] loss: 1.149442812204361\n",
      "[6, 300] loss: 1.1299358558654786\n",
      "[7, 100] loss: 1.0963305377960204\n",
      "[7, 200] loss: 1.103214486837387\n",
      "[7, 300] loss: 1.0970736861228942\n",
      "[8, 100] loss: 1.0480285412073136\n",
      "[8, 200] loss: 1.050350797176361\n",
      "[8, 300] loss: 1.0460370999574662\n",
      "[9, 100] loss: 1.0275471860170364\n",
      "[9, 200] loss: 1.0040368747711181\n",
      "[9, 300] loss: 1.0267467111349107\n",
      "[10, 100] loss: 1.0148311620950698\n",
      "[10, 200] loss: 1.000015287399292\n",
      "[10, 300] loss: 1.0142902141809464\n",
      "[11, 100] loss: 0.991751988530159\n",
      "[11, 200] loss: 0.9989942580461502\n",
      "[11, 300] loss: 0.9916528636217117\n",
      "[12, 100] loss: 0.9822862064838409\n",
      "[12, 200] loss: 0.9770385563373566\n",
      "[12, 300] loss: 0.9793929034471511\n",
      "[13, 100] loss: 0.9688758200407028\n",
      "[13, 200] loss: 0.9769115364551544\n",
      "[13, 300] loss: 0.9615455502271653\n",
      "[14, 100] loss: 0.9678728306293487\n",
      "[14, 200] loss: 0.9723680627346039\n",
      "[14, 300] loss: 0.9692350536584854\n",
      "[15, 100] loss: 0.962685614824295\n",
      "[15, 200] loss: 0.9751666224002838\n",
      "[15, 300] loss: 0.9583650469779968\n",
      "[16, 100] loss: 0.9653834277391433\n",
      "[16, 200] loss: 0.9397808730602264\n",
      "[16, 300] loss: 0.956640533208847\n",
      "[17, 100] loss: 0.9609280145168304\n",
      "[17, 200] loss: 0.9572642576694489\n",
      "[17, 300] loss: 0.9514244443178177\n",
      "[18, 100] loss: 0.9590985924005508\n",
      "[18, 200] loss: 0.9453450685739517\n",
      "[18, 300] loss: 0.9372525286674499\n",
      "[19, 100] loss: 0.9324819523096085\n",
      "[19, 200] loss: 0.9624626749753952\n",
      "[19, 300] loss: 0.9317364227771759\n",
      "[20, 100] loss: 0.9540504676103592\n",
      "[20, 200] loss: 0.9495525729656219\n",
      "[20, 300] loss: 0.9393471002578735\n",
      "[21, 100] loss: 0.9334875023365021\n",
      "[21, 200] loss: 0.9374287354946137\n",
      "[21, 300] loss: 0.9320590668916702\n",
      "[22, 100] loss: 0.9417108780145645\n",
      "[22, 200] loss: 0.9223014271259308\n",
      "[22, 300] loss: 0.9343818032741547\n",
      "[23, 100] loss: 0.9321443456411361\n",
      "[23, 200] loss: 0.9506752687692642\n",
      "[23, 300] loss: 0.9511555153131485\n",
      "[24, 100] loss: 0.9159718096256256\n",
      "[24, 200] loss: 0.9292321741580963\n",
      "[24, 300] loss: 0.9436377716064454\n",
      "[25, 100] loss: 0.9367937123775483\n",
      "[25, 200] loss: 0.9266523414850235\n",
      "[25, 300] loss: 0.9162650012969971\n",
      "[26, 100] loss: 0.9377052938938141\n",
      "[26, 200] loss: 0.9350216764211655\n",
      "[26, 300] loss: 0.9243244856595993\n",
      "[27, 100] loss: 0.9320020204782486\n",
      "[27, 200] loss: 0.9317320263385773\n",
      "[27, 300] loss: 0.9234276396036148\n",
      "[28, 100] loss: 0.9456923395395279\n",
      "[28, 200] loss: 0.918138381242752\n",
      "[28, 300] loss: 0.9300852006673813\n",
      "[29, 100] loss: 0.913720833659172\n",
      "[29, 200] loss: 0.9374981296062469\n",
      "[29, 300] loss: 0.9232877361774444\n",
      "[30, 100] loss: 0.9034998911619186\n",
      "[30, 200] loss: 0.9504786849021911\n",
      "[30, 300] loss: 0.9277352273464203\n",
      "[31, 100] loss: 0.9295501840114594\n",
      "[31, 200] loss: 0.9226272565126419\n",
      "[31, 300] loss: 0.9306896936893463\n",
      "[32, 100] loss: 0.9035005778074264\n",
      "[32, 200] loss: 0.9405428797006607\n",
      "[32, 300] loss: 0.9277681773900985\n",
      "[33, 100] loss: 0.9201173102855682\n",
      "[33, 200] loss: 0.9149134618043899\n",
      "[33, 300] loss: 0.9123261731863022\n",
      "[34, 100] loss: 0.9113400465250016\n",
      "[34, 200] loss: 0.9233074003458023\n",
      "[34, 300] loss: 0.8892560178041458\n",
      "[35, 100] loss: 0.9143865233659745\n",
      "[35, 200] loss: 0.9177138596773148\n",
      "[35, 300] loss: 0.9143279349803924\n",
      "[36, 100] loss: 0.9108792412281036\n",
      "[36, 200] loss: 0.9318376535177231\n",
      "[36, 300] loss: 0.9264932018518448\n",
      "[37, 100] loss: 0.9017466580867768\n",
      "[37, 200] loss: 0.8972142297029495\n",
      "[37, 300] loss: 0.9064757978916168\n",
      "[38, 100] loss: 0.922829675078392\n",
      "[38, 200] loss: 0.9070991647243499\n",
      "[38, 300] loss: 0.8918332201242447\n",
      "[39, 100] loss: 0.897112951874733\n",
      "[39, 200] loss: 0.897813823223114\n",
      "[39, 300] loss: 0.9281238424777984\n",
      "[40, 100] loss: 0.9086817228794097\n",
      "[40, 200] loss: 0.9122694838047027\n",
      "[40, 300] loss: 0.9058401989936828\n",
      "[41, 100] loss: 0.9192527621984482\n",
      "[41, 200] loss: 0.9116826444864273\n",
      "[41, 300] loss: 0.9179906666278839\n",
      "[42, 100] loss: 0.8990170675516128\n",
      "[42, 200] loss: 0.9071874368190765\n",
      "[42, 300] loss: 0.9059131699800491\n",
      "[43, 100] loss: 0.9015493106842041\n",
      "[43, 200] loss: 0.8995132333040238\n",
      "[43, 300] loss: 0.9077931725978852\n",
      "[44, 100] loss: 0.9043072551488877\n",
      "[44, 200] loss: 0.9328792124986649\n",
      "[44, 300] loss: 0.9249759650230408\n",
      "[45, 100] loss: 0.8953809642791748\n",
      "[45, 200] loss: 0.9041578716039658\n",
      "[45, 300] loss: 0.9064467597007752\n",
      "[46, 100] loss: 0.8887368500232696\n",
      "[46, 200] loss: 0.8875000989437103\n",
      "[46, 300] loss: 0.9023034530878067\n",
      "[47, 100] loss: 0.8986515510082245\n",
      "[47, 200] loss: 0.897999182343483\n",
      "[47, 300] loss: 0.9234869307279587\n",
      "[48, 100] loss: 0.9239359354972839\n",
      "[48, 200] loss: 0.9253581762313843\n",
      "[48, 300] loss: 0.9033566331863403\n",
      "[49, 100] loss: 0.9118019723892212\n",
      "[49, 200] loss: 0.9287677484750748\n",
      "[49, 300] loss: 0.9030447787046433\n",
      "[50, 100] loss: 0.8943280631303787\n",
      "[50, 200] loss: 0.8907619804143906\n",
      "[50, 300] loss: 0.9006473129987717\n",
      "[51, 100] loss: 0.9122439163923264\n",
      "[51, 200] loss: 0.9195465224981308\n",
      "[51, 300] loss: 0.9144509315490723\n",
      "[52, 100] loss: 0.9058417421579361\n",
      "[52, 200] loss: 0.9070366150140763\n",
      "[52, 300] loss: 0.8981432992219925\n",
      "[53, 100] loss: 0.9093598109483719\n",
      "[53, 200] loss: 0.894087290763855\n",
      "[53, 300] loss: 0.9029403734207153\n",
      "[54, 100] loss: 0.9146485316753388\n",
      "[54, 200] loss: 0.9031670278310776\n",
      "[54, 300] loss: 0.9213819909095764\n",
      "[55, 100] loss: 0.8989257776737213\n",
      "[55, 200] loss: 0.8837594121694565\n",
      "[55, 300] loss: 0.8951741254329681\n",
      "[56, 100] loss: 0.9007575935125351\n",
      "[56, 200] loss: 0.9229841709136963\n",
      "[56, 300] loss: 0.9055583775043488\n",
      "[57, 100] loss: 0.9068543219566345\n",
      "[57, 200] loss: 0.904807305932045\n",
      "[57, 300] loss: 0.8916246402263641\n",
      "[58, 100] loss: 0.9170943117141723\n",
      "[58, 200] loss: 0.9098541516065598\n",
      "[58, 300] loss: 0.8876400399208069\n",
      "[59, 100] loss: 0.9215009170770645\n",
      "[59, 200] loss: 0.9015123909711837\n",
      "[59, 300] loss: 0.913369157910347\n",
      "[60, 100] loss: 0.8967754524946213\n",
      "[60, 200] loss: 0.8976930981874466\n",
      "[60, 300] loss: 0.9158185315132141\n",
      "[61, 100] loss: 0.8811958450078964\n",
      "[61, 200] loss: 0.9099624764919281\n",
      "[61, 300] loss: 0.9102533239126206\n",
      "[62, 100] loss: 0.9078308421373368\n",
      "[62, 200] loss: 0.9072277992963791\n",
      "[62, 300] loss: 0.9093735235929489\n",
      "[63, 100] loss: 0.9118730735778808\n",
      "[63, 200] loss: 0.9057995426654816\n",
      "[63, 300] loss: 0.8810409712791443\n",
      "[64, 100] loss: 0.888116130232811\n",
      "[64, 200] loss: 0.8856213235855103\n",
      "[64, 300] loss: 0.8855114912986756\n",
      "[65, 100] loss: 0.8972968930006027\n",
      "[65, 200] loss: 0.8980457055568695\n",
      "[65, 300] loss: 0.894410605430603\n",
      "[66, 100] loss: 0.8859332305192947\n",
      "[66, 200] loss: 0.8888828343153\n",
      "[66, 300] loss: 0.8984618377685547\n",
      "[67, 100] loss: 0.8976225781440735\n",
      "[67, 200] loss: 0.8926525801420212\n",
      "[67, 300] loss: 0.9060887545347214\n",
      "[68, 100] loss: 0.8892928802967072\n",
      "[68, 200] loss: 0.8840676653385162\n",
      "[68, 300] loss: 0.8911426019668579\n",
      "[69, 100] loss: 0.8799515479803085\n",
      "[69, 200] loss: 0.8980229270458221\n",
      "[69, 300] loss: 0.8934052634239197\n",
      "[70, 100] loss: 0.8825618469715119\n",
      "[70, 200] loss: 0.8913920778036117\n",
      "[70, 300] loss: 0.8912200117111206\n",
      "[71, 100] loss: 0.8876630711555481\n",
      "[71, 200] loss: 0.8995995628833771\n",
      "[71, 300] loss: 0.9100643187761307\n",
      "[72, 100] loss: 0.8969007194042206\n",
      "[72, 200] loss: 0.9128526246547699\n",
      "[72, 300] loss: 0.8987198895215989\n",
      "[73, 100] loss: 0.8840946197509766\n",
      "[73, 200] loss: 0.8970762890577316\n",
      "[73, 300] loss: 0.9086802762746811\n",
      "[74, 100] loss: 0.8985221481323242\n",
      "[74, 200] loss: 0.8986604911088943\n",
      "[74, 300] loss: 0.9053925675153732\n",
      "[75, 100] loss: 0.8864248085021973\n",
      "[75, 200] loss: 0.8844636124372482\n",
      "[75, 300] loss: 0.887616621851921\n",
      "[76, 100] loss: 0.8865884166955947\n",
      "[76, 200] loss: 0.8901631391048431\n",
      "[76, 300] loss: 0.8918231785297394\n",
      "[77, 100] loss: 0.892310443520546\n",
      "[77, 200] loss: 0.8767261981964112\n",
      "[77, 300] loss: 0.8812876588106155\n",
      "[78, 100] loss: 0.8778811609745025\n",
      "[78, 200] loss: 0.9053769505023956\n",
      "[78, 300] loss: 0.8834968620538711\n",
      "[79, 100] loss: 0.8725110507011413\n",
      "[79, 200] loss: 0.8904969757795334\n",
      "[79, 300] loss: 0.8940843707323074\n",
      "[80, 100] loss: 0.8970898509025573\n",
      "[80, 200] loss: 0.8889055913686752\n",
      "[80, 300] loss: 0.8989443409442902\n",
      "[81, 100] loss: 0.8807469701766968\n",
      "[81, 200] loss: 0.8556564241647721\n",
      "[81, 300] loss: 0.8795816642045975\n",
      "[82, 100] loss: 0.9038598775863648\n",
      "[82, 200] loss: 0.904612438082695\n",
      "[82, 300] loss: 0.8877622485160828\n",
      "[83, 100] loss: 0.8924288529157639\n",
      "[83, 200] loss: 0.8900466597080231\n",
      "[83, 300] loss: 0.885124117732048\n",
      "[84, 100] loss: 0.8800666081905365\n",
      "[84, 200] loss: 0.8959117907285691\n",
      "[84, 300] loss: 0.8784567058086395\n",
      "[85, 100] loss: 0.8903603965044021\n",
      "[85, 200] loss: 0.8817375725507737\n",
      "[85, 300] loss: 0.8893445837497711\n",
      "[86, 100] loss: 0.8781055939197541\n",
      "[86, 200] loss: 0.8689621376991272\n",
      "[86, 300] loss: 0.8863356196880341\n",
      "[87, 100] loss: 0.8805398780107498\n",
      "[87, 200] loss: 0.8702736639976502\n",
      "[87, 300] loss: 0.8728080296516418\n",
      "[88, 100] loss: 0.8879205000400543\n",
      "[88, 200] loss: 0.9035168355703354\n",
      "[88, 300] loss: 0.9096072268486023\n",
      "[89, 100] loss: 0.9065582883358002\n",
      "[89, 200] loss: 0.8904823452234268\n",
      "[89, 300] loss: 0.8900250440835953\n",
      "[90, 100] loss: 0.8938203978538514\n",
      "[90, 200] loss: 0.8890918463468551\n",
      "[90, 300] loss: 0.9040135204792022\n",
      "[91, 100] loss: 0.8973497438430786\n",
      "[91, 200] loss: 0.9001234823465347\n",
      "[91, 300] loss: 0.9089834982156754\n",
      "[92, 100] loss: 0.8867128401994705\n",
      "[92, 200] loss: 0.8745230501890182\n",
      "[92, 300] loss: 0.8778082489967346\n",
      "[93, 100] loss: 0.8641703081130981\n",
      "[93, 200] loss: 0.8802791392803192\n",
      "[93, 300] loss: 0.8943799346685409\n",
      "[94, 100] loss: 0.903459415435791\n",
      "[94, 200] loss: 0.8752948045730591\n",
      "[94, 300] loss: 0.8907210493087768\n",
      "[95, 100] loss: 0.8637803852558136\n",
      "[95, 200] loss: 0.8887577605247498\n",
      "[95, 300] loss: 0.9069213885068893\n",
      "[96, 100] loss: 0.89149753510952\n",
      "[96, 200] loss: 0.9015596443414688\n",
      "[96, 300] loss: 0.8886254900693893\n",
      "[97, 100] loss: 0.8839923882484436\n",
      "[97, 200] loss: 0.8800614666938782\n",
      "[97, 300] loss: 0.9010320889949799\n",
      "[98, 100] loss: 0.8851493918895721\n",
      "[98, 200] loss: 0.8905208969116211\n",
      "[98, 300] loss: 0.8947801214456558\n",
      "[99, 100] loss: 0.8874263072013855\n",
      "[99, 200] loss: 0.8702811390161515\n",
      "[99, 300] loss: 0.8948886817693711\n",
      "[100, 100] loss: 0.8674665164947509\n",
      "[100, 200] loss: 0.878453048467636\n",
      "[100, 300] loss: 0.897031192779541\n",
      "Training model 13 in the ensemble...\n",
      "[1, 100] loss: 2.141521706581116\n",
      "[1, 200] loss: 1.9827964746952056\n",
      "[1, 300] loss: 1.934098423719406\n",
      "[2, 100] loss: 1.8485044240951538\n",
      "[2, 200] loss: 1.8326466798782348\n",
      "[2, 300] loss: 1.81311683177948\n",
      "[3, 100] loss: 1.7616743576526641\n",
      "[3, 200] loss: 1.7518352699279784\n",
      "[3, 300] loss: 1.7318563342094422\n",
      "[4, 100] loss: 1.6881602132320404\n",
      "[4, 200] loss: 1.6611131298542023\n",
      "[4, 300] loss: 1.656312769651413\n",
      "[5, 100] loss: 1.619985616207123\n",
      "[5, 200] loss: 1.5914520835876464\n",
      "[5, 300] loss: 1.559176322221756\n",
      "[6, 100] loss: 1.4834207570552826\n",
      "[6, 200] loss: 1.4607765364646912\n",
      "[6, 300] loss: 1.4172669315338136\n",
      "[7, 100] loss: 1.3581496632099153\n",
      "[7, 200] loss: 1.3276443600654602\n",
      "[7, 300] loss: 1.2868486547470093\n",
      "[8, 100] loss: 1.2297052395343782\n",
      "[8, 200] loss: 1.2340707683563232\n",
      "[8, 300] loss: 1.2062016928195953\n",
      "[9, 100] loss: 1.158840393424034\n",
      "[9, 200] loss: 1.136464307308197\n",
      "[9, 300] loss: 1.1080377054214479\n",
      "[10, 100] loss: 1.0947532814741134\n",
      "[10, 200] loss: 1.095032269358635\n",
      "[10, 300] loss: 1.0692853277921677\n",
      "[11, 100] loss: 1.0707743442058564\n",
      "[11, 200] loss: 1.0666536420583725\n",
      "[11, 300] loss: 1.045781866312027\n",
      "[12, 100] loss: 1.0284279108047485\n",
      "[12, 200] loss: 1.0064933979511261\n",
      "[12, 300] loss: 1.0213664108514786\n",
      "[13, 100] loss: 1.0079973930120467\n",
      "[13, 200] loss: 0.9887187105417251\n",
      "[13, 300] loss: 1.0076285392045974\n",
      "[14, 100] loss: 0.9967756873369217\n",
      "[14, 200] loss: 0.9699406671524048\n",
      "[14, 300] loss: 0.9707374769449234\n",
      "[15, 100] loss: 0.9681158357858658\n",
      "[15, 200] loss: 0.973186912536621\n",
      "[15, 300] loss: 0.9772935748100281\n",
      "[16, 100] loss: 0.9778543877601623\n",
      "[16, 200] loss: 0.9678153359889984\n",
      "[16, 300] loss: 0.960890839099884\n",
      "[17, 100] loss: 0.9670523494482041\n",
      "[17, 200] loss: 0.972814182639122\n",
      "[17, 300] loss: 0.9548643064498902\n",
      "[18, 100] loss: 0.9417328155040741\n",
      "[18, 200] loss: 0.9457356536388397\n",
      "[18, 300] loss: 0.9468699353933334\n",
      "[19, 100] loss: 0.9554765123128891\n",
      "[19, 200] loss: 0.9451297175884247\n",
      "[19, 300] loss: 0.919310780763626\n",
      "[20, 100] loss: 0.955265365242958\n",
      "[20, 200] loss: 0.9437591326236725\n",
      "[20, 300] loss: 0.9397451704740525\n",
      "[21, 100] loss: 0.9379453366994858\n",
      "[21, 200] loss: 0.9284784287214279\n",
      "[21, 300] loss: 0.9450101548433304\n",
      "[22, 100] loss: 0.9263039761781693\n",
      "[22, 200] loss: 0.952158369421959\n",
      "[22, 300] loss: 0.9455178785324097\n",
      "[23, 100] loss: 0.9390767467021942\n",
      "[23, 200] loss: 0.9376924395561218\n",
      "[23, 300] loss: 0.9147865808010102\n",
      "[24, 100] loss: 0.9235765343904495\n",
      "[24, 200] loss: 0.93708043217659\n",
      "[24, 300] loss: 0.9494047379493713\n",
      "[25, 100] loss: 0.926006048321724\n",
      "[25, 200] loss: 0.9329224330186844\n",
      "[25, 300] loss: 0.9196506601572036\n",
      "[26, 100] loss: 0.9425860345363617\n",
      "[26, 200] loss: 0.9321639913320542\n",
      "[26, 300] loss: 0.9383209145069122\n",
      "[27, 100] loss: 0.9274686127901077\n",
      "[27, 200] loss: 0.9182288163900375\n",
      "[27, 300] loss: 0.9330358672142028\n",
      "[28, 100] loss: 0.9288434487581253\n",
      "[28, 200] loss: 0.9274260658025741\n",
      "[28, 300] loss: 0.903506395816803\n",
      "[29, 100] loss: 0.9183245378732682\n",
      "[29, 200] loss: 0.9294603031873703\n",
      "[29, 300] loss: 0.9076042491197586\n",
      "[30, 100] loss: 0.9219428181648255\n",
      "[30, 200] loss: 0.9299629575014114\n",
      "[30, 300] loss: 0.9212748801708222\n",
      "[31, 100] loss: 0.905893343091011\n",
      "[31, 200] loss: 0.9337456315755844\n",
      "[31, 300] loss: 0.9049811834096908\n",
      "[32, 100] loss: 0.9232145178318024\n",
      "[32, 200] loss: 0.8870982784032821\n",
      "[32, 300] loss: 0.928542662858963\n",
      "[33, 100] loss: 0.9192671298980712\n",
      "[33, 200] loss: 0.9206050652265548\n",
      "[33, 300] loss: 0.9194192957878112\n",
      "[34, 100] loss: 0.9303851956129074\n",
      "[34, 200] loss: 0.9167562860250473\n",
      "[34, 300] loss: 0.9334455245733261\n",
      "[35, 100] loss: 0.9351073932647705\n",
      "[35, 200] loss: 0.9052761501073837\n",
      "[35, 300] loss: 0.9244314801692962\n",
      "[36, 100] loss: 0.9148175269365311\n",
      "[36, 200] loss: 0.9258453726768494\n",
      "[36, 300] loss: 0.9195710980892181\n",
      "[37, 100] loss: 0.9140852129459381\n",
      "[37, 200] loss: 0.9199276787042617\n",
      "[37, 300] loss: 0.9276094853878021\n",
      "[38, 100] loss: 0.9139108735322953\n",
      "[38, 200] loss: 0.9286202329397202\n",
      "[38, 300] loss: 0.9176057916879654\n",
      "[39, 100] loss: 0.9155147951841355\n",
      "[39, 200] loss: 0.921214206814766\n",
      "[39, 300] loss: 0.9237858062982559\n",
      "[40, 100] loss: 0.9122042191028595\n",
      "[40, 200] loss: 0.9265959709882736\n",
      "[40, 300] loss: 0.9062951493263245\n",
      "[41, 100] loss: 0.9239839464426041\n",
      "[41, 200] loss: 0.9025827091932297\n",
      "[41, 300] loss: 0.9212624633312225\n",
      "[42, 100] loss: 0.9037972438335419\n",
      "[42, 200] loss: 0.913249300122261\n",
      "[42, 300] loss: 0.9131499963998795\n",
      "[43, 100] loss: 0.9378305846452712\n",
      "[43, 200] loss: 0.9010167664289475\n",
      "[43, 300] loss: 0.908360550403595\n",
      "[44, 100] loss: 0.9119140571355819\n",
      "[44, 200] loss: 0.9099593490362168\n",
      "[44, 300] loss: 0.9120391279458999\n",
      "[45, 100] loss: 0.9179254496097564\n",
      "[45, 200] loss: 0.9156342339515686\n",
      "[45, 300] loss: 0.9213151210546493\n",
      "[46, 100] loss: 0.900022200345993\n",
      "[46, 200] loss: 0.930810506939888\n",
      "[46, 300] loss: 0.9135077273845673\n",
      "[47, 100] loss: 0.9168615978956223\n",
      "[47, 200] loss: 0.9090380907058716\n",
      "[47, 300] loss: 0.9031304389238357\n",
      "[48, 100] loss: 0.9095195269584656\n",
      "[48, 200] loss: 0.9167464077472687\n",
      "[48, 300] loss: 0.9021899616718292\n",
      "[49, 100] loss: 0.9153205114603042\n",
      "[49, 200] loss: 0.9080960285663605\n",
      "[49, 300] loss: 0.8929220664501191\n",
      "[50, 100] loss: 0.9033548134565353\n",
      "[50, 200] loss: 0.933698770403862\n",
      "[50, 300] loss: 0.9222219276428223\n",
      "[51, 100] loss: 0.8968031430244445\n",
      "[51, 200] loss: 0.9120329022407532\n",
      "[51, 300] loss: 0.9111137408018112\n",
      "[52, 100] loss: 0.9334075635671616\n",
      "[52, 200] loss: 0.901980590224266\n",
      "[52, 300] loss: 0.915585623383522\n",
      "[53, 100] loss: 0.92958860039711\n",
      "[53, 200] loss: 0.9152812939882279\n",
      "[53, 300] loss: 0.9022492676973343\n",
      "[54, 100] loss: 0.9153040832281113\n",
      "[54, 200] loss: 0.9085904610157013\n",
      "[54, 300] loss: 0.9245591592788697\n",
      "[55, 100] loss: 0.9248889249563217\n",
      "[55, 200] loss: 0.897668668627739\n",
      "[55, 300] loss: 0.9210240930318833\n",
      "[56, 100] loss: 0.9055680507421493\n",
      "[56, 200] loss: 0.9008866900205612\n",
      "[56, 300] loss: 0.9039339035749435\n",
      "[57, 100] loss: 0.9056168830394745\n",
      "[57, 200] loss: 0.9231520068645477\n",
      "[57, 300] loss: 0.9095332610607147\n",
      "[58, 100] loss: 0.8899861866235733\n",
      "[58, 200] loss: 0.9050625509023666\n",
      "[58, 300] loss: 0.9028226917982102\n",
      "[59, 100] loss: 0.905993692278862\n",
      "[59, 200] loss: 0.9119619691371917\n",
      "[59, 300] loss: 0.8865491265058517\n",
      "[60, 100] loss: 0.8902024841308593\n",
      "[60, 200] loss: 0.9054362118244171\n",
      "[60, 300] loss: 0.8995048785209656\n",
      "[61, 100] loss: 0.8848642975091934\n",
      "[61, 200] loss: 0.8872659534215928\n",
      "[61, 300] loss: 0.9023161464929581\n",
      "[62, 100] loss: 0.9190193665027618\n",
      "[62, 200] loss: 0.9123982840776443\n",
      "[62, 300] loss: 0.8968304938077927\n",
      "[63, 100] loss: 0.9080480688810348\n",
      "[63, 200] loss: 0.9065706527233124\n",
      "[63, 300] loss: 0.9171427589654922\n",
      "[64, 100] loss: 0.911229112148285\n",
      "[64, 200] loss: 0.9224627190828323\n",
      "[64, 300] loss: 0.9130437892675399\n",
      "[65, 100] loss: 0.9155766683816909\n",
      "[65, 200] loss: 0.8997235709428787\n",
      "[65, 300] loss: 0.9069326269626617\n",
      "[66, 100] loss: 0.9101313185691834\n",
      "[66, 200] loss: 0.895908784866333\n",
      "[66, 300] loss: 0.8960103833675385\n",
      "[67, 100] loss: 0.9233650267124176\n",
      "[67, 200] loss: 0.9122947263717651\n",
      "[67, 300] loss: 0.910010061264038\n",
      "[68, 100] loss: 0.8973228162527085\n",
      "[68, 200] loss: 0.908194990158081\n",
      "[68, 300] loss: 0.9105741518735886\n",
      "[69, 100] loss: 0.8832506710290908\n",
      "[69, 200] loss: 0.880085232257843\n",
      "[69, 300] loss: 0.8988703501224518\n",
      "[70, 100] loss: 0.8934650504589081\n",
      "[70, 200] loss: 0.9028522652387619\n",
      "[70, 300] loss: 0.893938679099083\n",
      "[71, 100] loss: 0.8966170865297317\n",
      "[71, 200] loss: 0.9139639902114868\n",
      "[71, 300] loss: 0.8970596015453338\n",
      "[72, 100] loss: 0.8976142203807831\n",
      "[72, 200] loss: 0.9019985044002533\n",
      "[72, 300] loss: 0.9074448347091675\n",
      "[73, 100] loss: 0.8938042140007019\n",
      "[73, 200] loss: 0.9074044173955917\n",
      "[73, 300] loss: 0.8977471512556076\n",
      "[74, 100] loss: 0.9064564085006714\n",
      "[74, 200] loss: 0.8968374091386795\n",
      "[74, 300] loss: 0.8667446160316468\n",
      "[75, 100] loss: 0.9171974313259125\n",
      "[75, 200] loss: 0.9087390398979187\n",
      "[75, 300] loss: 0.8981771719455719\n",
      "[76, 100] loss: 0.884451254606247\n",
      "[76, 200] loss: 0.8867422419786454\n",
      "[76, 300] loss: 0.8915667873620987\n",
      "[77, 100] loss: 0.8871556705236435\n",
      "[77, 200] loss: 0.9008145797252655\n",
      "[77, 300] loss: 0.9239199686050416\n",
      "[78, 100] loss: 0.9158214962482453\n",
      "[78, 200] loss: 0.8885362637043\n",
      "[78, 300] loss: 0.9185224211215973\n",
      "[79, 100] loss: 0.8964248025417327\n",
      "[79, 200] loss: 0.9055981492996216\n",
      "[79, 300] loss: 0.8880182147026062\n",
      "[80, 100] loss: 0.9063999098539353\n",
      "[80, 200] loss: 0.8900388020277024\n",
      "[80, 300] loss: 0.9006660330295563\n",
      "[81, 100] loss: 0.9079369336366654\n",
      "[81, 200] loss: 0.912419850230217\n",
      "[81, 300] loss: 0.9029563641548157\n",
      "[82, 100] loss: 0.8816895252466201\n",
      "[82, 200] loss: 0.9076215779781341\n",
      "[82, 300] loss: 0.8979120463132858\n",
      "[83, 100] loss: 0.891211569905281\n",
      "[83, 200] loss: 0.8903848659992218\n",
      "[83, 300] loss: 0.8867706090211869\n",
      "[84, 100] loss: 0.9067741054296493\n",
      "[84, 200] loss: 0.8756055480241776\n",
      "[84, 300] loss: 0.8940593647956848\n",
      "[85, 100] loss: 0.891331622004509\n",
      "[85, 200] loss: 0.8863888269662857\n",
      "[85, 300] loss: 0.8989997959136963\n",
      "[86, 100] loss: 0.9129063594341278\n",
      "[86, 200] loss: 0.9098873728513718\n",
      "[86, 300] loss: 0.9014624869823455\n",
      "[87, 100] loss: 0.8973127818107605\n",
      "[87, 200] loss: 0.8983552777767181\n",
      "[87, 300] loss: 0.894358731508255\n",
      "[88, 100] loss: 0.8894520020484924\n",
      "[88, 200] loss: 0.9059777021408081\n",
      "[88, 300] loss: 0.9010122734308242\n",
      "[89, 100] loss: 0.8912388342618942\n",
      "[89, 200] loss: 0.8888529169559479\n",
      "[89, 300] loss: 0.9078981220722199\n",
      "[90, 100] loss: 0.894810820221901\n",
      "[90, 200] loss: 0.9050011545419693\n",
      "[90, 300] loss: 0.8899914461374283\n",
      "[91, 100] loss: 0.8914771473407745\n",
      "[91, 200] loss: 0.8888261836767196\n",
      "[91, 300] loss: 0.8856584268808365\n",
      "[92, 100] loss: 0.904961987733841\n",
      "[92, 200] loss: 0.8962399637699128\n",
      "[92, 300] loss: 0.8997929161787033\n",
      "[93, 100] loss: 0.9187324345111847\n",
      "[93, 200] loss: 0.8999665462970734\n",
      "[93, 300] loss: 0.9003487366437912\n",
      "[94, 100] loss: 0.8755752485990524\n",
      "[94, 200] loss: 0.868223501443863\n",
      "[94, 300] loss: 0.8953610575199127\n",
      "[95, 100] loss: 0.8984809046983719\n",
      "[95, 200] loss: 0.8838476514816285\n",
      "[95, 300] loss: 0.885369843840599\n",
      "[96, 100] loss: 0.8986976975202561\n",
      "[96, 200] loss: 0.9001595306396485\n",
      "[96, 300] loss: 0.9009869545698166\n",
      "[97, 100] loss: 0.8801650255918503\n",
      "[97, 200] loss: 0.8748661559820176\n",
      "[97, 300] loss: 0.8961240303516388\n",
      "[98, 100] loss: 0.9139345741271973\n",
      "[98, 200] loss: 0.8867458987236023\n",
      "[98, 300] loss: 0.8847227102518082\n",
      "[99, 100] loss: 0.9020815163850784\n",
      "[99, 200] loss: 0.8983458518981934\n",
      "[99, 300] loss: 0.9047848373651505\n",
      "[100, 100] loss: 0.8846756023168564\n",
      "[100, 200] loss: 0.8928006505966186\n",
      "[100, 300] loss: 0.8914717453718185\n",
      "Training model 14 in the ensemble...\n",
      "[1, 100] loss: 2.1474670350551603\n",
      "[1, 200] loss: 1.9775282514095307\n",
      "[1, 300] loss: 1.8966966485977172\n",
      "[2, 100] loss: 1.8496986818313599\n",
      "[2, 200] loss: 1.8293242585659026\n",
      "[2, 300] loss: 1.788774311542511\n",
      "[3, 100] loss: 1.732428299188614\n",
      "[3, 200] loss: 1.7101566147804261\n",
      "[3, 300] loss: 1.6892289233207702\n",
      "[4, 100] loss: 1.6264508378505707\n",
      "[4, 200] loss: 1.5753708374500275\n",
      "[4, 300] loss: 1.5417892372608184\n",
      "[5, 100] loss: 1.4472839736938476\n",
      "[5, 200] loss: 1.4004522109031676\n",
      "[5, 300] loss: 1.3695846092700958\n",
      "[6, 100] loss: 1.2954257154464721\n",
      "[6, 200] loss: 1.2641847014427186\n",
      "[6, 300] loss: 1.2423152816295624\n",
      "[7, 100] loss: 1.1960313081741334\n",
      "[7, 200] loss: 1.1439341044425964\n",
      "[7, 300] loss: 1.1540384423732757\n",
      "[8, 100] loss: 1.1203794461488723\n",
      "[8, 200] loss: 1.093992145061493\n",
      "[8, 300] loss: 1.079120376110077\n",
      "[9, 100] loss: 1.0489754152297974\n",
      "[9, 200] loss: 1.0689278584718704\n",
      "[9, 300] loss: 1.0533045548200608\n",
      "[10, 100] loss: 1.0264670050144196\n",
      "[10, 200] loss: 1.0164053523540497\n",
      "[10, 300] loss: 1.0072213840484618\n",
      "[11, 100] loss: 1.0173302072286605\n",
      "[11, 200] loss: 0.9980434876680374\n",
      "[11, 300] loss: 0.9962464839220047\n",
      "[12, 100] loss: 0.989128103852272\n",
      "[12, 200] loss: 0.9766410368680954\n",
      "[12, 300] loss: 0.9730093520879746\n",
      "[13, 100] loss: 0.9807872515916825\n",
      "[13, 200] loss: 0.9724360114336014\n",
      "[13, 300] loss: 0.94699531853199\n",
      "[14, 100] loss: 0.9698550277948379\n",
      "[14, 200] loss: 0.9749023133516311\n",
      "[14, 300] loss: 0.9535548043251038\n",
      "[15, 100] loss: 0.9625689882040024\n",
      "[15, 200] loss: 0.9359535586833954\n",
      "[15, 300] loss: 0.959145245552063\n",
      "[16, 100] loss: 0.9550060117244721\n",
      "[16, 200] loss: 0.9309197759628296\n",
      "[16, 300] loss: 0.9442110735177994\n",
      "[17, 100] loss: 0.9419620406627655\n",
      "[17, 200] loss: 0.9297671246528626\n",
      "[17, 300] loss: 0.9423806864023209\n",
      "[18, 100] loss: 0.9572977936267852\n",
      "[18, 200] loss: 0.9464862561225891\n",
      "[18, 300] loss: 0.9477342158555985\n",
      "[19, 100] loss: 0.9394728344678879\n",
      "[19, 200] loss: 0.9200210934877395\n",
      "[19, 300] loss: 0.9187699753046036\n",
      "[20, 100] loss: 0.9334003961086274\n",
      "[20, 200] loss: 0.9261456215381623\n",
      "[20, 300] loss: 0.9372577589750289\n",
      "[21, 100] loss: 0.9090955418348312\n",
      "[21, 200] loss: 0.9269154691696166\n",
      "[21, 300] loss: 0.9071879786252975\n",
      "[22, 100] loss: 0.9287626570463181\n",
      "[22, 200] loss: 0.9267622697353363\n",
      "[22, 300] loss: 0.9365931367874145\n",
      "[23, 100] loss: 0.9399642640352249\n",
      "[23, 200] loss: 0.9101334565877914\n",
      "[23, 300] loss: 0.9320144945383072\n",
      "[24, 100] loss: 0.9180071103572846\n",
      "[24, 200] loss: 0.941633808016777\n",
      "[24, 300] loss: 0.9223937153816223\n",
      "[25, 100] loss: 0.9176668077707291\n",
      "[25, 200] loss: 0.9211846953630447\n",
      "[25, 300] loss: 0.9119924038648606\n",
      "[26, 100] loss: 0.9050585114955902\n",
      "[26, 200] loss: 0.9161745274066925\n",
      "[26, 300] loss: 0.9302354687452317\n",
      "[27, 100] loss: 0.9377707314491271\n",
      "[27, 200] loss: 0.9146657115221024\n",
      "[27, 300] loss: 0.9225323462486267\n",
      "[28, 100] loss: 0.9180499118566513\n",
      "[28, 200] loss: 0.8959582704305649\n",
      "[28, 300] loss: 0.9294682013988494\n",
      "[29, 100] loss: 0.9182749998569488\n",
      "[29, 200] loss: 0.8896326321363449\n",
      "[29, 300] loss: 0.9170996588468552\n",
      "[30, 100] loss: 0.935043044090271\n",
      "[30, 200] loss: 0.9233350247144699\n",
      "[30, 300] loss: 0.9167641967535018\n",
      "[31, 100] loss: 0.9144401788711548\n",
      "[31, 200] loss: 0.9185669112205506\n",
      "[31, 300] loss: 0.9251904422044754\n",
      "[32, 100] loss: 0.9238420361280442\n",
      "[32, 200] loss: 0.9056134849786759\n",
      "[32, 300] loss: 0.9194399505853653\n",
      "[33, 100] loss: 0.918217367529869\n",
      "[33, 200] loss: 0.9158766448497773\n",
      "[33, 300] loss: 0.9020172601938248\n",
      "[34, 100] loss: 0.9158146721124649\n",
      "[34, 200] loss: 0.9134909379482269\n",
      "[34, 300] loss: 0.9215523469448089\n",
      "[35, 100] loss: 0.9060711246728897\n",
      "[35, 200] loss: 0.9053896290063858\n",
      "[35, 300] loss: 0.9201311349868775\n",
      "[36, 100] loss: 0.9079605948925018\n",
      "[36, 200] loss: 0.9169927179813385\n",
      "[36, 300] loss: 0.9246515583992004\n",
      "[37, 100] loss: 0.9126501089334488\n",
      "[37, 200] loss: 0.9347923541069031\n",
      "[37, 300] loss: 0.9172378170490265\n",
      "[38, 100] loss: 0.9047652906179429\n",
      "[38, 200] loss: 0.9237431252002716\n",
      "[38, 300] loss: 0.9133737599849701\n",
      "[39, 100] loss: 0.9135083597898483\n",
      "[39, 200] loss: 0.891069374680519\n",
      "[39, 300] loss: 0.9138612347841263\n",
      "[40, 100] loss: 0.9462599676847457\n",
      "[40, 200] loss: 0.9156623339653015\n",
      "[40, 300] loss: 0.9099887496232987\n",
      "[41, 100] loss: 0.9252041149139404\n",
      "[41, 200] loss: 0.9016887587308884\n",
      "[41, 300] loss: 0.9010380631685257\n",
      "[42, 100] loss: 0.9327230155467987\n",
      "[42, 200] loss: 0.9103286117315292\n",
      "[42, 300] loss: 0.920939267873764\n",
      "[43, 100] loss: 0.9101407372951508\n",
      "[43, 200] loss: 0.9096761882305145\n",
      "[43, 300] loss: 0.9014539194107055\n",
      "[44, 100] loss: 0.9240470707416535\n",
      "[44, 200] loss: 0.9189336317777633\n",
      "[44, 300] loss: 0.9039371550083161\n",
      "[45, 100] loss: 0.882215039730072\n",
      "[45, 200] loss: 0.8877251821756363\n",
      "[45, 300] loss: 0.9028973591327667\n",
      "[46, 100] loss: 0.9115410786867142\n",
      "[46, 200] loss: 0.9075495660305023\n",
      "[46, 300] loss: 0.9253938120603561\n",
      "[47, 100] loss: 0.9025899159908295\n",
      "[47, 200] loss: 0.9049035769701004\n",
      "[47, 300] loss: 0.9138953799009323\n",
      "[48, 100] loss: 0.8873517495393753\n",
      "[48, 200] loss: 0.8933822780847549\n",
      "[48, 300] loss: 0.9267720317840576\n",
      "[49, 100] loss: 0.8980058234930038\n",
      "[49, 200] loss: 0.8923919188976288\n",
      "[49, 300] loss: 0.9090947633981705\n",
      "[50, 100] loss: 0.9218994891643524\n",
      "[50, 200] loss: 0.9025045347213745\n",
      "[50, 300] loss: 0.9020089417695999\n",
      "[51, 100] loss: 0.9121517586708069\n",
      "[51, 200] loss: 0.8976307827234268\n",
      "[51, 300] loss: 0.9028693777322769\n",
      "[52, 100] loss: 0.9135468655824661\n",
      "[52, 200] loss: 0.9000975847244262\n",
      "[52, 300] loss: 0.9004874223470688\n",
      "[53, 100] loss: 0.884618638753891\n",
      "[53, 200] loss: 0.8733257246017456\n",
      "[53, 300] loss: 0.8892283284664154\n",
      "[54, 100] loss: 0.9025525206327438\n",
      "[54, 200] loss: 0.882464702129364\n",
      "[54, 300] loss: 0.8962074726819992\n",
      "[55, 100] loss: 0.9046936911344529\n",
      "[55, 200] loss: 0.9083330404758453\n",
      "[55, 300] loss: 0.8911553293466568\n",
      "[56, 100] loss: 0.8890331727266312\n",
      "[56, 200] loss: 0.8962729376554489\n",
      "[56, 300] loss: 0.9065790855884552\n",
      "[57, 100] loss: 0.8983686649799347\n",
      "[57, 200] loss: 0.8857522469758987\n",
      "[57, 300] loss: 0.8780711090564728\n",
      "[58, 100] loss: 0.9070988517999649\n",
      "[58, 200] loss: 0.878660249710083\n",
      "[58, 300] loss: 0.8991566562652588\n",
      "[59, 100] loss: 0.9057886320352554\n",
      "[59, 200] loss: 0.9138839793205261\n",
      "[59, 300] loss: 0.9127491068840027\n",
      "[60, 100] loss: 0.9071409839391709\n",
      "[60, 200] loss: 0.8956215369701386\n",
      "[60, 300] loss: 0.9000151240825653\n",
      "[61, 100] loss: 0.9113991940021515\n",
      "[61, 200] loss: 0.8960484737157821\n",
      "[61, 300] loss: 0.9087719595432282\n",
      "[62, 100] loss: 0.887463019490242\n",
      "[62, 200] loss: 0.9059270244836807\n",
      "[62, 300] loss: 0.8907055205106735\n",
      "[63, 100] loss: 0.9070884555578231\n",
      "[63, 200] loss: 0.9010278314352036\n",
      "[63, 300] loss: 0.8956627839803696\n",
      "[64, 100] loss: 0.8956414473056793\n",
      "[64, 200] loss: 0.8984071099758149\n",
      "[64, 300] loss: 0.8685872501134873\n",
      "[65, 100] loss: 0.8991787403821945\n",
      "[65, 200] loss: 0.8819796627759934\n",
      "[65, 300] loss: 0.8916629135608674\n",
      "[66, 100] loss: 0.893062202334404\n",
      "[66, 200] loss: 0.8892883741855622\n",
      "[66, 300] loss: 0.9088111138343811\n",
      "[67, 100] loss: 0.895013934969902\n",
      "[67, 200] loss: 0.8961140251159668\n",
      "[67, 300] loss: 0.8549730867147446\n",
      "[68, 100] loss: 0.8999318724870682\n",
      "[68, 200] loss: 0.9042147499322891\n",
      "[68, 300] loss: 0.8917484420537949\n",
      "[69, 100] loss: 0.8931492704153061\n",
      "[69, 200] loss: 0.8787853360176087\n",
      "[69, 300] loss: 0.8938850003480912\n",
      "[70, 100] loss: 0.8893680733442306\n",
      "[70, 200] loss: 0.900850932598114\n",
      "[70, 300] loss: 0.8733982223272324\n",
      "[71, 100] loss: 0.8876689440011978\n",
      "[71, 200] loss: 0.8951960468292236\n",
      "[71, 300] loss: 0.8815608811378479\n",
      "[72, 100] loss: 0.8991167712211608\n",
      "[72, 200] loss: 0.9104943311214447\n",
      "[72, 300] loss: 0.9013897067308426\n",
      "[73, 100] loss: 0.8935165548324585\n",
      "[73, 200] loss: 0.8782361596822739\n",
      "[73, 300] loss: 0.885435249209404\n",
      "[74, 100] loss: 0.8820609301328659\n",
      "[74, 200] loss: 0.8981548464298248\n",
      "[74, 300] loss: 0.8998951065540314\n",
      "[75, 100] loss: 0.9048645067214965\n",
      "[75, 200] loss: 0.8981980562210083\n",
      "[75, 300] loss: 0.9095395565032959\n",
      "[76, 100] loss: 0.9062644171714783\n",
      "[76, 200] loss: 0.9058125638961791\n",
      "[76, 300] loss: 0.9006286579370498\n",
      "[77, 100] loss: 0.9043396067619324\n",
      "[77, 200] loss: 0.9019943445920944\n",
      "[77, 300] loss: 0.8906918591260911\n",
      "[78, 100] loss: 0.8892862957715988\n",
      "[78, 200] loss: 0.8788964319229126\n",
      "[78, 300] loss: 0.8970696491003036\n",
      "[79, 100] loss: 0.9073476761579513\n",
      "[79, 200] loss: 0.8759393721818924\n",
      "[79, 300] loss: 0.9080819243192673\n",
      "[80, 100] loss: 0.9001707303524017\n",
      "[80, 200] loss: 0.8936178308725357\n",
      "[80, 300] loss: 0.8996681469678879\n",
      "[81, 100] loss: 0.8946418625116348\n",
      "[81, 200] loss: 0.8805043327808381\n",
      "[81, 300] loss: 0.9119296675920486\n",
      "[82, 100] loss: 0.8854854542016983\n",
      "[82, 200] loss: 0.8876275873184204\n",
      "[82, 300] loss: 0.8844327634572983\n",
      "[83, 100] loss: 0.8996695405244828\n",
      "[83, 200] loss: 0.8987808299064636\n",
      "[83, 300] loss: 0.8969468361139298\n",
      "[84, 100] loss: 0.884534130692482\n",
      "[84, 200] loss: 0.8870148247480393\n",
      "[84, 300] loss: 0.8961006444692612\n",
      "[85, 100] loss: 0.8898657995462418\n",
      "[85, 200] loss: 0.9087368410825729\n",
      "[85, 300] loss: 0.8942085361480713\n",
      "[86, 100] loss: 0.90045767724514\n",
      "[86, 200] loss: 0.8929608714580536\n",
      "[86, 300] loss: 0.893330083489418\n",
      "[87, 100] loss: 0.8923446923494339\n",
      "[87, 200] loss: 0.9023463243246078\n",
      "[87, 300] loss: 0.8720696514844894\n",
      "[88, 100] loss: 0.875678573846817\n",
      "[88, 200] loss: 0.8824227583408356\n",
      "[88, 300] loss: 0.8878293734788895\n",
      "[89, 100] loss: 0.8952372944355012\n",
      "[89, 200] loss: 0.8977902990579605\n",
      "[89, 300] loss: 0.8939349532127381\n",
      "[90, 100] loss: 0.8848020768165589\n",
      "[90, 200] loss: 0.9044245368242264\n",
      "[90, 300] loss: 0.8986492520570755\n",
      "[91, 100] loss: 0.9013614821434021\n",
      "[91, 200] loss: 0.8956819069385529\n",
      "[91, 300] loss: 0.894144036769867\n",
      "[92, 100] loss: 0.8926169687509536\n",
      "[92, 200] loss: 0.880965034365654\n",
      "[92, 300] loss: 0.8873306697607041\n",
      "[93, 100] loss: 0.8899772089719772\n",
      "[93, 200] loss: 0.8868898510932922\n",
      "[93, 300] loss: 0.8946109753847122\n",
      "[94, 100] loss: 0.889198426604271\n",
      "[94, 200] loss: 0.8751033228635788\n",
      "[94, 300] loss: 0.8947689145803451\n",
      "[95, 100] loss: 0.880857965350151\n",
      "[95, 200] loss: 0.8917431753873825\n",
      "[95, 300] loss: 0.8878919714689255\n",
      "[96, 100] loss: 0.8937222325801849\n",
      "[96, 200] loss: 0.8877146172523499\n",
      "[96, 300] loss: 0.9033550125360489\n",
      "[97, 100] loss: 0.8869691371917725\n",
      "[97, 200] loss: 0.895343873500824\n",
      "[97, 300] loss: 0.8950072139501571\n",
      "[98, 100] loss: 0.8956435495615005\n",
      "[98, 200] loss: 0.8852271872758866\n",
      "[98, 300] loss: 0.888058465719223\n",
      "[99, 100] loss: 0.8689046901464462\n",
      "[99, 200] loss: 0.8950498676300049\n",
      "[99, 300] loss: 0.8841055256128311\n",
      "[100, 100] loss: 0.8918547397851944\n",
      "[100, 200] loss: 0.8654660826921463\n",
      "[100, 300] loss: 0.8941039723157883\n",
      "Training model 15 in the ensemble...\n",
      "[1, 100] loss: 2.1439063787460326\n",
      "[1, 200] loss: 1.9992065513134003\n",
      "[1, 300] loss: 1.9442559373378754\n",
      "[2, 100] loss: 1.8998416340351105\n",
      "[2, 200] loss: 1.8754457223415375\n",
      "[2, 300] loss: 1.8428201246261597\n",
      "[3, 100] loss: 1.809346648454666\n",
      "[3, 200] loss: 1.803089063167572\n",
      "[3, 300] loss: 1.7896541452407837\n",
      "[4, 100] loss: 1.760638531446457\n",
      "[4, 200] loss: 1.7556902515888213\n",
      "[4, 300] loss: 1.7377209103107452\n",
      "[5, 100] loss: 1.7129763567447662\n",
      "[5, 200] loss: 1.7134004473686217\n",
      "[5, 300] loss: 1.6978193974494935\n",
      "[6, 100] loss: 1.6600113856792449\n",
      "[6, 200] loss: 1.6838286018371582\n",
      "[6, 300] loss: 1.6588968789577485\n",
      "[7, 100] loss: 1.6450711476802826\n",
      "[7, 200] loss: 1.6382439136505127\n",
      "[7, 300] loss: 1.6290175902843476\n",
      "[8, 100] loss: 1.6223521947860717\n",
      "[8, 200] loss: 1.6137448632717133\n",
      "[8, 300] loss: 1.596447058916092\n",
      "[9, 100] loss: 1.5869895255565643\n",
      "[9, 200] loss: 1.565053986310959\n",
      "[9, 300] loss: 1.5765687763690948\n",
      "[10, 100] loss: 1.5456997299194335\n",
      "[10, 200] loss: 1.5487868642807008\n",
      "[10, 300] loss: 1.5480039274692536\n",
      "[11, 100] loss: 1.508652262687683\n",
      "[11, 200] loss: 1.5179989540576935\n",
      "[11, 300] loss: 1.4972563290596008\n",
      "[12, 100] loss: 1.4987943506240844\n",
      "[12, 200] loss: 1.4686130940914155\n",
      "[12, 300] loss: 1.454426429271698\n",
      "[13, 100] loss: 1.454320307970047\n",
      "[13, 200] loss: 1.4484034585952759\n",
      "[13, 300] loss: 1.4356896114349365\n",
      "[14, 100] loss: 1.4058732295036316\n",
      "[14, 200] loss: 1.3876147973537445\n",
      "[14, 300] loss: 1.388935194015503\n",
      "[15, 100] loss: 1.3829691421985626\n",
      "[15, 200] loss: 1.3655093610286713\n",
      "[15, 300] loss: 1.3667726266384124\n",
      "[16, 100] loss: 1.3488920187950135\n",
      "[16, 200] loss: 1.345890611410141\n",
      "[16, 300] loss: 1.3128694784641266\n",
      "[17, 100] loss: 1.3231585359573363\n",
      "[17, 200] loss: 1.2919040381908418\n",
      "[17, 300] loss: 1.2808476984500885\n",
      "[18, 100] loss: 1.2713755655288697\n",
      "[18, 200] loss: 1.2666682851314546\n",
      "[18, 300] loss: 1.263581600189209\n",
      "[19, 100] loss: 1.2283032417297364\n",
      "[19, 200] loss: 1.223078589439392\n",
      "[19, 300] loss: 1.203419109582901\n",
      "[20, 100] loss: 1.2014548480510712\n",
      "[20, 200] loss: 1.203780471086502\n",
      "[20, 300] loss: 1.1981435930728912\n",
      "[21, 100] loss: 1.1637567293643951\n",
      "[21, 200] loss: 1.1456061655282974\n",
      "[21, 300] loss: 1.155652149915695\n",
      "[22, 100] loss: 1.1364425647258758\n",
      "[22, 200] loss: 1.1248633581399918\n",
      "[22, 300] loss: 1.1149729299545288\n",
      "[23, 100] loss: 1.0724246436357499\n",
      "[23, 200] loss: 1.0782533526420592\n",
      "[23, 300] loss: 1.076452938914299\n",
      "[24, 100] loss: 1.0596129888296126\n",
      "[24, 200] loss: 1.0490225976705552\n",
      "[24, 300] loss: 1.052446881532669\n",
      "[25, 100] loss: 1.0285762244462966\n",
      "[25, 200] loss: 1.0196426594257355\n",
      "[25, 300] loss: 1.0018950819969177\n",
      "[26, 100] loss: 1.0302521657943726\n",
      "[26, 200] loss: 1.000381982922554\n",
      "[26, 300] loss: 0.99853600025177\n",
      "[27, 100] loss: 1.0129529809951783\n",
      "[27, 200] loss: 0.9855721455812454\n",
      "[27, 300] loss: 0.9801328241825104\n",
      "[28, 100] loss: 0.9824529320001603\n",
      "[28, 200] loss: 0.9556094282865524\n",
      "[28, 300] loss: 0.9625830733776093\n",
      "[29, 100] loss: 0.9606863749027252\n",
      "[29, 200] loss: 0.965113782286644\n",
      "[29, 300] loss: 0.9595527797937393\n",
      "[30, 100] loss: 0.9457632720470428\n",
      "[30, 200] loss: 0.9361758720874787\n",
      "[30, 300] loss: 0.9453435230255127\n",
      "[31, 100] loss: 0.9322068417072296\n",
      "[31, 200] loss: 0.9395709156990051\n",
      "[31, 300] loss: 0.9343062323331833\n",
      "[32, 100] loss: 0.9210659474134445\n",
      "[32, 200] loss: 0.9237862193584442\n",
      "[32, 300] loss: 0.9530820047855377\n",
      "[33, 100] loss: 0.9228398352861404\n",
      "[33, 200] loss: 0.9097846949100494\n",
      "[33, 300] loss: 0.9251166623830795\n",
      "[34, 100] loss: 0.9136037904024125\n",
      "[34, 200] loss: 0.9221847504377365\n",
      "[34, 300] loss: 0.9213449960947037\n",
      "[35, 100] loss: 0.9170663237571717\n",
      "[35, 200] loss: 0.897118536233902\n",
      "[35, 300] loss: 0.911250326037407\n",
      "[36, 100] loss: 0.904594361782074\n",
      "[36, 200] loss: 0.9234693849086761\n",
      "[36, 300] loss: 0.9356446921825409\n",
      "[37, 100] loss: 0.903507804274559\n",
      "[37, 200] loss: 0.9176414430141449\n",
      "[37, 300] loss: 0.9044039541482926\n",
      "[38, 100] loss: 0.9398464971780777\n",
      "[38, 200] loss: 0.9200328224897385\n",
      "[38, 300] loss: 0.9168216115236283\n",
      "[39, 100] loss: 0.9109739768505096\n",
      "[39, 200] loss: 0.90609912276268\n",
      "[39, 300] loss: 0.88202492415905\n",
      "[40, 100] loss: 0.8985822153091431\n",
      "[40, 200] loss: 0.8979784452915192\n",
      "[40, 300] loss: 0.9015489029884338\n",
      "[41, 100] loss: 0.8976816487312317\n",
      "[41, 200] loss: 0.8906050491333007\n",
      "[41, 300] loss: 0.9167800176143647\n",
      "[42, 100] loss: 0.9016623610258102\n",
      "[42, 200] loss: 0.8879521316289902\n",
      "[42, 300] loss: 0.9126604634523392\n",
      "[43, 100] loss: 0.8993320369720459\n",
      "[43, 200] loss: 0.9282251465320587\n",
      "[43, 300] loss: 0.898670061826706\n",
      "[44, 100] loss: 0.9178540223836898\n",
      "[44, 200] loss: 0.890411964058876\n",
      "[44, 300] loss: 0.9120806175470352\n",
      "[45, 100] loss: 0.8995361632108688\n",
      "[45, 200] loss: 0.8770289587974548\n",
      "[45, 300] loss: 0.8789454716444015\n",
      "[46, 100] loss: 0.913165014386177\n",
      "[46, 200] loss: 0.9147805041074752\n",
      "[46, 300] loss: 0.9029311239719391\n",
      "[47, 100] loss: 0.896754480600357\n",
      "[47, 200] loss: 0.8862524944543838\n",
      "[47, 300] loss: 0.9057961654663086\n",
      "[48, 100] loss: 0.9015480822324753\n",
      "[48, 200] loss: 0.9000998878479004\n",
      "[48, 300] loss: 0.923415088057518\n",
      "[49, 100] loss: 0.8887937742471695\n",
      "[49, 200] loss: 0.9077231657505035\n",
      "[49, 300] loss: 0.9120811080932617\n",
      "[50, 100] loss: 0.8913091653585434\n",
      "[50, 200] loss: 0.8901915657520294\n",
      "[50, 300] loss: 0.8976656413078308\n",
      "[51, 100] loss: 0.903612174987793\n",
      "[51, 200] loss: 0.9028804451227188\n",
      "[51, 300] loss: 0.9033518379926682\n",
      "[52, 100] loss: 0.9210653412342071\n",
      "[52, 200] loss: 0.9039523822069168\n",
      "[52, 300] loss: 0.9134520292282104\n",
      "[53, 100] loss: 0.8881960362195969\n",
      "[53, 200] loss: 0.8953692770004272\n",
      "[53, 300] loss: 0.8736605077981949\n",
      "[54, 100] loss: 0.8919626480340958\n",
      "[54, 200] loss: 0.9063907140493392\n",
      "[54, 300] loss: 0.8794145494699478\n",
      "[55, 100] loss: 0.8981670093536377\n",
      "[55, 200] loss: 0.8896883994340896\n",
      "[55, 300] loss: 0.8975144577026367\n",
      "[56, 100] loss: 0.9039415228366852\n",
      "[56, 200] loss: 0.8882320457696915\n",
      "[56, 300] loss: 0.8930304557085037\n",
      "[57, 100] loss: 0.8956616455316544\n",
      "[57, 200] loss: 0.8880325782299042\n",
      "[57, 300] loss: 0.9028665751218796\n",
      "[58, 100] loss: 0.9106231164932251\n",
      "[58, 200] loss: 0.9002109187841415\n",
      "[58, 300] loss: 0.8980964279174805\n",
      "[59, 100] loss: 0.8945731204748154\n",
      "[59, 200] loss: 0.8844423151016235\n",
      "[59, 300] loss: 0.9076475721597671\n",
      "[60, 100] loss: 0.8861482620239258\n",
      "[60, 200] loss: 0.8805293989181519\n",
      "[60, 300] loss: 0.8982709443569183\n",
      "[61, 100] loss: 0.9006422060728073\n",
      "[61, 200] loss: 0.8889402520656585\n",
      "[61, 300] loss: 0.8846434235572815\n",
      "[62, 100] loss: 0.9003789961338043\n",
      "[62, 200] loss: 0.8994808572530747\n",
      "[62, 300] loss: 0.8859422171115875\n",
      "[63, 100] loss: 0.8781648468971253\n",
      "[63, 200] loss: 0.8698230350017547\n",
      "[63, 300] loss: 0.8798253607749938\n",
      "[64, 100] loss: 0.8738792884349823\n",
      "[64, 200] loss: 0.8995333242416382\n",
      "[64, 300] loss: 0.8850770342350006\n",
      "[65, 100] loss: 0.8826600700616837\n",
      "[65, 200] loss: 0.8769733554124832\n",
      "[65, 300] loss: 0.9018211168050766\n",
      "[66, 100] loss: 0.8785731101036072\n",
      "[66, 200] loss: 0.8748201304674148\n",
      "[66, 300] loss: 0.8981583815813065\n",
      "[67, 100] loss: 0.8854177349805832\n",
      "[67, 200] loss: 0.8899481892585754\n",
      "[67, 300] loss: 0.8789230608940124\n",
      "[68, 100] loss: 0.8815933644771576\n",
      "[68, 200] loss: 0.9082355880737305\n",
      "[68, 300] loss: 0.8924021816253662\n",
      "[69, 100] loss: 0.8848477005958557\n",
      "[69, 200] loss: 0.9030961322784424\n",
      "[69, 300] loss: 0.8760143029689789\n",
      "[70, 100] loss: 0.8650313895940781\n",
      "[70, 200] loss: 0.8889304506778717\n",
      "[70, 300] loss: 0.8785281836986542\n",
      "[71, 100] loss: 0.9020096373558044\n",
      "[71, 200] loss: 0.8810694366693497\n",
      "[71, 300] loss: 0.9042805331945419\n",
      "[72, 100] loss: 0.8939310449361801\n",
      "[72, 200] loss: 0.8906229454278946\n",
      "[72, 300] loss: 0.8798025864362716\n",
      "[73, 100] loss: 0.8889690560102462\n",
      "[73, 200] loss: 0.9033111608028412\n",
      "[73, 300] loss: 0.8883178317546845\n",
      "[74, 100] loss: 0.8892336267232895\n",
      "[74, 200] loss: 0.8857414895296096\n",
      "[74, 300] loss: 0.8885550689697266\n",
      "[75, 100] loss: 0.8734489637613296\n",
      "[75, 200] loss: 0.8908320093154907\n",
      "[75, 300] loss: 0.899179562330246\n",
      "[76, 100] loss: 0.890064383149147\n",
      "[76, 200] loss: 0.8831435859203338\n",
      "[76, 300] loss: 0.8626608037948609\n",
      "[77, 100] loss: 0.8841350275278091\n",
      "[77, 200] loss: 0.8699194139242172\n",
      "[77, 300] loss: 0.8658785408735276\n",
      "[78, 100] loss: 0.8904526156187057\n",
      "[78, 200] loss: 0.8793628829717636\n",
      "[78, 300] loss: 0.8791182655096054\n",
      "[79, 100] loss: 0.8872439223527908\n",
      "[79, 200] loss: 0.8898701870441437\n",
      "[79, 300] loss: 0.8751936107873917\n",
      "[80, 100] loss: 0.8630836147069931\n",
      "[80, 200] loss: 0.8926415425539017\n",
      "[80, 300] loss: 0.8760863429307938\n",
      "[81, 100] loss: 0.8946279180049896\n",
      "[81, 200] loss: 0.873020446896553\n",
      "[81, 300] loss: 0.8772756475210189\n",
      "[82, 100] loss: 0.8907687222957611\n",
      "[82, 200] loss: 0.8927085888385773\n",
      "[82, 300] loss: 0.8890808922052383\n",
      "[83, 100] loss: 0.887004371881485\n",
      "[83, 200] loss: 0.887863609790802\n",
      "[83, 300] loss: 0.8786814111471176\n",
      "[84, 100] loss: 0.895371008515358\n",
      "[84, 200] loss: 0.8794512182474137\n",
      "[84, 300] loss: 0.8892063784599304\n",
      "[85, 100] loss: 0.8905027037858964\n",
      "[85, 200] loss: 0.8788187158107758\n",
      "[85, 300] loss: 0.8941747224330903\n",
      "[86, 100] loss: 0.874064514040947\n",
      "[86, 200] loss: 0.8794099754095077\n",
      "[86, 300] loss: 0.8900561809539795\n",
      "[87, 100] loss: 0.898915690779686\n",
      "[87, 200] loss: 0.8922470617294311\n",
      "[87, 300] loss: 0.8850820678472519\n",
      "[88, 100] loss: 0.866906498670578\n",
      "[88, 200] loss: 0.8933353942632675\n",
      "[88, 300] loss: 0.8816282731294632\n",
      "[89, 100] loss: 0.8872504097223282\n",
      "[89, 200] loss: 0.8913213586807252\n",
      "[89, 300] loss: 0.8855827462673187\n",
      "[90, 100] loss: 0.8981014728546143\n",
      "[90, 200] loss: 0.9020697838068008\n",
      "[90, 300] loss: 0.8796180832386017\n",
      "[91, 100] loss: 0.8813648456335068\n",
      "[91, 200] loss: 0.8910808128118515\n",
      "[91, 300] loss: 0.8690508425235748\n",
      "[92, 100] loss: 0.8906857371330261\n",
      "[92, 200] loss: 0.9098851674795151\n",
      "[92, 300] loss: 0.8962201350927352\n",
      "[93, 100] loss: 0.8830409014225006\n",
      "[93, 200] loss: 0.9076310408115387\n",
      "[93, 300] loss: 0.9058475238084793\n",
      "[94, 100] loss: 0.8652726835012436\n",
      "[94, 200] loss: 0.8961963176727294\n",
      "[94, 300] loss: 0.9032478326559067\n",
      "[95, 100] loss: 0.9070263350009918\n",
      "[95, 200] loss: 0.8852171075344085\n",
      "[95, 300] loss: 0.8985827380418777\n",
      "[96, 100] loss: 0.8883691036701202\n",
      "[96, 200] loss: 0.8824645841121673\n",
      "[96, 300] loss: 0.8948438197374344\n",
      "[97, 100] loss: 0.8945416796207428\n",
      "[97, 200] loss: 0.89790065407753\n",
      "[97, 300] loss: 0.8981531542539597\n",
      "[98, 100] loss: 0.8819246530532837\n",
      "[98, 200] loss: 0.8796392637491226\n",
      "[98, 300] loss: 0.8740525424480439\n",
      "[99, 100] loss: 0.8718787902593612\n",
      "[99, 200] loss: 0.8960186052322388\n",
      "[99, 300] loss: 0.8865061032772065\n",
      "[100, 100] loss: 0.8926652258634568\n",
      "[100, 200] loss: 0.884690934419632\n",
      "[100, 300] loss: 0.8979019051790238\n"
     ]
    }
   ],
   "source": [
    "# Call the train_with_ensemble function to train the ensemble models\n",
    "ensemble_models, ensemble_weights, loss_list = train_with_ensemble(\n",
    "    trainloader, testloader, net, criterion, optimizer, epochs, n_ensemble\n",
    ")\n",
    "\n",
    "# Data to save\n",
    "final_ensemble_data = {\n",
    "    'models': ensemble_models,  # List of model state dictionaries\n",
    "    'weights': ensemble_weights  # Corresponding weights for each model\n",
    "}\n",
    "\n",
    "# Save the final ensemble\n",
    "torch.save(final_ensemble_data, 'final_ensemble.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c9c9b12-34e6-4385-8912-d8398d883266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy: 72.48\n"
     ]
    }
   ],
   "source": [
    "# Load the saved ensemble\n",
    "saved_ensemble_data = torch.load('final_ensemble.pth.tar')\n",
    "loaded_models = [ResNet_cifar10().to(device) for _ in saved_ensemble_data['models']]\n",
    "\n",
    "# Load each state dictionary into a new model instance\n",
    "for model, state_dict in zip(loaded_models, saved_ensemble_data['models']):\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "# Evaluate the loaded ensemble\n",
    "ensemble_accuracy = evaluate_ensemble(testloader, loaded_models, saved_ensemble_data['weights'])\n",
    "\n",
    "print(f\"Ensemble Accuracy: {ensemble_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
